# Libc Heap

{{#include ../../banners/hacktricks-training.md}}

## Misingi ya Heap

Heap ni mahali ambapo programu inaweza kuhifadhi data inapoitisha kazi kama **`malloc`**, `calloc`... Zaidi ya hayo, wakati memory hii haitakumiwi tena, inarejeshwa kwa kuitisha kazi ya **`free`**.

Kama ilivyoonyeshwa, iko tu baada ya sehemu binary kupakiwa katika memory (angalia sehemu `[heap]`):

<figure><img src="../../images/image (1241).png" alt=""><figcaption></figcaption></figure>

### Ugawaji wa Chunk za Msingi

Wakati data inapoombwa kuhifadhiwa kwenye heap, sehemu ya heap inatengwa kwa ajili yake. Sehemu hii itakuwa ndani ya bin na ni data iliyohitajika + nafasi ya headers za bin + offset ya minimum bin size pekee itakayohifadhiwa kwa chunk. Lengo ni kutenga memory ndogo iwezekanavyo bila kuifanya iwe ngumu kupata kila chunk. Kwa hili, metadata chunk information inatumika kujua wapi kila chunk iliyotumika/imeachwa iko.

Kuna njia mbalimbali za kutenga nafasi kulingana na bin inayotumiwa, lakini mbinu ya jumla ni kama ifuatavyo:

- Programu inaanza kwa kuomba kiasi fulani cha memory.
- Ikiwa kwenye orodha ya chunks kuna mmoja ambaye ni mkubwa vya kutosha kutosheleza ombi, huyo atatumika.
- Hii inaweza hata kumaanisha sehemu ya chunk inayopatikana itatumika kwa ombi hili na kilicho baki kitatolewa kwenye orodha ya chunks.
- Ikiwa hakuna chunk inayopatikana kwenye orodha lakini bado kuna nafasi kwenye allocated heap memory, heap manager itaumba chunk mpya.
- Ikiwa hakuna nafasi ya kutosha kwenye heap kuunda chunk mpya, heap manager atamuomba kernel kupanua memory iliyotengwa kwa heap kisha kutumia memory hiyo kuunda chunk mpya.
- Ikiwa yote yanashindwa, `malloc` inarudisha null.

Kumbuka kwamba ikiwa requested **memory inavuka threshold**, **`mmap`** itatumika ku-map memory iliyohitajika.

## Arenas

Katika programu za **multithreaded**, heap manager lazima aepuke **race conditions** zinazoweza kusababisha crashes. Awali, hili lilifanywa kwa kutumia **global mutex** kuhakikisha kuwa thread moja tu ndilo linaweza kufikia heap kwa wakati mmoja, lakini hili lilisababisha **performance issues** kutokana na bottleneck inayosababishwa na mutex.

Ili kushughulikia hili, ptmalloc2 heap allocator ilileta "arenas," ambapo **arena kila moja** inafanya kazi kama **heap tofauti** yenye muundo wake wa data na **mutex**, kuruhusu thread nyingi kufanya operesheni za heap bila kuvurugiana, mradi tu zinatumia arenas tofauti.

Arena ya chaguo-msingi "main" inashughulikia operesheni za heap kwa programu za single-threaded. Wakati **threads mpya** zinaongezwa, heap manager huwagawia **secondary arenas** kupunguza contention. Kwanza inajaribu kuhusisha kila thread mpya na arena isiyotumika, ikizuia kuunda mpya endapo inahitajika, hadi kikomo cha mara 2 za idadi ya CPU cores kwa mifumo 32-bit na mara 8 kwa mifumo 64-bit. Mara kikomo kinapofikiwa, **threads lazima washare arenas**, jambo linaloweza kusababisha contention.

Tofauti na main arena, ambayo hupanuka kwa kutumia system call `brk`, secondary arenas huunda "subheaps" kwa kutumia `mmap` na `mprotect` kuiga tabia ya heap, kuruhusu unyumbufu katika kusimamia memory kwa operesheni za multithreaded.

### Subheaps

Subheaps hutoa akiba ya memory kwa secondary arenas katika programu za multithreaded, zikiruhusu kukua na kusimamia maeneo yao ya heap tofauti na heap ya awali. Hapa ni jinsi subheaps zinavyotofautiana na heap ya awali na jinsi zinavyofanya kazi:

1. Initial Heap vs. Subheaps:
- Initial heap iko moja kwa moja baada ya binary ya programu katika memory, na hupanuka kwa kutumia system call `sbrk`.
- Subheaps, zinazotumiwa na secondary arenas, huundwa kupitia `mmap`, system call inayomap memory eneo maalum.
2. Memory Reservation with `mmap`:
- Wakati heap manager anaumba subheap, anahifadhi block kubwa ya memory kupitia `mmap`. Hifadhi hii haitegemezi kupeleka memory mara moja; inaonyesha tu eneo ambalo mchakato mwingine wa system au allocations haipaswi kutumia.
- Kwa default, ukubwa uliohifadhiwa kwa subheap ni 1 MB kwa michakato ya 32-bit na 64 MB kwa michakato ya 64-bit.
3. Gradual Expansion with `mprotect`:
- Eneo la memory lililohifadhiwa awali limewekwa kama `PROT_NONE`, ikimaanisha kernel haitaji kutenga physical memory kwa nafasi hii bado.
- Ili "kukua" subheap, heap manager anatumia `mprotect` kubadilisha ruhusa za ukurasa kutoka `PROT_NONE` hadi `PROT_READ | PROT_WRITE`, kuhimiza kernel kutenga physical memory kwa addresses zilizohifadhiwa hapo awali. Mbinu hii hatua kwa hatua inaruhusu subheap kupanuka kadri inavyohitajika.
- Mara subheap nzima itakapochukuliwa, heap manager huunda subheap mpya kuendelea na allocation.

### heap_info <a href="#heap_info" id="heap_info"></a>

Struct hii inahifadhi taarifa zinazofaa za heap. Zaidi ya hayo, heap memory inaweza isiwe endelevu baada ya allocations zaidi; struct hii pia itahifadhi taarifa hiyo.
```c
// From https://github.com/bminor/glibc/blob/a07e000e82cb71238259e674529c37c12dc7d423/malloc/arena.c#L837

typedef struct _heap_info
{
mstate ar_ptr; /* Arena for this heap. */
struct _heap_info *prev; /* Previous heap. */
size_t size;   /* Current size in bytes. */
size_t mprotect_size; /* Size in bytes that has been mprotected
PROT_READ|PROT_WRITE.  */
size_t pagesize; /* Page size used when allocating the arena.  */
/* Make sure the following data is properly aligned, particularly
that sizeof (heap_info) + 2 * SIZE_SZ is a multiple of
MALLOC_ALIGNMENT. */
char pad[-3 * SIZE_SZ & MALLOC_ALIGN_MASK];
} heap_info;
```
### malloc_state

**Kila heap** (main arena au arenas za thread nyingine) ina **`malloc_state` structure.**\
Ni muhimu kutambua kwamba muundo wa **main arena `malloc_state`** ni **kigezo cha kimataifa (global variable) katika libc** (kwa hivyo uko katika nafasi ya kumbukumbu ya libc).\
Katika kesi za miundo ya **`malloc_state`** za heaps za thread, ziko **ndani ya "heap" ya thread hiyo mwenyewe**.

Kuna mambo kadhaa ya kuvutia ya kuzingatia kutoka katika muundo huu (tazama C code hapa chini):

- `__libc_lock_define (, mutex);` Iko ili kuhakikisha muundo huu kutoka heap unafikiwa na thread 1 kwa wakati
- Flags:

- ```c
#define NONCONTIGUOUS_BIT     (2U)

#define contiguous(M)          (((M)->flags & NONCONTIGUOUS_BIT) == 0)
#define noncontiguous(M)       (((M)->flags & NONCONTIGUOUS_BIT) != 0)
#define set_noncontiguous(M)   ((M)->flags |= NONCONTIGUOUS_BIT)
#define set_contiguous(M)      ((M)->flags &= ~NONCONTIGUOUS_BIT)
```

- The `mchunkptr bins[NBINS * 2 - 2];` ina **pointers** kwa **first and last chunks** za small, large na unsorted **bins** (the -2 ni kwa sababu index 0 haitumiwi)
- Kwa hivyo, the **first chunk** ya hizi bins itakuwa na **backwards pointer to this structure** na the **last chunk** ya hizi bins itakuwa na **forward pointer** kwa muundo huu. Which basically means that if you can l**eak these addresses in the main arena** you will have a pointer to the structure in the **libc**.
- The structs `struct malloc_state *next;` and `struct malloc_state *next_free;` ni linked lists za arenas
- The `top` chunk ni chunk ya mwisho, ambayo kwa msingi ni **nafasi yote iliyobaki ya heap**. Once the top chunk is "empty", the heap imepitwa kabisa na inahitaji kuomba nafasi zaidi.
- The `last reminder` chunk hutokana na kesi ambapo exact size chunk haipatikani na kwa hivyo chunk kubwa imegawanywa, sehemu ya pointer iliyobaki inawekwa hapa.
```c
// From https://github.com/bminor/glibc/blob/a07e000e82cb71238259e674529c37c12dc7d423/malloc/malloc.c#L1812

struct malloc_state
{
/* Serialize access.  */
__libc_lock_define (, mutex);

/* Flags (formerly in max_fast).  */
int flags;

/* Set if the fastbin chunks contain recently inserted free blocks.  */
/* Note this is a bool but not all targets support atomics on booleans.  */
int have_fastchunks;

/* Fastbins */
mfastbinptr fastbinsY[NFASTBINS];

/* Base of the topmost chunk -- not otherwise kept in a bin */
mchunkptr top;

/* The remainder from the most recent split of a small request */
mchunkptr last_remainder;

/* Normal bins packed as described above */
mchunkptr bins[NBINS * 2 - 2];

/* Bitmap of bins */
unsigned int binmap[BINMAPSIZE];

/* Linked list */
struct malloc_state *next;

/* Linked list for free arenas.  Access to this field is serialized
by free_list_lock in arena.c.  */
struct malloc_state *next_free;

/* Number of threads attached to this arena.  0 if the arena is on
the free list.  Access to this field is serialized by
free_list_lock in arena.c.  */
INTERNAL_SIZE_T attached_threads;

/* Memory allocated from the system in this arena.  */
INTERNAL_SIZE_T system_mem;
INTERNAL_SIZE_T max_system_mem;
};
```
### malloc_chunk

Muundo huu unawakilisha kipande maalum cha kumbukumbu. Sehemu mbalimbali zina maana tofauti kwa vipande vilivyotengwa na visivyotengwa.
```c
// https://github.com/bminor/glibc/blob/master/malloc/malloc.c
struct malloc_chunk {
INTERNAL_SIZE_T      mchunk_prev_size;  /* Size of previous chunk, if it is free. */
INTERNAL_SIZE_T      mchunk_size;       /* Size in bytes, including overhead. */
struct malloc_chunk* fd;                /* double links -- used only if this chunk is free. */
struct malloc_chunk* bk;
/* Only used for large blocks: pointer to next larger size.  */
struct malloc_chunk* fd_nextsize; /* double links -- used only if this chunk is free. */
struct malloc_chunk* bk_nextsize;
};

typedef struct malloc_chunk* mchunkptr;
```
Kama ilivyotajwa hapo awali, vipande hivi pia vina metadata, iliyoonyeshwa vizuri katika picha hii:

<figure><img src="../../images/image (1242).png" alt=""><figcaption><p><a href="https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png">https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png</a></p></figcaption></figure>

Metadata kawaida ni 0x08B ikionyesha ukubwa wa chunk ya sasa kwa kutumia bits 3 za mwisho kuonyesha:

- `A`: Ikiwa 1 inatoka kwenye subheap, ikiwa 0 iko katika main arena
- `M`: Ikiwa 1, chunk hii ni sehemu ya nafasi iliyotengwa kwa mmap na si sehemu ya heap
- `P`: Ikiwa 1, chunk ya awali inatumika

Kisha, nafasi ya user data, na hatimaye 0x08B kuonyesha ukubwa wa chunk ya awali wakati chunk iko available (au kuhifadhi user data wakati imeallocated).

Zaidi ya hayo, wakati available, user data hutumika pia kuhifadhi data zifuatazo:

- **`fd`**: Kiashiria (pointer) kwa chunk inayofuata
- **`bk`**: Kiashiria (pointer) kwa chunk ya awali
- **`fd_nextsize`**: Kiashiria (pointer) kwa chunk ya kwanza kwenye list ambayo ni ndogo kuliko yake
- **`bk_nextsize`:** Kiashiria (pointer) kwa chunk ya kwanza kwenye list ambayo ni kubwa kuliko yake

<figure><img src="../../images/image (1243).png" alt=""><figcaption><p><a href="https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png">https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png</a></p></figcaption></figure>

> [!TIP]
> Angalia jinsi kuunganisha list kwa njia hii kunazuia haja ya kuwa na array ambapo kila chunk mmoja mmoja anasajiliwa.

### Chunk Pointers

Wakati malloc inapotumika, pointer kwenye content inayoweza kuandikwa inarudishwa (mara tu baada ya headers), hata hivyo, wakati unadhibiti chunks, unahitaji pointer kwa mwanzo wa headers (metadata).\
Kwa mabadiliko haya, functions hizi zinatumika:
```c
// https://github.com/bminor/glibc/blob/master/malloc/malloc.c

/* Convert a chunk address to a user mem pointer without correcting the tag.  */
#define chunk2mem(p) ((void*)((char*)(p) + CHUNK_HDR_SZ))

/* Convert a user mem pointer to a chunk address and extract the right tag.  */
#define mem2chunk(mem) ((mchunkptr)tag_at (((char*)(mem) - CHUNK_HDR_SZ)))

/* The smallest possible chunk */
#define MIN_CHUNK_SIZE        (offsetof(struct malloc_chunk, fd_nextsize))

/* The smallest size we can malloc is an aligned minimal chunk */

#define MINSIZE  \
(unsigned long)(((MIN_CHUNK_SIZE+MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK))
```
### Ulinganifu & ukubwa wa chini

pointer kwa chunk na `0x0f` lazima ziwe 0.
```c
// From https://github.com/bminor/glibc/blob/a07e000e82cb71238259e674529c37c12dc7d423/sysdeps/generic/malloc-size.h#L61
#define MALLOC_ALIGN_MASK (MALLOC_ALIGNMENT - 1)

// https://github.com/bminor/glibc/blob/a07e000e82cb71238259e674529c37c12dc7d423/sysdeps/i386/malloc-alignment.h
#define MALLOC_ALIGNMENT 16


// https://github.com/bminor/glibc/blob/master/malloc/malloc.c
/* Check if m has acceptable alignment */
#define aligned_OK(m)  (((unsigned long)(m) & MALLOC_ALIGN_MASK) == 0)

#define misaligned_chunk(p) \
((uintptr_t)(MALLOC_ALIGNMENT == CHUNK_HDR_SZ ? (p) : chunk2mem (p)) \
& MALLOC_ALIGN_MASK)


/* pad request bytes into a usable size -- internal version */
/* Note: This must be a macro that evaluates to a compile time constant
if passed a literal constant.  */
#define request2size(req)                                         \
(((req) + SIZE_SZ + MALLOC_ALIGN_MASK < MINSIZE)  ?             \
MINSIZE :                                                      \
((req) + SIZE_SZ + MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK)

/* Check if REQ overflows when padded and aligned and if the resulting
value is less than PTRDIFF_T.  Returns the requested size or
MINSIZE in case the value is less than MINSIZE, or 0 if any of the
previous checks fail.  */
static inline size_t
checked_request2size (size_t req) __nonnull (1)
{
if (__glibc_unlikely (req > PTRDIFF_MAX))
return 0;

/* When using tagged memory, we cannot share the end of the user
block with the header for the next chunk, so ensure that we
allocate blocks that are rounded up to the granule size.  Take
care not to overflow from close to MAX_SIZE_T to a small
number.  Ideally, this would be part of request2size(), but that
must be a macro that produces a compile time constant if passed
a constant literal.  */
if (__glibc_unlikely (mtag_enabled))
{
/* Ensure this is not evaluated if !mtag_enabled, see gcc PR 99551.  */
asm ("");

req = (req + (__MTAG_GRANULE_SIZE - 1)) &
~(size_t)(__MTAG_GRANULE_SIZE - 1);
}

return request2size (req);
}
```
Kumbuka kwamba kwa kuhesabu jumla ya nafasi inayohitajika, `SIZE_SZ` inaongezwa mara 1 tu kwa sababu uwanja wa `prev_size` unaweza kutumika kuhifadhi data; kwa hivyo inahitajika tu kichwa cha awali.

### Pata data za Chunk na badilisha metadata

Funsi hizi hufanya kazi kwa kupokea pointer kwa chunk na ni muhimu kwa kuangalia/kuseti metadata:

- Kagua chunk flags
```c
// From https://github.com/bminor/glibc/blob/master/malloc/malloc.c


/* size field is or'ed with PREV_INUSE when previous adjacent chunk in use */
#define PREV_INUSE 0x1

/* extract inuse bit of previous chunk */
#define prev_inuse(p)       ((p)->mchunk_size & PREV_INUSE)


/* size field is or'ed with IS_MMAPPED if the chunk was obtained with mmap() */
#define IS_MMAPPED 0x2

/* check for mmap()'ed chunk */
#define chunk_is_mmapped(p) ((p)->mchunk_size & IS_MMAPPED)


/* size field is or'ed with NON_MAIN_ARENA if the chunk was obtained
from a non-main arena.  This is only set immediately before handing
the chunk to the user, if necessary.  */
#define NON_MAIN_ARENA 0x4

/* Check for chunk from main arena.  */
#define chunk_main_arena(p) (((p)->mchunk_size & NON_MAIN_ARENA) == 0)

/* Mark a chunk as not being on the main arena.  */
#define set_non_main_arena(p) ((p)->mchunk_size |= NON_MAIN_ARENA)
```
- Ukubwa na pointers kwa chunks nyingine
```c
/*
Bits to mask off when extracting size

Note: IS_MMAPPED is intentionally not masked off from size field in
macros for which mmapped chunks should never be seen. This should
cause helpful core dumps to occur if it is tried by accident by
people extending or adapting this malloc.
*/
#define SIZE_BITS (PREV_INUSE | IS_MMAPPED | NON_MAIN_ARENA)

/* Get size, ignoring use bits */
#define chunksize(p) (chunksize_nomask (p) & ~(SIZE_BITS))

/* Like chunksize, but do not mask SIZE_BITS.  */
#define chunksize_nomask(p)         ((p)->mchunk_size)

/* Ptr to next physical malloc_chunk. */
#define next_chunk(p) ((mchunkptr) (((char *) (p)) + chunksize (p)))

/* Size of the chunk below P.  Only valid if !prev_inuse (P).  */
#define prev_size(p) ((p)->mchunk_prev_size)

/* Set the size of the chunk below P.  Only valid if !prev_inuse (P).  */
#define set_prev_size(p, sz) ((p)->mchunk_prev_size = (sz))

/* Ptr to previous physical malloc_chunk.  Only valid if !prev_inuse (P).  */
#define prev_chunk(p) ((mchunkptr) (((char *) (p)) - prev_size (p)))

/* Treat space at ptr + offset as a chunk */
#define chunk_at_offset(p, s)  ((mchunkptr) (((char *) (p)) + (s)))
```
- Bit ya tatizo
```c
/* extract p's inuse bit */
#define inuse(p)							      \
((((mchunkptr) (((char *) (p)) + chunksize (p)))->mchunk_size) & PREV_INUSE)

/* set/clear chunk as being inuse without otherwise disturbing */
#define set_inuse(p)							      \
((mchunkptr) (((char *) (p)) + chunksize (p)))->mchunk_size |= PREV_INUSE

#define clear_inuse(p)							      \
((mchunkptr) (((char *) (p)) + chunksize (p)))->mchunk_size &= ~(PREV_INUSE)


/* check/set/clear inuse bits in known places */
#define inuse_bit_at_offset(p, s)					      \
(((mchunkptr) (((char *) (p)) + (s)))->mchunk_size & PREV_INUSE)

#define set_inuse_bit_at_offset(p, s)					      \
(((mchunkptr) (((char *) (p)) + (s)))->mchunk_size |= PREV_INUSE)

#define clear_inuse_bit_at_offset(p, s)					      \
(((mchunkptr) (((char *) (p)) + (s)))->mchunk_size &= ~(PREV_INUSE))
```
- Weka head na footer (wanapotumika nambari za chunk)
```c
/* Set size at head, without disturbing its use bit */
#define set_head_size(p, s)  ((p)->mchunk_size = (((p)->mchunk_size & SIZE_BITS) | (s)))

/* Set size/use field */
#define set_head(p, s)       ((p)->mchunk_size = (s))

/* Set size at footer (only when chunk is not in use) */
#define set_foot(p, s)       (((mchunkptr) ((char *) (p) + (s)))->mchunk_prev_size = (s))
```
Pata ukubwa wa data halisi inayoweza kutumika ndani ya chunk
```c
#pragma GCC poison mchunk_size
#pragma GCC poison mchunk_prev_size

/* This is the size of the real usable data in the chunk.  Not valid for
dumped heap chunks.  */
#define memsize(p)                                                    \
(__MTAG_GRANULE_SIZE > SIZE_SZ && __glibc_unlikely (mtag_enabled) ? \
chunksize (p) - CHUNK_HDR_SZ :                                    \
chunksize (p) - CHUNK_HDR_SZ + (chunk_is_mmapped (p) ? 0 : SIZE_SZ))

/* If memory tagging is enabled the layout changes to accommodate the granule
size, this is wasteful for small allocations so not done by default.
Both the chunk header and user data has to be granule aligned.  */
_Static_assert (__MTAG_GRANULE_SIZE <= CHUNK_HDR_SZ,
"memory tagging is not supported with large granule.");

static __always_inline void *
tag_new_usable (void *ptr)
{
if (__glibc_unlikely (mtag_enabled) && ptr)
{
mchunkptr cp = mem2chunk(ptr);
ptr = __libc_mtag_tag_region (__libc_mtag_new_tag (ptr), memsize (cp));
}
return ptr;
}
```
## Examples

### Quick Heap Example

Mfano mfupi wa heap kutoka [https://guyinatuxedo.github.io/25-heap/index.html](https://guyinatuxedo.github.io/25-heap/index.html) lakini kwa arm64:
```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

void main(void)
{
char *ptr;
ptr = malloc(0x10);
strcpy(ptr, "panda");
}
```
Weka breakpoint mwishoni mwa main function na tuone wapi taarifa zilihifadhiwa:

<figure><img src="../../images/image (1239).png" alt=""><figcaption></figcaption></figure>

Inawezekana kuona kuwa string panda ilihifadhiwa kwenye `0xaaaaaaac12a0` (ambayo ilikuwa address iliyotolewa kama jibu na malloc ndani ya `x0`). Ukikagua 0x10 bytes kabla yake, inaonekana kuwa `0x0` inaonyesha kuwa **previous chunk is not used** (length 0) na urefu wa chunk hii ni `0x21`.

Sehemu za ziada zilizohifadhiwa (0x21-0x10=0x11) zinatokana na **added headers** (0x10) na 0x1 haitomaanishi ilihifadhiwa 0x21B, bali ni kwamba bits 3 za mwisho za urefu wa header ya sasa zina maana maalum. Kwa kuwa urefu daima umewekwa 16-byte aligned (katika mashine za 64bits), bits hizi kawaida hazitatumika kwenye namba ya urefu.
```
0x1:     Previous in Use     - Specifies that the chunk before it in memory is in use
0x2:     Is MMAPPED          - Specifies that the chunk was obtained with mmap()
0x4:     Non Main Arena      - Specifies that the chunk was obtained from outside of the main arena
```
### Mfano wa Multithreading

<details>

<summary>Multithread</summary>
```c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>
#include <sys/types.h>


void* threadFuncMalloc(void* arg) {
printf("Hello from thread 1\n");
char* addr = (char*) malloc(1000);
printf("After malloc and before free in thread 1\n");
free(addr);
printf("After free in thread 1\n");
}

void* threadFuncNoMalloc(void* arg) {
printf("Hello from thread 2\n");
}


int main() {
pthread_t t1;
void* s;
int ret;
char* addr;

printf("Before creating thread 1\n");
getchar();
ret = pthread_create(&t1, NULL, threadFuncMalloc, NULL);
getchar();

printf("Before creating thread 2\n");
ret = pthread_create(&t1, NULL, threadFuncNoMalloc, NULL);

printf("Before exit\n");
getchar();

return 0;
}
```
</details>

Debugging mfano uliopita, inawezekana kuona kwamba mwanzoni kuna arena 1 tu:

<figure><img src="../../images/image (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

Kisha, baada ya kuitwa thread ya kwanza, ile inayoitwa malloc, arena mpya inaundwa:

<figure><img src="../../images/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

na ndani yake kuna chunks kadhaa zinazopatikana:

<figure><img src="../../images/image (2) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## Bins & Memory Allocations/Frees

Angalia ni bins gani na jinsi zinavyopangwa, pamoja na jinsi memory inavyotengwa (allocated) na kufutwa (freed) katika:


{{#ref}}
bins-and-memory-allocations.md
{{#endref}}

## Ukaguzi wa Usalama wa Heap Functions

Functions zinazohusiana na heap zitafanya ukaguzi fulani kabla ya kutekeleza vitendo vyazo ili kujaribu kuhakikisha heap haikuharibika:


{{#ref}}
heap-memory-functions/heap-functions-security-checks.md
{{#endref}}

## Masomo ya Kesi

Chunguza primitives maalum za allocator zinazotokana na bugs za ulimwengu halisi:

{{#ref}}
virtualbox-slirp-nat-packet-heap-exploitation.md
{{#endref}}

## Marejeo

- [https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/](https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/)
- [https://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/](https://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/)


{{#include ../../banners/hacktricks-training.md}}
