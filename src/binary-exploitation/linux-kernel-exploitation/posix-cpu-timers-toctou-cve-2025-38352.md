# POSIX CPU Timers TOCTOU race (CVE-2025-38352)

{{#include ../../banners/hacktricks-training.md}}

Esta página documenta una condición de carrera TOCTOU en Linux/Android POSIX CPU timers que puede corromper el estado del timer y provocar el crash del kernel, y bajo ciertas circunstancias poder dirigirse hacia privilege escalation.

- Componente afectado: kernel/time/posix-cpu-timers.c
- Primitiva: expiry vs deletion race under task exit
- Sensible a la configuración: CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n (IRQ-context expiry path)

Breve resumen interno (relevant for exploitation)
- Tres relojes CPU gestionan la contabilidad de timers vía cpu_clock_sample():
- CPUCLOCK_PROF: utime + stime
- CPUCLOCK_VIRT: utime only
- CPUCLOCK_SCHED: task_sched_runtime()
- La creación del timer vincula un timer a una task/pid e inicializa los timerqueue nodes:
```c
static int posix_cpu_timer_create(struct k_itimer *new_timer) {
struct pid *pid;
rcu_read_lock();
pid = pid_for_clock(new_timer->it_clock, false);
if (!pid) { rcu_read_unlock(); return -EINVAL; }
new_timer->kclock = &clock_posix_cpu;
timerqueue_init(&new_timer->it.cpu.node);
new_timer->it.cpu.pid = get_pid(pid);
rcu_read_unlock();
return 0;
}
```
- Arming inserta en una per-base timerqueue y puede actualizar la next-expiry cache:
```c
static void arm_timer(struct k_itimer *timer, struct task_struct *p) {
struct posix_cputimer_base *base = timer_base(timer, p);
struct cpu_timer *ctmr = &timer->it.cpu;
u64 newexp = cpu_timer_getexpires(ctmr);
if (!cpu_timer_enqueue(&base->tqhead, ctmr)) return;
if (newexp < base->nextevt) base->nextevt = newexp;
}
```
- La ruta rápida evita el procesamiento costoso a menos que las expiraciones en caché indiquen una posible activación:
```c
static inline bool fastpath_timer_check(struct task_struct *tsk) {
struct posix_cputimers *pct = &tsk->posix_cputimers;
if (!expiry_cache_is_inactive(pct)) {
u64 samples[CPUCLOCK_MAX];
task_sample_cputime(tsk, samples);
if (task_cputimers_expired(samples, pct))
return true;
}
return false;
}
```
- Expiración recopila timers expirados, los marca como disparados, los mueve fuera de la cola; la entrega real se pospone:
```c
#define MAX_COLLECTED 20
static u64 collect_timerqueue(struct timerqueue_head *head,
struct list_head *firing, u64 now) {
struct timerqueue_node *next; int i = 0;
while ((next = timerqueue_getnext(head))) {
struct cpu_timer *ctmr = container_of(next, struct cpu_timer, node);
u64 expires = cpu_timer_getexpires(ctmr);
if (++i == MAX_COLLECTED || now < expires) return expires;
ctmr->firing = 1;                           // critical state
rcu_assign_pointer(ctmr->handling, current);
cpu_timer_dequeue(ctmr);
list_add_tail(&ctmr->elist, firing);
}
return U64_MAX;
}
```
Dos modos de procesamiento de expiración
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK=y: la expiración se pospone vía task_work en la tarea objetivo
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n: la expiración se maneja directamente en el contexto IRQ
```c
void run_posix_cpu_timers(void) {
struct task_struct *tsk = current;
__run_posix_cpu_timers(tsk);
}
#ifdef CONFIG_POSIX_CPU_TIMERS_TASK_WORK
static inline void __run_posix_cpu_timers(struct task_struct *tsk) {
if (WARN_ON_ONCE(tsk->posix_cputimers_work.scheduled)) return;
tsk->posix_cputimers_work.scheduled = true;
task_work_add(tsk, &tsk->posix_cputimers_work.work, TWA_RESUME);
}
#else
static inline void __run_posix_cpu_timers(struct task_struct *tsk) {
lockdep_posixtimer_enter();
handle_posix_cpu_timers(tsk);                  // IRQ-context path
lockdep_posixtimer_exit();
}
#endif
```
En la ruta IRQ-context, la firing list se procesa fuera de sighand
```c
static void handle_posix_cpu_timers(struct task_struct *tsk) {
struct k_itimer *timer, *next; unsigned long flags, start;
LIST_HEAD(firing);
if (!lock_task_sighand(tsk, &flags)) return;   // may fail on exit
do {
start = READ_ONCE(jiffies); barrier();
check_thread_timers(tsk, &firing);
check_process_timers(tsk, &firing);
} while (!posix_cpu_timers_enable_work(tsk, start));
unlock_task_sighand(tsk, &flags);              // race window opens here
list_for_each_entry_safe(timer, next, &firing, it.cpu.elist) {
int cpu_firing;
spin_lock(&timer->it_lock);
list_del_init(&timer->it.cpu.elist);
cpu_firing = timer->it.cpu.firing;         // read then reset
timer->it.cpu.firing = 0;
if (likely(cpu_firing >= 0)) cpu_timer_fire(timer);
rcu_assign_pointer(timer->it.cpu.handling, NULL);
spin_unlock(&timer->it_lock);
}
}
```
Causa raíz: TOCTOU entre la expiración en tiempo de IRQ y la eliminación concurrente durante la salida de la tarea
Precondiciones
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK está deshabilitado (se usa la ruta IRQ)
- La tarea objetivo está saliendo pero no ha sido completamente recolectada
- Otro hilo llama concurrentemente a posix_cpu_timer_del() para el mismo timer

Secuencia
1) update_process_times() dispara run_posix_cpu_timers() en contexto IRQ para la tarea que está saliendo.
2) collect_timerqueue() asigna ctmr->firing = 1 y mueve el timer a la lista temporal de firing.
3) handle_posix_cpu_timers() suelta sighand vía unlock_task_sighand() para entregar timers fuera del lock.
4) Inmediatamente después del unlock, la tarea que está saliendo puede ser recolectada; un hilo paralelo ejecuta posix_cpu_timer_del().
5) En esta ventana, posix_cpu_timer_del() puede fallar al adquirir el estado vía cpu_timer_task_rcu()/lock_task_sighand() y por tanto omitir la protección normal en vuelo que comprueba timer->it.cpu.firing. La eliminación procede como si timer->it.cpu.firing no estuviera establecido, corrompiendo el estado mientras se maneja la expiración, lo que conduce a bloqueos/UB.

Por qué el modo TASK_WORK es seguro por diseño
- Con CONFIG_POSIX_CPU_TIMERS_TASK_WORK=y, la expiración se difiere a task_work; exit_task_work se ejecuta antes de exit_notify, por lo que no ocurre la superposición en tiempo de IRQ con la recolección.
- Aun así, si la tarea ya está saliendo, task_work_add() falla; condicionar en exit_state hace que ambos modos sean consistentes.

Solución (Android common kernel) y justificación
- Agregar un retorno temprano si la tarea actual está saliendo, condicionando todo el procesamiento:
```c
// kernel/time/posix-cpu-timers.c (Android common kernel commit 157f357d50b5038e5eaad0b2b438f923ac40afeb)
if (tsk->exit_state)
return;
```
- Esto evita entrar en handle_posix_cpu_timers() para tareas que están saliendo, eliminando la ventana donde posix_cpu_timer_del() podría perder it.cpu.firing y competir con el procesamiento de expiración.

Impacto
- La corrupción de memoria del kernel de las estructuras de timer durante expiración/eliminación concurrente puede causar fallos inmediatos (DoS) y es una primitiva potente hacia la escalada de privilegios debido a las oportunidades de manipulación arbitraria del estado del kernel.

Activación del bug (condiciones seguras y reproducibles)
Build/config
- Asegúrate de CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n y usa un kernel sin la corrección de gating de exit_state.

Estrategia en tiempo de ejecución
- Apunta a un hilo que esté a punto de salir y adjunta un CPU timer a él (por hilo o reloj a nivel de proceso):
- Para por-hilo: timer_create(CLOCK_THREAD_CPUTIME_ID, ...)
- Para nivel de proceso: timer_create(CLOCK_PROCESS_CPUTIME_ID, ...)
- Pónlo en marcha con una expiración inicial muy corta y un intervalo pequeño para maximizar las entradas en la ruta IRQ:
```c
static timer_t t;
static void setup_cpu_timer(void) {
struct sigevent sev = {0};
sev.sigev_notify = SIGEV_SIGNAL;    // delivery type not critical for the race
sev.sigev_signo = SIGUSR1;
if (timer_create(CLOCK_THREAD_CPUTIME_ID, &sev, &t)) perror("timer_create");
struct itimerspec its = {0};
its.it_value.tv_nsec = 1;           // fire ASAP
its.it_interval.tv_nsec = 1;        // re-fire
if (timer_settime(t, 0, &its, NULL)) perror("timer_settime");
}
```
- Desde un sibling thread, eliminar concurrentemente el mismo timer mientras el target thread sale:
```c
void *deleter(void *arg) {
for (;;) (void)timer_delete(t);     // hammer delete in a loop
}
```
- Amplificadores de race: alta tasa de scheduler ticks, carga de CPU, ciclos repetidos de salida/re-creación de hilos. El crash típicamente se manifiesta cuando posix_cpu_timer_del() omite detectar el firing debido a que falla la búsqueda/bloqueo de la task justo después de unlock_task_sighand().

Detection and hardening
- Mitigation: aplicar la comprobación exit_state; preferir habilitar CONFIG_POSIX_CPU_TIMERS_TASK_WORK cuando sea factible.
- Observability: añadir tracepoints/WARN_ONCE alrededor de unlock_task_sighand()/posix_cpu_timer_del(); alertar cuando se observe it.cpu.firing==1 junto con fallos en cpu_timer_task_rcu()/lock_task_sighand(); vigilar inconsistencias de timerqueue alrededor de la salida de la task.

Audit hotspots (for reviewers)
- update_process_times() → run_posix_cpu_timers() (IRQ)
- __run_posix_cpu_timers() selection (TASK_WORK vs IRQ path)
- collect_timerqueue(): sets ctmr->firing and moves nodes
- handle_posix_cpu_timers(): drops sighand before firing loop
- posix_cpu_timer_del(): relies on it.cpu.firing to detect in-flight expiry; this check is skipped when task lookup/lock fails during exit/reap

Notas para investigación de explotación
- El comportamiento divulgado es una primitiva fiable para provocar un kernel crash; convertirlo en una escalada de privilegios suele requerir una superposición controlable adicional (object lifetime o influencia write-what-where) fuera del alcance de este resumen. Tratar cualquier PoC como potencialmente desestabilizador y ejecutarlo solo en emulators/VMs.

## References
- [Race Against Time in the Kernel’s Clockwork (StreyPaws)](https://streypaws.github.io/posts/Race-Against-Time-in-the-Kernel-Clockwork/)
- [Android security bulletin – September 2025](https://source.android.com/docs/security/bulletin/2025-09-01)
- [Android common kernel patch commit 157f357d50b5…](https://android.googlesource.com/kernel/common/+/157f357d50b5038e5eaad0b2b438f923ac40afeb%5E%21/#F0)

{{#include ../../banners/hacktricks-training.md}}
