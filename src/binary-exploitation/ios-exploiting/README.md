# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

### 1. **Code Signing** / Runtime Signature Verification
**Introduced early (iPhone OS → iOS)**
Esta es una de las protecciones fundamentales: **all executable code** (apps, dynamic libraries, JIT-ed code, extensions, frameworks, caches) debe estar firmada criptográficamente por una cadena de certificados con raíz en la confianza de Apple. En tiempo de ejecución, antes de cargar un binario en memoria (o antes de realizar saltos a través de ciertos límites), el sistema verifica su firma. Si el código se modifica (bit-flipped, parchado) o no está firmado, la carga falla.

- **Thwarts**: la etapa “classic payload drop + execute” en cadenas de explotación; code injection arbitrario; modificar un binario existente para insertar lógica maliciosa.
- **Mechanism detail**:
* El Mach-O loader (y el dynamic linker) comprueban las páginas de código, segmentos, entitlements, team IDs, y que la firma cubra el contenido del archivo.
* Para regiones de memoria como caches JIT o código generado dinámicamente, Apple exige que las páginas estén firmadas o validadas vía APIs especiales (p.ej. `mprotect` con verificaciones de code-sign).
* La firma incluye entitlements e identificadores; el OS fuerza que ciertas APIs o capacidades privilegiadas requieran entitlements específicos que no pueden falsificarse.

<details>
<summary>Example</summary>
Supongamos que un exploit obtiene ejecución de código en un proceso e intenta escribir shellcode en el heap y saltar hacia él. En iOS, esa página necesitaría marcarse como ejecutable **y** satisfacer las restricciones de code-signature. Dado que el shellcode no está firmado con el certificado de Apple, el salto falla o el sistema rechaza hacer ejecutable esa región de memoria.
</details>


### 2. **CoreTrust**
**Introduced around iOS 14+ era (or gradually in newer devices / later iOS)**
CoreTrust es el subsistema que realiza la **validación de firmas en tiempo de ejecución** de binarios (incluyendo binarios del sistema y de usuario) contra **la raíz de Apple** en lugar de confiar en stores de confianza en userland en caché.

- **Thwarts**: tampering post-instalación de binarios, técnicas de jailbreaking que intentan sustituir o parchear librerías del sistema o apps de usuario; engañar al sistema reemplazando binarios de confianza por contrapartes maliciosas.
- **Mechanism detail**:
* En lugar de confiar en una base local de confianza o caché de certificados, CoreTrust consulta o refiere a la raíz de Apple directamente o verifica certificados intermedios en una cadena segura.
* Asegura que modificaciones (p.ej. en el filesystem) a binarios existentes sean detectadas y rechazadas.
* Ata entitlements, team IDs, flags de code signing y otro metadata al binario en tiempo de carga.

<details>
<summary>Example</summary>
Un jailbreak podría intentar reemplazar `SpringBoard` o `libsystem` por una versión parchada para ganar persistencia. Pero cuando el loader del OS o CoreTrust comprueban, detectan la discordancia de firma (o entitlements modificados) y se niegan a ejecutar.
</details>


### 3. **Data Execution Prevention (DEP / NX / W^X)**
**Introduced in many OSes earlier; iOS had NX-bit / w^x for a long time**
DEP impone que las páginas marcadas como escribibles (para datos) sean **no ejecutables**, y las páginas marcadas como ejecutables sean **no escribibles**. No se puede simplemente escribir shellcode en un heap o stack y ejecutarlo.

- **Thwarts**: ejecución directa de shellcode; buffer-overflow clásico → salto a shellcode inyectado.
- **Mechanism detail**:
* La MMU / flags de protección de memoria (vía page tables) hacen cumplir la separación.
* Cualquier intento de marcar una página escribible como ejecutable dispara una comprobación del sistema (y está o prohibido o requiere aprobación de code-sign).
* En muchos casos, hacer páginas ejecutables requiere usar APIs del OS que imponen restricciones o comprobaciones adicionales.

<details>
<summary>Example</summary>
Un overflow escribe shellcode en el heap. El atacante intenta `mprotect(heap_addr, size, PROT_EXEC)` para hacerlo ejecutable. Pero el sistema se niega o valida que la nueva página debe pasar las restricciones de code-sign (lo que el shellcode no puede).
</details>

### 4. **Address Space Layout Randomization (ASLR)**
**Introduced in iOS ~4–5 era (roughly iOS 4–5 timeframe)**
ASLR aleatoriza las direcciones base de regiones clave de memoria: librerías, heap, stack, etc., en cada lanzamiento de proceso. Las direcciones de gadgets se mueven entre ejecuciones.

- **Thwarts**: hardcoding de direcciones de gadgets para ROP/JOP; cadenas de exploit estáticas; saltos a offsets conocidos.
- **Mechanism detail**:
* Cada librería / módulo dinámico cargado es rebased en un offset aleatorio.
* Los punteros base de stack y heap se aleatorizan (dentro de ciertos límites de entropía).
* A veces otras regiones (p.ej. asignaciones via mmap) también se aleatorizan.
* Combinado con mitigaciones de information-leak, fuerza al atacante a primero leakear una dirección o pointer para descubrir bases en tiempo de ejecución.

<details>
<summary>Example</summary>
Una cadena ROP espera un gadget en `0x….lib + offset`. Pero como `lib` se rebasa diferente en cada ejecución, la cadena hardcodeada falla. Un exploit debe primero leakear la dirección base del módulo antes de calcular direcciones de gadgets.
</details>


### 5. **Kernel Address Space Layout Randomization (KASLR)**
**Introduced in iOS ~ (iOS 5 / iOS 6 timeframe)**
Análogo a ASLR de usuario, KASLR aleatoriza la base del **kernel text** y otras estructuras del kernel en el arranque.

- **Thwarts**: exploits a nivel kernel que dependen de ubicaciones fijas de código o datos del kernel; exploits kernel estáticos.
- **Mechanism detail**:
* En cada boot, la dirección base del kernel se aleatoriza (dentro de un rango).
* Estructuras de datos del kernel (como `task_structs`, `vm_map`, etc.) también pueden ser relocadas o desplazadas.
* Los atacantes deben primero leakear pointers del kernel o usar vulnerabilidades de information disclosure para calcular offsets antes de manipular estructuras o código del kernel.

<details>
<summary>Example</summary>
Una vulnerabilidad local apunta a corromper un function pointer del kernel (p.ej. en una `vtable`) en `KERN_BASE + offset`. Pero dado que `KERN_BASE` es desconocida, el atacante debe leakearla primero (p.ej. vía una primitive de lectura) antes de calcular la dirección correcta para corromper.
</details>


### 6. **Kernel Patch Protection (KPP / AMCC)**
**Introduced in newer iOS / A-series hardware (post around iOS 15–16 era or newer chips)**
KPP (aka AMCC) monitoriza continuamente la integridad de las páginas de kernel text (via hash o checksum). Si detecta tampering (parches, hooks inline, modificaciones de código) fuera de ventanas permitidas, dispara un kernel panic o reboot.

- **Thwarts**: parcheo persistente del kernel (modificar instrucciones del kernel), hooks inline, sobrescrituras estáticas de funciones.
- **Mechanism detail**:
* Un módulo hardware o firmware monitoriza la región de kernel text.
* Periódica o bajo demanda re-hashea las páginas y compara con valores esperados.
* Si hay mismatches fuera de ventanas benignas de actualización, hace panic al dispositivo (para evitar parches maliciosos persistentes).
* Los atacantes deben evitar ventanas de detección o usar rutas legítimas de parcheo.

<details>
<summary>Example</summary>
Un exploit intenta parchear el prólogo de una función del kernel (p.ej. `memcmp`) para interceptar llamadas. Pero KPP detecta que la hash de la página de código ya no coincide con la esperada y provoca un kernel panic, colapsando el dispositivo antes de que el parche se estabilice.
</details>


### 7. **Kernel Text Read‐Only Region (KTRR)**
**Introduced in modern SoCs (post ~A12 / newer hardware)**
KTRR es un mecanismo aplicado por hardware: una vez que el kernel text se bloquea temprano durante el arranque, se vuelve de solo lectura desde EL1 (el kernel), impidiendo futuras escrituras sobre páginas de código.

- **Thwarts**: cualquier modificación al código del kernel después del boot (p.ej. parcheo, in-place code injection) a nivel de privilegio EL1.
- **Mechanism detail**:
* Durante el boot (en la etapa secure/bootloader), el memory controller (o una unidad hardware segura) marca las páginas físicas que contienen kernel text como read-only.
* Incluso si un exploit consigue privilegios completos de kernel, no puede escribir en esas páginas para parchear instrucciones.
* Para modificarlas, el atacante debe primero comprometer la cadena de arranque o subvertir KTRR mismo.

<details>
<summary>Example</summary>
Un exploit de escalada de privilegios salta a EL1 y escribe un trampoline en una función del kernel (p.ej. en el handler de `syscall`). Pero como las páginas están bloqueadas como read-only por KTRR, la escritura falla (o dispara fallo), por lo que los parches no se aplican.
</details>


### 8. **Pointer Authentication Codes (PAC)**
**Introduced with ARMv8.3 (hardware), Apple beginning with A12 / iOS ~12+**
- PAC es una característica hardware introducida en **ARMv8.3-A** para detectar manipulación de valores punteros (return addresses, function pointers, ciertos data pointers) embebiendo una pequeña firma criptográfica (un “MAC”) en bits altos no usados del puntero.
- La firma (“PAC”) se calcula sobre el valor del puntero más un **modifier** (un valor de contexto, p.ej. stack pointer o algún dato distintivo). De ese modo, el mismo valor de puntero en diferentes contextos obtiene un PAC distinto.
- En el momento de uso, antes de desreferenciar o hacer branch a través de ese puntero, una instrucción de **authenticate** verifica el PAC. Si es válido, la PAC se quita y se obtiene el puntero puro; si es inválido, el puntero queda “poisoned” (o se genera una fault).
- Las llaves usadas para producir/validar PACs viven en registros privilegiados (EL1, kernel) y no son directamente legibles desde user mode.
- Porque no todos los 64 bits de un puntero se usan en muchos sistemas (p.ej. espacio de direcciones de 48 bits), los bits superiores están “libres” y pueden contener el PAC sin alterar la dirección efectiva.

#### Architectural Basis & Key Types

- ARMv8.3 introduce **cinco llaves de 128-bit** (cada una implementada vía dos registros sistema de 64-bit) para pointer authentication.
- **APIAKey** — para instruction pointers (dominio “I”, key A)
- **APIBKey** — segunda llave para instruction pointers (dominio “I”, key B)
- **APDAKey** — para data pointers (dominio “D”, key A)
- **APDBKey** — para data pointers (dominio “D”, key B)
- **APGAKey** — llave “genérica”, para firmar datos no-puntero u otros usos genéricos

- Estas llaves se almacenan en registros de sistema privilegiados (accesibles solo en EL1/EL2, etc.), no accesibles desde user mode.
- El PAC se calcula mediante una función criptográfica (ARM sugiere QARMA como algoritmo) usando:
1. El valor del puntero (porción canónica)
2. Un **modifier** (un valor de contexto, como una salt)
3. La llave secreta
4. Algo de lógica interna de tweak
Si el PAC resultante coincide con lo almacenado en los bits superiores del puntero, la autenticación tiene éxito.


#### Instruction Families

La convención de nombres es: **PAC** / **AUT** / **XPAC**, luego letras de dominio.
- `PACxx` instrucciones **firman** un puntero e insertan un PAC
- `AUTxx` instrucciones **autentican + quitan** (validan y eliminan el PAC)
- `XPACxx` instrucciones **quitan** sin validar

Domains / sufijos:

| Mnemonic     | Significado / Dominio                      | Key / Domain     | Example Usage in Assembly |
|--------------|--------------------------------------------|------------------|---------------------------|
| **PACIA**    | Sign instruction pointer con APIAKey       | “I, A”           | `PACIA X0, X1` — sign pointer in X0 using APIAKey with modifier X1|
| **PACIB**    | Sign instruction pointer con APIBKey       | “I, B”           | `PACIB X2, X3`            |
| **PACDA**    | Sign data pointer con APDAKey              | “D, A”           | `PACDA X4, X5`            |
| **PACDB**    | Sign data pointer con APDBKey              | “D, B”           | `PACDB X6, X7`            |
| **PACG / PACGA** | Generic (non-pointer) signing con APGAKey | “G”            | `PACGA X8, X9, X10` (sign X9 with modifier X10 into X8) |
| **AUTIA**    | Authenticate APIA-signed instruction pointer & strip PAC | “I, A” | `AUTIA X0, X1` — check PAC on X0 using modifier X1, then strip |
| **AUTIB**    | Authenticate APIB domain                   | “I, B”           | `AUTIB X2, X3`            |
| **AUTDA**    | Authenticate APDA-signed data pointer      | “D, A”           | `AUTDA X4, X5`            |
| **AUTDB**    | Authenticate APDB-signed data pointer      | “D, B”           | `AUTDB X6, X7`            |
| **AUTGA**    | Authenticate generic / blob (APGA)         | “G”              | `AUTGA X8, X9, X10` (validate generic) |
| **XPACI**     | Strip PAC (instruction pointer, no validation) | “I”          | `XPACI X0` — remove PAC from X0 (instruction domain) |
| **XPACD**     | Strip PAC (data pointer, no validation)    | “D”              | `XPACD X4` — remove PAC from data pointer in X4 |


Hay formas especializadas / alias:

- `PACIASP` es atajo para `PACIA X30, SP` (sign the link register usando SP como modifier)
- `AUTIASP` es `AUTIA X30, SP` (authenticate link register con SP)
- Formas combinadas como `RETAA`, `RETAB` (authenticate-and-return) o `BLRAA` (authenticate & branch) existen en extensiones ARM / soporte de compilador.
- También variantes con modifier cero: `PACIZA` / `PACIZB` donde el modifier es implícitamente cero, etc.

#### Modifiers

El objetivo principal del modifier es **vincular el PAC a un contexto específico** para que la misma dirección firmada en distintos contextos produzca PACs distintos. Es como añadir una **salt a un hash.**

Por lo tanto:
- El **modifier** es un valor de contexto (otro registro) que se mezcla en la computación del PAC. Elecciones típicas: stack pointer (`SP`), frame pointer, o algún ID de objeto.
- Usar SP como modifier es común para signing de return addresses: el PAC queda atado al frame de stack específico. Si intentas reutilizar el LR en otro frame, el modifier cambia y la validación PAC falla.
- El mismo valor de puntero firmado bajo modifiers distintos produce PACs distintos.
- El modifier **no necesita ser secreto**, pero idealmente no está controlado por el atacante.
- Para instrucciones que firman o verifican punteros donde no existe un modifier significativo, algunas formas usan cero o una constante implícita.

#### Apple / iOS / XNU Customizations & Observations

- La implementación PAC de Apple incluye **diversificadores por boot** para que las llaves o tweaks cambien en cada arranque, impidiendo reuso entre boots.
- También incluyen **mitigaciones cross-domain** para que PACs firmados en user mode no puedan reutilizarse fácilmente en kernel mode, etc.
- En Apple M1 / Apple Silicon, ingeniería inversa mostró que hay **nueve tipos de modifier** y registros sistema específicos de Apple para control de llaves.
- Apple usa PAC en muchos subsistemas del kernel: signing de return addresses, integridad de punteros en datos del kernel, signed thread contexts, etc.
- Google Project Zero mostró cómo bajo una powerful memory read/write primitive en kernel, uno podría forjar kernel PACs (para A keys) en dispositivos A12, pero Apple parcheó muchas de esas vías.
- En el sistema de Apple, algunas llaves son **globales al kernel**, mientras procesos de usuario pueden obtener randomness por proceso para llaves.

#### PAC Bypasses

1. **Kernel-mode PAC: theoretical vs real bypasses**

-   Dado que las llaves y la lógica PAC del kernel están fuertemente controladas (registros privilegiados, diversificadores, aislamiento de dominios), forjar punteros firmados arbitrarios del kernel es muy difícil.
-   Azad en 2020 "iOS Kernel PAC, One Year Later" reportó que en iOS 12-13 encontró algunos bypasses parciales (signing gadgets, reuse de signed states, indirect branches sin protección) pero no un bypass genérico completo. [bazad.github.io](https://bazad.github.io/presentations/BlackHat-USA-2020-iOS_Kernel_PAC_One_Year_Later.pdf)
-   Las customizaciones “Dark Magic” de Apple reducen aún más las superficies explotables (domain switching, bits de habilitación por key). [i.blackhat.com](https://i.blackhat.com/BH-US-23/Presentations/US-23-Zec-Apple-PAC-Four-Years-Later.pdf)
-   Hay un conocido **kernel PAC bypass CVE-2023-32424** en Apple silicon (M1/M2) reportado por Zecao Cai et al. [i.blackhat.com](https://i.blackhat.com/BH-US-23/Presentations/US-23-Zec-Apple-PAC-Four-Years-Later.pdf)
-   Pero estos bypasses suelen depender de gadgets muy específicos o bugs de implementación; no son bypasses de propósito general.

Por tanto, kernel PAC se considera **highly robust**, aunque no perfecto.

2. **User-mode / runtime PAC bypass techniques**

Estos son más comunes, y explotan imperfecciones en cómo PAC se aplica o se usa en dynamic linking / runtime frameworks. Abajo hay clases, con ejemplos.

2.1 **Shared Cache / A key issues**

-   El **dyld shared cache** es un gran blob pre-linked de frameworks y librerías del sistema. Debido a que se comparte tanto, function pointers dentro del shared cache están “pre-signed” y luego usados por muchos procesos. Los atacantes atacan estos punteros ya firmados como “PAC oracles”.
-   Algunas técnicas de bypass intentan extraer o reutilizar punteros firmados con A-key presentes en el shared cache y reutilizarlos en gadgets.
-   La charla "No Clicks Required" describe construir un oracle sobre el shared cache para inferir direcciones relativas y combinar eso con punteros firmados para bypassear PAC. [saelo.github.io](https://saelo.github.io/presentations/offensivecon_20_no_clicks.pdf)
-   Además, imports de function pointers desde librerías compartidas en userspace se encontraron insuficientemente protegidos por PAC, permitiendo a un atacante obtener function pointers sin cambiar su firma. (entrada de bug de Project Zero) [bugs.chromium.org](https://bugs.chromium.org/p/project-zero/issues/detail?id=2044&utm_source=chatgpt.com)

2.2 **dlsym(3) / dynamic symbol resolution**

-   Un bypass conocido es llamar a `dlsym()` para obtener un function pointer *ya firmado* (signed con A-key, diversifier cero) y luego usarlo. Como `dlsym` devuelve un puntero legítimamente firmado, usarlo evita la necesidad de forjar PAC.
-   El blog de Epsilon detalla cómo algunos bypasss explotan esto: llamar a `dlsym("someSym")` produce un puntero firmado que puede usarse para llamadas indirectas. [blog.epsilon-sec.com](https://blog.epsilon-sec.com/tag/pac.html)
-   Synacktiv en "iOS 18.4 --- dlsym considered harmful" describe un bug: algunos símbolos resueltos vía `dlsym` en iOS 18.4 devuelven punteros que están incorrectamente firmados (o con diversificadores buggy), posibilitando un PAC bypass no intencionado. [Synacktiv](https://www.synacktiv.com/en/publications/ios-184-dlsym-considered-harmful)
-   La lógica en dyld para dlsym incluye: cuando `result->isCode`, firman el puntero retornado con `__builtin_ptrauth_sign_unauthenticated(..., key_asia, 0)`, i.e. contexto cero. [blog.epsilon-sec.com](https://blog.epsilon-sec.com/tag/pac.html)

Por tanto, `dlsym` es un vector frecuente en bypasses PAC en user-mode.

2.3 **Other DYLD / runtime relocations**

-   El loader DYLD y la lógica de relocation dinámica es compleja y a veces mapea temporalmente páginas como read/write para realizar relocations, luego las vuelve read-only. Los atacantes explotan esas ventanas. La charla de Synacktiv describe "Operation Triangulation", un bypass basado en timing de PAC vía relocations dinámicas. [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)
-   Las páginas de DYLD ahora están protegidas con SPRR / VM_FLAGS_TPRO (algunas flags de protección para dyld). Pero versiones anteriores tenían guardias más débiles. [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)
-   En cadenas de explotación de WebKit, el loader DYLD es a menudo un objetivo para bypass de PAC. Las slides mencionan que muchos bypasses PAC han atacado al loader DYLD (vía relocation, interposer hooks). [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

2.4 **NSPredicate / NSExpression / ObjC / SLOP**

-   En cadenas de exploit en userland, métodos del runtime Objective-C como `NSPredicate`, `NSExpression` o `NSInvocation` se usan para contrabandear llamadas de control sin una aparente forja de punteros.
-   En iOS más antiguos (antes de PAC), un exploit usó **fake NSInvocation** objects para llamar selectors arbitrarios sobre memoria controlada. Con PAC, se requieren modificaciones. Pero la técnica SLOP (SeLector Oriented Programming) se extiende bajo PAC también. [Project Zero](https://googleprojectzero.blogspot.com/2020/01/remote-iphone-exploitation-part-3.html)
-   La técnica original SLOP permitía encadenar llamadas ObjC creando invocations falsas; el bypass se apoya en que ISA o selector pointers a veces no están totalmente protegidos por PAC. [Project Zero](https://googleprojectzero.blogspot.com/2020/01/remote-iphone-exploitation-part-3.html)
-   En entornos donde pointer authentication se aplica parcialmente, métodos / selectors / target pointers pueden no tener siempre protección PAC, dejando margen para bypass.

#### Example Flow

<details>
<summary>Example Signing & Authenticating</summary>
```
; Example: function prologue / return address protection
my_func:
stp x29, x30, [sp, #-0x20]!        ; push frame pointer + LR
mov x29, sp
PACIASP                            ; sign LR (x30) using SP as modifier
; … body …
mov sp, x29
ldp x29, x30, [sp], #0x20         ; restore
AUTIASP                            ; authenticate & strip PAC
ret

; Example: indirect function pointer stored in a struct
; suppose X1 contains a function pointer
PACDA X1, X2     ; sign data pointer X1 with context X2
STR X1, [X0]      ; store signed pointer

; later retrieval:
LDR X1, [X0]
AUTDA X1, X2       ; authenticate & strip
BLR X1             ; branch to valid target

; Example: stripping for comparison (unsafe)
LDR X1, [X0]
XPACI X1           ; strip PAC (instruction domain)
CMP X1, #some_label_address
BEQ matched_label
```
</details>

<details>
<summary>Example</summary>
Un buffer overflow sobrescribe una dirección de retorno en la stack. El atacante escribe la dirección del gadget objetivo pero no puede calcular el PAC correcto. Cuando la función retorna, la instrucción `AUTIA` de la CPU falla porque el PAC no coincide. La cadena falla.
El análisis de Project Zero sobre A12 (iPhone XS) mostró cómo Apple usa PAC y métodos para forjar PACs si un atacante tiene una primitiva de lectura/escritura de memoria.
</details>


### 9. **Branch Target Identification (BTI)**
**Introducido con ARMv8.5 (hardware más reciente)**
BTI es una característica de hardware que comprueba los **targets de ramas indirectas**: al ejecutar `blr` o llamadas/saltos indirectos, el objetivo debe comenzar con un **BTI landing pad** (`BTI j` o `BTI c`). Saltar a direcciones de gadget que no tienen el landing pad provoca una excepción.

La implementación de LLVM anota tres variantes de instrucciones BTI y cómo se mapean a tipos de rama.

| BTI Variant | What it permits (which branch types) | Typical placement / use case |
|-------------|----------------------------------------|-------------------------------|
| **BTI C** | Targets of *call*-style indirect branches (e.g. `BLR`, or `BR` using X16/X17) | Put at entry of functions that may be called indirectly |
| **BTI J** | Targets of *jump*-style branches (e.g. `BR` used for tail calls) | Placed at the beginning of blocks reachable by jump tables or tail-calls |
| **BTI JC** | Acts as both C and J | Can be targeted by either call or jump branches |

- En código compilado con branch target enforcement, los compiladores insertan una instrucción BTI (C, J, o JC) en cada target válido de rama indirecta (comienzos de funciones o bloques alcanzables por saltos) de modo que las ramas indirectas solo tengan éxito hacia esos lugares.
- **Las ramas / llamadas directas** (es decir, `B`, `BL` con dirección fija) **no están restringidas** por BTI. La suposición es que las páginas de código son confiables y el atacante no puede cambiarlas (por eso las ramas directas son seguras).
- Además, las instrucciones **RET / return** generalmente no están restringidas por BTI porque las direcciones de retorno están protegidas vía PAC o mecanismos de firmado de retorno.

#### Mechanism and enforcement

- Cuando la CPU decodifica una **rama indirecta (BLR / BR)** en una página marcada como “guarded / BTI-enabled”, comprueba si la primera instrucción de la dirección objetivo es un BTI válido (C, J o JC según lo permitido). Si no lo es, ocurre una **Branch Target Exception**.
- La codificación de la instrucción BTI está diseñada para reutilizar opcodes previamente reservados para NOPs (en versiones anteriores de ARM). Así que los binarios BTI-enabled permanecen retrocompatibles: en hardware sin soporte BTI, esas instrucciones actúan como NOPs.
- Los passes del compilador que añaden BTIs los insertan solo donde se necesitan: en funciones que pueden ser llamadas indirectamente, o en bloques básicos que son target de saltos.
- Algunos parches y código de LLVM muestran que BTI no se inserta en *todos* los bloques básicos — solo en aquellos que son potenciales targets de rama (p. ej. provenientes de switch / jump tables).

#### BTI + PAC synergy

PAC protege el valor del puntero (la fuente) — asegura que la cadena de llamadas/retornos indirectas no haya sido manipulada.

BTI asegura que incluso un puntero válido solo pueda apuntar a puntos de entrada correctamente marcados.

Combinados, un atacante necesita tanto un puntero válido con PAC correcto como que el objetivo tenga un BTI colocado allí. Esto aumenta la dificultad de construir gadgets exploitables.

#### Example


<details>
<summary>Example</summary>
Un exploit intenta pivotar hacia un gadget en `0xABCDEF` que no comienza con `BTI c`. La CPU, al ejecutar `blr x0`, comprueba el objetivo y falla porque la alineación de la instrucción no incluye un landing pad válido. Por tanto muchos gadgets se vuelven inutilizables a menos que incluyan el prefijo BTI.
</details>


### 10. **Privileged Access Never (PAN) & Privileged Execute Never (PXN)**
**Introducidos en extensiones ARMv8 más recientes / soporte en iOS (para kernel hardened)**

#### PAN (Privileged Access Never)

- **PAN** es una característica introducida en **ARMv8.1-A** que evita que código **privilegiado** (EL1 o EL2) **lea o escriba** memoria marcada como **accesible por usuario (EL0)**, a menos que PAN esté explícitamente deshabilitado.
- La idea: incluso si el kernel es engañado o comprometido, no puede desreferenciar punteros de user-space arbitrariamente sin primero *limpiar* PAN, reduciendo así riesgos de exploits tipo **`ret2usr`** o mal uso de buffers controlados por el usuario.
- Cuando PAN está habilitado (PSTATE.PAN = 1), cualquier instrucción privilegiada de carga/almacenamiento que acceda a una dirección virtual que sea “accesible en EL0” provoca una **falla de permiso**.
- El kernel, cuando necesita legítimamente acceder a memoria de usuario (p. ej. copiar datos hacia/desde buffers de usuario), debe **deshabilitar temporalmente PAN** (o usar instrucciones de “unprivileged load/store”) para permitir ese acceso.
- En Linux en ARM64, el soporte de PAN se introdujo alrededor de 2015: parches del kernel añadieron detección de la característica y reemplazaron `get_user` / `put_user` etc. con variantes que limpian PAN alrededor de accesos a memoria user.

**Matiz / limitación / bug clave**
- Como señaló Siguza y otros, un bug de especificación (o comportamiento ambiguo) en el diseño de ARM significa que los mapeos de usuario execute-only (`--x`) pueden **no activar PAN**. En otras palabras, si una página de usuario está marcada como ejecutable pero sin permiso de lectura, el intento del kernel de leer podría evitar PAN porque la arquitectura considera “accesible en EL0” que requiera permiso de lectura, no solo ejecución. Esto lleva a una omisión de PAN en ciertas configuraciones.
- Por ello, si iOS / XNU permite páginas de usuario execute-only (como algunos setups de JIT o code-cache), el kernel podría leer accidentalmente desde ellas incluso con PAN habilitado. Esta es un área sutil conocida como explotable en algunos sistemas ARMv8+.

#### PXN (Privileged eXecute Never)

- **PXN** es un flag de la tabla de páginas (en las entradas de la tabla de páginas, leaf o block entries) que indica que la página **no es ejecutable cuando se ejecuta en modo privilegiado** (es decir, cuando EL1 ejecuta).
- PXN impide que el kernel (o cualquier código privilegiado) salte hacia o ejecute instrucciones desde páginas de user-space incluso si el control es desviado. En efecto, detiene una redirección de flujo de control a código de usuario desde nivel kernel.
- Combinado con PAN, esto asegura que:
1. El kernel no puede (por defecto) leer o escribir datos de user-space (PAN)
2. El kernel no puede ejecutar código de user-space (PXN)
- En el formato de la tabla de páginas de ARMv8, las entradas leaf tienen un bit `PXN` (y también `UXN` para execute-never no privilegiado) en sus bits de atributo.

Así que incluso si el kernel tiene un puntero a función corrupto apuntando a memoria user, y trata de rampear allí, el bit PXN causaría una falla.

#### Memory-permission model & how PAN and PXN map to page table bits

Para entender cómo funcionan PAN / PXN, necesitas ver cómo funciona la traducción y el modelo de permisos de ARM (simplificado):

- Cada entrada de página o block tiene campos de atributo incluyendo **AP[2:1]** para permisos de acceso (lectura/escritura, privilegiado vs no privilegiado) y bits **UXN / PXN** para restricciones de execute-never.
- Cuando PSTATE.PAN es 1 (habilitado), el hardware aplica semánticas modificadas: los accesos privilegiados a páginas marcadas como “accesibles por EL0” (es decir, accesibles por usuario) son deshabilitados (falla).
- Debido al bug mencionado, las páginas que están marcadas solo como ejecutables (sin permiso de lectura) pueden no contar como “accesibles por EL0” bajo ciertas implementaciones, con lo que se evita PAN.
- Cuando el bit PXN de una página está establecido, incluso si el fetch de instrucción viene desde un nivel de privilegio superior, la ejecución está prohibida.

#### Kernel usage of PAN / PXN in a hardened OS (e.g. iOS / XNU)

En un diseño de kernel hardenizado (como el que Apple podría usar):

- El kernel habilita PAN por defecto (así el código privilegiado está restringido).
- En rutas que necesitan legítimamente leer o escribir buffers de usuario (p. ej. copia de buffers de syscalls, I/O, read/write de punteros de usuario), el kernel deshabilita **temporalmente PAN** o usa instrucciones especiales para sobrescribirlo.
- Después de terminar el acceso a datos de usuario, debe re-habilitar PAN.
- PXN se aplica vía tablas de páginas: las páginas de usuario tienen PXN = 1 (así el kernel no puede ejecutarlas), las páginas del kernel no tienen PXN (así el código del kernel puede ejecutarse).
- El kernel debe asegurarse de que ninguna ruta de código cause ejecución en regiones de memoria de usuario (eso podría evitar PXN) — así que las cadenas de exploit que dependen de “saltar a shellcode controlado por el usuario” quedan bloqueadas.

Debido al bypass de PAN vía páginas execute-only mencionado, en un sistema real Apple podría deshabilitar o no permitir páginas execute-only de usuario, o parchear alrededor de la debilidad de la especificación.

#### Attack surfaces, bypasses, and mitigations

- **PAN bypass vía páginas execute-only**: como se discutió, la spec permite una laguna: páginas de usuario con execute-only (sin permiso de lectura) podrían no contar como “accesibles en EL0”, por lo que PAN no bloqueará lecturas del kernel desde tales páginas en algunas implementaciones. Esto le da al atacante una vía inusual para alimentar datos vía secciones “execute-only”.
- **Exploit por ventana temporal**: si el kernel deshabilita PAN por una ventana más larga de la necesaria, una carrera o ruta maliciosa podría explotar esa ventana para realizar accesos a memoria de usuario no intencionados.
- **Olvidar re-habilitar**: si rutas de código fallan en volver a habilitar PAN, operaciones kernel posteriores podrían acceder incorrectamente a memoria de usuario.
- **Mala configuración de PXN**: si las tablas de páginas no establecen PXN en páginas de usuario o mapean incorrectamente páginas de código de usuario, el kernel podría ser engañado para ejecutar código de user-space.
- **Speculation / side-channels**: análogo a bypasses especulativos, pueden existir efectos microarquitecturales transitorios que provoquen violaciones temporales de las comprobaciones PAN / PXN (aunque tales ataques dependen mucho del diseño de la CPU).
- **Interacciones complejas**: en características más avanzadas (p. ej. JIT, memoria compartida, regiones de código just-in-time), el kernel puede necesitar control fino para permitir ciertos accesos de memoria o ejecución en regiones mapeadas por el usuario; diseñar eso de forma segura bajo las restricciones PAN/PXN no es trivial.

#### Example

<details>
<summary>Code Example</summary>
Here are illustrative pseudo-assembly sequences showing enabling/disabling PAN around user memory access, and how a fault might occur.
```  
// Suppose kernel entry point, PAN is enabled (privileged code cannot access user memory by default)

; Kernel receives a syscall with user pointer in X0
; wants to read an integer from user space
mov   X1, X0        ; X1 = user pointer

; disable PAN to allow privileged access to user memory
MSR   PSTATE.PAN, #0   ; clear PAN bit, disabling the restriction

ldr   W2, [X1]       ; now allowed load from user address

; re-enable PAN before doing other kernel logic
MSR   PSTATE.PAN, #1   ; set PAN

; ... further kernel work ...

; Later, suppose an exploit corrupts a pointer to a user-space code page and jumps there
BR    X3             ; branch to X3 (which points into user memory)

; Because the target page is marked PXN = 1 for privileged execution,
; the CPU throws an exception (fault) and rejects execution
```
Si el kernel no hubiera establecido **PXN** en esa página de usuario, entonces la rama podría tener éxito — lo cual sería inseguro.

Si el kernel olvida volver a habilitar **PAN** después de acceder a memoria de usuario, se abre una ventana donde lógica adicional del kernel podría leer/escribir accidentalmente memoria de usuario arbitraria.

Si el puntero de usuario apunta a una página execute-only (página de usuario con sólo permiso de ejecución, sin lectura/escritura), bajo el bug de la especificación PAN, `ldr W2, [X1]` podría **no** generar fallo incluso con PAN habilitado, permitiendo un exploit de bypass, dependiendo de la implementación.

</details>

<details>
<summary>Ejemplo</summary>
Una vulnerabilidad en el kernel intenta tomar un puntero a función proporcionado por el usuario y llamarlo en contexto kernel (i.e. `call user_buffer`). Bajo PAN/PXN, esa operación está prohibida o provoca fallo.
</details>

---

### 11. **Top Byte Ignore (TBI) / Pointer Tagging**
**Introduced in ARMv8.5 / newer (or optional extension)**
TBI significa que el byte superior (el byte más significativo) de un puntero de 64 bits se ignora en la traducción de direcciones. Esto permite al OS o al hardware incrustar bits de **tag** en el byte superior del puntero sin afectar la dirección real.

- TBI stands for **Top Byte Ignore** (sometimes called *Address Tagging*). Es una característica de hardware (disponible en muchas implementaciones ARMv8+) que **ignora los 8 bits superiores** (bits 63:56) de un puntero de 64 bits cuando realiza **traducción de direcciones / load/store / instruction fetch**.
- En efecto, la CPU trata un puntero `0xTTxxxx_xxxx_xxxx` (donde `TT` = top byte) como `0x00xxxx_xxxx_xxxx` a efectos de traducción de direcciones, ignorando (enmascarando) el byte superior. El byte superior puede ser usado por software para almacenar **metadata / tag bits**.
- Esto da al software espacio "gratuito" en banda para incrustar un byte de tag en cada puntero sin alterar qué ubicación de memoria referencia.
- La arquitectura asegura que loads, stores y instruction fetch traten el puntero con su byte superior enmascarado (i.e. tag eliminado) antes de realizar el acceso real a memoria.

Así, TBI desacopla el **puntero lógico** (puntero + tag) de la **dirección física** usada para operaciones de memoria.

#### Why TBI: Use cases and motivation

- **Pointer tagging / metadata**: Puedes almacenar metadata extra (p.ej. tipo de objeto, versión, bounds, tags de integridad) en ese byte superior. Cuando luego usas el puntero, el tag es ignorado a nivel de hardware, por lo que no necesitas retirarlo manualmente para el acceso a memoria.
- **Memory tagging / MTE (Memory Tagging Extension)**: TBI es el mecanismo base de hardware sobre el que se construye MTE. En ARMv8.5, la **Memory Tagging Extension** usa los bits 59:56 del puntero como un **tag lógico** y lo compara con un **allocation tag** almacenado en memoria.
- **Enhanced security & integrity**: Combinando TBI con pointer authentication (PAC) o chequeos en tiempo de ejecución, puedes exigir no sólo que el valor del puntero sea correcto sino también que el tag lo sea. Un atacante que sobreescriba un puntero sin el tag correcto producirá un tag que no coincide.
- **Compatibility**: Debido a que TBI es opcional y los bits de tag son ignorados por hardware, el código existente sin tag continúa funcionando normalmente. Los bits de tag efectivamente se convierten en bits “no relevantes” para código legacy.

#### Example
<details>
<summary>Ejemplo</summary>
Un puntero a función incluía un tag en su byte superior (por ejemplo `0xAA`). Un exploit sobreescribe los bits bajos del puntero pero olvida el tag, así que cuando el kernel verifica o sanitiza, el puntero falla o es rechazado.
</details>

---

### 12. **Page Protection Layer (PPL)**
**Introduced in late iOS / modern hardware (iOS ~17 / Apple silicon / high-end models)** (some reports show PPL circa macOS / Apple silicon, but Apple is bringing analogous protections to iOS)

- PPL está diseñado como un **límite de protección intra-kernel**: incluso si el kernel (EL1) está comprometido y tiene capacidades de lectura/escritura, **no debería poder modificar libremente** ciertas **páginas sensibles** (especialmente tablas de páginas, metadata de code-signing, páginas de código del kernel, entitlements, trust caches, etc.).
- Efectivamente crea un **“kernel dentro del kernel”** — un componente más pequeño y de confianza (PPL) con **privilegios elevados** que es el único que puede modificar páginas protegidas. Otro código del kernel debe llamar a rutinas del PPL para efectuar cambios.
- Esto reduce la superficie de ataque para exploits de kernel: incluso con R/W/execute arbitrario en modo kernel, el código del exploit debe además entrar en el dominio PPL (o bypass PPL) para modificar estructuras críticas.
- En Apple silicon más modernos (A15+ / M2+), Apple está migrando hacia **SPTM (Secure Page Table Monitor)**, que en muchos casos reemplaza a PPL para la protección de page-tables en esas plataformas.

Aquí se describe cómo se cree que opera PPL, basado en análisis públicos:

#### Use of APRR / permission routing (APRR = Access Permission ReRouting)

- Apple hardware usa un mecanismo llamado **APRR (Access Permission ReRouting)**, que permite que las entradas de tabla de páginas (PTEs) contengan índices pequeños, en lugar de bits de permiso completos. Esos índices se mapean vía registros APRR a permisos efectivos. Esto permite remapear dinámicamente permisos por dominio.
- PPL aprovecha APRR para segregar privilegios dentro del contexto del kernel: sólo el dominio PPL está permitido para actualizar el mapeo entre índices y permisos efectivos. Es decir, cuando código no-PPL del kernel escribe una PTE o intenta cambiar bits de permiso, la lógica APRR lo deshabilita (o aplica un mapeo de sólo-lectura).
- El propio código PPL se ejecuta en una región restringida (p.ej. `__PPLTEXT`) que normalmente no es ejecutable ni escribible hasta que unas puertas de entrada permiten temporalmente su ejecución. El kernel llama a puntos de entrada PPL (“rutinas PPL”) para realizar operaciones sensibles.

#### Gate / Entry & Exit

- Cuando el kernel necesita modificar una página protegida (p.ej. cambiar permisos de una página de código del kernel, o modificar page tables), llama a una rutina wrapper del PPL, que hace validación y luego transiciona al dominio PPL. Fuera de ese dominio, las páginas protegidas son efectivamente de sólo lectura o no modificables por el kernel principal.
- Durante la entrada a PPL, los mapeos APRR se ajustan para que las páginas en la región PPL se establezcan como **ejecutables y escribibles** dentro de PPL. Al salir, se devuelven a sólo-lectura / no-escribibles. Esto asegura que sólo las rutinas PPL auditadas puedan escribir en páginas protegidas.
- Fuera de PPL, intentos del código del kernel de escribir en esas páginas protegidas provocarán fallos (permiso denegado) porque el mapeo APRR para ese dominio de código no permite escritura.

#### Protected page categories

Las páginas que PPL típicamente protege incluyen:

- Estructuras de page table (entradas de tablas de traducción, metadata de mapeo)
- Páginas de código del kernel, especialmente las que contienen lógica crítica
- Metadata de code-sign (trust caches, blobs de firmas)
- Tablas de entitlements, tablas de enforcement de firmas
- Otras estructuras de kernel de alto valor donde parchearlas permitiría bypass de checks de firma o manipulación de credenciales

La idea es que incluso si la memoria del kernel está totalmente controlada, el atacante no puede simplemente parchear o reescribir estas páginas, a menos que también comprometa rutinas PPL o eluda PPL.

#### Known Bypasses & Vulnerabilities

1. **Project Zero’s PPL bypass (stale TLB trick)**

- Un writeup público de Project Zero describe un bypass que involucra **entradas TLB obsoletas**.
- La idea:

1. Allocate two physical pages A and B, mark them as PPL pages (so they are protected).
2. Map two virtual addresses P and Q whose L3 translation table pages come from A and B.
3. Spin a thread to continuously access Q, keeping its TLB entry alive.
4. Call `pmap_remove_options()` to remove mappings starting at P; due to a bug, the code mistakenly removes the TTEs for both P and Q, but only invalidates the TLB entry for P, leaving Q’s stale entry live.
5. Reuse B (page Q’s table) to map arbitrary memory (e.g. PPL-protected pages). Because the stale TLB entry still maps Q’s old mapping, that mapping remains valid for that context.
6. Through this, the attacker can put writable mapping of PPL-protected pages in place without going through PPL interface.

- Este exploit requería un control fino del mapeo físico y del comportamiento del TLB. Demuestra que un límite de seguridad que depende de la corrección del TLB/mapeos debe ser extremadamente cuidadoso con las invalidaciones de TLB y la consistencia de mapeo.

- Project Zero comentó que bypasses como este son sutiles y raros, pero posibles en sistemas complejos. Aun así, consideran a PPL como una mitigación sólida.

2. **Other potential hazards & constraints**

- Si un exploit del kernel puede entrar directamente en rutinas PPL (vía llamadas a los wrappers PPL), podría eludir restricciones. Por tanto la validación de argumentos es crítica.
- Bugs en el propio código PPL (p.ej. overflow aritmético, checks de límites) pueden permitir modificaciones fuera de límite dentro de PPL. Project Zero observó que tal bug en `pmap_remove_options_internal()` fue explotado en su bypass.
- El límite PPL está irrevocablemente ligado a la aplicación por hardware (APRR, memory controller), así que sólo es tan fuerte como la implementación hardware.

#### Example
<details>
<summary>Ejemplo de código</summary>
Here’s a simplified pseudocode / logic showing how a kernel might call into PPL to modify protected pages:
```c
// In kernel (outside PPL domain)
function kernel_modify_pptable(pt_addr, new_entry) {
// validate arguments, etc.
return ppl_call_modify(pt_addr, new_entry)  // call PPL wrapper
}

// In PPL (trusted domain)
function ppl_call_modify(pt_addr, new_entry) {
// temporarily enable write access to protected pages (via APRR adjustments)
aprr_set_index_for_write(PPL_INDEX)
// perform the modification
*pt_addr = new_entry
// restore permissions (make pages read-only again)
aprr_restore_default()
return success
}

// If kernel code outside PPL does:
*pt_addr = new_entry  // a direct write
// It will fault because APRR mapping for non-PPL domain disallows write to that page
```
El kernel puede realizar muchas operaciones normales, pero solo a través de las rutinas `ppl_call_*` puede cambiar protected mappings o parchear código.
</details>

<details>
<summary>Ejemplo</summary>
Un kernel exploit intenta sobrescribir la entitlement table, o desactivar la enforcement de code-sign modificando un kernel signature blob. Como esa página está PPL-protected, la escritura queda bloqueada a menos que se haga a través de la PPL interface. Así que incluso con ejecución de código en kernel, no puedes bypass code-sign constraints ni modificar credential data arbitrariamente.
En iOS 17+ ciertos dispositivos usan SPTM para aislar aún más las páginas gestionadas por PPL.
</details>

#### PPL → SPTM / Replacements / Future

- En los SoC modernos de Apple (A15 o posteriores, M2 o posteriores), Apple soporta **SPTM** (Secure Page Table Monitor), que **reemplaza a PPL** para las protecciones de page table.
- Apple indica en la documentación: “Page Protection Layer (PPL) and Secure Page Table Monitor (SPTM) enforce execution of signed and trusted code … PPL manages the page table permission overrides … Secure Page Table Monitor replaces PPL on supported platforms.”
- La arquitectura SPTM probablemente desplaza más la aplicación de políticas a un monitor de mayor privilegio fuera del control del kernel, reduciendo aún más la frontera de confianza.

### MTE | EMTE | MIE

Aquí hay una descripción a alto nivel de cómo opera EMTE en el entorno MIE de Apple:

1. **Tag assignment**
- Cuando se asigna memoria (p. ej. en kernel o en user space mediante secure allocators), se asigna un **secret tag** a ese bloque.
- El pointer devuelto al user o al kernel incluye ese tag en sus bits altos (usando TBI / top byte ignore mechanisms).

2. **Tag checking on access**
- Siempre que se ejecuta una load o store usando un pointer, el hardware comprueba que el tag del pointer coincide con el tag del bloque de memoria (allocation tag). Si hay mismatch, ocurre un fault inmediatamente (ya que es síncrono).
- Al ser síncrono, no existe una ventana de “detención retardada” para la detección.

3. **Retagging on free / reuse**
- Cuando la memoria se libera, el allocator cambia el tag del bloque (por lo que pointers antiguos con tags viejos ya no coinciden).
- Un pointer use-after-free tendría por tanto un tag obsoleto y causaría un mismatch al acceder.

4. **Neighbor-tag differentiation to catch overflows**
- Las asignaciones adyacentes reciben tags distintos. Si un buffer overflow se desborda hacia la memoria del vecino, el mismatch de tags causa un fault.
- Esto es especialmente potente para detectar pequeños overflows que cruzan la boundary.

5. **Tag confidentiality enforcement**
- Apple debe evitar que los valores de tag sean leaked (porque si un atacante aprende el tag, podría construir pointers con tags correctos).
- Incluyen protecciones (controles microarquitecturales / especulativos) para evitar side-channel leakage de los bits de tag.

6. **Kernel and user-space integration**
- Apple usa EMTE no solo en user-space sino también en componentes críticos del kernel / OS (para proteger el kernel frente a la corrupción de memoria).
- El hardware/OS asegura que las reglas de tag se apliquen incluso cuando el kernel se ejecuta en nombre del user space.

<details>
<summary>Ejemplo</summary>
```
Allocate A = 0x1000, assign tag T1
Allocate B = 0x2000, assign tag T2

// pointer P points into A with tag T1
P = (T1 << 56) | 0x1000

// Valid store
*(P + offset) = value // tag T1 matches allocation → allowed

// Overflow attempt: P’ = P + size_of_A (into B region)
*(P' + delta) = value
→ pointer includes tag T1 but memory block has tag T2 → mismatch → fault

// Free A, allocator retags it to T3
free(A)

// Use-after-free:
*(P) = value
→ pointer still has old tag T1, memory region is now T3 → mismatch → fault
```
</details>

#### Limitaciones & desafíos

- **Intrablock overflows**: Si el overflow permanece dentro de la misma asignación (no cruza la frontera) y el tag permanece igual, tag mismatch no lo detecta.
- **Tag width limitation**: Solo unos pocos bits (p. ej. 4 bits, o un dominio pequeño) están disponibles para el tag—namespace limitado.
- **Side-channel leaks**: Si los tag bits pueden ser leaked (vía cache / speculative execution), el atacante puede aprender tags válidos y eludir la protección. La Tag Confidentiality Enforcement de Apple está pensada para mitigar esto.
- **Performance overhead**: Las comprobaciones de tag en cada load/store añaden coste; Apple debe optimizar el hardware para reducir el overhead.
- **Compatibility & fallback**: En hardware antiguo o en partes que no soportan EMTE, debe existir un fallback. Apple afirma que MIE solo está habilitado en dispositivos con soporte.
- **Complex allocator logic**: El allocator debe gestionar tags, retagging, alinear límites y evitar colisiones de mis-tags. Bugs en la lógica del allocator podrían introducir vulnerabilidades.
- **Mixed memory / hybrid areas**: Parte de la memoria puede permanecer untagged (legacy), haciendo la interoperabilidad más compleja.
- **Speculative / transient attacks**: Como con muchas protecciones microarquitecturales, la speculative execution o fusiones de micro-op podrían eludir las comprobaciones de forma transitoria o hacer tag bits leak.
- **Limited to supported regions**: Apple podría aplicar EMTE solo en áreas selectivas y de alto riesgo (kernel, subsistemas críticos de seguridad), no de forma universal.



---

## Key enhancements / differences compared to standard MTE

Aquí están las mejoras y cambios que Apple destaca:

| Feature | Original MTE | EMTE (Apple’s enhanced) / MIE |
|---|---|---|
| **Check mode** | Soporta modos synchronous y asynchronous. En async, los tag mismatches se reportan más tarde (delayed)| Apple insiste en **synchronous mode** por defecto—los tag mismatches se detectan inmediatamente, sin ventanas de delay/race.|
| **Coverage of non-tagged memory** | Accesos a memoria no-tagged (p. ej. globals) pueden evitar comprobaciones en algunas implementaciones | EMTE requiere que accesos desde una región tagged hacia memoria no-tagged también validen conocimiento del tag, dificultando eludir la protección mezclando allocations.|
| **Tag confidentiality / secrecy** | Los tags podrían ser observables o leak vía side channels | Apple añade **Tag Confidentiality Enforcement**, que intenta prevenir el leak de valores de tag (vía canales especulativos, etc.).|
| **Allocator integration & retagging** | MTE deja gran parte de la lógica del allocator al software | Los secure typed allocators de Apple (kalloc_type, xzone malloc, etc.) se integran con EMTE: cuando la memoria se asigna o libera, los tags se gestionan a granularidad fina.|
| **Always-on by default** | En muchas plataformas, MTE es opcional o está off por defecto | Apple habilita EMTE / MIE por defecto en hardware soportado (p. ej. iPhone 17 / A19) para kernel y muchos procesos de usuario.|

Porque Apple controla tanto el hardware como la pila de software, puede aplicar EMTE de forma estricta, evitar penalizaciones de rendimiento y cerrar agujeros de side-channel.

---

## How EMTE works in practice (Apple / MIE)

Aquí hay una descripción de alto nivel de cómo opera EMTE bajo el esquema MIE de Apple:

1. **Tag assignment**
- Cuando se asigna memoria (p. ej. en kernel o en user space vía secure allocators), se asigna un **secret tag** a ese bloque.
- El puntero devuelto al usuario o al kernel incluye ese tag en sus bits altos (usando TBI / top byte ignore mechanisms).

2. **Tag checking on access**
- Siempre que se ejecuta un load o store usando un puntero, el hardware comprueba que el tag del puntero coincida con el tag del bloque de memoria (allocation tag). Si hay mismatch, falla inmediatamente (ya que es synchronous).
- Al ser synchronous, no existe la ventana de “detección retrasada”.

3. **Retagging on free / reuse**
- Cuando la memoria se libera, el allocator cambia el tag del bloque (por lo que punteros antiguos con tags viejos ya no coinciden).
- Un puntero use-after-free por tanto tendrá un tag stale y causará mismatch al acceder.

4. **Neighbor-tag differentiation to catch overflows**
- A las allocations adyacentes se les asignan tags distintos. Si un buffer overflow se desborda hacia la memoria del vecino, el tag mismatch causa un fault.
- Esto es especialmente efectivo para detectar pequeños overflows que cruzan el límite.

5. **Tag confidentiality enforcement**
- Apple debe evitar que los valores de tag sean leak (porque si el atacante conoce el tag, podría fabricar punteros con tags correctos).
- Incluyen protecciones (controles microarquitecturales / especulativos) para evitar el leak de bits de tag.

6. **Kernel and user-space integration**
- Apple usa EMTE no solo en user-space sino también en componentes del kernel/OS críticos (para proteger el kernel contra corrupción de memoria).
- El hardware/OS asegura que las reglas de tag se apliquen incluso cuando el kernel ejecuta en nombre de user space.

Porque EMTE está integrado en MIE, Apple usa EMTE en modo synchronous en las superficies de ataque clave, no como opción o modo de depuración.



---

## Exception handling in XNU

Cuando ocurre una **exception** (p. ej., `EXC_BAD_ACCESS`, `EXC_BAD_INSTRUCTION`, `EXC_CRASH`, `EXC_ARM_PAC`, etc.), la capa **Mach** del kernel XNU es responsable de interceptarla antes de que se convierta en una señal al estilo UNIX (como `SIGSEGV`, `SIGBUS`, `SIGILL`, ...).

Este proceso involucra múltiples capas de propagación y manejo de excepciones antes de llegar al user space o convertirse en una señal BSD.


### Exception Flow (High-Level)

1.  **CPU triggers a synchronous exception** (p. ej., invalid pointer dereference, PAC failure, illegal instruction, etc.).

2.  **Low-level trap handler** runs (`trap.c`, `exception.c` en la fuente de XNU).

3.  El trap handler llama a **`exception_triage()`**, el núcleo del manejo de excepciones Mach.

4.  `exception_triage()` decide cómo enrutar la exception:

-   Primero al **thread's exception port**.

-   Luego al **task's exception port**.

-   Luego al **host's exception port** (a menudo `launchd` o `ReportCrash`).

Si ninguno de estos ports maneja la exception, el kernel puede:

-   **Convertirla en una BSD signal** (para procesos de user-space).

-   **Panic** (para excepciones en kernel-space).


### Core Function: `exception_triage()`

La función `exception_triage()` enruta las Mach exceptions a lo largo de la cadena de handlers posibles hasta que alguna la maneja o hasta que finalmente sea fatal. Está definida en `osfmk/kern/exception.c`.
```c
void exception_triage(exception_type_t exception, mach_exception_data_t code, mach_msg_type_number_t codeCnt);
```
**Flujo Típico de Llamadas:**

`exception_triage()
└── exception_deliver()
├── exception_deliver_thread()
├── exception_deliver_task()
└── exception_deliver_host()`

Si todo falla → manejado por `bsd_exception()` → convertido en una señal como `SIGSEGV`.


### Puertos de Excepción

Cada objeto Mach (thread, task, host) puede registrar **puertos de excepción**, donde se envían los mensajes de excepción.

Están definidos por la API:
```
task_set_exception_ports()
thread_set_exception_ports()
host_set_exception_ports()
```
Cada puerto de excepción tiene:

-   A **mask** (qué excepciones quiere recibir)
-   A **port name** (Mach port para recibir mensajes)
-   A **behavior** (cómo el kernel envía el mensaje)
-   A **flavor** (qué thread state incluir)


### Debuggers and Exception Handling

A **debugger** (e.g., LLDB) sets an **exception port** on the target task or thread, usually using `task_set_exception_ports()`.

**Cuando ocurre una excepción:**

-   El mensaje Mach se envía al proceso del debugger.
-   El debugger puede decidir **handle** (reanudar, modificar registros, saltar instrucción) o **not handle** la excepción.
-   Si el debugger no la maneja, la excepción se propaga al siguiente nivel (task → host).


### Flow of `EXC_BAD_ACCESS`

1.  El thread desreferencia un puntero inválido → CPU genera Data Abort.

2.  El manejador de traps del kernel llama a `exception_triage(EXC_BAD_ACCESS, ...)`.

3.  Mensaje enviado a:

-   Thread port → (el debugger puede interceptar breakpoint).

-   Si el debugger lo ignora → Task port → (manejador a nivel de proceso).

-   Si se ignora → Host port (usualmente ReportCrash).

4.  Si nadie la maneja → `bsd_exception()` traduce a `SIGSEGV`.


### PAC Exceptions

Cuando Pointer Authentication (PAC) falla (firma no coincide), se eleva una excepción Mach especial:

-   **`EXC_ARM_PAC`** (type)
-   Los códigos pueden incluir detalles (p. ej., tipo de key, tipo de pointer).

Si el binario tiene la flag **`TFRO_PAC_EXC_FATAL`**, el kernel trata fallos de PAC como **fatales**, evitando la intercepción del debugger. Esto es para prevenir que atacantes usen debuggers para eludir las comprobaciones PAC y está habilitado para binarios de plataforma.


### Software Breakpoints

A software breakpoint (`int3` on x86, `brk` on ARM64) is implemented by **causing a deliberate fault**.\
El debugger captura esto vía el exception port:

-   Modifica el instruction pointer o la memoria.
-   Restaura la instrucción original.
-   Reanuda la ejecución.

Este mismo mecanismo es lo que te permite "catch" una excepción PAC --- **a menos que `TFRO_PAC_EXC_FATAL`** esté establecida, en cuyo caso nunca llega al debugger.


### Conversion to BSD Signals

Si ningún manejador acepta la excepción:

-   El kernel llama a `task_exception_notify() → bsd_exception()`.

-   Esto mapea las excepciones Mach a señales:

| Excepción Mach | Señal |
| --- | --- |
| EXC_BAD_ACCESS | SIGSEGV or SIGBUS |
| EXC_BAD_INSTRUCTION | SIGILL |
| EXC_ARITHMETIC | SIGFPE |
| EXC_SOFTWARE | SIGTRAP |
| EXC_BREAKPOINT | SIGTRAP |
| EXC_CRASH | SIGKILL |
| EXC_ARM_PAC | SIGILL (si no es fatal) |


### Key Files in XNU Source

-   `osfmk/kern/exception.c` → Núcleo de `exception_triage()`, `exception_deliver_*()`.

-   `bsd/kern/kern_sig.c` → Lógica de entrega de señales.

-   `osfmk/arm64/trap.c` → Manejadores de trap de bajo nivel.

-   `osfmk/mach/exc.h` → Códigos de excepción y estructuras.

-   `osfmk/kern/task.c` → Configuración del task exception port.

---

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

El kernel usaba un **zone allocator** (`kalloc`) dividido en "zones" de tamaño fijo.  
Cada zone solo almacena asignaciones de una única clase de tamaño.

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | Estructuras muy pequeñas del kernel, punteros.                              |
| `default.kalloc.32`  | 32 bytes     | Estructuras pequeñas, cabeceras de objetos.                                 |
| `default.kalloc.64`  | 64 bytes     | IPC messages, buffers minúsculos del kernel.                                |
| `default.kalloc.128` | 128 bytes    | Objetos medianos como partes de `OSObject`.                                 |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | Estructuras grandes, metadatos de IOSurface/graphics.                       |

**Cómo funcionaba:**
- Cada petición de allocation se redondeaba hacia arriba al tamaño de zone más cercano.
(Ej., una petición de 50 bytes cae en la zone `kalloc.64`).
- La memoria en cada zone se mantenía en una **free list** — los chunks liberados por el kernel volvían a esa zone.
- Si desbordabas un buffer de 64 bytes, sobrescribirías el **objeto siguiente en la misma zone**.

Por eso **heap spraying / feng shui** era tan efectivo: podías predecir los vecinos de un objeto al realizar asignaciones de la misma clase de tamaño.

### The freelist

Dentro de cada kalloc zone, los objetos liberados no se devolvían directamente al sistema — iban a una freelist, una lista enlazada de chunks disponibles.

- Cuando se liberaba un chunk, el kernel escribía un puntero al inicio de ese chunk → la dirección del siguiente chunk libre en la misma zone.

- La zone mantenía un puntero HEAD al primer chunk libre.

- La allocation siempre usaba el HEAD actual:

1. Pop HEAD (devolver esa memoria al llamador).

2. Actualizar HEAD = HEAD->next (almacenado en el header del chunk liberado).

- El free empujaba chunks de vuelta:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Así que la freelist era simplemente una lista enlazada construida dentro de la propia memoria liberada.

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Explotación de la freelist

Debido a que los primeros 8 bytes de un free chunk = freelist pointer, un atacante podría corromperlo:

1. **Heap overflow** hacia un freed chunk adyacente → sobrescribir su “next” pointer.

2. **Use-after-free** que escriba en un freed object → sobrescribir su “next” pointer.

Luego, en la siguiente asignación de ese tamaño:

- El allocator extrae el corrupted chunk.

- Sigue el “next” pointer suministrado por el atacante.

- Devuelve un pointer a memoria arbitraria, habilitando fake object primitives o targeted overwrite.

Ejemplo visual de freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist design hizo que la explotación fuera muy efectiva antes de las hardening: vecinos predecibles por heap sprays, enlaces de freelist con punteros raw, y la ausencia de separación por tipo permitían a los atacantes escalar bugs UAF/overflow hacia control arbitrario de la memoria del kernel.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **dar forma a la disposición del heap** para que cuando un atacante dispare un overflow o use-after-free, el objeto objetivo (víctima) quede justo al lado de un objeto controlado por el atacante.\
De ese modo, cuando ocurre la corrupción de memoria, el atacante puede sobrescribir de forma fiable el objeto víctima con datos controlados.

**Pasos:**

1. Spray allocations (fill the holes)
- Con el tiempo, el kernel heap se fragmenta: algunas zonas tienen huecos donde se liberaron objetos antiguos.
- El atacante primero hace muchas allocaciones dummy para llenar esos huecos, de modo que el heap quede “empaquetado” y predecible.

2. Force new pages
- Una vez que los huecos están llenos, las siguientes allocations deben venir de nuevas páginas añadidas a la zona.
- Páginas nuevas significan que los objetos se agruparán juntos, no dispersos por memoria fragmentada antigua.
- Esto da al atacante mucho mejor control sobre los vecinos.

3. Place attacker objects
- El atacante ahora vuelve a sprayear, creando muchos objetos controlados por él en esas nuevas páginas.
- Estos objetos son predecibles en tamaño y ubicación (ya que todos pertenecen a la misma zone).

4. Free a controlled object (make a gap)
- El atacante libera deliberadamente uno de sus propios objetos.
- Esto crea un “hueco” en el heap, que el allocator reutilizará luego para la próxima allocation de ese tamaño.

5. Victim object lands in the hole
- El atacante provoca que el kernel aloque el objeto víctima (el que quiere corromper).
- Dado que el hueco es el primer slot disponible en la freelist, la víctima se coloca exactamente donde el atacante liberó su objeto.

6. Overflow / UAF into victim
- Ahora el atacante tiene objetos controlados alrededor de la víctima.
- Al overflow desde uno de sus propios objetos (o reutilizando uno liberado), puede sobrescribir de forma fiable los campos de memoria de la víctima con valores elegidos.

**Por qué funciona**:

- Predictibilidad del zone allocator: allocations del mismo tamaño siempre provienen de la misma zone.
- Comportamiento de la freelist: las nuevas allocations reutilizan primero el chunk liberado más recientemente.
- Heap sprays: el atacante llena la memoria con contenido predecible y controla el layout.
- Resultado final: el atacante controla dónde cae el objeto víctima y qué datos están adyacentes a él.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple hardened el allocator y hizo que **heap grooming sea mucho más difícil**:

### 1. From Classic kalloc to kalloc_type
- **Before**: existía una única zona `kalloc.<size>` para cada clase de tamaño (16, 32, 64, … 1280, etc.). Cualquier objeto de ese tamaño se colocaba ahí → los objetos del atacante podían quedar junto a objetos privilegiados del kernel.
- **Now**:
- Los objetos del kernel se asignan desde **typed zones** (`kalloc_type`).
- Cada tipo de objeto (p. ej., `ipc_port_t`, `task_t`, `OSString`, `OSData`) tiene su propia zona dedicada, incluso si tienen el mismo tamaño.
- El mapeo entre tipo de objeto ↔ zone se genera desde el **sistema kalloc_type** en tiempo de compilación.

Un atacante ya no puede garantizar que datos controlados (`OSData`) terminen adyacentes a objetos sensibles del kernel (`task_t`) del mismo tamaño.

### 2. Slabs and Per-CPU Caches
- El heap se divide en **slabs** (páginas de memoria partidas en chunks de tamaño fijo para esa zona).
- Cada zone tiene una **per-CPU cache** para reducir la contención.
- Ruta de allocation:
1. Intentar la per-CPU cache.
2. Si está vacía, sacar de la global freelist.
3. Si la freelist está vacía, alocar un nuevo slab (una o más páginas).
- **Beneficio**: esta descentralización hace que los heap sprays sean menos deterministas, ya que las allocations pueden satisfacerse desde caches de CPUs diferentes.

### 3. Randomization inside zones
- Dentro de una zone, los elementos liberados no se entregan en un simple orden FIFO/LIFO.
- XNU moderno usa **encoded freelist pointers** (safe-linking como Linux, introducido ~iOS 14).
- Cada freelist pointer está **XOR-encoded** con una cookie secreta por zone.
- Esto evita que los atacantes forjen un puntero de freelist falso si consiguen un write primitive.
- Algunas allocations se **aleatorizan en su colocación dentro de un slab**, así que sprayear no garantiza adyacencia.

### 4. Guarded Allocations
- Ciertos objetos críticos del kernel (p. ej., credenciales, estructuras de task) se asignan en **guarded zones**.
- Estas zones insertan **guard pages** (memoria no mapeada) entre slabs o usan **redzones** alrededor de objetos.
- Cualquier overflow hacia la guard page dispara una fault → pánico inmediato en lugar de corrupción silenciosa.

### 5. Page Protection Layer (PPL) and SPTM
- Incluso si controlas un objeto liberado, no puedes modificar toda la memoria del kernel:
- **PPL (Page Protection Layer)** hace cumplir que ciertas regiones (p. ej., datos de code signing, entitlements) sean **read-only** incluso para el propio kernel.
- En dispositivos **A15/M2+**, este rol se reemplaza/mejora por **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- Estas capas hardware-forzadas significan que los atacantes no pueden escalar desde una sola corrupción de heap a parcheo arbitrario de estructuras críticas de seguridad.
- **(Added / Enhanced)**: además, se usa **PAC (Pointer Authentication Codes)** en el kernel para proteger punteros (especialmente punteros a funciones, vtables) de modo que forjarlos o corromperlos sea más difícil.
- **(Added / Enhanced)**: las zones pueden imponer **zone_require / zone enforcement**, i.e. que un objeto liberado solo pueda retornarse a través de su zona tipada correcta; frees cross-zone inválidos pueden panicar o ser rechazados. (Apple alude a esto en sus posts sobre memory safety)

### 6. Large Allocations
- No todas las allocations pasan por `kalloc_type`.
- Requests muy grandes (por encima de ~16 KB) evitan las typed zones y se sirven directamente desde **kernel VM (kmem)** vía page allocations.
- Estas son menos predecibles, pero también menos explotables, ya que no comparten slabs con otros objetos.

### 7. Allocation Patterns Attackers Target
Aunque con estas protecciones, los atacantes aún buscan:
- **Reference count objects**: si puedes manipular contadores retain/release, puedes provocar use-after-free.
- **Objects with function pointers (vtables)**: corromper uno todavía puede dar control de flujo.
- **Shared memory objects (IOSurface, Mach ports)**: siguen siendo objetivos porque sirven de puente user ↔ kernel.

Pero — a diferencia de antes — no puedes simplemente sprayear `OSData` y esperar que esté al lado de un `task_t`. Necesitas bugs específicos por tipo o info leaks para tener éxito.

### Example: Allocation Flow in Modern Heap

Supongamos que userspace llama a IOKit para alocar un objeto `OSData`:

1. **Type lookup** → `OSData` mapea a la zona `kalloc_type_osdata` (size 64 bytes).
2. Check per-CPU cache for free elements.
- Si se encuentra → devolver uno.
- Si está vacío → ir a la global freelist.
- Si la freelist está vacía → alocar un nuevo slab (página de 4KB → 64 chunks de 64 bytes).
3. Devolver chunk al caller.

**Protección de freelist pointer**:
- Cada chunk liberado almacena la dirección del siguiente chunk libre, pero codificada con una llave secreta.
- Sobrescribir ese campo con datos del atacante no funcionará a menos que conozcas la llave.

---

## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages, and **PAC** protects pointers |
| Allocation reuse validation     | None (freelist pointers raw)                               | **zone_require / zone enforcement**             |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |
| Large allocations handling      | All small allocations managed equally                       | Large ones bypass zones → handled via VM         |

---

## Modern Userland Heap (iOS, macOS — type-aware / xzone malloc)

En versiones recientes de los OS de Apple (especialmente iOS 17+), Apple introdujo un allocator de userland más seguro, **xzone malloc** (XZM). Este es el análogo en user-space de `kalloc_type` del kernel, aplicando awareness por tipo, aislamiento de metadata y salvaguardas de memory tagging.

### Goals & Design Principles

- **Type segregation / type awareness**: agrupar allocations por *tipo o uso (pointer vs data)* para prevenir type confusion y reuse cross-type.
- **Metadata isolation**: separar metadata del heap (p. ej. free lists, bits de tamaño/estado) del payload de los objetos para que writes OOB sean menos probables de corromper metadata.
- **Guard pages / redzones**: insertar páginas no mapeadas o padding alrededor de allocations para detectar overflows.
- **Memory tagging (EMTE / MIE)**: trabajar junto con tagging hardware para detectar use-after-free, OOB y accesos inválidos.
- **Scalable performance**: mantener baja sobrecarga, evitar fragmentación excesiva y soportar muchas allocations por segundo con baja latencia.

### Architecture & Components

A continuación los elementos principales del allocator xzone:

#### Segment Groups & Zones

- **Segment groups** parten el address space por categorías de uso: p. ej. `data`, `pointer_xzones`, `data_large`, `pointer_large`.
- Cada segment group contiene **segments** (rangos VM) que alojan allocations para esa categoría.
- Asociado a cada segment hay un **metadata slab** (área VM separada) que almacena metadata (p. ej. bits free/used, clases de tamaño) para ese segment. Esta **metadata out-of-line (OOL)** asegura que la metadata no se mezcle con los payloads de los objetos, mitigando la corrupción por overflows.
- Los segments se dividen en **chunks** (slices) que a su vez se subdividen en **blocks** (unidades de allocation). Un chunk está ligado a una clase de tamaño y segment group específicos (i.e. todos los blocks en un chunk comparten mismo tamaño y categoría).
- Para allocations pequeñas/medias, se usan chunks de tamaño fijo; para large/huge, puede mapearse por separado.

#### Chunks & Blocks

- Un **chunk** es una región (a menudo varias páginas) dedicada a allocations de una clase de tamaño dentro de un grupo.
- Dentro de un chunk, los **blocks** son slots disponibles para allocations. Los blocks liberados se rastrean vía el metadata slab — p. ej. mediante bitmaps o free lists almacenadas out-of-line.
- Entre chunks (o dentro), pueden insertarse **guard slices / guard pages** (p. ej. slices no mapeadas) para capturar escrituras OOB.

#### Type / Type ID

- Cada sitio de allocation (o llamada a malloc, calloc, etc.) se asocia con un **type identifier** (un `malloc_type_id_t`) que codifica qué tipo de objeto se está allocando. Ese type ID se pasa al allocator, que lo usa para seleccionar qué zone / segment debe servir la allocation.
- Por esto, incluso si dos allocations tienen el mismo tamaño, pueden ir a zones totalmente distintas si sus tipos difieren.
- En las primeras versiones de iOS 17, no todas las APIs (p. ej. CFAllocator) eran plenamente type-aware; Apple abordó algunas de esas debilidades en iOS 18.

---

### Allocation & Freeing Workflow

Aquí hay un flujo de alto nivel de cómo operan allocation y deallocation en xzone:

1. **malloc / calloc / realloc / typed alloc** se invoca con un tamaño y type ID.
2. El allocator usa el **type ID** para elegir el segment group / zone correcta.
3. Dentro de esa zone/segment, busca un chunk que tenga blocks libres del tamaño solicitado.
- Puede consultar **local caches / per-thread pools** o **free block lists** desde la metadata.
- Si no hay ningún block libre disponible, puede alocar un nuevo chunk en esa zone.
4. Se actualiza el metadata slab (bit de free limpiado, bookkeeping).
5. Si memory tagging (EMTE) está activo, el block devuelto recibe una **tag** asignada, y la metadata se actualiza para reflejar su estado “live”.
6. Cuando se llama a `free()`:
- El block se marca como liberado en metadata (vía OOL slab).
- El block puede colocarse en una free list o almacenarse en pool para reuse.
- Opcionalmente, el contenido del block puede limpiarse o envenenarse para reducir leaks de datos o explotación UAF.
- La tag hardware asociada al block puede invalidarse o retaggearse.
- Si un chunk entero queda libre (todos los blocks liberados), el allocator puede **reclamar** ese chunk (desmapearlo o retornarlo al OS) bajo presión de memoria.

---

### Security Features & Hardening

Estas son las defensas incorporadas en el xzone moderno de userland:

| Feature | Purpose | Notes |
|---|-------------------------------|-----------------------------------------|
| **Metadata decoupling** | Prevent overflow from corrupting metadata | Metadata vive en una región VM separada (metadata slab)|
| **Guard pages / unmapped slices** | Catch out-of-bounds writes | Ayuda a detectar buffer overflows en lugar de corromper silenciosamente blocks adyacentes|
| **Type-based segregation** | Prevent cross-type reuse & type confusion | Incluso allocations del mismo tamaño pero de distinto tipo van a different zones|
| **Memory Tagging (EMTE / MIE)** | Detect invalid access, stale references, OOB, UAF | xzone trabaja en conjunto con hardware EMTE en modo síncrono (“Memory Integrity Enforcement”)|
| **Delayed reuse / poisoning / zap** | Reduce chance of use-after-free exploitation | Blocks liberados pueden ser envenenados, zerodeados o puestos en cuarentena antes de reuse |
| **Chunk reclamation / dynamic unmapping** | Reduce memory waste and fragmentation | Chunks enteros pueden desmapearse cuando no se usan |
| **Randomization / placement variation** | Prevent deterministic adjacency | Blocks en un chunk y la selección de chunk pueden tener aspectos randomizados |
| **Segregation of “data-only” allocations** | Separate allocations that don’t store pointers | Separa allocations que no almacenan punteros |

---

### Interaction with Memory Integrity Enforcement (MIE / EMTE)

- MIE (Memory Integrity Enforcement) de Apple es el framework hardware + OS que trae **Enhanced Memory Tagging Extension (EMTE)** a modo always-on y síncrono sobre superficies de ataque importantes.
- El allocator xzone es una base fundamental de MIE en user space: allocations hechas vía xzone obtienen tags, y los accesos son verificados por hardware.
- En MIE, el allocator, la asignación de tags, la gestión de metadata y la enforcement de confidencialidad de tags están integrados para asegurar que errores de memoria (p. ej. stale reads, OOB, UAF) se detecten inmediatamente y no se exploten después.

---

Si quieres, también puedo generar una cheat-sheet o un diagrama de los internos de xzone para tu libro. ¿Quieres que haga eso a continuación?
::contentReference[oai:20]{index=20}


---

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


## JSKit-Based Safari Chains and PREYHUNTER Stagers

### Renderer RCE abstraction with JSKit
- **Reusable entry**: Recent in-the-wild chains abused a WebKit JIT bug (patched as CVE-2023-41993) purely to gain JavaScript-level arbitrary read/write. The exploit immediately pivots into a purchased framework called **JSKit**, so any future Safari bug only needs to deliver the same primitive.
- **Version abstraction & PAC bypasses**: JSKit bundles support for a wide range of iOS releases together with multiple, selectable Pointer Authentication Code bypass modules. The framework fingerprints the target build, selects the appropriate PAC bypass logic, and verifies every step (primitive validation, shellcode launch) before progressing.
- **Manual Mach-O mapping**: JSKit parses Mach-O headers directly from memory, resolves the symbols it needs inside dyld-cached images, and can manually map additional Mach-O payloads without writing them to disk. This keeps the renderer process in-memory only and evades code-signature checks tied to filesystem artifacts.
- **Portfolio model**: Debug strings such as *"exploit number 7"* show that the suppliers maintain multiple interchangeable WebKit exploits. Once the JS primitive matches JSKit’s interface, the rest of the chain is unchanged across campaigns.

### Kernel bridge: IPC UAF -> code-sign bypass pattern
- **Kernel IPC UAF (CVE-2023-41992)**: The second stage, still running inside the Safari context, triggers a kernel use-after-free in IPC code, re-allocates the freed object from userland, and abuses the dangling pointers to pivot into arbitrary kernel read/write. The stage also reuses PAC bypass material previously computed by JSKit instead of re-deriving it.
- **Code-signing bypass (CVE-2023-41991)**: With kernel R/W available, the exploit patches the trust cache / code-signing structures so unsigned payloads execute as `system`. The stage then exposes a lightweight kernel R/W service to later payloads.
- **Composed pattern**: This chain demonstrates a reusable recipe that defenders should expect going forward:
```
WebKit renderer RCE -> kernel IPC UAF -> kernel arbitrary R/W -> code-sign bypass -> unsigned system stager
```
### Módulos helper & watcher de PREYHUNTER
- **Watcher anti-analysis**: Un binario watcher dedicado perfila continuamente el dispositivo y aborta la kill-chain cuando se detecta un entorno de investigación. Inspecciona `security.mac.amfi.developer_mode_status`, la presencia de una consola `diagnosticd`, locales `US` o `IL`, rastros de jailbreak como **Cydia**, procesos como `bash`, `tcpdump`, `frida`, `sshd`, o `checkrain`, apps AV móviles (McAfee, AvastMobileSecurity, NortonMobileSecurity), configuraciones de proxy HTTP personalizadas y CAs raíz personalizadas. Si falla cualquier comprobación se bloquea la entrega de payloads adicionales.
- **Helper surveillance hooks**: El componente helper se comunica con otras etapas a través de `/tmp/helper.sock`, luego carga conjuntos de hooks llamados **DMHooker** y **UMHooker**. Estos hooks interceptan rutas de audio VOIP (las grabaciones se almacenan en `/private/var/tmp/l/voip_%lu_%u_PART.m4a`), implementan un keylogger a nivel de sistema, capturan fotos sin UI, y enganchan SpringBoard para suprimir las notificaciones que esas acciones normalmente generarían. Por tanto, el helper actúa como una capa sigilosa de validación + vigilancia ligera antes de desplegar implantes más pesados como Predator.

### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

## Referencias

- [Google Threat Intelligence – Intellexa zero-day exploits continue](https://cloud.google.com/blog/topics/threat-intelligence/intellexa-zero-day-exploits-continue)

{{#include ../../banners/hacktricks-training.md}}
