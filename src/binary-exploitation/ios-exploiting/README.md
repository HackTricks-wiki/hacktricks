# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** in iOS는 앱, 라이브러리, 익스텐션 등 실행 가능한 모든 코드에 대해 Apple이 발급한 인증서로 암호학적 서명을 요구하는 방식으로 동작합니다. 코드가 로드될 때 iOS는 Apple의 신뢰 루트에 대해 디지털 서명을 검증합니다. 서명이 유효하지 않거나, 없거나, 변경된 경우 OS는 실행을 거부합니다. 이는 공격자가 정상 앱에 악성 코드를 주입하거나 서명되지 않은 바이너리를 실행하는 것을 방지하여 임의 또는 변조된 코드를 실행하는 대부분의 익스플로잇 체인을 차단합니다.
- **CoreTrust**는 런타임에서 code signing을 강제하는 iOS 서브시스템입니다. CoreTrust는 캐시된 신뢰 저장소에 의존하지 않고 Apple의 루트 인증서를 사용해 직접 서명을 검증하므로 Apple이 서명했거나 유효한 entitlements를 가진 바이너리만 실행될 수 있습니다. CoreTrust는 공격자가 설치 후 앱을 변조하거나 시스템 라이브러리를 수정하고 서명되지 않은 코드를 로드하려 해도, 코드가 올바르게 서명되어 있지 않으면 시스템이 실행을 차단하도록 보장합니다. 이러한 엄격한 적용은 이전 iOS 버전에서 약하거나 우회 가능한 서명 검사로 허용되던 많은 사후 익스플로잇 벡터를 차단합니다.
- **Data Execution Prevention (DEP)**는 메모리 영역을 명시적으로 코드가 포함되어 있지 않는 한 비실행(executable)으로 표시합니다. 이는 공격자가 스택이나 힙 같은 데이터 영역에 shellcode를 주입해 실행하는 것을 막아 ROP(Return-Oriented Programming) 같은 더 복잡한 기법에 의존하게 만듭니다.
- **ASLR (Address Space Layout Randomization)**는 코드, 라이브러리, 스택, 힙의 메모리 주소를 매번 시스템 실행 시 무작위화합니다. 이는 공격자가 유용한 명령이나 가젯의 위치를 예측하기 어렵게 만들어 고정된 메모리 레이아웃에 의존하는 많은 익스플로잇 체인을 깨뜨립니다.
- **KASLR (Kernel ASLR)**는 동일한 무작위화 개념을 iOS 커널에 적용합니다. 부팅마다 커널의 베이스 주소를 섞음으로써 공격자가 커널 함수나 구조체의 위치를 신뢰성 있게 찾는 것을 방지하여 커널 수준 익스플로잇의 난이도를 높입니다.
- **Kernel Patch Protection (KPP)** (iOS에서는 **AMCC (Apple Mobile File Integrity)** 라고도 함)는 커널의 코드 페이지가 변경되지 않았는지 지속적으로 모니터링합니다. 익스플로잇이 커널 함수를 패치하거나 악성 코드를 삽입하려는 시도가 감지되면 장치는 즉시 panic 상태가 되어 재부팅됩니다. 이 보호 기능은 공격자가 단순히 커널 명령을 후킹하거나 패치하여 지속성을 얻는 것을 훨씬 어렵게 만듭니다.
- **Kernel Text Readonly Region (KTRR)**는 iOS 장치에 도입된 하드웨어 기반 보안 기능입니다. CPU의 메모리 컨트롤러를 사용해 부팅 이후에 커널의 코드(text) 섹션을 영구적으로 읽기 전용으로 표시합니다. 일단 잠기면 커널 자체조차 이 메모리 영역을 수정할 수 없습니다. 이는 공격자나 권한 있는 코드조차 런타임에 커널 명령을 패치하는 것을 막아 직접 커널 코드를 수정하던 주요 클래스의 익스플로잇을 차단합니다.
- **Pointer Authentication Codes (PAC)**는 포인터의 사용 전에 무결성을 검증하기 위해 포인터의 남는 비트에 암호화 서명을 포함합니다. 포인터(예: 반환 주소나 함수 포인터)가 생성될 때 CPU가 비밀 키로 서명하고, 역참조하기 전에 CPU가 서명을 검사합니다. 포인터가 변조되었다면 검사가 실패하고 실행이 중단됩니다. 이는 공격자가 메모리 손상 익스플로잇에서 포인터를 위조하거나 재사용하는 것을 방지하여 ROP나 JOP 같은 기법을 안정적으로 수행하기 어렵게 만듭니다.
- **Privilege Access never (PAN)**는 커널(특권 모드)이 명시적으로 접근을 활성화하지 않는 한 사용자 공간 메모리에 직접 접근하는 것을 방지하는 하드웨어 기능입니다. 이는 커널 코드 실행을 획득한 공격자가 사용자 메모리를 쉽게 읽거나 써서 권한 상승을 하거나 민감한 데이터를 훔치는 것을 차단합니다. 엄격한 분리를 시행함으로써 PAN은 커널 익스플로잇의 영향을 줄이고 많은 일반적인 권한 상승 기법을 차단합니다.
- **Page Protection Layer (PPL)**는 특히 code signing 및 entitlements와 관련된 중요한 커널 관리 메모리 영역을 보호하는 iOS 보안 메커니즘입니다. PPL은 MMU(Memory Management Unit)와 추가 검사를 사용하여 엄격한 쓰기 보호를 시행하므로 권한이 있는 커널 코드조차 민감한 페이지를 임의로 수정할 수 없습니다. 이는 커널 수준 실행을 획득한 공격자가 보안에 중요한 구조체를 변조하여 지속성을 확보하거나 code-signing을 우회하는 것을 훨씬 어렵게 만듭니다.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

커널은 고정 크기의 "zones"로 나뉜 **zone allocator** (`kalloc`)를 사용했습니다.
각 zone은 단일 크기 클래스의 할당만 저장했습니다.

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | 매우 작은 커널 구조체, 포인터.                                                |
| `default.kalloc.32`  | 32 bytes     | 작은 구조체, 객체 헤더.                                                      |
| `default.kalloc.64`  | 64 bytes     | IPC 메시지, 작은 커널 버퍼.                                                  |
| `default.kalloc.128` | 128 bytes    | `OSObject`의 일부 같은 중간 크기 객체.                                       |
| `default.kalloc.256` | 256 bytes    | 더 큰 IPC 메시지, 배열, 디바이스 구조체.                                      |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | 큰 구조체, IOSurface/graphics metadata.                                     |

작동 방식:
- 각 할당 요청은 가장 가까운 zone 크기로 **올림(rounded up)** 됩니다.
(예: 50바이트 요청은 `kalloc.64` zone에 배치됩니다).
- 각 zone의 메모리는 **freelist**에 보관되었습니다 — 커널이 해제한 청크는 해당 zone으로 돌아갔습니다.
- 64바이트 버퍼를 오버플로우하면 동일한 zone의 **다음 객체를 덮어쓰게** 됩니다.

이 때문에 **heap spraying / feng shui**가 매우 효과적이었습니다: 같은 크기 클래스의 할당을 뿌리면 객체의 이웃을 예측할 수 있었습니다.

### The freelist

각 kalloc zone 내부에서 해제된 객체들은 시스템에 직접 반환되지 않고 freelist에 들어갔습니다. freelist는 사용 가능한 청크들의 연결 리스트였습니다.

- 청크가 해제될 때, 커널은 그 청크의 시작 부분에 포인터를 작성했습니다 → 동일한 zone 내의 다음 자유 청크의 주소.
- zone은 첫 번째 자유 청크를 가리키는 HEAD 포인터를 유지했습니다.
- 할당은 항상 현재 HEAD를 사용했습니다:

1. Pop HEAD (그 메모리를 호출자에게 반환).

2. HEAD = HEAD->next (해제된 청크의 헤더에 저장된 값으로 업데이트).

- 해제는 청크를 다시 푸시했습니다:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

따라서 freelist는 해제된 메모리 자체 안에 구성된 단순한 연결 리스트였습니다.

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### freelist 악용

Because the first 8 bytes of a free chunk = freelist pointer, an attacker could corrupt it:

1. **Heap overflow** into an adjacent freed chunk → 그 “next” pointer를 덮어쓴다.

2. **Use-after-free** write into a freed object → 그 “next” pointer를 덮어쓴다.

Then, on the next allocation of that size:

- 할당자는 손상된 청크를 팝한다.
- 공격자가 제공한 “next” pointer를 따라간다.
- 임의 메모리에 대한 포인터를 반환하여 fake object primitives 또는 targeted overwrite를 가능하게 한다.

Visual example of freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
이 freelist 설계는 하드닝 이전에 익스플로잇을 매우 효과적으로 만들었습니다: heap sprays로 인한 예측 가능한 인접 객체, raw pointer freelist 링크, 그리고 타입 분리가 없어 공격자가 UAF/overflow 버그를 임의의 커널 메모리 제어로 승격시킬 수 있었습니다.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Over time, the kernel heap gets fragmented: some zones have holes where old
objects were freed.
- The attacker first makes lots of dummy allocations to fill these gaps, so
the heap becomes “packed” and predictable.

2. Force new pages
- Once the holes are filled, the next allocations must come from new pages
added to the zone.
- Fresh pages mean objects will be clustered together, not scattered across
old fragmented memory.
- This gives the attacker much better control of neighbors.

3. Place attacker objects
- The attacker now sprays again, creating lots of attacker-controlled objects
in those new pages.
- These objects are predictable in size and placement (since they all belong
to the same zone).

4. Free a controlled object (make a gap)
- The attacker deliberately frees one of their own objects.
- This creates a “hole” in the heap, which the allocator will later reuse for
the next allocation of that size.

5. Victim object lands in the hole
- The attacker triggers the kernel to allocate the victim object (the one
they want to corrupt).
- Since the hole is the first available slot in the freelist, the victim is
placed exactly where the attacker freed their object.

6. Overflow / UAF into victim
- Now the attacker has attacker-controlled objects around the victim.
- By overflowing from one of their own objects (or reusing a freed one), they
can reliably overwrite the victim’s memory fields with chosen values.

**Why it works**:

- Zone allocator predictability: allocations of the same size always come from
the same zone.
- Freelist behavior: new allocations reuse the most recently freed chunk first.
- Heap sprays: attacker fills memory with predictable content and controls layout.
- End result: attacker controls where the victim object lands and what data sits
next to it.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple hardened the allocator and made **heap grooming much harder**:

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

An attacker can no longer guarantee that controlled data (`OSData`) ends up adjacent to sensitive kernel objects (`task_t`) of the same size.

### 2. Slabs and Per-CPU Caches
- The heap is divided into **slabs** (pages of memory carved into fixed-size chunks for that zone).
- Each zone has a **per-CPU cache** to reduce contention.
- Allocation path:
1. Try per-CPU cache.
2. If empty, pull from the global freelist.
3. If freelist is empty, allocate a new slab (one or more pages).
- **Benefit**: This decentralization makes heap sprays less deterministic, since allocations may be satisfied from different CPUs’ caches.

### 3. Randomization inside zones
- Within a zone, freed elements are not handed back in simple FIFO/LIFO order.
- Modern XNU uses **encoded freelist pointers** (safe-linking like Linux, introduced ~iOS 14).
- Each freelist pointer is **XOR-encoded** with a per-zone secret cookie.
- This prevents attackers from forging a fake freelist pointer if they gain a write primitive.
- Some allocations are **randomized in their placement within a slab**, so spraying doesn’t guarantee adjacency.

### 4. Guarded Allocations
- Certain critical kernel objects (e.g., credentials, task structures) are allocated in **guarded zones**.
- These zones insert **guard pages** (unmapped memory) between slabs or use **redzones** around objects.
- Any overflow into the guard page triggers a fault → immediate panic instead of silent corruption.

### 5. Page Protection Layer (PPL) and SPTM
- Even if you control a freed object, you can’t modify all of kernel memory:
- **PPL (Page Protection Layer)** enforces that certain regions (e.g., code signing data, entitlements) are **read-only** even to the kernel itself.
- On **A15/M2+ devices**, this role is replaced/enhanced by **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- These hardware-enforced layers mean attackers can’t escalate from a single heap corruption to arbitrary patching of critical security structures.

### 6. Large Allocations
- Not all allocations go through `kalloc_type`.
- Very large requests (above ~16KB) bypass typed zones and are served directly from **kernel VM (kmem)** via page allocations.
- These are less predictable, but also less exploitable, since they don’t share slabs with other objects.

### 7. Allocation Patterns Attackers Target
Even with these protections, attackers still look for:
- **Reference count objects**: if you can tamper with retain/release counters, you may cause use-after-free.
- **Objects with function pointers (vtables)**: corrupting one still yields control flow.
- **Shared memory objects (IOSurface, Mach ports)**: these are still attack targets because they bridge user ↔ kernel.

But — unlike before — you can’t just spray `OSData` and expect it to neighbor a `task_t`. You need **type-specific bugs** or **info leaks** to succeed.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Each freed chunk stores the address of the next free chunk, but encoded with a secret key.
- Overwriting that field with attacker data won’t work unless you know the key.


## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and install it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


{{#include ../../banners/hacktricks-training.md}}
