# iOS Uitbuiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigasies

### 1. **Code Signing** / Runtime Signature Verification
**Ingevoer vroeg (iPhone OS → iOS)**
Dit is een van die fundamentele beskermings: **alle uitvoerbare kode** (apps, dynamic libraries, JIT-ed code, extensions, frameworks, caches) moet kriptografies onderteken wees deur 'n sertifikaatketting wat in Apple se trust gewortel is. Tydens uitvoering, voordat 'n binêre in geheue gelaai word (of voordat spronge oor sekere grense uitgevoer word), kontroleer die stelsel sy handtekening. As die kode gewysig is (bit-flipped, gepatch) of ongeteken, misluk die laai.

- **Voorkom**: die “klassieke payload drop + execute” stadium in exploit-chains; arbitrary code injection; die wysiging van 'n bestaande binêre om kwaadwillige logika in te voeg.
- **Meganisme besonderhede**:
* Die Mach-O loader (en dynamic linker) kontroleer code pages, segmente, entitlements, team IDs, en dat die handtekening die lêer se inhoud dek.
* Vir geheuegebiede soos JIT caches of dinamies gegenereerde kode, dwing Apple dat bladsye geteken of gevalideer moet wees via spesiale APIs (bv. `mprotect` met code-sign checks).
* Die handtekening sluit entitlements en identifiers in; die OS dwing af dat sekere APIs of bevoorregte vermoëns spesifieke entitlements vereis wat nie vervals kan word nie.

<details>
<summary>Voorbeeld</summary>
Stel 'n exploit kry code execution in 'n proses en probeer shellcode op 'n heap skryf en daarna na dit jump. Op iOS sou daardie bladsy as executable gemerk moet wees **en** aan code-signature-vereistes voldoen. Omdat die shellcode nie met Apple se sertifikaat geteken is nie, misluk die jump of weier die stelsel om daardie geheuegebied executable te maak.
</details>


### 2. **CoreTrust**
**Ingevoer rondom iOS 14+ era (of geleidelik op nuwer toestelle / later iOS)**
CoreTrust is die subsisteem wat **runtime signature validation** van binaries uitvoer (insluitend stelsel- en gebruikersbinaries) teen **Apple’s root certificate** eerder as om op gecachte userland trust stores te staatmaak.

- **Voorkom**: post-install tampering van binaries, jailbreaking-tegnieke wat probeer om system libraries of user apps te swap of te patch; die stelsel mislei deur vertroude binaries met kwaadwillige eweknieë te vervang.
- **Meganisme besonderhede**:
* In plaas daarvan om 'n plaaslike trust-databasis of sertifikaat-cache te vertrou, haal CoreTrust Apple se root direk of verifieer intermediate certificates in 'n veilige ketting.
* Dit verseker dat wysigings (bv. in die filesystem) aan bestaande binaries opgespoor en geweier word.
* Dit bind entitlements, team IDs, code signing flags en ander metadata aan die binêre tydens laai.

<details>
<summary>Voorbeeld</summary>
’n jailbreak mag probeer om `SpringBoard` of `libsystem` te vervang met 'n gepatchte weergawe om persistentie te kry. Maar wanneer die OS se loader of CoreTrust kontroleer, sien dit die handtekening-onovereenstemming (of gewysigde entitlements) en weier om dit uit te voer.
</details>


### 3. **Data Execution Prevention (DEP / NX / W^X)**
**Ingevoer in baie OS'e vroeër; iOS het NX-bit / w^x al lank**
DEP dwing af dat bladsye wat as writable (vir data) gemerk is, **nie-executable** is, en bladsye wat executable is, **nie-writable** is. Jy kan nie net shellcode in 'n heap of stack-area skryf en dit uitvoer nie.

- **Voorkom**: direkte shellcode-execution; klassieke buffer-overflow → jump na geïnjekteerde shellcode.
- **Meganisme besonderhede**:
* Die MMU / memory protection flags (via page tables) dwing die skeiding af.
* Enige poging om 'n writable bladsy executable te merk, aktiveer 'n stelselkontrole (en word óf verbied óf vereis code-sign approval).
* In baie gevalle vereis dit om bladsye executable te maak dat jy OS APIs gebruik wat addisionele beperkings of kontroles afdwing.

<details>
<summary>Voorbeeld</summary>
'n overflow skryf shellcode op die heap. Die aanvaller probeer `mprotect(heap_addr, size, PROT_EXEC)` om dit executable te maak. Maar die stelsel weier of valideer dat die nuwe bladsy code-sign constraints moet passeer (wat die shellcode nie doen nie).
</details>

### 4. **Address Space Layout Randomization (ASLR)**
**Ingevoer in iOS ~4–5 era (ongeveer iOS 4–5 tydperk)**
ASLR randomiseer die basisadresse van sleutel geheuegebiede: libraries, heap, stack, ens., by elke proses se aanvang. Gadgets se adresse verander tussen aanslae.

- **Voorkom**: hardcoding van gadget-adresse vir ROP/JOP; statiese exploit-chain; blind jumping na bekende offsets.
- **Meganisme besonderhede**:
* Elke gelaaide library / dynamic module word op 'n gerandomiseerde offset herbasis.
* Stack- en heap-basiswysers word gerandomiseer (binne sekere entropy-grense).
* Soms word ander gebiede (bv. mmap allocations) ook gerandomiseer.
* Gekombineer met information-leak mitigations, dwing dit die aanvaller om eers 'n adres of pointer te leak om basisadresse tydens uitvoering te ontdek.

<details>
<summary>Voorbeeld</summary>
'n ROP-ketting verwag 'n gadget by `0x….lib + offset`. Maar aangesien `lib` elke run anders herlokaliseer word, misluk die hardgekodeerde ketting. 'n Exploit moet eers die base address van die module leak voordat gadget-adresse bereken kan word.
</details>


### 5. **Kernel Address Space Layout Randomization (KASLR)**
**Ingevoer in iOS ~ (iOS 5 / iOS 6 tydperk)**
Analoog met user ASLR, KASLR randomiseer die basis van die **kernel text** en ander kernel-strukture tydens opstart.

- **Voorkom**: kernel-level exploits wat op vaste ligging van kernel-kode of -data staatmaak; statiese kernel exploits.
- **Meganisme besonderhede**:
* By elke boot word die kernel se basisadres gerandomiseer (binne 'n reeks).
* Kernel datastrukture (soos `task_structs`, `vm_map`, ens.) kan ook herlokaliseer of verskuif word.
* Aanvallers moet eers kernel pointers leak of gebruik maak van information disclosure kwesbaarhede om offsets te bereken voordat hulle kernel-strukture of kode kaap.

<details>
<summary>Voorbeeld</summary>
'n plaaslike kwetsbaarheid mik om 'n kernel function pointer (bv. in `vtable`) by `KERN_BASE + offset` te korrupteer. Maar aangesien `KERN_BASE` onbekend is, moet die aanvaller dit eers leak (bv. via 'n read primitive) voordat die korrekte adres vir korrupsie bereken kan word.
</details>


### 6. **Kernel Patch Protection (KPP / AMCC)**
**Ingevoer in nuwer iOS / A-series hardware (post omtrent iOS 15–16 era of nuwer chips)**
KPP (aka AMCC) monitor voortdurend die integriteit van kernel text bladsye (via hash of checksum). As dit tampering (patches, inline hooks, kode-wysigings) buite toegelate vensters ontdek, veroorsaak dit 'n kernel panic of herbegin.

- **Voorkom**: persistent kernel patching (wysiging van kernel-instruksies), inline hooks, statiese funksie-oor-skrywings.
- **Meganisme besonderhede**:
* 'n Hardware- of firmware-module monitor die kernel text area.
* Dit her-hash bladsye periodies of op aanvraag en vergelyk teen verwagte waardes.
* As mismatch plaasvind buite ordentlike update-vensters, panikeer dit die toestel (om persistent kwaadwilligheid te voorkom).
* Aanvallers moet óf deteckie-vensters vermy óf wettige patch-paaie gebruik.

<details>
<summary>Voorbeeld</summary>
'n exploit probeer 'n kernel-funksie proloog (bv. `memcmp`) te patch om oproepe te onderskep. Maar KPP raaksien dat die code-bladsy se hash nie meer by die verwagte waarde pas nie en veroorsaak 'n kernel panic, wat die toestel laat crash voordat die patch kon konsolideer.
</details>


### 7. **Kernel Text Read‐Only Region (KTRR)**
**Ingevoer in moderne SoCs (post ~A12 / nuwer hardware)**
KTRR is 'n hardware-afgedwinge meganisme: sodra die kernel text vroeg tydens boot gesluit word, word dit read-only vanaf EL1 (die kernel), wat verdere skryfbevoegdheid na code-bladsye voorkom.

- **Voorkom**: enige wysigings aan kernel-kode ná boot (bv. patching, in-place code injection) op EL1 privilege-vlak.
- **Meganisme besonderhede**:
* Tydens boot (in secure/bootloader-stadium) merk die memory controller (of 'n secure hardware-eenheid) die fisiese bladsye wat kernel text bevat as read-only.
* Selfs as 'n exploit volle kernel-privileges kry, kan dit nie daardie bladsye skryf om instruksies te patch nie.
* Om dit te wysig, moet die aanvaller eers die boot ketting kompromitteer, of KTRR self ondermyn.

<details>
<summary>Voorbeeld</summary>
'n privilege-escalation exploit spring na EL1 en skryf 'n trampoline in 'n kernel-funksie (bv. in `syscall` handler). Maar omdat die bladsye deur KTRR as read-only gemerk is, misluk die skryf (of veroorsaak 'n fout), so patches word nie toegepas nie.
</details>


### 8. **Pointer Authentication Codes (PAC)**
**Ingevoer met ARMv8.3 (hardware), Apple begin by A12 / iOS ~12+**
- PAC is 'n hardware-funksie wat in **ARMv8.3-A** ingestel is om die manipulasie van pointer-waardes (return addresses, function pointers, sekere data pointers) op te spoor deur 'n klein kriptografiese handtekening (’n “MAC”) in ongebruikte hoë-bits van die pointer in te sluit.
- Die handtekening (“PAC”) word bereken oor die pointer-waarde plus 'n **modifier** (’n kontekswaarde, bv. stack pointer of ander onderskeidende data). So kry dieselfde pointer-waarde in verskillende kontekste 'n ander PAC.
- By gebruikstyd hou 'n **authenticate** instruksie die PAC na. As dit geldig is, word die PAC gestript en die suiwer pointer verkry; as dit ongeldig is, word die pointer “poisoned” (of 'n fout word opgegooi).
- Die sleutels wat vir die produksie/validering van PACs gebruik word, woon in bevoorregte registers (EL1, kernel) en is nie direk leesbaar vanaf user mode nie.
- Omdat nie alle 64-bits van 'n pointer in baie stelsels gebruik word nie (bv. 48-bit adresruimte), is die boonste bits “spaar” en kan die PAC daarin gehou word sonder om die effektiewe adres te verander.

#### Architecturale Basis & Sleutelsoorte

- ARMv8.3 bring in **vyf 128-bit sleutels** (elkeen geïmplementeer via twee 64-bit stelselregisters) vir pointer authentication.
- **APIAKey** — vir instruction pointers (domein “I”, sleutel A)
- **APIBKey** — tweede instruction pointer sleutel (domein “I”, sleutel B)
- **APDAKey** — vir data pointers (domein “D”, sleutel A)
- **APDBKey** — vir data pointers (domein “D”, sleutel B)
- **APGAKey** — “generic” sleutel, vir signing van nie-pointer data of ander generiese gebruike

- Hierdie sleutels word in bevoorregte stelselregisters gestoor (toeganklik slegs by EL1/EL2 ens.), nie toeganklik vanuit user mode nie.
- Die PAC word bereken via 'n kriptografiese funksie (ARM beveel QARMA as die algoritme voor) wat gebruik maak van:
1. Die pointer-waarde (kanoniese gedeelte)
2. 'n **modifier** (’n kontekswaarde, soos 'n salt)
3. Die geheime sleutel
4. Sommige interne tweak-logika
As die resulting PAC ooreenstem met wat in die boonste bits van die pointer gestoor is, slaag authenticatie.

#### Instruksiefamilies

Die naamkonvensie is: **PAC** / **AUT** / **XPAC**, dan domeinletters.
- `PACxx` instruksies **sign** 'n pointer en voeg 'n PAC in
- `AUTxx` instruksies **authenticate + strip** (valideer en verwyder die PAC)
- `XPACxx` instruksies **strip** sonder validasie

Domeine / suffixes:

| Mnemonic     | Meaning / Domain                      | Key / Domain     | Example Usage in Assembly |
|--------------|-----------------------------------------|--------------------|-----------------------------|
| **PACIA**    | Onderteken instruction pointer met APIAKey   | “I, A”             | `PACIA X0, X1` — sign pointer in X0 using APIAKey with modifier X1|
| **PACIB**    | Onderteken instruction pointer met APIBKey   | “I, B”             | `PACIB X2, X3`              |
| **PACDA**    | Onderteken data pointer met APDAKey           | “D, A”             | `PACDA X4, X5`              |
| **PACDB**    | Onderteken data pointer met APDBKey           | “D, B”             | `PACDB X6, X7`              |
| **PACG / PACGA** | Generies (nie-pointer) ondertekening met APGAKey | “G”         | `PACGA X8, X9, X10` (sign X9 with modifier X10 into X8) |
| **AUTIA**    | Authenticate APIA-onderteken instruction pointer & strip PAC | “I, A” | `AUTIA X0, X1` — check PAC on X0 using modifier X1, then strip |
| **AUTIB**    | Authenticate APIB domein                 | “I, B”             | `AUTIB X2, X3`               |
| **AUTDA**    | Authenticate APDA-onderteken data pointer    | “D, A”             | `AUTDA X4, X5`               |
| **AUTDB**    | Authenticate APDB-onderteken data pointer    | “D, B”             | `AUTDB X6, X7`               |
| **AUTGA**    | Authenticate generies / blob (APGA)        | “G”               | `AUTGA X8, X9, X10` (validate generic) |
| **XPACI**     | Verwyder PAC (instruction pointer, geen validasie) | “I”         | `XPACI X0` — remove PAC from X0 (instruction domain) |
| **XPACD**     | Verwyder PAC (data pointer, geen validasie)    | “D”             | `XPACD X4` — remove PAC from data pointer in X4 |


Daar is gespesialiseerde / alias-vorme:

- `PACIASP` is afkorting vir `PACIA X30, SP` (onderteken die link register met SP as modifier)
- `AUTIASP` is `AUTIA X30, SP` (authenticate link register met SP)
- Gekombineerde vorms soos `RETAA`, `RETAB` (authenticate-and-return) of `BLRAA` (authenticate & branch) bestaan in ARM-uitbreidings / compiler-ondersteuning.
- Ook zero-modifier variante: `PACIZA` / `PACIZB` waar die modifier implisiet nul is, ens.

#### Modifiers

Die hoofdoel van die modifier is om die PAC te **bind aan 'n spesifieke konteks** sodat dieselfde adres onderteken in verskillende kontekste verskillende PACs gee. Dit voorkom eenvoudige pointer-hergebruik oor rame of objecte. Dit is soos om 'n **salt by 'n hash** te voeg.

Dus:
- Die **modifier** is 'n kontekswaarde (nog 'n register) wat in die PAC-berekening gemeng word. Tipiese keuses: die stack pointer (`SP`), 'n frame pointer, of 'n object ID.
- Die gebruik van SP as modifier is algemeen vir return address signing: die PAC word verbind aan die spesifieke stack-frame. As jy probeer om die LR in 'n ander raam te hergebruik, verander die modifier, en validering van PAC misluk.
- Dieselfde pointer-waarde wat onder verskillende modifiers geteken is, gee verskillende PACs.
- Die modifier hoef **nie geheim** te wees nie, maar idealiter is dit nie deur die aanvaller beheer nie.
- Vir instruksies wat pointers teken of verifieer waar geen sinvolle modifier bestaan nie, gebruik sommige vorme nul of 'n implisiete konstante.

#### Apple / iOS / XNU Aanpassings & Waarnemings

- Apple se PAC-implementering sluit **per-boot diversifiers** in sodat sleutels of tweaks by elke boot verander, wat hergebruik oor boots verhoed.
- Hulle sluit ook **cross-domain mitigations** in sodat PACs wat in user mode geteken is nie maklik in kernel mode hergebruik kan word nie, ens.
- Op Apple M1 / Apple Silicon het omgekeerde ingenieurswese getoon dat daar **nege modifier-tipes** en Apple-spesifieke stelselregisters vir sleutelbeheer is.
- Apple gebruik PAC oor baie kernel-substelsels: return address signing, pointer-integriteit in kernel-data, getekende thread contexts, ens.
- Google Project Zero het getoon hoe, onder 'n magtige memory read/write primitive in die kernel, 'n aanvaller kernel PACs (vir A sleutels) op A12-era toestelle kon vervals, maar Apple het baie van daardie paaie gepatch.
- In Apple se stelsel is sommige sleutels **globaal oor die kernel**, terwyl gebruikerprosesse per-proses sleutel-willekeurigheid kan kry.

#### PAC Bypasses

1. **Kernel-mode PAC: teoreties vs werklike bypasses**

-   Omdat kernel PAC-sleutels en logika noukeurig beheer word (bevoorregte registers, diversifiers, domein-isolasie), is dit baie moeilik om arbitrêre getekende kernel-pointers te vervals.
-   Azad se 2020 "iOS Kernel PAC, One Year Later" rapporteer dat in iOS 12-13 hy 'n paar gedeeltelike bypasses gevind het (signing gadgets, hergebruik van getekende states, onbeskermde indirekte takke) maar geen volledige generiese bypass nie. [bazad.github.io](https://bazad.github.io/presentations/BlackHat-USA-2020-iOS_Kernel_PAC_One_Year_Later.pdf)
-   Apple se "Dark Magic" aanpassings beperk die exploiteerbare oppervlakke verder (domeinwisseling, per-sleutel aan-/af-skuifbits). [i.blackhat.com](https://i.blackhat.com/BH-US-23/Presentations/US-23-Zec-Apple-PAC-Four-Years-Later.pdf)
-   Daar is 'n bekende **kernel PAC bypass CVE-2023-32424** op Apple silicon (M1/M2) gerapporteer deur Zecao Cai et al. [i.blackhat.com](https://i.blackhat.com/BH-US-23/Presentations/US-23-Zec-Apple-PAC-Four-Years-Later.pdf)
-   Maar hierdie bypasses berus dikwels op baie spesifieke gadgets of implementasiebugs; hulle is nie generiese bypasses nie.

Dus word kernel PAC geag as **baie robuust**, alhoewel nie perfek nie.

2. **User-mode / runtime PAC bypass tegnieke**

Hierdie is meer algemeen, en misbruik onvolmaakthede in hoe PAC toegepas word of in dinamiese linking / runtime frameworks. Hieronder is klasse met voorbeelde.

2.1 **Shared Cache / A key issues**

-   Die **dyld shared cache** is 'n groot pre-linked blob van stelsel frameworks en libraries. Omdat dit so wyd gedeel word, is funksiepointers binne die shared cache "pre-signed" en word dan deur baie prosesse gebruik. Aanvallers mik na hierdie reeds-getekende pointers as "PAC oracles".

-   Sommige bypass-tegnieke probeer om A-key getekende pointers wat in die shared cache voorkom, te onttrek of te hergebruik in gadgets.

-   Die "No Clicks Required" praatjie beskryf die bou van 'n orakel oor die shared cache om relatiewe adresse af te lei en dit met getekende pointers te kombineer om PAC te omseil. [saelo.github.io](https://saelo.github.io/presentations/offensivecon_20_no_clicks.pdf)

-   Ook is imports van funksiepointers uit shared libraries in userspace gevind as onvoldoende deur PAC beskerm, wat 'n aanvaller toelaat om funksiepointers te kry sonder om hul handtekening te verander. (Project Zero bug entry) [bugs.chromium.org](https://bugs.chromium.org/p/project-zero/issues/detail?id=2044&utm_source=chatgpt.com)

2.2 **dlsym(3) / dynamic symbol resolution**

-   Een bekende bypass is om `dlsym()` aan te roep om 'n *reeds-getekende* funksiepointer (geteken met A-key, diversifier nul) te kry en dan dit te gebruik. Omdat `dlsym` 'n wettige getekende pointer teruggee, omseil dit die behoefte om PAC te vervals.

-   Epsilon se blog verduidelik hoe sommige bypasses dit uitbuit: om `dlsym("someSym")` te roep gee 'n getekende pointer en kan gebruik word vir indirekte oproepe. [blog.epsilon-sec.com](https://blog.epsilon-sec.com/tag/pac.html)

-   Synacktiv se "iOS 18.4 --- dlsym considered harmful" beskryf 'n bug: sommige simbole wat via `dlsym` op iOS 18.4 opgelos word, retourneer pointers wat verkeerd geteken is (of met buggy diversifiers), wat onbedoelde PAC-bypass moontlik maak. [Synacktiv](https://www.synacktiv.com/en/publications/ios-184-dlsym-considered-harmful)

-   Die logika in dyld vir dlsym sluit in: wanneer `result->isCode`, teken hulle die teruggegewe pointer met `__builtin_ptrauth_sign_unauthenticated(..., key_asia, 0)`, d.w.s. konteks nul. [blog.epsilon-sec.com](https://blog.epsilon-sec.com/tag/pac.html)

Dus, `dlsym` is 'n gereelde vektor in user-mode PAC bypasses.

2.3 **Other DYLD / runtime relocations**

-   Die DYLD loader en dinamiese relocasie-logika is kompleks en soms map dit bladsye tydelik as read/write om relocations uit te voer, en skakel dan terug na read-only. Aanvallers misbruik hierdie vensters. Synacktiv se praatjie beskryf "Operation Triangulation", 'n timing-gebaseerde PAC bypass via dinamiese relocations. [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

-   DYLD bladsye is nou beskerm met SPRR / VM_FLAGS_TPRO (sommige protection flags vir dyld). Maar vroeër weergawes het swakker beskerming gehad. [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

-   In WebKit exploit-chains is die DYLD loader dikwels 'n teiken vir PAC bypass. Die skyfies noem dat baie PAC bypasses die DYLD loader geteiken het (via relocatie, interposer hooks). [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

2.4 **NSPredicate / NSExpression / ObjC / SLOP**

-   In userland exploit-chains word Objective-C runtime-metodes soos `NSPredicate`, `NSExpression` of `NSInvocation` gebruik om kontrole-oproepe te smuggel sonder duidelike pointer-vervalsings.

-   Op ouer iOS (voor PAC) het 'n exploit fake NSInvocation-objects gebruik om arbitrary selectors op beheerlike geheue te roep. Met PAC is aanpassings nodig. Maar die tegniek SLOP (SeLector Oriented Programming) is onder PAC uitgebrei. [Project Zero](https://googleprojectzero.blogspot.com/2020/01/remote-iphone-exploitation-part-3.html)

-   Die oorspronklike SLOP-tegniek het toegelaat om ObjC-oproepe te ketting deur fake invocations te skep; die bypass berus daarop dat ISA of selector pointers soms nie volledig deur PAC beskerm is nie. [Project Zero](https://googleprojectzero.blogspot.com/2020/01/remote-iphone-exploitation-part-3.html)

-   In omgewings waar pointer authentication gedeeltelik toegepas word, mag metodes / selectors / target pointers nie altyd PAC-beskerming hê nie, wat ruimte vir bypass gee.

#### Voorbeeld Flow

<details>
<summary>Voorbeeld: Ondertekening & Verifikasie</summary>
```
; Example: function prologue / return address protection
my_func:
stp x29, x30, [sp, #-0x20]!        ; push frame pointer + LR
mov x29, sp
PACIASP                            ; sign LR (x30) using SP as modifier
; … body …
mov sp, x29
ldp x29, x30, [sp], #0x20         ; restore
AUTIASP                            ; authenticate & strip PAC
ret

; Example: indirect function pointer stored in a struct
; suppose X1 contains a function pointer
PACDA X1, X2     ; sign data pointer X1 with context X2
STR X1, [X0]      ; store signed pointer

; later retrieval:
LDR X1, [X0]
AUTDA X1, X2       ; authenticate & strip
BLR X1             ; branch to valid target

; Example: stripping for comparison (unsafe)
LDR X1, [X0]
XPACI X1           ; strip PAC (instruction domain)
CMP X1, #some_label_address
BEQ matched_label
```
</details>

<details>
<summary>Voorbeeld</summary>
A buffer overflow oorskryf 'n return address op die stack. Die aanvaller skryf die teiken gadget address maar kan nie die korrekte PAC bereken nie. Wanneer die funksie terugkeer, faal die CPU se `AUTIA` instruksie omdat die PAC nie ooreenstem nie. Die ketting misluk.
Project Zero se analise van A12 (iPhone XS) het getoon hoe Apple se PAC gebruik word en metodes om PACs te vervals indien 'n aanvaller 'n memory read/write primitive het.
</details>


### 9. **Tak-doelidentifikasie (BTI)**
**Ingevoer met ARMv8.5 (later hardeware)**
BTI is 'n hardewarefunksie wat **indirekte branch-doelwitte** nagaan: wanneer `blr` of indirekte calls/jumps uitgevoer word, moet die teiken begin met 'n **BTI landing pad** (`BTI j` of `BTI c`). Spring na gadget-adresse wat nie die landing pad het nie, veroorsaak 'n uitsondering.

LLVM se implementasie noem drie variante van BTI-instruksies en hoe hulle op branch-tipeskaart.

| BTI Variant | Wat dit toelaat (watter branch-tipes) | Tipiese plasing / gebruiksgeval |
|-------------|----------------------------------------|-------------------------------|
| **BTI C** | Targets van *call*-styl indirekte branches (bv. `BLR`, of `BR` wat X16/X17 gebruik) | Plaas by die ingang van funksies wat indirek opgeroep kan word |
| **BTI J** | Targets van *jump*-styl branches (bv. `BR` wat vir tail calls gebruik word) | Geplaas by die begin van blocks wat deur jump tables of tail-calls bereikbaar is |
| **BTI JC** | Werk as beide C en J | Kan deur óf call óf jump branches geteiken word |

- In kode wat met branch target enforcement saamgestel is, voeg kompileerders 'n BTI-instruksie (C, J, of JC) by by elke geldige indirekte-branch teiken (funksie-beginne of blocks bereikbaar deur jumps) sodat indirekte branches net na daardie plekke kan slaag.
- **Direkte branches / oproepe** (d.w.s. vaste-adres `B`, `BL`) word **nie deur BTI beperk** nie. Die aanneming is dat kodebladsye vertrou word en 'n aanvaller hulle nie kan verander nie (dus is direkte branches veilig).
- Ook, **RET / return** instruksies is oor die algemeen nie deur BTI beperk nie omdat return-adresse beskerm word via PAC of return signing-meganismes.

#### Meeganisme en afdwinging

- Wanneer die CPU 'n **indirekte branch (BLR / BR)** decodeer in 'n bladsy gemerk as “guarded / BTI-enabled,” kyk dit of die teikenadres se eerste instruksie 'n geldige BTI is (C, J, of JC soos toegelaat). Indien nie, gebeur 'n **Branch Target Exception**.
- Die BTI-instruksie-enkoding is ontwerp om opcodes her te gebruik wat voorheen gereserveer was vir NOPs (in vroeër ARM weergawes). Dus bly BTI-enabled binaries backward-compatible: op hardeware sonder BTI-ondersteuning tree daardie instruksies as NOPs op.
- Die compiler-passe wat BTIs byvoeg, plaas hulle slegs waar nodig: funksies wat indirek opgeroep kan word, of basic blocks wat deur jumps geteiken word.
- Sommige patches en LLVM-kode toon dat BTI nie in *alle* basic blocks ingevoeg word nie — slegs in daardie wat potensiële branch targets is (bv. van switch / jump tables).

#### BTI + PAC sinergie

PAC beskerm die pointer-waarde (die bron) — dit verseker dat die ketting van indirekte oproepe / returns nie gemanipuleer is nie.

BTI verseker dat selfs 'n geldige pointer slegs na behoorlik gemerkte ingangspunte kan wys.

Gekombineerd benodig 'n aanvaller beide 'n geldige pointer met die korrekte PAC en dat die teiken 'n BTI daar het. Dit verhoog die moeilikheid om exploit gadgets te konstrueer.

#### Voorbeeld


<details>
<summary>Voorbeeld</summary>
'n Exploit probeer om na 'n gadget by `0xABCDEF` te pivot wat nie met `BTI c` begin nie. Die CPU, by die uitvoer van `blr x0`, kontroleer die teiken en fault omdat die instruksie-alignment nie 'n geldige landing pad insluit nie. Dus raak baie gadgets onbruikbaar tensy hulle 'n BTI-voorvoegsel het.
</details>


### 10. **PAN (Privileged Access Never) & PXN (Privileged Execute Never)**
**Ingevoer in meer onlangse ARMv8 uitbreidings / iOS-ondersteuning (vir geharde kernel)**

#### PAN (Privileged Access Never)

- **PAN** is 'n funksie wat in **ARMv8.1-A** ingevoer is wat voorkom dat **geprivilegieerde kode** (EL1 of EL2) **lees of skryf** na geheue wat as **user-accessible (EL0)** gemerk is, tensy PAN eksplisiet gedeaktiveer word.
- Die idee: selfs as die kernel mislei of gekompromitteer word, kan dit nie willekeurig user-space pointers dereference sonder eers PAN uit te skakel nie, wat die risiko's van **`ret2usr`** styl exploits of misbruik van user-gekontroleerde buffers verlaag.
- Wanneer PAN geaktiveer is (PSTATE.PAN = 1), veroorsaak enige geprivilegieerde load/store instruksie wat toegang tot 'n virtuele adres wat “accessible at EL0” is, 'n **permission fault**.
- Die kernel, wanneer dit legitiem user-space geheue moet toegang (bv. kopieer data na/van user buffers), moet **PAN tydelik deaktiveer** (of overskakel na “unprivileged load/store” instruksies) om daardie toegang toe te laat.
- In Linux op ARM64 is PAN-ondersteuning ingestel omstreeks 2015: kernel patches het die funksie gedetekteer en `get_user` / `put_user` ens. vervang met variante wat PAN rondom user memory accesses onklaar maak.

**Belangrike nuans / beperking / bug**
- Soos deur Siguza en ander aangeteken, beteken 'n spesifikasie-fout (of dubbelgevoelige gedrag) in ARM se ontwerp dat **execute-only user mappings** (`--x`) moontlik **nie PAN veroorsaak nie**. Met ander woorde, as 'n user bladsy uitvoerbaar gemerk is maar sonder leespermit, mag die kernel se leespoging PAN omseil omdat die argitektuur “accessible at EL0” as vereis leespermit beskou, nie net uitvoerbaarheid nie. Dit lei tot 'n PAN-bypass in sekere konfigurasies.
- Omdat hiervan, as iOS / XNU execute-only user pages toelaat (soos sommige JIT of code-cache opstellings mag), mag die kernel per ongeluk van hulle lees selfs met PAN geaktiveer. Dit is 'n bekende fyn te exploiteer gebied in sekere ARMv8+ stelsels.

#### PXN (Privileged eXecute Never)

- **PXN** is 'n bladsy-tabel vlag (in die page table entries, leaf of block entries) wat aandui dat die bladsy **nie uitvoerbaar is wanneer in geprivilegieerde modus** (d.w.s. wanneer EL1 dit uitvoer) nie.
- PXN voorkom dat die kernel (of enige geprivilegieerde kode) na user-space bladsye spring of instruksies van user-space bladsye uitvoer selfs as beheer gediversieer word. In werklikheid stop dit 'n kernel-vlak control-flow herleiding na user geheugen.
- Gekombineer met PAN verseker dit dat:
1. Kernel kan nie (standaard) user-space data lees of skryf nie (PAN)
2. Kernel kan nie user-space kode uitvoer nie (PXN)
- In die ARMv8 page table-formaat het leaf entries 'n `PXN` bit (en ook `UXN` vir unprivileged execute-never) in hul attribuut-bits.

Dus selfs as die kernel 'n gekorrupte funksie-pen wys na user geheue, en dit probeer daarheen branch, sal die PXN-bit 'n fault veroorsaak.

#### Geheue-toegangsmodel & hoe PAN en PXN op bladsy-tabelbits kaart

Om te verstaan hoe PAN / PXN werk, moet jy sien hoe ARM se translasi e en permissiemodel werk (vereenvoudig):

- Elke bladsy of blok entry het attribuutvelde insluitend **AP[2:1]** vir toegangspasmming (lees/skryf, geprivilegieerd vs ongeprivilegieerd) en **UXN / PXN** bits vir execute-never beperkings.
- Wanneer PSTATE.PAN 1 is (geaktiveer), dwing die hardeware veranderde semantiek af: geprivilegieerde toegang tot bladsye gemerk as “accessible by EL0” (d.w.s. user-accessible) word geweier (fault).
- As gevolg van die genoemde fout, mag bladsye wat slegs uitvoerbaar gemerk is, en nie leespermit het nie, nie as “accessible by EL0” beskou word nie onder sekere implementasies, en so PAN omseil.
- Wanneer 'n bladsy se PXN-bit gestel is, is uitvoering verbied selfs al kom die instruksie-fetch van 'n hoër privilege-vlak af.

#### Kernel gebruik van PAN / PXN in 'n geharde OS (bv. iOS / XNU)

In 'n geharde kernel-ontwerp (soos wat Apple dalk gebruik):

- Die kernel skakel PAN standaard aan (sodat geprivilegieerde kode beperk is).
- In paaie wat regmatig user-buffer lees of skryf benodig (bv. syscall buffer kopie, I/O, read/write user pointer), deaktiveer die kernel tydelik **PAN** of gebruik spesiale instruksies om dit te oorstuur.
- Nadat user data-toegang klaar is, moet dit PAN weer aktiveer.
- PXN word afgedwing via bladsy-tabelle: user bladsye het PXN = 1 (sodat kernel hulle nie kan uitvoer nie), kernel bladsye het nie PXN nie (sodat kernel-kode uitgevoer kan word).
- Die kernel moet verseker dat geen kodeloops na user geheuesone lei wat PXN omseil nie — dus word exploit-kettinge wat op “spring na user-gekontroleerde shellcode” staatmaak, geblokkeer.

As gevolg van die genoemde PAN-bypass via execute-only bladsye, kan Apple in 'n werklike stelsel execute-only user bladsye deaktiveer of die spesifikasie-kwessie omseil.

#### Aanvals-oppervlakke, omseilings, en mitigasies

- **PAN-bypass via execute-only bladsye**: soos bespreek, laat die spes 'n gap: user bladsye met execute-only (geen leesperm nie) mag nie as “accessible at EL0” gereken word nie, dus sal PAN kernel-lees nie blokkeer nie in sommige implementasies. Dit gee 'n aanvaller 'n ongewone pad om data via “execute-only” afdelings te voer.
- **Temporale venster-exploit**: as die kernel PAN uitskakel vir 'n venster langer as nodig, kan 'n race of kwaadwillige pad daardie venster misbruik om onbedoelde user memory access te doen.
- **Vergeet om weer te aktiveer**: as kodepade versuim om PAN weer aan te sit, mag volgende kernel-aksies verkeerdelik user-geheue toegang kry.
- **Verkeerde konfigurasie van PXN**: as page tables nie PXN op user-bladsye stel nie of user-kode bladsye verkeerd map, kan die kernel geblokkeer word om user-space kode uit te voer.
- **Spesulasie / side-channels**: analoog aan spekulatiewe omseilings, kan daar mikro-argitektoniese newe-effekte wees wat tydelike skending van PAN / PXN-toetse veroorsaak (alhoewel sulke aanvalle sterk afhanklik is van CPU-ontwerp).
- **Komplekse interaksies**: In meer gevorderde funksies (bv. JIT, gedeelde geheue, just-in-time code regions), het die kernel fynbeheer nodig om sekere geheue-toegange of uitvoering in user-gemapte areas toe te laat; om dit veilig te ontwerp onder PAN/PXN-beperkings is nie eenvoudig nie.

#### Voorbeeld

<details>
<summary>Kodevoorbeeld</summary>
Here are illustrative pseudo-assembly sequences showing enabling/disabling PAN around user memory access, and how a fault might occur.
</details>
```  
// Suppose kernel entry point, PAN is enabled (privileged code cannot access user memory by default)

; Kernel receives a syscall with user pointer in X0
; wants to read an integer from user space
mov   X1, X0        ; X1 = user pointer

; disable PAN to allow privileged access to user memory
MSR   PSTATE.PAN, #0   ; clear PAN bit, disabling the restriction

ldr   W2, [X1]       ; now allowed load from user address

; re-enable PAN before doing other kernel logic
MSR   PSTATE.PAN, #1   ; set PAN

; ... further kernel work ...

; Later, suppose an exploit corrupts a pointer to a user-space code page and jumps there
BR    X3             ; branch to X3 (which points into user memory)

; Because the target page is marked PXN = 1 for privileged execution,
; the CPU throws an exception (fault) and rejects execution
```
If die kernel **nie** PXN op daardie user page gestel het nie, kon die branch slaag — wat onveilig sou wees.

As die kernel vergeet om PAN weer te aktiveer nadat dit user memory geaccess het, maak dit ’n venster oop waar verdere kernel logic per ongeluk arbitrêre user memory kan read/write.

As die user pointer na ’n execute-only page wys (user page met slegs execute permission, geen read/write), kan, weens die PAN spec bug, `ldr W2, [X1]` **nie** fault nie selfs al is PAN enabled, wat ’n bypass exploit moontlik maak, afhangend van implementasie.

</details>

<details>
<summary>Example</summary>
’n kernel vulnerability probeer ’n user-provided function pointer neem en dit in kernel context call (bv. `call user_buffer`). Onder PAN/PXN is daardie operasie nie toegelaat nie of dit faults.
</details>

---

### 11. **Top Byte Ignore (TBI) / Pointer Tagging**
**Ingevoer in ARMv8.5 / newer (of opsionele uitbreiding)**
TBI beteken dat die top byte (mees-beduidende byte) van ’n 64-bit pointer geïgnoreer word deur address translation. Dit laat die OS of hardeware toe om **tag bits** in die pointer se top byte in te sluit sonder om die werklike adres te beïnvloed.

- TBI staan vir **Top Byte Ignore** (soms genoem *Address Tagging*). Dit is ’n hardware-funksie (beskikbaar in baie ARMv8+ implementasies) wat **die top 8 bits ignoreer** (bits 63:56) van ’n 64-bit pointer wanneer address translation / load/store / instruction fetch uitgevoer word.
- In effek behandel die CPU ’n pointer `0xTTxxxx_xxxx_xxxx` (waar `TT` = top byte) as `0x00xxxx_xxxx_xxxx` vir die doeleindes van address translation, deur die top byte te ignoreer (te mask). Die top byte kan deur software gebruik word om **metadata / tag bits** te stoor.
- Dit gee software “gratis” in-band ruimte om ’n byte tag in elke pointer in te sluit sonder om te verander watter memory-ligging dit verwys.
- Die argitektuur verseker dat loads, stores, en instruction fetch die pointer met sy top byte gemasker (d.w.s. tag verwyder) behandel voordat die werklike memory access plaasvind.

Dus skei TBI die **logical pointer** (pointer + tag) van die **physical address** wat vir memory operations gebruik word.

#### Waarom TBI: Gebruiksgevalle en motivering

- **Pointer tagging / metadata**: Jy kan ekstra metadata (bv. object type, version, bounds, integrity tags) in daardie top byte stoor. Wanneer jy later die pointer gebruik, word die tag op hardewarevlak geignoreer, so jy hoef dit nie manueel te strip vir die memory access nie.
- **Memory tagging / MTE (Memory Tagging Extension)**: TBI is die basiese hardware-meganisme waarop MTE bou. In ARMv8.5 gebruik die **Memory Tagging Extension** bits 59:56 van die pointer as ’n **logical tag** en vergelyk dit met ’n **allocation tag** wat in memory gestoor is.
- **Enhanced security & integrity**: Deur TBI te kombineer met pointer authentication (PAC) of runtime checks, kan jy dwing dat nie net die pointer-waarde maar ook die tag korrek is. ’n aanvaller wat ’n pointer oor skryf sonder die korrekte tag sal ’n mismatchende tag veroorsaak.
- **Compatibility**: Omdat TBI opsioneel is en tag bits deur hardeware geignoreer word, sal bestaande ongetagde code normaal voortgaan om te werk. Die tag bits word effektief “don’t care” bits vir legacy code.

#### Example
<details>
<summary>Example</summary>
’n function pointer het ’n tag in sy top byte gehad (bv. `0xAA`). ’n exploit oor skryf die pointer se laer bits maar negligeer die tag, so wanneer die kernel verifieer of sanitize, misluk of word die pointer verwerp.
</details>

---

### 12. **Page Protection Layer (PPL)**
**Ingevoer in late iOS / moderne hardware (iOS ~17 / Apple silicon / high-end models)** (sommige verslae wys PPL ongeveer in macOS / Apple silicon, maar Apple bring soortgelyke beskerming na iOS)

- PPL is ontwerp as ’n **intra-kernel protection boundary**: selfs as die kernel (EL1) gekompromitteer is en read/write vermoëns het, **moet dit nie vrylik sekere sensitiewe pages kan wysig nie** (veral page tables, code-signing metadata, kernel code pages, entitlements, trust caches, ens.).
- Dit skep effektiﬂik ’n **“kernel within the kernel”** — ’n kleiner vertroude komponent (PPL) met **verhoogde voorregte** wat alleen protected pages kan wysig. Ander kernel code moet PPL routines aanroep om veranderinge te maak.
- Dit verminder die aanvalsvlak vir kernel exploits: selfs met volle arbitrêre R/W/execute in kernel mode, moet exploit code ook op een of ander manier in die PPL-domein inkom (of PPL omseil) om kritieke strukture te wysig.
- Op nuwer Apple silicon (A15+ / M2+) skuif Apple na **SPTM (Secure Page Table Monitor)**, wat in baie gevalle PPL vervang vir page-table beskerming op daardie platforms.

Hierdie is hoe PPL vermoedelik werk, gebaseer op openbare analise:

#### Use of APRR / permission routing (APRR = Access Permission ReRouting)

- Apple hardeware gebruik ’n meganisme genaamd **APRR (Access Permission ReRouting)**, wat toelaat dat page table entries (PTEs) klein indekse bevat, in plaas van volle permission bits. Daardie indekse word via APRR registers na werklike permissies gemap. Dit laat dinamiese herkartering van permissies per domein toe.
- PPL gebruik APRR om privilegie binne kernel context te segregeer: slegs die PPL-domein mag die mapping tussen indekse en effektiewe permissies opdateer. Dit beteken dat wanneer non-PPL kernel code ’n PTE skryf of probeer permission bits flip, die APRR-logika dit disallow (of read-only mapping afdwing).
- PPL-kode self loop in ’n beperkte streek (bv. `__PPLTEXT`) wat normaalweg nie-uitvoerbaar of nie-skryfbaar is totdat entry gates dit tydelik toelaat. Die kernel roep PPL entry points (“PPL routines”) aan om sensitiewe operasies uit te voer.

#### Gate / Entry & Exit

- Wanneer die kernel ’n protected page moet wysig (bv. verander permissies van ’n kernel code page, of page tables wysig), roep dit ’n **PPL wrapper** routine aan, wat validasie doen en dan in die PPL-domein oorskakel. Buite daardie domein is die protected pages effektiﬂik read-only of nie-wysigbaar deur die hoof-kernel.
- Tydens PPL entry word die APRR mappings aangepas sodat memory pages in die PPL-streek binne PPL op **executable & writable** gestel word. By exit word hulle teruggestel na read-only / non-writable. Dit verseker dat slegs goed-geouditeerde PPL-routines na protected pages kan skryf.
- Buite PPL sal pogings deur kernel code om op daardie protected pages te skryf fault (permission denied) omdat die APRR-mapping vir daardie code-domein nie skryf toelaat nie.

#### Protected page categories

Die pages wat PPL tipies beskerm sluit in:

- Page table structures (translation table entries, mapping metadata)
- Kernel code pages, veral dié wat kritieke logika bevat
- Code-sign metadata (trust caches, signature blobs)
- Entitlement tables, signature enforcement tables
- Ander hoë-waarde kernel strukture waar ’n patch dit moontlik sou maak om signature checks of credential manipulasie te omseil

Die idee is dat selfs as die kernel memory volle beheer ondervind, kan die aanvaller nie sommer net hierdie pages patch of herskryf nie, tensy hulle ook PPL-routines kompromitteer of PPL omseil.

#### Known Bypasses & Vulnerabilities

1. **Project Zero’s PPL bypass (stale TLB trick)**

- ’n Publieke uiteensetting deur Project Zero beskryf ’n bypass wat stale TLB entries uitbuit.
- Die idee:

1. Allocate twee physical pages A en B, merk hulle as PPL pages (sodat hulle beskerm is).
2. Map twee virtual addresses P en Q waarvan die L3 translation table pages van A en B kom.
3. Spin ’n thread wat deurlopend Q benader, en hou sodoende die TLB entry lewend.
4. Roep `pmap_remove_options()` aan om mappings te verwyder beginnende by P; as gevolg van ’n bug verwyder die kode per ongeluk die TTEs vir beide P en Q, maar invalideer slegs die TLB entry vir P, wat Q se stale entry lewend laat.
5. Hergebruik B (page Q se table) om arbitrêre memory te map (bv. PPL-protected pages). Omdat die stale TLB entry steeds Q se ou mapping kaart, bly daardie mapping geldig vir daardie konteks.
6. Deur dit kan die aanvaller ’n skryfbare mapping van PPL-protected pages in plek sit sonder om deur die PPL-interface te gaan.

- Hierdie exploit het fyn beheer oor physical mapping en TLB-gedrag benodig. Dit demonstreer dat ’n veiligheidsgrens wat op TLB/mapping korrektheid staatmaak uiters versigtig met TLB-invaliderings en mapping-konsistensie moet wees.

- Project Zero het opgemerk dat bypasses soos hierdie subtiel en skaars is, maar moontlik in komplekse stelsels. Hulle beskou steeds PPL as ’n stewige mitigasie.

2. **Other potential hazards & constraints**

- As ’n kernel exploit direk PPL routines kan betree (byvoorbeeld deur die PPL wrappers aan te roep), kan dit die restriksies omseil. Daarom is argumentvalidasie kritiek.
- Bugs in die PPL-kode self (bv. arithmetic overflow, boundary checks) kan binne PPL out-of-bounds wysigings toelaat. Project Zero het opgemerk dat so ’n bug in `pmap_remove_options_internal()` in hul bypass uitgebuit is.
- Die PPL-grens is onherroeplik gekoppel aan hardware-implementering (APRR, memory controller), dus is dit net so sterk as die hardeware-implementasie.

#### Example
<details>
<summary>Code Example</summary>
Hier is ’n vereenvoudigde pseudokode / logika wat wys hoe ’n kernel in PPL kan aanroep om protected pages te wysig:
```c
// In kernel (outside PPL domain)
function kernel_modify_pptable(pt_addr, new_entry) {
// validate arguments, etc.
return ppl_call_modify(pt_addr, new_entry)  // call PPL wrapper
}

// In PPL (trusted domain)
function ppl_call_modify(pt_addr, new_entry) {
// temporarily enable write access to protected pages (via APRR adjustments)
aprr_set_index_for_write(PPL_INDEX)
// perform the modification
*pt_addr = new_entry
// restore permissions (make pages read-only again)
aprr_restore_default()
return success
}

// If kernel code outside PPL does:
*pt_addr = new_entry  // a direct write
// It will fault because APRR mapping for non-PPL domain disallows write to that page
```
Die kernel kan baie normale operasies uitvoer, maar slegs deur die `ppl_call_*`-roetines kan dit beskermde mappings verander of kode patch.
</details>

<details>
<summary>Example</summary>
A kernel exploit probeer die entitlement table oor skryf, of code-sign enforcement deaktiveer deur `kernel signature blob` te wysig. Omdat daardie bladsy PPL-beskerm is, word die skryf geblokkeer tensy dit deur die PPL-interface gaan. Selfs met kernel code execution kan jy dus nie code-sign-beperkings omseil of credential data arbitrêr wysig nie.
Op iOS 17+ gebruik sekere toestelle SPTM om PPL-beheerde bladsye verder te isoleer.
</details>

#### PPL → SPTM / Vervangings / Toekoms

- Op Apple se moderne SoCs (A15 of later, M2 of later) ondersteun Apple **SPTM** (Secure Page Table Monitor), wat **PPL vervang** vir page table protections.
- Apple noem in dokumentasie: “Page Protection Layer (PPL) and Secure Page Table Monitor (SPTM) enforce execution of signed and trusted code … PPL manages the page table permission overrides … Secure Page Table Monitor replaces PPL on supported platforms.”
- Die SPTM-argitektuur skuif waarskynlik meer beleid-afdwinging na ‘n hoër-privilege monitor buite kernelbeheer, wat die trust boundary verder verminder.

### MTE | EMTE | MIE

Hier’s ‘n hoërvlak beskrywing van hoe EMTE werk binne Apple se MIE-opstelling:

1. **Tag assignment**
- Wanneer geheue gealloceer word (bv. in kernel of user space via secure allocators), word ‘n **geheime tag** aan daardie blok toegewys.
- Die pointer wat aan die gebruiker of kernel teruggegee word sluit daardie tag in sy hoë bits in (gebruikmakend van TBI / top byte ignore meganismes).

2. **Tag checking on access**
- Wanneer ‘n load of store uitgevoer word met ‘n pointer, kontroleer die hardware dat die pointer se tag ooreenstem met die geheueblok se tag (allocation tag). Indien dit nie ooreenstem nie, gooi dit onmiddellik ‘n fout (aangesien dit sinchronies is).
- Omdat dit sinchronies is, is daar geen “delayed detection” window nie.

3. **Retagging on free / reuse**
- Wanneer geheue vrygestel word, verander die allocator die blok se tag (sodat ouer pointers met ou tags nie meer ooreenstem nie).
- ‘n use-after-free pointer sal dus ‘n stale tag hê en mismatch wanneer dit geaccess word.

4. **Neighbor-tag differentiation to catch overflows**
- Aanliggende allocations kry distinkte tags. As ‘n buffer overflow in die buurman se geheue afloop, veroorsaak die tag mismatch ‘n fout.
- Dit is veral kragtig om klein overflows wat oor ‘n grens steek op te spoor.

5. **Tag confidentiality enforcement**
- Apple moet verhoed dat tag values being leaked (want as ‘n aanvaller die tag leer, kan hulle pointers met korrekte tags vervaardig).
- Hulle sluit beskermings in (microarchitectural / speculative controls) om side-channel leakage van tag bits te vermy.

6. **Kernel and user-space integration**
- Apple gebruik EMTE nie net in user-space nie, maar ook in kernel / OS-kritieke komponente (om die kernel teen geheuekorrupsie te beskerm).
- Die hardware/OS verseker dat tag-reëls geld selfs wanneer die kernel namens user space uitgevoer word.

<details>
<summary>Example</summary>
```
Allocate A = 0x1000, assign tag T1
Allocate B = 0x2000, assign tag T2

// pointer P points into A with tag T1
P = (T1 << 56) | 0x1000

// Valid store
*(P + offset) = value // tag T1 matches allocation → allowed

// Overflow attempt: P’ = P + size_of_A (into B region)
*(P' + delta) = value
→ pointer includes tag T1 but memory block has tag T2 → mismatch → fault

// Free A, allocator retags it to T3
free(A)

// Use-after-free:
*(P) = value
→ pointer still has old tag T1, memory region is now T3 → mismatch → fault
```
</details>

#### Beperkings & uitdagings

- **Intrablock overflows**: As die overflow binne dieselfde toekenning bly (oorskry nie die grens nie) en die tag bly dieselfde, sal tag mismatch dit nie vang nie.
- **Tag width limitation**: Slegs 'n paar bits (bv. 4 bits, of 'n klein domein) is beskikbaar vir die tag — beperkte naamruimte.
- **Side-channel leaks**: As tag bits via cache / speculative execution geleak kan word, kan attacker geldige tags leer en omseil. Apple se tag confidentiality enforcement is bedoel om dit te mitigate.
- **Performance overhead**: Tag checks by elke load/store voeg koste by; Apple moet die hardware optimaliseer om die overhead laag te druk.
- **Compatibility & fallback**: Op ouer hardeware of dele wat EMTE nie ondersteun nie, moet 'n fallback bestaan. Apple beweer MIE is slegs geaktiveer op toestelle met ondersteuning.
- **Complex allocator logic**: Die allocator moet tags, retagging, uitlijningsgrense hanteer en mis-tag collisions vermy. Foute in allocator-logika kan kwesbaarhede inbring.
- **Mixed memory / hybrid areas**: Sommige geheugen mag ontagged bly (legacy), wat interoperabiliteit moeilik maak.
- **Speculative / transient attacks**: Soos met baie microarchitectural protections, kan speculative execution of micro-op fusions kontroles tydelik omseil of tag bits leak.
- **Limited to supported regions**: Apple mag EMTE slegs afdwing in selektiewe, hoë-risiko areas (kernel, security-critical subsystems), nie universeel nie.

---

## Sleutelverbeterings / verskille vergeleke met standaard MTE

Hier is die verbeterings en veranderinge waarop Apple klem lê:

| Feature | Original MTE | EMTE (Apple’s enhanced) / MIE |
|---|---|---|
| **Check mode** | Ondersteun sinchrone en asynchrone modes. In async word tag mismatches later gerapporteer (vertraag) | Apple vereis standaard **synchronous mode** — tag mismatches word onmiddellik gevang, geen vertraagde/ras-vensters toegelaat nie. |
| **Coverage of non-tagged memory** | Accesses to non-tagged memory (e.g. globals) mag in sommige implementasies kontroles omseil | EMTE vereis dat accesses van 'n tagged region na non-tagged memory ook tag knowledge valideer, wat dit moeiliker maak om te omseil deur allocations te meng. |
| **Tag confidentiality / secrecy** | Tags mag observeerbaar of leaked via side channels wees | Apple voeg **Tag Confidentiality Enforcement** by, wat poog om leakage van tag values te keer (via speculative side-channels ens.). |
| **Allocator integration & retagging** | MTE laat baie van die allocator-logika aan sagteware oor | Apple se secure typed allocators (kalloc_type, xzone malloc, etc.) integreer met EMTE: wanneer memory toegeken of vrygestel word, word tags op fyn granulariteit bestuur. |
| **Always-on by default** | Op baie platforms is MTE opsioneel of standaard af | Apple aktiveer EMTE / MIE standaard op ondersteunende hardeware (bv. iPhone 17 / A19) vir kernel en baie user processes. |

Omdat Apple beide die hardware en sagteware-stapel beheer, kan dit EMTE styf afdwing, performance-pitfalls vermy en side-channel gapings dichtslaan.

---

## Hoe EMTE in die praktyk werk (Apple / MIE)

Hier is 'n hoëvlak-beskrywing van hoe EMTE onder Apple se MIE-opset werk:

1. **Tag assignment**
- Wanneer memory toegeken word (bv. in kernel of user space via secure allocators), word 'n **secret tag** aan daardie blok toegeken.
- Die pointer wat aan die user of kernel teruggegee word, bevat daardie tag in sy hoë bits (deur TBI / top byte ignore-meganismes).

2. **Tag checking on access**
- Wanneer 'n load of store uitgevoer word met 'n pointer, kontroleer die hardware dat die pointer se tag ooreenstem met die memory block se tag (allocation tag). By mismatch, word onmiddellik 'n fault gegenereer (aangesien dit synchronous is).
- Omdat dit synchronous is, bestaan daar geen “delayed detection”-venster nie.

3. **Retagging on free / reuse**
- Wanneer memory vrygestel word, verander die allocator die blok se tag (sodat ou punters met ou tags nie meer ooreenstem nie).
- 'n use-after-free pointer sal dus 'n stale tag hê en by toegang mismatch veroorsaak.

4. **Neighbor-tag differentiation to catch overflows**
- Aangrensende allocations kry onderskeibare tags. As 'n buffer overflow in buurgeheue afloop, sal tag mismatch 'n fault veroorsaak.
- Dit is veral kragtig om klein overflows wat grens oorskry, op te vang.

5. **Tag confidentiality enforcement**
- Apple moet verhoed dat tag values geleak word (want as attacker die tag leer, kan hulle pointers met korrekte tags saamstel).
- Hulle sluit beskermings in (microarchitectural / speculative controls) om side-channel leak van tag bits te beperk.

6. **Kernel and user-space integration**
- Apple gebruik EMTE nie net in user-space nie, maar ook in kernel / OS-kritieke komponente (om die kernel teen memory corruption te beskerm).
- Die hardware/OS verseker dat tag-reëls steeds van toepassing is selfs wanneer die kernel namens user space uitvoer.

Omdat EMTE in MIE ingebou is, gebruik Apple EMTE in synchronous mode oor sleutel-aanvalsvlakke, nie as 'n opt-in of debugging-modus nie.

---

## Exception handling in XNU

Wanneer 'n **exception** voorkom (bv. `EXC_BAD_ACCESS`, `EXC_BAD_INSTRUCTION`, `EXC_CRASH`, `EXC_ARM_PAC`, ens.), is die **Mach layer** van die XNU kernel verantwoordelik om dit te onderskep voordat dit 'n UNIX-style **signal** word (soos `SIGSEGV`, `SIGBUS`, `SIGILL`, ...).

Hierdie proses behels meerdere lae van exception-propagasie en -hantering voordat dit user space bereik of in 'n BSD signal omskep word.

### Uitsonderingsvloei (Hoëvlak)

1.  Die CPU trigger 'n synchronous exception (bv. ongeldige pointer dereference, PAC failure, illegal instruction, ens.).
2.  Die laevlak trap handler loop (`trap.c`, `exception.c` in die XNU bron).
3.  Die trap handler roep **`exception_triage()`** aan, die kern van die Mach exception-hantering.
4.  `exception_triage()` bepaal hoe om die exception te roeteer:

-   Eerstens na die **thread's exception port**.
-   Dan na die **task's exception port**.
-   Dan na die **host's exception port** (dikwels `launchd` of `ReportCrash`).

As geen van hierdie ports die exception hanteer nie, mag die kernel:

-   **Convert it into a BSD signal** (vir user-space prosesse).
-   **Panic** (vir kernel-space exceptions).

### Kernfunksie: `exception_triage()`

Die funksie `exception_triage()` roeteer Mach exceptions op die ketting van moontlike handlers totdat een dit hanteer of totdat dit finaal fataal is. Dit is gedefinieer in `osfmk/kern/exception.c`.
```c
void exception_triage(exception_type_t exception, mach_exception_data_t code, mach_msg_type_number_t codeCnt);
```
**Tipiese Oproepvloei:**

`exception_triage()
└── exception_deliver()
├── exception_deliver_thread()
├── exception_deliver_task()
└── exception_deliver_host()`

As alles misluk → hanteer deur `bsd_exception()` → vertaal na 'n sein soos `SIGSEGV`.


### Uitsonderingspoorte

Elke Mach-objek (thread, task, host) kan **uitsonderingspoorte** registreer, waar uitsonderingsboodskappe heen gestuur word.

Hulle word deur die API gedefinieer:
```
task_set_exception_ports()
thread_set_exception_ports()
host_set_exception_ports()
```
Elke exception port het:

-   'n **mask** (watter exceptions dit wil ontvang)
-   'n **port name** (Mach port om boodskappe te ontvang)
-   'n **behavior** (hoe die kernel die boodskap stuur)
-   'n **flavor** (watter thread state om in te sluit)


### Debuggers en Uitsonderingshantering

'n **debugger** (bv., LLDB) stel 'n **exception port** op die teiken task of thread, gewoonlik deur `task_set_exception_ports()` te gebruik.

**Wanneer 'n exception voorkom:**

-   Die Mach-boodskap word na die debugger-proses gestuur.
-   Die debugger kan besluit om te **handle** (hervat, registre wysig, instruksie oorslaan) of die exception **nie te handle** nie.
-   As die debugger dit nie handle nie, propagereer die exception na die volgende vlak (task → host).


### Vloei van `EXC_BAD_ACCESS`

1.  Thread dereferensieer 'n ongeldig pointer → CPU gooi Data Abort.

2.  Kernel trap handler roep `exception_triage(EXC_BAD_ACCESS, ...)` aan.

3.  Boodskap gestuur na:

-   Thread port → (debugger kan breakpoint onderskep).

-   As die debugger dit ignoreer → Task port → (process-level handler).

-   As dit genegeer word → Host port (gewoonlik ReportCrash).

4.  As niemand dit hanteer nie → `bsd_exception()` vertaal na `SIGSEGV`.


### PAC Exceptions

Wanneer Pointer Authentication (PAC) misluk (handtekening stem nie ooreen nie), word 'n spesiale Mach-exception gegooi:

-   **`EXC_ARM_PAC`** (type)
-   Codes kan besonderhede insluit (bv., sleuteltipe, pointertipe).

As die binary die vlag **`TFRO_PAC_EXC_FATAL`** het, behandel die kernel PAC-foute as **fatal**, omseilend debugger-intersepsie. Dit is om te verhoed dat aanvallers debuggers gebruik om PAC-kontroles te omseil en dit is aangeskakel vir **platform binaries**.


### Software Breakpoints

'n sagteware breakpoint (`int3` on x86, `brk` on ARM64) word geïmplementeer deur 'n doelbewuste fout te veroorsaak.\
Die debugger vang dit via die exception port:

-   Wysig instruction pointer of geheue.
-   Herstel oorspronklike instruksie.
-   Hervat uitvoering.

Dieselfde meganisme laat jou toe om 'n PAC-exception te "vang" --- **tensy `TFRO_PAC_EXC_FATAL`** gestel is, in welke geval dit nooit by die debugger uitkom nie.


### Omskakeling na BSD-signaale

As geen handler die exception aanvaar nie:

-   Kernel roep `task_exception_notify() → bsd_exception()` aan.

-   Dit kaart Mach-exceptions toe na signalen:

| Mach-uitsondering | Signaal |
| --- | --- |
| EXC_BAD_ACCESS | SIGSEGV or SIGBUS |
| EXC_BAD_INSTRUCTION | SIGILL |
| EXC_ARITHMETIC | SIGFPE |
| EXC_SOFTWARE | SIGTRAP |
| EXC_BREAKPOINT | SIGTRAP |
| EXC_CRASH | SIGKILL |
| EXC_ARM_PAC | SIGILL (on non-fatal) |


### Sleutellêers in XNU Source

-   `osfmk/kern/exception.c` → Kern van `exception_triage()`, `exception_deliver_*()`.

-   `bsd/kern/kern_sig.c` → Logika vir signaallewering.

-   `osfmk/arm64/trap.c` → Laevlak trap handlers.

-   `osfmk/mach/exc.h` → Exception codes en strukture.

-   `osfmk/kern/task.c` → Task exception port opstelling.

---

## Ou Kernel Heap (Pre-iOS 15 / Pre-A12 era)

Die kernel het 'n **zone allocator** (`kalloc`) gebruik wat in vaste-grootte "zones" verdeel is.
Elke zone berg slegs toewysings van 'n enkele grootteklas.

Uit die skermskoot:

| Zone Naam            | Elementgrootte | Voorbeeldgebruik                                                                 |
|----------------------|--------------|----------------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | Baie klein kernel structs, pointers.                                             |
| `default.kalloc.32`  | 32 bytes     | Klein structs, objekheaders.                                                     |
| `default.kalloc.64`  | 64 bytes     | IPC messages, klein kernel buffers.                                              |
| `default.kalloc.128` | 128 bytes    | Medium-objekte soos dele van `OSObject`.                                         |
| …                    | …            | …                                                                                |
| `default.kalloc.1280`| 1280 bytes   | Groot strukture, IOSurface/graphics metadata.                                    |

Hoe dit gewerk het:
- Elke toewysingsversoek word **afgerond** na die naaste zone-grootte.
(bv., 'n 50-byte versoek beland in die `kalloc.64` zone).
- Geheue in elke zone is in 'n **free list** gehou — blokke wat deur die kernel vrygestel is, het teruggegaan na daardie zone.
- As jy 'n 64-byte buffer oorloop, sal jy die **volgende objek in dieselfde zone** oorskryf.

Dit is hoekom **heap spraying / feng shui** so effektief was: jy kon objekbure voorspel deur toewysings van dieselfde grootteklas te spuit.

### Die freelist

Binne elke kalloc-zone is vrygestelde objekte nie direk aan die stelsel teruggegee nie — hulle het in 'n freelist gegaan, 'n gekoppelde lys van beskikbare blokke.

- Wanneer 'n blok vrygestel is, het die kernel 'n pointer by die begin van daardie blok geskryf → die adres van die volgende vrye blok in dieselfde zone.

- Die zone het 'n HEAD-pointer na die eerste vrye blok gehou.

- Toewysing het altyd die huidige HEAD gebruik:

1. Pop HEAD (gee daardie geheue terug aan die aanroeper).

2. Werk HEAD = HEAD->next by (gestoor in die vrygestelde blok se header).

- By die vrylating is blokke teruggedruk:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Dus was die freelist net 'n gekoppelde lys gebou binne die vrygestelde geheue self.

Normale toestand:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Uitbuiting van die freelist

Omdat die eerste 8 bytes van 'n free chunk die freelist pointer is, kan 'n aanvaller dit korrupteer:

1. **Heap overflow** in 'n aangrensende freed chunk → oorskryf sy “next” pointer.

2. **Use-after-free** skryf in 'n freed object → oorskryf sy “next” pointer.

Dan, by die volgende toewysing van daardie grootte:

- Die allocator haal die gekorrupteerde chunk uit.
- Volg die deur die aanvaller verskafte “next” pointer.
- Gee 'n pointer na ewekansige geheue terug, wat fake object primitives of targeted overwrite moontlik maak.

Visuele voorbeeld van freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist-ontwerp het uitbuiting baie effektief gemaak vóór hardening: voorspelbare bure vanaf heap sprays, raw pointer freelist links, en geen type separation het aanvalle toegelaat om UAF/overflow-bugs in arbitrêre kernel-geheuebeheer op te skaal.

### Heap Grooming / Feng Shui
Die doel van heap grooming is om die heap-lay-out te **vorm** sodat wanneer ’n aanvaller ’n overflow of use-after-free trigger, die teiken (slagoffer) object direk langs ’n aanvaller-gekontroleerde object sit.\
Op dié manier, wanneer geheuekorrupsie plaasvind, kan die aanvaller betroubaar die slagoffer-object met beheerdata oorskryf.

**Stappe:**

1. Spray allocations (fill the holes)
- Oor tyd raak die kernel heap gefragmenteer: sommige zones het gapings waar ou objects vrygestel is.
- Die aanvaller maak eers baie dummy-allocations om hierdie gapings te vul, sodat die heap “gepakte” en voorspelbaar word.

2. Force new pages
- Sodra die gapings gevul is, moet die volgende allocations van nuwe pages kom wat by die zone gevoeg word.
- Vars pages beteken objects sal saamgegroepeer wees, nie oor ou gefragmenteerde geheue versprei nie.
- Dit gee die aanvaller baie beter beheer oor bure.

3. Place attacker objects
- Die aanvaller spray nou weer en skep baie aanvaller-gekontroleerde objects in daardie nuwe pages.
- Hierdie objects is voorspelbaar in grootte en plek (aangesien hulle almal by dieselfde zone hoort).

4. Free a controlled object (make a gap)
- Die aanvaller vrygestel doelbewus een van hul eie objects.
- Dit skep ’n “gat” in die heap wat die allocator later sal hergebruik vir die volgende allocation van daardie grootte.

5. Victim object lands in the hole
- Die aanvaller trigger nou die kernel om die slagoffer-object (die een wat hulle wil korrupteer) te allocate.
- Aangesien die gat die eerste beskikbare slot in die freelist is, word die slagoffer presies geplaas waar die aanvaller hul object vrygestel het.

6. Overflow / UAF into victim
- Nou het die aanvaller aanvaller-gekontroleerde objects rondom die slagoffer.
- Deur te overflow vanaf een van hul eie objects (of ’n vrygestelde een hergebruiken), kan hulle betroubaar die slagoffer se geheuevelde met gekose waardes oorskryf.

**Waarom dit werk**:

- Zone allocator-voorspelbaarheid: allocations van dieselfde grootte kom altyd uit dieselfde zone.
- Freelist-gedrag: nuwe allocations hergebruik die mees onlangs vrygestelde blok eers.
- Heap sprays: die aanvaller vul geheue met voorspelbare inhoud en beheer die lay-out.
- Eindresultaat: die aanvaller beheer waar die slagoffer-object land en watter data langs dit sit.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple het die allocator gehard en gemaak dat **heap grooming baie moeiliker** is:

### 1. From Classic kalloc to kalloc_type
- **Before**: ’n enkele `kalloc.<size>` zone het bestaan vir elke grootteklas (16, 32, 64, … 1280, ens.). Enige object van daardie grootte is daar geplaas → aanvaller-objects kon langs bevoorregte kernel-objects sit.
- **Now**:
- Kernel objects word gealloceer uit **typed zones** (`kalloc_type`).
- Elke tipe object (bv. `ipc_port_t`, `task_t`, `OSString`, `OSData`) het sy eie toegewyde zone, selfs al is hulle dieselfde grootte.
- Die mapping tussen object type ↔ zone word by compile-tyd vanaf die **kalloc_type system** gegenereer.

’n Aanvaller kan nie meer waarborg dat beheerdata (`OSData`) langs sensitiewe kernel-objects (`task_t`) van dieselfde grootte eindig nie.

### 2. Slabs and Per-CPU Caches
- Die heap is verdeel in **slabs** (pages geheue uitgesny in vas-grootte stukke vir daardie zone).
- Elke zone het ’n **per-CPU cache** om kontensie te verminder.
- Allocation-pad:
1. Probeer per-CPU cache.
2. Indien leeg, haal uit die global freelist.
3. Indien freelist leeg is, alloceer ’n nuwe slab (een of meer pages).
- **Voordeel**: Hierdie desentralisasie maak heap sprays minder deterministies, aangesien allocations moontlik uit verskillende CPU’s se caches bevredig word.

### 3. Randomization inside zones
- Binne ’n zone word vrygestelde elemente nie teruggegee in eenvoudige FIFO/LIFO volgorde nie.
- Moderne XNU gebruik **encoded freelist pointers** (safe-linking soos Linux, ingevoer ~iOS 14).
- Elke freelist pointer is **XOR-geënkodeer** met ’n per-zone geheime cookie.
- Dit voorkom dat aanvallers ’n vals freelist pointer kan vervals as hulle ’n write primitive kry.
- Sommige allocations word **gerandomiseer in hul plasing binne ’n slab**, sodat spraying nie aanbidbaarheid van nabyheid waarborg nie.

### 4. Guarded Allocations
- Sekere kritieke kernel-objects (bv. credentials, task structures) word in **guarded zones** gealloceer.
- Hierdie zones voeg **guard pages** (unmapped memory) tussen slabs in of gebruik **redzones** rondom objects.
- Enige overflow in die guard page veroorsaak ’n fout → onmiddellike panic in plaas van stil korrupsie.

### 5. Page Protection Layer (PPL) and SPTM
- Selfs as jy ’n vrygestelde object beheer, kan jy nie alle kernel-geheue wysig nie:
- **PPL (Page Protection Layer)** dwing af dat sekere streke (bv. code signing data, entitlements) **read-only** is selfs vir die kernel self.
- Op **A15/M2+ devices**, word hierdie rol vervang/versterk deur **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- Hierdie hardware-afgedwingde lae beteken dat aanvallers nie van ’n enkele heap-korrupsie na arbitrêre patching van kritieke sekuriteitsstrukture kan eskaleer nie.
- **(Added / Enhanced)**: ook, **PAC (Pointer Authentication Codes)** word in die kernel gebruik om pointers (veral function pointers, vtables) te beskerm sodat vervalsing of korrupsie daarvan moeiliker word.
- **(Added / Enhanced)**: zones kan **zone_require / zone enforcement** afdwing, d.w.s. dat ’n object wat vrygestel is slegs deur sy korrekte typed zone teruggegee kan word; ongeldige cross-zone frees kan panic veroorsaak of verwerp word. (Apple verwys daarna in hul memory safety poste)

### 6. Large Allocations
- Nie alle allocations gaan deur `kalloc_type` nie.
- Baie groot versoeke (bo ~16 KB) omseil typed zones en word direk uit **kernel VM (kmem)** via page allocations voorsien.
- Hierdie is minder voorspelbaar, maar ook minder uitbuitbaar, aangesien hulle nie slabs met ander objects deel nie.

### 7. Allocation Patterns Attackers Target
Selfs met hierdie beskermings soek aanvallers steeds na:
- **Reference count objects**: as jy die retain/release tellers kan knoei, kan jy use-after-free veroorsaak.
- **Objects with function pointers (vtables)**: korrupsie van een gee steeds control flow.
- **Shared memory objects (IOSurface, Mach ports)**: hierdie bly aanvalspunte omdat hulle user ↔ kernel bridge.

Maar — anders as vroeër — kan jy nie net `OSData` spray en verwag dat dit langs ’n `task_t` beland nie. Jy het nodig vir **type-specific bugs** of **info leaks** om sukses te behaal.

### Example: Allocation Flow in Modern Heap

Stel userspace roep IOKit op om ’n `OSData` object te alloceer:

1. **Type lookup** → `OSData` map na `kalloc_type_osdata` zone (grootte 64 bytes).
2. Check per-CPU cache vir vrye elemente.
- As gevind → return een.
- As leeg → gaan na global freelist.
- As freelist leeg → alloceer ’n nuwe slab (page van 4KB → 64 stukkies van 64 bytes).
3. Return chunk aan caller.

**Freelist pointer protection**:
- Elke vrygestelde chunk stoor die adres van die volgende vrye chunk, maar geënkodeer met ’n geheime sleutel.
- Oorskryf van daardie veld met aanvallerdata sal nie werk tensy jy die sleutel ken nie.

---

## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages, and **PAC** protects pointers |
| Allocation reuse validation     | None (freelist pointers raw)                               | **zone_require / zone enforcement**             |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |
| Large allocations handling      | All small allocations managed equally                       | Large ones bypass zones → handled via VM         |

---

## Modern Userland Heap (iOS, macOS — type-aware / xzone malloc)

In onlangse Apple OS-weergawes (veral iOS 17+), het Apple ’n veiliger userland allocator bekendgestel, **xzone malloc** (XZM). Dit is die user-space analoog van die kernel se `kalloc_type`, wat tipe-bewustheid, metadata-isolasie en geheue-tagging-maatreëls toepas.

### Goals & Design Principles

- **Type segregation / type awareness**: groepeer allocations per tipe of gebruik (pointer vs data) om type confusion en cross-type reuse te voorkom.
- **Metadata isolation**: skei heap-metadata (bv. free lists, size/state bits) van object payloads sodat out-of-bounds writes minder waarskynlik metadata korrupteer.
- **Guard pages / redzones**: voeg unmapped pages of padding rondom allocations in om overflows te vang.
- **Memory tagging (EMTE / MIE)**: werk saam met hardware-tagging om use-after-free, out-of-bounds en ongeldige toegang te detecteer.
- **Scalable performance**: behou lae overhead, voorkom oormatige fragmentasie, en ondersteun baie allocations per sekonde met lae latensie.

### Architecture & Components

Hierdie is die hoofelemente in die xzone allocator:

#### Segment Groups & Zones

- **Segment groups** verdeel die adresruimte volgens gebruikskategorieë: bv. `data`, `pointer_xzones`, `data_large`, `pointer_large`.
- Elke segment group bevat **segments** (VM-reekse) wat allocations vir daardie kategorie huisves.
- Geassosieer met elke segment is ’n **metadata slab** (afsonderlike VM-gebied) wat metadata stoor (bv. free/used bits, size classes) vir daardie segment. Hierdie **out-of-line (OOL) metadata** verseker dat metadata nie met object payloads gemeng word nie, wat korrupsie deur overflows verminder.
- Segmente word in **chunks** (sny) verdeel wat op hul beurt in **blocks** (allocasie-eenhede) onderverdeel is. ’n Chunk is gebonde aan ’n spesifieke grootteklas en segment group (d.w.s. alle blocks in ’n chunk deel dieselfde grootte & kategorie).
- Vir klein/mid-size allocations gebruik dit vaste-grootte chunks; vir groot/baie groot, kan dit afsonderlik map.

#### Chunks & Blocks

- ’n **Chunk** is ’n gebied (dikwels verskeie pages) toegewy aan allocations van een grootteklas binne ’n group.
- Binne ’n chunk is **blocks** beskikbaar vir allocations. Vrygestelde blocks word deur die metadata slab opgespoor — bv. via bitmaps of free lists gestoor out-of-line.
- Tussen chunks (of binne) kan **guard slices / guard pages** ingevoeg word (bv. unmapped slices) om out-of-bounds writes op te vang.

#### Type / Type ID

- Elke allocasie-plek (of oproep na malloc, calloc, ens.) is geassosieer met ’n **type identifier** (’n `malloc_type_id_t`) wat enkodeer watter soort object gealloceer word. Daardie type ID word aan die allocator deurgegee, wat dit gebruik om te kies watter zone/segment die allocasie moet voorsien.
- As gevolg hiervan, selfs al het twee allocations dieselfde grootte, kan hulle in heeltemal verskillende zones beland as hul tipes verskil.
- In vroeë iOS 17-weergawes was nie alle APIs (bv. CFAllocator) volledig type-aware nie; Apple het ’n paar van daardie swakpunte in iOS 18 aangespreek.

---

### Allocation & Freeing Workflow

Hier is ’n hoëvlakvloei van hoe allocation en deallocation in xzone werk:

1. **malloc / calloc / realloc / typed alloc** word geroep met ’n grootte en type ID.
2. Die allocator gebruik die **type ID** om die korrekte segment group / zone te kies.
3. Binne daardie zone/segment soek dit ’n chunk met vrye blocks van die aangevraagde grootte.
- Dit kan plaaslike caches / per-thread pools of free block lists uit metadata raadpleeg.
- As geen vrye block beskikbaar is nie, kan dit ’n nuwe chunk in daardie zone alloceer.
4. Die metadata slab word bygewerk (vry-bit verwyder, boekhouding).
5. As memory tagging (EMTE) in werking is, kry die teruggegewe block ’n **tag** en word metadata bygewerk om sy “lewende” toestand te toon.
6. Wanneer `free()` geroep word:
- Die block word in die metadata as vry gemerk (via OOL slab).
- Die block kan in ’n free list geplaas of gepoel word vir hergebruik.
- Opsioneel kan block-inhoud geclear of ge-poison word om data-lekke of use-after-free uitbuiting te verminder.
- Die hardware-tag wat met die block geassosieer is, kan ongeldig gemaak of hergetag word.
- As ’n hele chunk vry raak (alle blocks vry), kan die allocator daardie chunk **reclaim** (unmap of teruggee aan OS) onder geheue-druk.

---

### Security Features & Hardening

Dit is die verdedigings ingebou in moderne userland xzone:

| Feature | Purpose | Notes |
|---|-------------------------------|-----------------------------------------|
| **Metadata decoupling** | Prevent overflow from corrupting metadata | Metadata lives in separate VM region (metadata slab)|
| **Guard pages / unmapped slices** | Catch out-of-bounds writes | Helps detect buffer overflows rather than silently corrupting adjacent blocks|
| **Type-based segregation** | Prevent cross-type reuse & type confusion | Even same-size allocations from different types go to different zones|
| **Memory Tagging (EMTE / MIE)** | Detect invalid access, stale references, OOB, UAF | xzone works in concert with hardware EMTE in synchronous mode (“Memory Integrity Enforcement”)|
| **Delayed reuse / poisoning / zap** | Reduce chance of use-after-free exploitation | Freed blocks may be poisoned, zeroed, or quarantined before reuse |
| **Chunk reclamation / dynamic unmapping** | Reduce memory waste and fragmentation | Entire chunks may be unmapped when unused |
| **Randomization / placement variation** | Prevent deterministic adjacency | Blocks in a chunk and chunk selection may have randomized aspects |
| **Segregation of “data-only” allocations** | Separate allocations that don’t store pointers | Reduces attacker control over metadata or control fields|

---

### Interaction with Memory Integrity Enforcement (MIE / EMTE)

- Apple se MIE (Memory Integrity Enforcement) is die hardware + OS-raming wat **Enhanced Memory Tagging Extension (EMTE)** in altyd-aan, sinchrone modus oor groot aanvalsvlakke bring.
- Die xzone allocator is ’n fundamentele fondament van MIE in user space: allocations wat via xzone gedoen word kry tags, en toegang word deur hardware geverifieer.
- In MIE is die allocator, tag-toewysing, metadata-bestuur en tag-konfidensialiteit-integriteit geïntegreer om seker te maak dat geheuefoute (bv. stale reads, OOB, UAF) onmiddellik gevang word, nie later uitgebuit nie.

---

As jy wil, kan ek ook ’n cheat-sheet of diagram van xzone-internals vir jou boek genereer. Wil jy dat ek dit volgende doen?
::contentReference[oaicite:20]{index=20}


---

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Laai BinDiff DMG af vanaf [https://www.zynamics.com/bindiff/manual] en installeer dit.

Open Ghidra met `ghidraRun` en gaan na `File` --> `Install Extensions`, druk die add-knoppie en kies die pad `/Applications/BinDiff/Extra/Ghidra/BinExport` en klik OK en install dit selfs al is daar ’n weergawe-onversoening.

### Using BinDiff with Kernel versions

1. Gaan na die bladsy [https://ipsw.me/](https://ipsw.me/) en laai die iOS-weergawe(s) af wat jy wil diff. Hierdie sal `.ipsw`-lêers wees.
2. Ontpak totdat jy die bin-formaat van die kernelcache van albei `.ipsw`-lêers kry. Daar is inligting oor hoe om dit te doen in:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra met `ghidraRun`, skep ’n nuwe projek en laai die kernelcaches.
4. Open elke kernelcache sodat hulle outomaties deur Ghidra geanaliseer word.
5. Dan, in die project Window van Ghidra, regsklik elke kernelcache, kies `Export`, kies formaat `Binary BinExport (v2) for BinDiff` en exporteer hulle.
6. Open BinDiff, skep ’n nuwe workspace en voeg ’n nuwe diff by deur as primêre lêer die kernelcache aan te dui wat die kwetsbaarheid bevat en as sekondêre lêer die gepatchte kernelcache.

---

## Finding the right XNU version

As jy vir kwesbaarhede in ’n spesifieke weergawe van iOS wil kyk, kan jy nagaan watter XNU-release weergawe daardie iOS-weergawe gebruik by [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

Byvoorbeeld, die weergawes `15.1 RC`, `15.1` en `15.1.1` gebruik die weergawe `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.

### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

{{#include ../../banners/hacktricks-training.md}}
