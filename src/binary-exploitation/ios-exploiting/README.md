# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** in iOS funciona exigindo que cada trecho de código executável (apps, libraries, extensions, etc.) seja criptograficamente assinado com um certificado emitido pela Apple. Quando o código é carregado, iOS verifica a assinatura digital contra a raiz confiável da Apple. Se a assinatura for inválida, ausente ou modificada, o SO se recusa a executá-lo. Isso impede que atacantes injetem código malicioso em apps legítimos ou executem binários sem assinatura, bloqueando efetivamente a maioria das cadeias de exploit que dependem de executar código arbitrário ou adulterado.
- **CoreTrust** é o subsistema do iOS responsável por fazer cumprir o code signing em tempo de execução. Ele verifica diretamente assinaturas usando o certificado raiz da Apple sem depender de caches de confiança, o que significa que somente binários assinados pela Apple (ou com entitlements válidos) podem ser executados. O CoreTrust garante que mesmo se um atacante adulterar um app após a instalação, modificar bibliotecas do sistema ou tentar carregar código não assinado, o sistema bloqueará a execução a menos que o código ainda esteja devidamente assinado. Essa aplicação estrita fecha muitos vetores de pós-exploração que versões antigas do iOS permitiam por meio de verificações de assinatura mais fracas ou contornáveis.
- **Data Execution Prevention (DEP)** marca regiões de memória como não executáveis a menos que contenham explicitamente código. Isso impede que atacantes injetem shellcode em regiões de dados (como stack ou heap) e o executem, forçando-os a depender de técnicas mais complexas como ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** randomiza os endereços de memória de código, bibliotecas, stack e heap a cada execução do sistema. Isso torna muito mais difícil para atacantes preverem onde instruções ou gadgets úteis estão, quebrando muitas cadeias de exploit que dependem de layouts de memória fixos.
- **KASLR (Kernel ASLR)** aplica o mesmo conceito de randomização ao kernel do iOS. Embaralhando o endereço base do kernel a cada boot, impede que atacantes localizem de forma confiável funções ou estruturas do kernel, aumentando a dificuldade de exploits em nível de kernel que buscariam obter controle total do sistema.
- **Kernel Patch Protection (KPP)**, também conhecido como **AMCC (Apple Mobile File Integrity)** no iOS, monitora continuamente as páginas de código do kernel para garantir que não foram modificadas. Se qualquer adulteração for detectada — como um exploit tentando patchar funções do kernel ou inserir código malicioso — o dispositivo entrará imediatamente em panic e fará reboot. Essa proteção torna exploits persistentes no kernel muito mais difíceis, já que atacantes não podem simplesmente hookar ou patchar instruções do kernel sem provocar um crash do sistema.
- **Kernel Text Readonly Region (KTRR)** é uma feature de segurança baseada em hardware introduzida em dispositivos iOS. Ela usa o memory controller da CPU para marcar a seção de código (text) do kernel como permanentemente read-only após o boot. Uma vez bloqueada, até o próprio kernel não pode modificar essa região de memória. Isso impede que atacantes — e mesmo código privilegiado — patcharem instruções do kernel em tempo de execução, fechando uma grande classe de exploits que dependiam de modificar código do kernel diretamente.
- **Pointer Authentication Codes (PAC)** usa assinaturas criptográficas embutidas em bits não utilizados de pointers para verificar sua integridade antes do uso. Quando um pointer (como um return address ou function pointer) é criado, a CPU o assina com uma chave secreta; antes de desreferenciar, a CPU verifica a assinatura. Se o pointer foi adulterado, a checagem falha e a execução é interrompida. Isso impede que atacantes forjem ou reutilizem pointers corrompidos em exploits de corrupção de memória, tornando técnicas como ROP ou JOP muito mais difíceis de executar de forma confiável.
- **Privilege Access never (PAN)** é uma feature de hardware que impede o kernel (modo privilegiado) de acessar diretamente memória de user-space a menos que explicitamente habilite esse acesso. Isso bloqueia atacantes que obtiveram execução de código no kernel de ler ou escrever facilmente a memória do usuário para escalar privilégios ou roubar dados sensíveis. Ao impor separação estrita, PAN reduz o impacto de exploits no kernel e bloqueia muitas técnicas comuns de escalada de privilégio.
- **Page Protection Layer (PPL)** é um mecanismo de segurança do iOS que protege regiões críticas de memória gerenciadas pelo kernel, especialmente as relacionadas a code signing e entitlements. Ele aplica proteções de escrita estritas usando a MMU (Memory Management Unit) e checagens adicionais, garantindo que até código privilegiado do kernel não possa modificar arbitrariamente páginas sensíveis. Isso impede que atacantes com execução em nível de kernel manipulem estruturas críticas de segurança, tornando persistência e bypasses de code-signing significativamente mais difíceis.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

O kernel usava um **zone allocator** (`kalloc`) dividido em "zones" de tamanho fixo.
Cada zone armazenava apenas alocações de uma única classe de tamanho.

A partir da captura de tela:

| Nome da Zona          | Tamanho do Elemento | Exemplo de Uso                                                              |
|-----------------------|---------------------|------------------------------------------------------------------------------|
| `default.kalloc.16`   | 16 bytes            | Structs de kernel muito pequenos, pointers.                                  |
| `default.kalloc.32`   | 32 bytes            | Small structs, object headers.                                               |
| `default.kalloc.64`   | 64 bytes            | Mensagens IPC, tiny kernel buffers.                                          |
| `default.kalloc.128`  | 128 bytes           | Objetos médios como partes de `OSObject`.                                    |
| …                     | …                   | …                                                                            |
| `default.kalloc.1280` | 1280 bytes          | Estruturas grandes, IOSurface/graphics metadata.                             |

Como funcionava:
- Cada pedido de alocação era **arredondado para cima** até o tamanho da zone mais próxima.
  (Ex.: um pedido de 50 bytes cai na zone `kalloc.64`).
- A memória em cada zone era mantida em um **freelist** — chunks liberados pelo kernel voltavam para aquela zone.
- Se você overflowasse um buffer de 64 bytes, você sobrescreveria o **próximo objeto na mesma zone**.

É por isso que **heap spraying / feng shui** era tão efetivo: você podia prever vizinhos de objetos ao espalhar alocações da mesma classe de tamanho.

### The freelist

Dentro de cada kalloc zone, objetos freed não eram devolvidos diretamente ao sistema — iam para um freelist, uma linked list de chunks disponíveis.

- Quando um chunk era liberado, o kernel escrevia um pointer no começo desse chunk → o endereço do próximo chunk livre na mesma zone.

- A zone mantinha um pointer HEAD para o primeiro chunk livre.

- A alocação sempre usava o HEAD atual:

1. Pop HEAD (retorna essa memória para o caller).

2. Atualiza HEAD = HEAD->next (armazenado no header do chunk freed).

- O freeing empurrava chunks de volta:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Então o freelist era apenas uma linked list construída dentro da própria memória liberada.

Estado normal:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Explorando a freelist

Porque os primeiros 8 bytes de um free chunk = freelist pointer, um atacante poderia corrompê-lo:

1. **Heap overflow** em um free chunk adjacente → sobrescrever seu “next” pointer.

2. **Use-after-free** write em um freed object → sobrescrever seu “next” pointer.

Então, na próxima alocação desse tamanho:

- O allocator retira o corrupted chunk.

- Segue o “next” pointer fornecido pelo atacante.

- Retorna um ponteiro para memória arbitrária, permitindo fake object primitives ou targeted overwrite.

Visual example of freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist design made exploitation highly effective pre-hardening: predictable neighbors from heap sprays, raw pointer freelist links, and no type separation allowed attackers to escalate UAF/overflow bugs into arbitrary kernel memory control.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Over time, the kernel heap gets fragmented: some zones have holes where old
objects were freed.
- The attacker first makes lots of dummy allocations to fill these gaps, so
the heap becomes “packed” and predictable.

2. Force new pages
- Once the holes are filled, the next allocations must come from new pages
added to the zone.
- Fresh pages mean objects will be clustered together, not scattered across
old fragmented memory.
- This gives the attacker much better control of neighbors.

3. Place attacker objects
- The attacker now sprays again, creating lots of attacker-controlled objects
in those new pages.
- These objects are predictable in size and placement (since they all belong
to the same zone).

4. Free a controlled object (make a gap)
- The attacker deliberately frees one of their own objects.
- This creates a “hole” in the heap, which the allocator will later reuse for
the next allocation of that size.

5. Victim object lands in the hole
- The attacker triggers the kernel to allocate the victim object (the one
they want to corrupt).
- Since the hole is the first available slot in the freelist, the victim is
placed exactly where the attacker freed their object.

6. Overflow / UAF into victim
- Now the attacker has attacker-controlled objects around the victim.
- By overflowing from one of their own objects (or reusing a freed one), they
can reliably overwrite the victim’s memory fields with chosen values.

**Why it works**:

- Zone allocator predictability: allocations of the same size always come from
the same zone.
- Freelist behavior: new allocations reuse the most recently freed chunk first.
- Heap sprays: attacker fills memory with predictable content and controls layout.
- End result: attacker controls where the victim object lands and what data sits
next to it.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple hardened the allocator and made **heap grooming much harder**:

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

An attacker can no longer guarantee that controlled data (`OSData`) ends up adjacent to sensitive kernel objects (`task_t`) of the same size.

### 2. Slabs and Per-CPU Caches
- The heap is divided into **slabs** (pages of memory carved into fixed-size chunks for that zone).
- Each zone has a **per-CPU cache** to reduce contention.
- Allocation path:
1. Try per-CPU cache.
2. If empty, pull from the global freelist.
3. If freelist is empty, allocate a new slab (one or more pages).
- **Benefit**: This decentralization makes heap sprays less deterministic, since allocations may be satisfied from different CPUs’ caches.

### 3. Randomization inside zones
- Within a zone, freed elements are not handed back in simple FIFO/LIFO order.
- Modern XNU uses **encoded freelist pointers** (safe-linking like Linux, introduced ~iOS 14).
- Each freelist pointer is **XOR-encoded** with a per-zone secret cookie.
- This prevents attackers from forging a fake freelist pointer if they gain a write primitive.
- Some allocations are **randomized in their placement within a slab**, so spraying doesn’t guarantee adjacency.

### 4. Guarded Allocations
- Certain critical kernel objects (e.g., credentials, task structures) are allocated in **guarded zones**.
- These zones insert **guard pages** (unmapped memory) between slabs or use **redzones** around objects.
- Any overflow into the guard page triggers a fault → immediate panic instead of silent corruption.

### 5. Page Protection Layer (PPL) and SPTM
- Even if you control a freed object, you can’t modify all of kernel memory:
- **PPL (Page Protection Layer)** enforces that certain regions (e.g., code signing data, entitlements) are **read-only** even to the kernel itself.
- On **A15/M2+ devices**, this role is replaced/enhanced by **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- These hardware-enforced layers mean attackers can’t escalate from a single heap corruption to arbitrary patching of critical security structures.

### 6. Large Allocations
- Not all allocations go through `kalloc_type`.
- Very large requests (above ~16KB) bypass typed zones and are served directly from **kernel VM (kmem)** via page allocations.
- These are less predictable, but also less exploitable, since they don’t share slabs with other objects.

### 7. Allocation Patterns Attackers Target
Even with these protections, attackers still look for:
- **Reference count objects**: if you can tamper with retain/release counters, you may cause use-after-free.
- **Objects with function pointers (vtables)**: corrupting one still yields control flow.
- **Shared memory objects (IOSurface, Mach ports)**: these are still attack targets because they bridge user ↔ kernel.

But — unlike before — you can’t just spray `OSData` and expect it to neighbor a `task_t`. You need **type-specific bugs** or **info leaks** to succeed.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Each freed chunk stores the address of the next free chunk, but encoded with a secret key.
- Overwriting that field with attacker data won’t work unless you know the key.


## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

{{#include ../../banners/hacktricks-training.md}}
