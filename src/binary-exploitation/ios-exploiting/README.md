# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** in iOS works by requiring every piece of executable code (apps, libraries, extensions, etc.) to be cryptographically signed with a certificate issued by Apple. When code is loaded, iOS verifies the digital signature against Apple’s trusted root. If the signature is invalid, missing, or modified, the OS refuses to run it. This prevents attackers from injecting malicious code into legitimate apps or running unsigned binaries, effectively stopping most exploit chains that rely on executing arbitrary or tampered code.
- **CoreTrust** is the iOS subsystem responsible for enforcing code signing at runtime. It directly verifies signatures using Apple’s root certificate without relying on cached trust stores, meaning only binaries signed by Apple (or with valid entitlements) can execute. CoreTrust ensures that even if an attacker tampers with an app after installation, modifies system libraries, or tries to load unsigned code, the system will block execution unless the code is still properly signed. This strict enforcement closes many post-exploitation vectors that older iOS versions allowed through weaker or bypassable signature checks.
- **Data Execution Prevention (DEP)** marks memory regions as non-executable unless they explicitly contain code. This stops attackers from injecting shellcode into data regions (like the stack or heap) and running it, forcing them to rely on more complex techniques like ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** randomizes the memory addresses of code, libraries, stack, and heap every time the system runs. This makes it much harder for attackers to predict where useful instructions or gadgets are, breaking many exploit chains that depend on fixed memory layouts.
- **KASLR (Kernel ASLR)** applies the same randomization concept to the iOS kernel. By shuffling the kernel’s base address at each boot, it prevents attackers from reliably locating kernel functions or structures, raising the difficulty of kernel-level exploits that would otherwise gain full system control.
- **Kernel Patch Protection (KPP)** also known as **AMCC (Apple Mobile File Integrity)** in iOS, continuously monitors the kernel’s code pages to ensure they haven’t been modified. If any tampering is detected—such as an exploit trying to patch kernel functions or insert malicious code—the device will immediately panic and reboot. This protection makes persistent kernel exploits far harder, as attackers can’t simply hook or patch kernel instructions without triggering a system crash.
- **Kernel Text Readonly Region (KTRR)** is a hardware-based security feature introduced on iOS devices. It uses the CPU’s memory controller to mark the kernel’s code (text) section as permanently read-only after boot. Once locked, even the kernel itself cannot modify this memory region. This prevents attackers—and even privileged code—from patching kernel instructions at runtime, closing off a major class of exploits that relied on modifying kernel code directly.
- **Pointer Authentication Codes (PAC)** use cryptographic signatures embedded into unused bits of pointers to verify their integrity before use. When a pointer (like a return address or function pointer) is created, the CPU signs it with a secret key; before dereferencing, the CPU checks the signature. If the pointer was tampered with, the check fails and execution stops. This prevents attackers from forging or reusing corrupted pointers in memory corruption exploits, making techniques like ROP or JOP much harder to pull off reliably.
- **Privilege Access never (PAN)** is a hardware feature that prevents the kernel (privileged mode) from directly accessing user-space memory unless it explicitly enables access. This stops attackers who gained kernel code execution from easily reading or writing user memory to escalate exploits or steal sensitive data. By enforcing strict separation, PAN reduces the impact of kernel exploits and blocks many common privilege-escalation techniques.
- **Page Protection Layer (PPL)** is an iOS security mechanism that protects critical kernel-managed memory regions, especially those related to code signing and entitlements. It enforces strict write protections using the MMU (Memory Management Unit) and additional checks, ensuring that even privileged kernel code cannot arbitrarily modify sensitive pages. This prevents attackers who gain kernel-level execution from tampering with security-critical structures, making persistence and code-signing bypasses significantly harder.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

The kernel used a **zone allocator** (`kalloc`) divided into fixed-size "zones."
Each zone only stores allocations of a single size class.

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | बहुत छोटे kernel structs, pointers.                                         |
| `default.kalloc.32`  | 32 bytes     | छोटे structs, object headers.                                               |
| `default.kalloc.64`  | 64 bytes     | IPC messages, छोटे kernel buffers.                                          |
| `default.kalloc.128` | 128 bytes    | मध्यम objects जैसे `OSObject` के हिस्से।                                     |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | बड़े structures, IOSurface/graphics metadata.                               |

**How it worked:**
- Each allocation request gets **rounded up** to the nearest zone size.
(उदाहरण के लिए, a 50-byte request `kalloc.64` zone में land करेगा).
- Memory in each zone was kept in a **free list** — chunks freed by the kernel went back into that zone.
- If you overflowed a 64-byte buffer, you’d overwrite the **next object in the same zone**.

This is why **heap spraying / feng shui** was so effective: you could predict object neighbors by spraying allocations of the same size class.

### The freelist

Inside each kalloc zone, freed objects weren’t returned directly to the system — they went into a freelist, a linked list of available chunks.

- When a chunk was freed, the kernel wrote a pointer at the start of that chunk → the address of the next free chunk in the same zone.

- The zone kept a HEAD pointer to the first free chunk.

- Allocation always used the current HEAD:

1. Pop HEAD (return that memory to the caller).

2. Update HEAD = HEAD->next (stored in the freed chunk’s header).

- Freeing pushed chunks back:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

So the freelist was just a linked list built inside the freed memory itself.

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### freelist का शोषण

क्योंकि एक free chunk के पहले 8 bytes freelist pointer के बराबर होते हैं, तो attacker इसे corrupt कर सकता है:

1. **Heap overflow** पास के freed chunk में → इसके “next” pointer को overwrite कर देना।

2. **Use-after-free** freed object में लिखना → इसके “next” pointer को overwrite कर देना।

फिर, उसी size के अगले allocation पर:

- allocator corrupted chunk को pop कर देता है।
- attacker-supplied “next” pointer का पालन करता है।
- arbitrary memory के लिए एक pointer लौटाता है, जिससे fake object primitives या targeted overwrite संभव हो जाते हैं।

freelist poisoning का दृश्य उदाहरण:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist design ने exploitation को pre-hardening के दौरान बहुत प्रभावी बना दिया: predictable neighbors from heap sprays, raw pointer freelist links, और no type separation ने attackers को UAF/overflow bugs को arbitrary kernel memory control में escalate करने की अनुमति दी।

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Over time, the kernel heap gets fragmented: some zones have holes where old
objects were freed.
- The attacker first makes lots of dummy allocations to fill these gaps, so
the heap becomes “packed” and predictable.

2. Force new pages
- Once the holes are filled, the next allocations must come from new pages
added to the zone.
- Fresh pages mean objects will be clustered together, not scattered across
old fragmented memory.
- This gives the attacker much better control of neighbors.

3. Place attacker objects
- The attacker now sprays again, creating lots of attacker-controlled objects
in those new pages.
- These objects are predictable in size and placement (since they all belong
to the same zone).

4. Free a controlled object (make a gap)
- The attacker deliberately frees one of their own objects.
- This creates a “hole” in the heap, which the allocator will later reuse for
the next allocation of that size.

5. Victim object lands in the hole
- The attacker triggers the kernel to allocate the victim object (the one
they want to corrupt).
- Since the hole is the first available slot in the freelist, the victim is
placed exactly where the attacker freed their object.

6. Overflow / UAF into victim
- Now the attacker has attacker-controlled objects around the victim.
- By overflowing from one of their own objects (or reusing a freed one), they
can reliably overwrite the victim’s memory fields with chosen values.

**Why it works**:

- Zone allocator predictability: allocations of the same size always come from
the same zone.
- Freelist behavior: new allocations reuse the most recently freed chunk first.
- Heap sprays: attacker fills memory with predictable content and controls layout.
- End result: attacker controls where the victim object lands and what data sits
next to it.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple ने allocator को harden किया और **heap grooming को काफी कठिन** बना दिया:

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

An attacker अब यह guarantee नहीं कर सकता कि controlled data (`OSData`) उसी size के sensitive kernel objects (`task_t`) के adjacent आ जाएगी।

### 2. Slabs and Per-CPU Caches
- The heap को **slabs** में बाँटा गया है (pages of memory जिन्हें उस zone के fixed-size chunks में काटा जाता है)।
- हर zone का एक **per-CPU cache** होता है ताकि contention कम हो।
- Allocation path:
1. Try per-CPU cache.
2. If empty, pull from the global freelist.
3. If freelist is empty, allocate a new slab (one or more pages).
- **Benefit**: यह decentralization heap sprays को कम deterministic बनाती है, क्योंकि allocations अलग-अलग CPUs’ caches से पूरी हो सकती हैं।

### 3. Randomization inside zones
- Zone के अंदर, freed elements simple FIFO/LIFO order में वापस नहीं दिए जाते।
- Modern XNU uses **encoded freelist pointers** (safe-linking जैसे Linux, introduced ~iOS 14)।
- हर freelist pointer को एक per-zone secret cookie के साथ **XOR-encode** किया जाता है।
- इससे attackers को fake freelist pointer forge करना मुश्किल हो जाता है अगर उनके पास write primitive हो।
- कुछ allocations को **slab के भीतर placement में randomize** किया जाता है, इसलिए spraying adjacency की गारंटी नहीं देता।

### 4. Guarded Allocations
- कुछ critical kernel objects (जैसे credentials, task structures) **guarded zones** में allocate किए जाते हैं।
- ये zones slabs के बीच **guard pages** (unmapped memory) डालते हैं या objects के चारों ओर **redzones** इस्तेमाल करते हैं।
- Guard page में overflow होना एक fault trigger करता है → silent corruption की बजाय immediate panic।

### 5. Page Protection Layer (PPL) and SPTM
- भले ही आप किसी freed object को control कर लें, आप पूरा kernel memory modify नहीं कर सकते:
- **PPL (Page Protection Layer)** enforce करता है कि कुछ regions (जैसे code signing data, entitlements) kernel के लिए भी **read-only** रहें।
- **A15/M2+ devices** पर यह role **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)** से replace/enhanced हुआ है।
- ये hardware-enforced layers attackers को single heap corruption से critical security structures के arbitrary patching से रोकती हैं।

### 6. Large Allocations
- सब allocations `kalloc_type` से नहीं गुजरते।
- बहुत बड़े requests (≈16KB से ऊपर) typed zones को bypass करते हैं और सीधे **kernel VM (kmem)** से page allocations के रूप में serve होते हैं।
- ये कम predictable हैं, लेकिन कम exploitable भी होते हैं क्योंकि वे slabs को दूसरों के साथ share नहीं करते।

### 7. Allocation Patterns Attackers Target
इस protections के बावजूद, attackers अब भी इन पर नजर रखते हैं:
- **Reference count objects**: अगर आप retain/release counters को tamper कर सकें, तो use-after-free पैदा कर सकते हैं।
- **Objects with function pointers (vtables)**: एक को corrupt करके भी control flow मिल सकता है।
- **Shared memory objects (IOSurface, Mach ports)**: ये अभी भी attack targets हैं क्योंकि ये user ↔ kernel को bridge करते हैं।

पर — पहले की तरह — आप बस `OSData` को spray करके यह उम्मीद नहीं कर सकते कि वह `task_t` के साथ neighbor हो जाएगी। सफल होने के लिए आपको **type-specific bugs** या **info leaks** चाहिए होंगे।

### Example: Allocation Flow in Modern Heap

मान लीजिए userspace IOKit को call करके एक `OSData` object allocate करता है:

1. **Type lookup** → `OSData` map होता है `kalloc_type_osdata` zone में (size 64 bytes)।
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- हर freed chunk में next free chunk का address stored होता है, लेकिन इसे secret key से encoded किया जाता है।
- उस field को attacker data से overwrite करना तब काम नहीं करेगा जब तक आप key नहीं जानते।

## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

{{#include ../../banners/hacktricks-training.md}}
