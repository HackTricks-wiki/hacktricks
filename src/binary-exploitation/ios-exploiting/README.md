# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** en iOS funciona exigiendo que cada pieza de código ejecutable (apps, libraries, extensions, etc.) esté firmada criptográficamente con un certificado emitido por Apple. Cuando se carga el código, iOS verifica la firma digital contra la raíz de confianza de Apple. Si la firma es inválida, falta o ha sido modificada, el SO se niega a ejecutarlo. Esto impide que los atacantes inyecten código malicioso en apps legítimas o ejecuten binarios sin firmar, deteniendo efectivamente la mayoría de las cadenas de exploit que dependen de ejecutar código arbitrario o manipulado.
- **CoreTrust** es el subsistema de iOS responsable de hacer cumplir la firma de código en tiempo de ejecución. Verifica directamente las firmas usando el certificado raíz de Apple sin confiar en caches de confianza, lo que significa que solo pueden ejecutarse binarios firmados por Apple (o con entitlements válidos). CoreTrust asegura que incluso si un atacante manipula una app después de la instalación, modifica librerías del sistema o intenta cargar código sin firmar, el sistema bloqueará la ejecución a menos que el código siga estando correctamente firmado. Esta estricta aplicación cierra muchos vectores de post-explotación que versiones antiguas de iOS permitían mediante comprobaciones de firma más débiles o sorteables.
- **Data Execution Prevention (DEP)** marca regiones de memoria como no ejecutables a menos que contengan explícitamente código. Esto impide que los atacantes inyecten shellcode en regiones de datos (como el stack o el heap) y lo ejecuten, obligándoles a depender de técnicas más complejas como ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** aleatoriza las direcciones de memoria de código, librerías, stack y heap cada vez que el sistema arranca. Esto dificulta mucho que los atacantes predigan dónde están instrucciones o gadgets útiles, rompiendo muchas cadenas de exploit que dependen de un layout de memoria fijo.
- **KASLR (Kernel ASLR)** aplica el mismo concepto de aleatorización al kernel de iOS. Al barajar la dirección base del kernel en cada arranque, impide que los atacantes localicen de forma fiable funciones o estructuras del kernel, aumentando la dificultad de exploits a nivel de kernel que de otro modo obtendrían control total del sistema.
- **Kernel Patch Protection (KPP)**, también conocido como **AMCC (Apple Mobile File Integrity)** en iOS, monitoriza continuamente las páginas de código del kernel para asegurar que no han sido modificadas. Si se detecta cualquier manipulación —por ejemplo, un exploit intentando parchear funciones del kernel o insertar código malicioso— el dispositivo hará panic y se reiniciará inmediatamente. Esta protección hace que los exploits persistentes en el kernel sean mucho más difíciles, ya que los atacantes no pueden simplemente hookear o parchear instrucciones del kernel sin provocar un crash del sistema.
- **Kernel Text Readonly Region (KTRR)** es una característica de seguridad basada en hardware introducida en dispositivos iOS. Usa el controlador de memoria de la CPU para marcar la sección de código (text) del kernel como permanentemente de solo lectura después del arranque. Una vez bloqueada, incluso el kernel no puede modificar esa región de memoria. Esto impide que los atacantes —e incluso código privilegiado— parcheen instrucciones del kernel en tiempo de ejecución, cerrando una gran clase de exploits que dependían de modificar directamente el código del kernel.
- **Pointer Authentication Codes (PAC)** usan firmas criptográficas incrustadas en bits no usados de los pointers para verificar su integridad antes de usarlos. Cuando se crea un pointer (como una return address o un function pointer), la CPU lo firma con una clave secreta; antes de desreferenciarlo, la CPU comprueba la firma. Si el pointer fue manipulado, la comprobación falla y la ejecución se detiene. Esto impide que los atacantes forjen o reutilicen pointers corrompidos en exploits de corrupción de memoria, haciendo técnicas como ROP o JOP mucho más difíciles de realizar con fiabilidad.
- **Privilege Access never (PAN)** es una característica de hardware que impide que el kernel (modo privilegiado) acceda directamente a memoria de user-space a menos que explícitamente habilite ese acceso. Esto frena a atacantes que obtuvieron ejecución de código en el kernel para leer o escribir memoria de usuario fácilmente y así escalar exploits o robar datos sensibles. Al imponer una separación estricta, PAN reduce el impacto de exploits de kernel y bloquea muchas técnicas comunes de escalada de privilegios.
- **Page Protection Layer (PPL)** es un mecanismo de seguridad de iOS que protege regiones críticas de memoria gestionadas por el kernel, especialmente las relacionadas con code signing y entitlements. Aplica protecciones estrictas de escritura usando la MMU (Memory Management Unit) y comprobaciones adicionales, asegurando que incluso código privilegiado del kernel no pueda modificar páginas sensibles de forma arbitraria. Esto evita que atacantes que obtengan ejecución a nivel de kernel manipulen estructuras críticas de seguridad, haciendo la persistencia y los bypasses de code-signing significativamente más difíciles.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

El kernel usaba un **zone allocator** (`kalloc`) dividido en "zones" de tamaño fijo. Cada zone solo almacenaba asignaciones (allocations) de una única clase de tamaño.

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | Estructuras de kernel muy pequeñas, pointers.                               |
| `default.kalloc.32`  | 32 bytes     | Structs pequeños, object headers.                                           |
| `default.kalloc.64`  | 64 bytes     | IPC messages, tiny kernel buffers.                                          |
| `default.kalloc.128` | 128 bytes    | Objetos medianos como partes de `OSObject`.                                 |
| `default.kalloc.256` | 256 bytes    | Mensajes IPC más grandes, arrays, device structures.                        |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | Estructuras grandes, IOSurface/graphics metadata.                           |

**How it worked:**
- Cada petición de allocation se redondeaba hacia arriba (rounded up) al tamaño de zone más cercano.
(E.g., una petición de 50 bytes cae en la zone `kalloc.64`).
- La memoria en cada zone se mantenía en una **free list** — los chunks liberados por el kernel volvían a esa zone.
- Si desbordabas un buffer de 64 bytes, sobrescribirías el **siguiente objeto en la misma zone**.

Por eso el heap spraying / feng shui era tan efectivo: podías predecir los vecinos de los objetos rellenando allocations de la misma clase de tamaño.

### The freelist

Dentro de cada kalloc zone, los objetos liberados no se devolvían directamente al sistema — iban a una freelist, una lista enlazada de chunks disponibles.

- Cuando se liberaba un chunk, el kernel escribía un puntero al inicio de ese chunk → la dirección del siguiente chunk libre en la misma zone.

- La zone mantenía un puntero HEAD al primer chunk libre.

- La allocation siempre usaba el HEAD actual:

1. Pop HEAD (devolver esa memoria al llamador).

2. Actualizar HEAD = HEAD->next (almacenado en el header del chunk liberado).

- Freeing empujaba los chunks de vuelta:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Así que la freelist era simplemente una lista enlazada construida dentro de la propia memoria liberada.

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Explotando el freelist

Porque los primeros 8 bytes de un free chunk = freelist pointer, un atacante podría corromperlo:

1. **Heap overflow** en un freed chunk adyacente → sobrescribir su “next” pointer.

2. **Use-after-free** write en un objeto freed → sobrescribir su “next” pointer.

Entonces, en la siguiente asignación de ese tamaño:

- El allocator pops el chunk corrompido.
- Sigue el “next” pointer suministrado por el atacante.
- Devuelve un pointer a memoria arbitraria, permitiendo fake object primitives o sobrescritura dirigida.

Ejemplo visual de freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
Este diseño de freelist hacía que la explotación fuera muy efectiva antes del hardening: vecinos predecibles por heap sprays, enlaces de freelist con punteros crudos y la ausencia de separación por tipo permitían a los atacantes escalar bugs de UAF/overflow hasta lograr control arbitrario de la memoria del kernel.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Con el tiempo, el kernel heap se fragmenta: algunas zonas tienen huecos donde se liberaron objetos antiguos.
- El atacante primero hace muchas asignaciones dummy para rellenar esos huecos, de modo que el heap quede “empaquetado” y predecible.

2. Force new pages
- Una vez que los huecos están llenos, las siguientes asignaciones deben provenir de páginas nuevas añadidas a la zona.
- Páginas nuevas significan que los objetos estarán agrupados, no dispersos por memoria fragmentada antigua.
- Esto da al atacante mucho mejor control sobre los vecinos.

3. Place attacker objects
- El atacante vuelve a hacer spray, creando muchas instancias de objetos controlados por él en esas páginas nuevas.
- Estos objetos son predecibles en tamaño y colocación (ya que todos pertenecen a la misma zona).

4. Free a controlled object (make a gap)
- El atacante libera deliberadamente uno de sus propios objetos.
- Esto crea un “hueco” en el heap, que el allocator reutilizará luego para la próxima asignación de ese tamaño.

5. Victim object lands in the hole
- El atacante provoca que el kernel asigne el objeto víctima (el que quiere corromper).
- Dado que el hueco es la primera ranura disponible en la freelist, la víctima se coloca exactamente donde el atacante liberó su objeto.

6. Overflow / UAF into victim
- Ahora el atacante tiene objetos controlados alrededor de la víctima.
- Al desbordar desde uno de sus propios objetos (o reutilizando uno liberado), puede sobrescribir de forma fiable los campos de memoria de la víctima con valores elegidos.

**Why it works**:

- Predictibilidad del zone allocator: las asignaciones del mismo tamaño siempre provienen de la misma zona.
- Comportamiento de la freelist: las nuevas asignaciones reutilizan primero el chunk liberado más recientemente.
- Heap sprays: el atacante llena la memoria con contenido predecible y controla el layout.
- Resultado final: el atacante controla dónde cae el objeto víctima y qué datos quedan junto a él.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple endureció el allocator y hizo que el **heap grooming sea mucho más difícil**:

### 1. From Classic kalloc to kalloc_type
- **Before**: existedía una sola zona `kalloc.<size>` para cada clase de tamaño (16, 32, 64, … 1280, etc.). Cualquier objeto de ese tamaño se colocaba allí → los objetos del atacante podían quedar junto a objetos privilegiados del kernel.
- **Now**:
- Los objetos del kernel se asignan desde **typed zones** (`kalloc_type`).
- Cada tipo de objeto (por ejemplo, `ipc_port_t`, `task_t`, `OSString`, `OSData`) tiene su propia zona dedicada, incluso si tienen el mismo tamaño.
- El mapeo entre tipo de objeto ↔ zona se genera desde el **kalloc_type system** en tiempo de compilación.

Un atacante ya no puede garantizar que datos controlados (`OSData`) queden adyacentes a objetos sensibles del kernel (`task_t`) del mismo tamaño.

### 2. Slabs and Per-CPU Caches
- El heap se divide en **slabs** (páginas de memoria partidas en chunks de tamaño fijo para esa zona).
- Cada zona tiene una **per-CPU cache** para reducir la contención.
- Ruta de asignación:
1. Intentar la per-CPU cache.
2. Si está vacía, tomar del global freelist.
3. Si la freelist está vacía, asignar un nuevo slab (una o más páginas).
- **Beneficio**: esta descentralización hace que los heap sprays sean menos deterministas, ya que las asignaciones pueden servirse desde cachés de diferentes CPUs.

### 3. Randomization inside zones
- Dentro de una zona, los elementos liberados no se entregan en un simple orden FIFO/LIFO.
- XNU moderno usa **encoded freelist pointers** (safe-linking al estilo Linux, introducido ~iOS 14).
- Cada puntero de freelist está **XOR-encodeado** con una cookie secreta por zona.
- Esto impide que un atacante forje un puntero de freelist falso si obtiene una primitiva de escritura.
- Algunas asignaciones se **aleatorizan en su colocación dentro de un slab**, por lo que el spraying no garantiza adyacencia.

### 4. Guarded Allocations
- Ciertos objetos críticos del kernel (p. ej., credenciales, estructuras task) se asignan en **guarded zones**.
- Estas zonas insertan **guard pages** (memoria no mapeada) entre slabs o usan **redzones** alrededor de objetos.
- Cualquier overflow hacia la guard page provoca un fault → pánico inmediato en lugar de corrupción silenciosa.

### 5. Page Protection Layer (PPL) and SPTM
- Incluso si controlas un objeto liberado, no puedes modificar toda la memoria del kernel:
- **PPL (Page Protection Layer)** hace cumplir que ciertas regiones (p. ej., datos de code signing, entitlements) sean **read-only** incluso para el propio kernel.
- En dispositivos **A15/M2+**, este rol se reemplaza/mejora con **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- Estas capas impuestas por hardware significan que los atacantes no pueden escalar desde una sola corrupción en el heap a parcheos arbitrarios de estructuras críticas de seguridad.

### 6. Large Allocations
- No todas las asignaciones pasan por `kalloc_type`.
- Peticiones muy grandes (por encima de ~16KB) evitan las typed zones y se sirven directamente desde **kernel VM (kmem)** mediante asignaciones de páginas.
- Estas son menos predecibles, pero también menos explotables, ya que no comparten slabs con otros objetos.

### 7. Allocation Patterns Attackers Target
Even with these protections, attackers still look for:
- **Reference count objects**: si puedes manipular contadores retain/release, puedes causar use-after-free.
- **Objects with function pointers (vtables)**: corromper uno todavía da control de flujo.
- **Shared memory objects (IOSurface, Mach ports)**: siguen siendo objetivos porque enlazan user ↔ kernel.

But — unlike before — you can’t just spray `OSData` and expect it to neighbor a `task_t`. You need **type-specific bugs** or **info leaks** to succeed.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Each freed chunk stores the address of the next free chunk, but encoded with a secret key.
- Overwriting that field with attacker data won’t work unless you know the key.


## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and install it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


{{#include ../../banners/hacktricks-training.md}}
