# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** dans iOS fonctionne en exigeant que chaque morceau de code exécutable (apps, libraries, extensions, etc.) soit signé cryptographiquement avec un certificat émis par Apple. Lorsque le code est chargé, iOS vérifie la signature numérique par rapport à la racine de confiance d’Apple. Si la signature est invalide, absente ou modifiée, l’OS refuse de l’exécuter. Cela empêche les attaquants d’injecter du code malveillant dans des apps légitimes ou d’exécuter des binaires non signés, bloquant ainsi la plupart des chaînes d’exploit qui reposent sur l’exécution de code arbitraire ou altéré.
- **CoreTrust** est le sous-système iOS responsable de l’application du code signing au runtime. Il vérifie directement les signatures en utilisant le certificat racine d’Apple sans s’appuyer sur des magasins de confiance mis en cache, ce qui signifie que seuls les binaires signés par Apple (ou avec des entitlements valides) peuvent s’exécuter. CoreTrust garantit que même si un attaquant altère une app après l’installation, modifie des libraries système, ou tente de charger du code non signé, le système bloquera l’exécution à moins que le code soit toujours correctement signé. Cette application stricte ferme de nombreux vecteurs post-exploitation que les anciennes versions d’iOS laissaient ouverts via des vérifications de signature plus faibles ou contournables.
- **Data Execution Prevention (DEP)** marque des régions mémoire comme non-exécutables à moins qu’elles ne contiennent explicitement du code. Cela empêche les attaquants d’injecter du shellcode dans des régions de données (comme le stack ou le heap) et de l’exécuter, les forçant à utiliser des techniques plus complexes comme ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** randomise les adresses mémoire du code, des libraries, du stack et du heap à chaque exécution du système. Cela rend beaucoup plus difficile pour un attaquant de prédire où se trouvent des instructions utiles ou des gadgets, cassant de nombreuses chaînes d’exploit qui dépendent d’un agencement mémoire fixe.
- **KASLR (Kernel ASLR)** applique le même concept de randomisation au kernel iOS. En mélangeant l’adresse de base du kernel à chaque démarrage, il empêche les attaquants de localiser de façon fiable des fonctions ou structures du kernel, augmentant la difficulté des exploits au niveau kernel qui obtiendraient autrement un contrôle total du système.
- **Kernel Patch Protection (KPP)**, aussi connu sous le nom **AMCC (Apple Mobile File Integrity)** dans iOS, surveille en continu les pages de code du kernel pour s’assurer qu’elles n’ont pas été modifiées. Si une altération est détectée — par exemple un exploit tentant de patcher des fonctions du kernel ou d’insérer du code malveillant — le dispositif paniquera et redémarrera immédiatement. Cette protection rend les exploits persistants au niveau kernel beaucoup plus difficiles, car les attaquants ne peuvent pas simplement hooker ou patcher des instructions du kernel sans déclencher un plantage système.
- **Kernel Text Readonly Region (KTRR)** est une fonctionnalité matérielle de sécurité introduite sur les appareils iOS. Elle utilise le contrôleur mémoire du CPU pour marquer la section de code (text) du kernel comme en lecture seule de façon permanente après le boot. Une fois verrouillée, même le kernel lui-même ne peut pas modifier cette région mémoire. Cela empêche les attaquants — et même du code privilégié — de patcher les instructions du kernel au runtime, fermant une grande classe d’exploits qui dépendaient de la modification directe du code kernel.
- **Pointer Authentication Codes (PAC)** utilisent des signatures cryptographiques intégrées dans des bits inutilisés des pointeurs pour vérifier leur intégrité avant utilisation. Lorsqu’un pointeur (comme une adresse de retour ou un function pointer) est créé, le CPU le signe avec une clé secrète ; avant la déréférence, le CPU vérifie la signature. Si le pointeur a été altéré, la vérification échoue et l’exécution s’arrête. Cela empêche les attaquants de forger ou de réutiliser des pointeurs corrompus dans des bugs de corruption mémoire, rendant des techniques comme ROP ou JOP beaucoup plus difficiles à réaliser de manière fiable.
- **Privilege Access never (PAN)** est une fonctionnalité matérielle qui empêche le kernel (mode privilégié) d’accéder directement à la mémoire user-space à moins qu’il n’active explicitement cet accès. Cela empêche les attaquants ayant obtenu l’exécution de code kernel de lire ou écrire facilement la mémoire utilisateur pour escalader des privilèges ou voler des données sensibles. En imposant une séparation stricte, PAN réduit l’impact des exploits kernel et bloque de nombreuses techniques courantes d’élévation de privilèges.
- **Page Protection Layer (PPL)** est un mécanisme de sécurité iOS qui protège des régions mémoire critiques gérées par le kernel, spécialement celles liées au code signing et aux entitlements. Il impose des protections d’écriture strictes en utilisant la MMU (Memory Management Unit) et des contrôles supplémentaires, garantissant que même du code kernel privilégié ne peut pas modifier arbitrairement des pages sensibles. Cela empêche les attaquants ayant obtenu l’exécution au niveau kernel de manipuler des structures critiques pour la sécurité, rendant la persistance et les contournements du code signing significativement plus difficiles.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

Le kernel utilisait un **zone allocator** (`kalloc`) divisé en "zones" de tailles fixes.
Chaque zone ne stockait que des allocations d’une seule classe de taille.

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | Very small kernel structs, pointers.                                        |
| `default.kalloc.32`  | 32 bytes     | Small structs, object headers.                                              |
| `default.kalloc.64`  | 64 bytes     | IPC messages, tiny kernel buffers.                                          |
| `default.kalloc.128` | 128 bytes    | Medium objects like parts of `OSObject`.                                    |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | Large structures, IOSurface/graphics metadata.                              |

**How it worked:**
- Each allocation request gets **rounded up** to the nearest zone size.
(E.g., a 50-byte request lands in the `kalloc.64` zone).
- Memory in each zone was kept in a **free list** — chunks freed by the kernel went back into that zone.
- If you overflowed a 64-byte buffer, you’d overwrite the **next object in the same zone**.

This is why **heap spraying / feng shui** was so effective: you could predict object neighbors by spraying allocations of the same size class.

### The freelist

Inside each kalloc zone, freed objects weren’t returned directly to the system — they went into a freelist, a linked list of available chunks.

- When a chunk was freed, the kernel wrote a pointer at the start of that chunk → the address of the next free chunk in the same zone.

- The zone kept a HEAD pointer to the first free chunk.

- Allocation always used the current HEAD:

1. Pop HEAD (return that memory to the caller).

2. Update HEAD = HEAD->next (stored in the freed chunk’s header).

- Freeing pushed chunks back:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

So the freelist was just a linked list built inside the freed memory itself.

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Exploitation de la freelist

Parce que les 8 premiers octets d'un chunk libre = freelist pointer, un attaquant pourrait le corrompre :

1. **Heap overflow** dans un chunk libéré adjacent → écraser son “next” pointer.

2. **Use-after-free** écrire dans un objet libéré → écraser son “next” pointer.

Ensuite, lors de la prochaine allocation de cette taille :

- L'allocator dépile le chunk corrompu.
- Suit le “next” pointer fourni par l'attaquant.
- Retourne un pointeur vers de la mémoire arbitraire, permettant fake object primitives ou targeted overwrite.

Exemple visuel de freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist design made exploitation highly effective pre-hardening: predictable neighbors from heap sprays, raw pointer freelist links, and no type separation allowed attackers to escalate UAF/overflow bugs into arbitrary kernel memory control.

### Heap Grooming / Feng Shui
Le but du heap grooming est de **modeler l'agencement du heap** afin que, lorsqu'un attaquant déclenche un overflow ou un use-after-free, l'objet cible (victime) se retrouve juste à côté d'un objet contrôlé par l'attaquant.\
Ainsi, lorsqu'une corruption mémoire se produit, l'attaquant peut de manière fiable écraser l'objet victime avec des données contrôlées.

**Steps:**

1. Spray allocations (fill the holes)
- Au fil du temps, le heap du kernel se fragmente : certaines zones présentent des trous où d'anciens objets ont été libérés.
- L'attaquant crée d'abord de nombreuses allocations factices pour combler ces espaces, de sorte que le heap devient « compact » et prévisible.

2. Force new pages
- Une fois les trous comblés, les allocations suivantes doivent provenir de nouvelles pages ajoutées à la zone.
- Des pages neuves signifient que les objets seront regroupés, pas dispersés dans une mémoire fragmentée.
- Cela donne à l'attaquant un bien meilleur contrôle des voisins.

3. Place attacker objects
- L'attaquant effectue à nouveau des heap sprays, créant de nombreux objets contrôlés par l'attaquant dans ces nouvelles pages.
- Ces objets sont prévisibles en taille et en emplacement (puisqu'ils appartiennent tous à la même zone).

4. Free a controlled object (make a gap)
- L'attaquant libère délibérément un de ses propres objets.
- Cela crée un « trou » dans le heap, que l'allocateur réutilisera ensuite pour la prochaine allocation de cette taille.

5. Victim object lands in the hole
- L'attaquant déclenche la création par le kernel de l'objet victime (celui qu'il veut corrompre).
- Puisque le trou est le premier emplacement disponible dans la freelist, la victime est placée exactement là où l'attaquant a libéré son objet.

6. Overflow / UAF into victim
- L'attaquant a maintenant des objets contrôlés autour de la victime.
- En provoquant un overflow depuis un de leurs propres objets (ou en réutilisant un objet libéré), ils peuvent de manière fiable écraser les champs mémoire de la victime avec des valeurs choisies.

**Why it works**:

- Zone allocator predictability: les allocations de la même taille proviennent toujours de la même zone.
- Freelist behavior: les nouvelles allocations réutilisent d'abord le chunk le plus récemment libéré.
- Heap sprays: l'attaquant remplit la mémoire avec un contenu prévisible et contrôle l'agencement.
- End result: l'attaquant contrôle où l'objet victime est placé et quelles données l'entourent.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple a durci l'allocateur et rendu le **heap grooming beaucoup plus difficile** :

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

Un attaquant ne peut plus garantir que des données contrôlées (`OSData`) se retrouvent adjacentes à des objets kernel sensibles (`task_t`) de la même taille.

### 2. Slabs and Per-CPU Caches
- Le heap est divisé en **slabs** (pages de mémoire découpées en chunks de taille fixe pour cette zone).
- Chaque zone possède un **cache par CPU** pour réduire la contention.
- Allocation path:
1. Essayer le cache par CPU.
2. Si vide, puiser dans la freelist globale.
3. Si la freelist est vide, allouer un nouveau slab (une ou plusieurs pages).
- **Benefit**: Cette décentralisation rend les heap sprays moins déterministes, puisque les allocations peuvent être satisfaites depuis les caches de différents CPU.

### 3. Randomization inside zones
- Au sein d'une zone, les éléments libérés ne sont pas rendus dans un ordre FIFO/LIFO simple.
- Modern XNU uses **encoded freelist pointers** (safe-linking like Linux, introduced ~iOS 14).
- Each freelist pointer is **XOR-encoded** with a per-zone secret cookie.
- This prevents attackers from forging a fake freelist pointer if they gain a write primitive.
- Certaines allocations sont **randomisées dans leur placement au sein d'un slab**, donc le spraying ne garantit pas l'adjacence.

### 4. Guarded Allocations
- Certains objets kernel critiques (p.ex. credentials, task structures) sont alloués dans des **zones protégées**.
- Ces zones insèrent des **guard pages** (mémoire non mappée) entre les slabs ou utilisent des **redzones** autour des objets.
- Tout overflow dans la guard page déclenche une fault → panic immédiat plutôt qu'une corruption silencieuse.

### 5. Page Protection Layer (PPL) and SPTM
- Même si vous contrôlez un objet libéré, vous ne pouvez pas modifier l'ensemble de la mémoire kernel :
- **PPL (Page Protection Layer)** impose que certaines régions (p.ex. données de code signing, entitlements) soient **en lecture seule** même pour le kernel lui-même.
- On **A15/M2+ devices**, this role is replaced/enhanced by **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- Ces couches imposées par le hardware signifient que les attaquants ne peuvent pas escalader depuis une simple corruption de heap vers un patch arbitraire de structures de sécurité critiques.

### 6. Large Allocations
- Not all allocations go through `kalloc_type`.
- Les requêtes très volumineuses (au-delà d'environ 16KB) contournent les zones typées et sont servies directement depuis la **kernel VM (kmem)** via des allocations de pages.
- Celles-ci sont moins prévisibles, mais aussi moins exploitables, puisqu'elles ne partagent pas de slabs avec d'autres objets.

### 7. Allocation Patterns Attackers Target
Même avec ces protections, les attaquants recherchent toujours :
- **Reference count objects** : si vous pouvez altérer les compteurs retain/release, vous pouvez provoquer un use-after-free.
- **Objects with function pointers (vtables)** : en corrompant l'un d'eux, on obtient toujours du contrôle du flux d'exécution.
- **Shared memory objects (IOSurface, Mach ports)** : ces objets restent des cibles car ils font le pont user ↔ kernel.

Mais — contrairement à avant — vous ne pouvez pas simplement spray `OSData` et vous attendre à le voir voisin d'un `task_t`. Vous avez besoin de **bugs spécifiques au type** ou d'**info leaks** pour réussir.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Chaque chunk libéré stocke l'adresse du chunk libre suivant, mais encodée avec une clé secrète.
- Écraser ce champ avec des données de l'attaquant ne fonctionnera pas à moins de connaître la clé.


## Comparison Table

| Fonctionnalité                  | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Granularité d'allocation        | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Prévisibilité du placement      | Élevée (objets de même taille côte à côte)                 | Faible (regroupement par type + randomisation)   |
| Gestion de la freelist          | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Contrôle des objets adjacents   | Facile via sprays/frees (feng shui predictable)            | Difficile — typed zones séparent les objets de l'attaquant |
| Protections des données/code kernel | Few hardware protections                                 | **PPL / SPTM** protect page tables & code pages   |
| Fiabilité de l'exploit          | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Téléchargez le DMG de BinDiff depuis [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) et installez-le.

Ouvrez Ghidra avec `ghidraRun` et allez dans `File` --> `Install Extensions`, appuyez sur le bouton add et sélectionnez le chemin `/Applications/BinDiff/Extra/Ghidra/BinExport` puis cliquez sur OK et installez-le même s'il y a un mismatch de version.

### Using BinDiff with Kernel versions

1. Allez sur la page [https://ipsw.me/](https://ipsw.me/) et téléchargez les versions iOS que vous voulez comparer. Ce seront des fichiers `.ipsw`.
2. Décompressez jusqu'à obtenir le format bin du kernelcache des deux fichiers `.ipsw`. Vous trouverez des informations sur comment faire ceci sur :

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Ouvrez Ghidra avec `ghidraRun`, créez un nouveau projet et chargez les kernelcaches.
4. Ouvrez chaque kernelcache afin qu'ils soient automatiquement analysés par Ghidra.
5. Ensuite, dans la fenêtre de projet de Ghidra, faites un clic droit sur chaque kernelcache, sélectionnez `Export`, choisissez le format `Binary BinExport (v2) for BinDiff` et exportez-les.
6. Ouvrez BinDiff, créez un nouveau workspace et ajoutez un nouveau diff en indiquant comme fichier primaire le kernelcache contenant la vulnérabilité et comme fichier secondaire le kernelcache patché.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

{{#include ../../banners/hacktricks-training.md}}
