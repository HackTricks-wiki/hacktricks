# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** in iOS działa w ten sposób, że każdy kawałek wykonywalnego kodu (apps, libraries, extensions, etc.) musi być kryptograficznie podpisany certyfikatem wydanym przez Apple. Gdy kod jest ładowany, iOS weryfikuje podpis cyfrowy względem zaufanego rootu Apple. Jeśli podpis jest nieprawidłowy, brakujący lub zmodyfikowany, system odmawia uruchomienia. To uniemożliwia atakującym wstrzykiwanie złośliwego kodu do legalnych aplikacji lub uruchamianie unsigned binaries, efektywnie blokując większość łańcuchów exploitów polegających na wykonaniu dowolnego lub zmodyfikowanego kodu.
- **CoreTrust** to podsystem iOS odpowiedzialny za egzekwowanie code signing w czasie wykonywania. Weryfikuje on podpisy bezpośrednio przy użyciu root certyfikatu Apple, nie polegając na cache’owanych store’ach zaufania, co oznacza, że tylko binaria podpisane przez Apple (lub posiadające ważne entitlements) mogą być uruchamiane. CoreTrust zapewnia, że nawet jeśli atakujący zmanipuluje aplikację po instalacji, zmodyfikuje systemowe biblioteki lub spróbuje załadować unsigned code, system zablokuje wykonanie, chyba że kod nadal jest poprawnie podpisany. Ta ścisła egzekucja zamyka wiele wektorów post-exploitation, które starsze wersje iOS pozwalały obejść przez słabsze lub obchodliwe sprawdzanie podpisów.
- **Data Execution Prevention (DEP)** oznacza regiony pamięci jako non-executable, chyba że jawnie zawierają kod. To uniemożliwia atakującym wstrzykiwanie shellcode do obszarów danych (jak stack czy heap) i jego uruchomienie, zmuszając do użycia bardziej złożonych technik jak ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** losowo rozmieszcza adresy pamięci kodu, bibliotek, stosu i sterty przy każdym uruchomieniu systemu. To utrudnia atakującym przewidzenie, gdzie znajdują się przydatne instrukcje lub gadgets, łamiąc wiele łańcuchów exploitów zależnych od stałego layoutu pamięci.
- **KASLR (Kernel ASLR)** stosuje ten sam koncept randomizacji do kernela iOS. Poprzez mieszanie bazowego adresu kernela przy każdym bootie, uniemożliwia atakującym niezawodne zlokalizowanie funkcji czy struktur kernela, podnosząc trudność exploitów na poziomie kernela, które w przeciwnym razie uzyskałyby pełną kontrolę nad systemem.
- **Kernel Patch Protection (KPP)** znane także jako **AMCC (Apple Mobile File Integrity)** w iOS, ciągle monitoruje strony kodu kernela, aby upewnić się, że nie zostały zmodyfikowane. Jeśli wykryte zostanie jakiekolwiek manipulowanie — np. exploit próbujący załatać funkcje kernela albo wstrzyknąć złośliwy kod — urządzenie natychmiast zpanicuje i zrestartuje się. Ta ochrona sprawia, że trwałe exploity na poziomie kernela są znacznie trudniejsze, ponieważ atakujący nie mogą po prostu hookować lub łatać instrukcji kernela bez wywołania crasha systemu.
- **Kernel Text Readonly Region (KTRR)** to sprzętowa funkcja bezpieczeństwa wprowadzona na urządzeniach iOS. Wykorzystuje kontroler pamięci CPU, aby oznaczyć sekcję kodu (text) kernela jako na stałe read-only po starcie. Gdy zostanie zablokowana, nawet sam kernel nie może modyfikować tego regionu pamięci. To zapobiega atakującym — a nawet uprzywilejowanemu kodowi — w łacie instrukcji kernela w czasie działania, zamykając dużą klasę exploitów polegających na bezpośredniej modyfikacji kodu kernela.
- **Pointer Authentication Codes (PAC)** używają podpisów kryptograficznych osadzonych w nieużywanych bitach pointerów, aby weryfikować ich integralność przed użyciem. Gdy pointer (np. return address lub function pointer) jest tworzony, CPU podpisuje go z użyciem sekretnego klucza; przed dereferencją CPU sprawdza ten podpis. Jeśli pointer został zmanipulowany, check nie przejdzie i wykonanie zostanie przerwane. To uniemożliwia atakującym fałszowanie lub ponowne użycie uszkodzonych pointerów w exploitach bazujących na korupcji pamięci, czyniąc techniki takie jak ROP czy JOP znacznie trudniejszymi do zrealizowania.
- **Privilege Access never (PAN)** to funkcja sprzętowa, która zapobiega bezpośredniemu dostępowi kernela (privileged mode) do pamięci user-space, chyba że jawnie włączy dostęp. To hamuje atakujących, którzy uzyskali wykonanie kodu w kernelu, przed łatwym odczytem lub zapisem pamięci użytkownika celem eskalacji exploitów lub kradzieży wrażliwych danych. Przez egzekwowanie ścisłego rozdziału, PAN zmniejsza wpływ exploitów kernelowych i blokuje wiele powszechnych technik eskalacji uprawnień.
- **Page Protection Layer (PPL)** to mechanizm bezpieczeństwa iOS, który chroni krytyczne regiony pamięci zarządzane przez kernel, szczególnie te związane z code signing i entitlements. Egzekwuje ścisłe write protections używając MMU (Memory Management Unit) oraz dodatkowych checków, zapewniając, że nawet uprzywilejowany kod kernela nie może arbitralnie modyfikować wrażliwych stron. To uniemożliwia atakującym, którzy uzyskali execution na poziomie kernela, manipulowanie strukturami krytycznymi dla bezpieczeństwa, czyniąc persistence i obejścia code-signing znacznie trudniejszymi.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

Kernel używał **zone allocator** (`kalloc`) podzielonego na strefy o stałym rozmiarze ("zones").
Każda strefa przechowywała alokacje tylko jednej klasy rozmiaru.

Z ekranu:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | Very small kernel structs, pointers.                                        |
| `default.kalloc.32`  | 32 bytes     | Small structs, object headers.                                              |
| `default.kalloc.64`  | 64 bytes     | IPC messages, tiny kernel buffers.                                          |
| `default.kalloc.128` | 128 bytes    | Medium objects like parts of `OSObject`.                                    |
| `default.kalloc.256` | 256 bytes    | Larger IPC messages, arrays, device structures.                             |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | Large structures, IOSurface/graphics metadata.                              |

**Jak to działało:**
- Każde żądanie alokacji było **zaokrąglane w górę** do najbliższego rozmiaru strefy.
(Np. żądanie 50 bajtów trafiało do strefy `kalloc.64`).
- Pamięć w każdej strefie była utrzymywana w **freelist** — chunky zwolnione przez kernel wracały do tej strefy.
- Jeśli przepełniłeś 64-bajtowy bufor, nadpisałbyś **następny obiekt w tej samej strefie**.

Dlatego właśnie **heap spraying / feng shui** było tak skuteczne: można było przewidzieć sąsiedztwo obiektów przez spryskiwanie alokacji tej samej klasy rozmiaru.

### The freelist

Wewnątrz każdej strefy kalloc, zwolnione obiekty nie były zwracane bezpośrednio do systemu — trafiały do freelist, listy powiązanej dostępnych chunków.

- Gdy chunk był zwalniany, kernel zapisywał wskaźnik na początek tego chunka → adres następnego wolnego chunka w tej samej strefie.

- Strefa trzymała HEAD wskaźnik do pierwszego wolnego chunka.

- Alokacja zawsze używała aktualnego HEAD:

1. Pop HEAD (zwróć tę pamięć callerowi).

2. Update HEAD = HEAD->next (przechowywane w headerze zwolnionego chunka).

- Freeing wrzucało chunk z powrotem:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Więc freelist był po prostu linked list budowaną wewnątrz samej zwolnionej pamięci.

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Wykorzystywanie freelist

Ponieważ pierwsze 8 bajtów wolnego chunk = freelist pointer, atakujący może go uszkodzić:

1. **Heap overflow** into an adjacent freed chunk → overwrite its “next” pointer.

2. **Use-after-free** write into a freed object → overwrite its “next” pointer.

Then, on the next allocation of that size:

- Alokator wyciąga (pop) sfałszowany chunk.

- Podąża za dostarczonym przez atakującego “next” pointer.

- Zwraca wskaźnik do dowolnej pamięci, umożliwiając fake object primitives lub ukierunkowane nadpisanie.

Wizualny przykład freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
Ten freelist design sprawiał, że eksploatacja była wysoce efektywna przed hardeningiem: przewidywalni neighbors z heap sprays, surowe wskaźniki raw pointer freelist links oraz brak separacji typów pozwalały atakującym eskalować błędy UAF/overflow do dowolnej kontroli pamięci jądra.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Over time, the kernel heap gets fragmented: some zones have holes where old
objects were freed.
- The attacker first makes lots of dummy allocations to fill these gaps, so
the heap becomes “packed” and predictable.

2. Force new pages
- Once the holes are filled, the next allocations must come from new pages
added to the zone.
- Fresh pages mean objects will be clustered together, not scattered across
old fragmented memory.
- This gives the attacker much better control of neighbors.

3. Place attacker objects
- The attacker now sprays again, creating lots of attacker-controlled objects
in those new pages.
- These objects are predictable in size and placement (since they all belong
to the same zone).

4. Free a controlled object (make a gap)
- The attacker deliberately frees one of their own objects.
- This creates a “hole” in the heap, which the allocator will later reuse for
the next allocation of that size.

5. Victim object lands in the hole
- The attacker triggers the kernel to allocate the victim object (the one
they want to corrupt).
- Since the hole is the first available slot in the freelist, the victim is
placed exactly where the attacker freed their object.

6. Overflow / UAF into victim
- Now the attacker has attacker-controlled objects around the victim.
- By overflowing from one of their own objects (or reusing a freed one), they
can reliably overwrite the victim’s memory fields with chosen values.

**Why it works**:

- Zone allocator predictability: allocations of the same size always come from
the same zone.
- Freelist behavior: new allocations reuse the most recently freed chunk first.
- Heap sprays: attacker fills memory with predictable content and controls layout.
- End result: attacker controls where the victim object lands and what data sits
next to it.

---

## Nowoczesny Kernel Heap (iOS 15+/A12+ SoCs)

Apple wzmocniło allocator i sprawiło, że **heap grooming jest znacznie trudniejsze**:

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

An attacker can no longer guarantee that controlled data (`OSData`) ends up adjacent to sensitive kernel objects (`task_t`) of the same size.

### 2. Slabs and Per-CPU Caches
- The heap is divided into **slabs** (pages of memory carved into fixed-size chunks for that zone).
- Each zone has a **per-CPU cache** to reduce contention.
- Allocation path:
1. Try per-CPU cache.
2. If empty, pull from the global freelist.
3. If freelist is empty, allocate a new slab (one or more pages).
- **Benefit**: This decentralization makes heap sprays less deterministic, since allocations may be satisfied from different CPUs’ caches.

### 3. Randomization inside zones
- Within a zone, freed elements are not handed back in simple FIFO/LIFO order.
- Modern XNU uses **encoded freelist pointers** (safe-linking like Linux, introduced ~iOS 14).
- Each freelist pointer is **XOR-encoded** with a per-zone secret cookie.
- This prevents attackers from forging a fake freelist pointer if they gain a write primitive.
- Some allocations are **randomized in their placement within a slab**, so spraying doesn’t guarantee adjacency.

### 4. Guarded Allocations
- Certain critical kernel objects (e.g., credentials, task structures) are allocated in **guarded zones**.
- These zones insert **guard pages** (unmapped memory) between slabs or use **redzones** around objects.
- Any overflow into the guard page triggers a fault → immediate panic instead of silent corruption.

### 5. Page Protection Layer (PPL) and SPTM
- Even if you control a freed object, you can’t modify all of kernel memory:
- **PPL (Page Protection Layer)** enforces that certain regions (e.g., code signing data, entitlements) are **read-only** even to the kernel itself.
- On **A15/M2+ devices**, this role is replaced/enhanced by **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- These hardware-enforced layers mean attackers can’t escalate from a single heap corruption to arbitrary patching of critical security structures.

### 6. Large Allocations
- Not all allocations go through `kalloc_type`.
- Very large requests (above ~16KB) bypass typed zones and are served directly from **kernel VM (kmem)** via page allocations.
- These are less predictable, but also less exploitable, since they don’t share slabs with other objects.

### 7. Allocation Patterns Attackers Target
Even with these protections, attackers still look for:
- **Reference count objects**: if you can tamper with retain/release counters, you may cause use-after-free.
- **Objects with function pointers (vtables)**: corrupting one still yields control flow.
- **Shared memory objects (IOSurface, Mach ports)**: these are still attack targets because they bridge user ↔ kernel.

But — unlike before — you can’t just spray `OSData` and expect it to neighbor a `task_t`. You need **type-specific bugs** or **info leaks** to succeed.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Each freed chunk stores the address of the next free chunk, but encoded with a secret key.
- Overwriting that field with attacker data won’t work unless you know the key.


## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


{{#include ../../banners/hacktricks-training.md}}
