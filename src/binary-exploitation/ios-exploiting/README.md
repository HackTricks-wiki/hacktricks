# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

- **Code Signing** en iOS funciona exigiendo que cada pieza de código ejecutable (apps, libraries, extensions, etc.) esté firmada criptográficamente con un certificado emitido por Apple. Cuando se carga código, iOS verifica la firma digital contra la raíz de confianza de Apple. Si la firma es inválida, falta o ha sido modificada, el SO se niega a ejecutarlo. Esto evita que atacantes inyecten código malicioso en apps legítimas o ejecuten binarios no firmados, deteniendo efectivamente la mayoría de cadenas de exploit que dependen de ejecutar código arbitrario o manipulado.
- **CoreTrust** es el subsistema de iOS responsable de hacer cumplir la firma de código en tiempo de ejecución. Verifica directamente las firmas usando el certificado raíz de Apple sin depender de tiendas de confianza en caché, lo que significa que solo pueden ejecutarse binarios firmados por Apple (o con entitlements válidos). CoreTrust asegura que incluso si un atacante manipula una app tras la instalación, modifica librerías del sistema o intenta cargar código no firmado, el sistema bloqueará la ejecución a menos que el código siga correctamente firmado. Esta aplicación estricta cierra muchos vectores de post-explotación que versiones antiguas de iOS permitían mediante comprobaciones de firma más débiles o sorteables.
- **Data Execution Prevention (DEP)** marca regiones de memoria como no ejecutables a menos que contengan explícitamente código. Esto impide que atacantes inyecten shellcode en regiones de datos (como stack o heap) y lo ejecuten, obligándolos a recurrir a técnicas más complejas como ROP (Return-Oriented Programming).
- **ASLR (Address Space Layout Randomization)** aleatoriza las direcciones de memoria de código, librerías, stack y heap cada vez que se inicia el sistema. Esto dificulta mucho que un atacante prediga dónde están instrucciones útiles o gadgets, rompiendo muchas cadenas de exploit que dependen de una disposición de memoria fija.
- **KASLR (Kernel ASLR)** aplica el mismo concepto de aleatorización al kernel de iOS. Al mezclar la dirección base del kernel en cada arranque, evita que los atacantes localicen de forma fiable funciones o estructuras del kernel, aumentando la dificultad de exploits a nivel de kernel que, de otro modo, ganarían control total del sistema.
- **Kernel Patch Protection (KPP)**, también conocido como **AMCC (Apple Mobile File Integrity)** en iOS, monitoriza continuamente las páginas de código del kernel para garantizar que no hayan sido modificadas. Si se detecta cualquier manipulación —por ejemplo, un exploit que intente parchear funciones del kernel o insertar código malicioso— el dispositivo entrará en panic y se reiniciará inmediatamente. Esta protección dificulta mucho los exploits persistentes en el kernel, ya que los atacantes no pueden simplemente enganchar o parchear instrucciones del kernel sin provocar un fallo del sistema.
- **Kernel Text Readonly Region (KTRR)** es una característica de seguridad basada en hardware introducida en dispositivos iOS. Usa el controlador de memoria de la CPU para marcar la sección de código (text) del kernel como permanentemente de solo lectura después del arranque. Una vez bloqueada, ni siquiera el propio kernel puede modificar esa región de memoria. Esto evita que atacantes —e incluso código privilegiado— parcheen instrucciones del kernel en tiempo de ejecución, cerrando una gran clase de exploits que dependían de modificar directamente el código del kernel.
- **Pointer Authentication Codes (PAC)** usan firmas criptográficas incrustadas en bits no usados de punteros para verificar su integridad antes de usarlos. Cuando se crea un puntero (por ejemplo una dirección de retorno o un function pointer), la CPU lo firma con una clave secreta; antes de desreferenciarlo, la CPU comprueba la firma. Si el puntero fue manipulado, la comprobación falla y la ejecución se detiene. Esto impide que los atacantes forjen o reutilicen punteros corrompidos en exploits de corrupción de memoria, haciendo técnicas como ROP o JOP mucho más difíciles de ejecutar con fiabilidad.
- **Privilege Access never (PAN)** es una característica de hardware que impide que el kernel (modo privilegiado) acceda directamente a la memoria de espacio de usuario a menos que active explícitamente el acceso. Esto impide que atacantes que obtuvieron ejecución de código en el kernel lean o escriban fácilmente la memoria de usuario para escalar exploits o robar datos sensibles. Al imponer una separación estricta, PAN reduce el impacto de exploits de kernel y bloquea muchas técnicas comunes de escalada de privilegios.
- **Page Protection Layer (PPL)** es un mecanismo de seguridad de iOS que protege regiones críticas de memoria gestionadas por el kernel, especialmente las relacionadas con code signing y entitlements. Impone protecciones estrictas de escritura usando la MMU (Memory Management Unit) y comprobaciones adicionales, asegurando que incluso código privilegiado del kernel no puede modificar arbitrariamente páginas sensibles. Esto evita que atacantes que logran ejecución a nivel de kernel manipulen estructuras críticas de seguridad, haciendo mucho más difíciles la persistencia y los bypasses de code signing.

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

El kernel usaba un **zone allocator** (`kalloc`) dividido en "zones" de tamaño fijo. Cada zone sólo almacenaba allocations de una única clase de tamaño.

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | Estructuras muy pequeñas del kernel, punteros.                              |
| `default.kalloc.32`  | 32 bytes     | Estructuras pequeñas, object headers.                                       |
| `default.kalloc.64`  | 64 bytes     | IPC messages, tiny kernel buffers.                                          |
| `default.kalloc.128` | 128 bytes    | Objetos medianos como partes de `OSObject`.                                 |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | Estructuras grandes, IOSurface/graphics metadata.                           |

**Cómo funcionaba:**
- Cada solicitud de asignación se redondeaba hacia arriba al tamaño de zone más cercano. (Ej.: una solicitud de 50 bytes termina en la zona `kalloc.64`).
- La memoria en cada zone se mantenía en una **freelist** — los chunks liberados por el kernel volvían a esa zone.
- Si sobrescribías un buffer de 64 bytes, sobreescribías el **objeto siguiente en la misma zone**.

Por eso **heap spraying / feng shui** era tan efectivo: podías predecir los vecinos de un objeto al alocar objetos de la misma clase de tamaño.

### The freelist

Dentro de cada zone de kalloc, los objetos liberados no se devolvían directamente al sistema — iban a una freelist, una lista enlazada de chunks disponibles.

- Cuando se liberaba un chunk, el kernel escribía un puntero al inicio de ese chunk → la dirección del siguiente chunk libre en la misma zone.

- La zone mantenía un puntero HEAD al primer chunk libre.

- Las allocations siempre usaban el HEAD actual:

1. Pop HEAD (devolver esa memoria al llamador).

2. Actualizar HEAD = HEAD->next (almacenado en el header del chunk liberado).

- Liberar inserta los chunks de nuevo:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Así que la freelist era simplemente una lista enlazada construida dentro de la propia memoria liberada.

Estado normal:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Explotando la freelist

Porque los primeros 8 bytes de un free chunk = freelist pointer, un atacante podría corromperlo:

1. **Heap overflow** en un freed chunk adyacente → sobrescribir su “next” pointer.

2. **Use-after-free** escribir en un freed object → sobrescribir su “next” pointer.

Entonces, en la siguiente allocation de ese tamaño:

- El allocator extrae el chunk corrompido.

- Sigue el “next” pointer provisto por el atacante.

- Devuelve un pointer a memoria arbitraria, permitiendo fake object primitives o targeted overwrite.

Ejemplo visual de freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist design made exploitation highly effective pre-hardening: predictable neighbors from heap sprays, raw pointer freelist links, and no type separation allowed attackers to escalate UAF/overflow bugs into arbitrary kernel memory control.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Over time, the kernel heap gets fragmented: some zones have holes where old
objects were freed.
- The attacker first makes lots of dummy allocations to fill these gaps, so
the heap becomes “packed” and predictable.

2. Force new pages
- Once the holes are filled, the next allocations must come from new pages
added to the zone.
- Fresh pages mean objects will be clustered together, not scattered across
old fragmented memory.
- This gives the attacker much better control of neighbors.

3. Place attacker objects
- The attacker now sprays again, creating lots of attacker-controlled objects
in those new pages.
- These objects are predictable in size and placement (since they all belong
to the same zone).

4. Free a controlled object (make a gap)
- The attacker deliberately frees one of their own objects.
- This creates a “hole” in the heap, which the allocator will later reuse for
the next allocation of that size.

5. Victim object lands in the hole
- The attacker triggers the kernel to allocate the victim object (the one
they want to corrupt).
- Since the hole is the first available slot in the freelist, the victim is
placed exactly where the attacker freed their object.

6. Overflow / UAF into victim
- Now the attacker has attacker-controlled objects around the victim.
- By overflowing from one of their own objects (or reusing a freed one), they
can reliably overwrite the victim’s memory fields with chosen values.

**Why it works**:

- Zone allocator predictability: allocations of the same size always come from
the same zone.
- Freelist behavior: new allocations reuse the most recently freed chunk first.
- Heap sprays: attacker fills memory with predictable content and controls layout.
- End result: attacker controls where the victim object lands and what data sits
next to it.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple hardened the allocator and made **heap grooming much harder**:

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

An attacker can no longer guarantee that controlled data (`OSData`) ends up adjacent to sensitive kernel objects (`task_t`) of the same size.

### 2. Slabs and Per-CPU Caches
- The heap is divided into **slabs** (pages of memory carved into fixed-size chunks for that zone).
- Each zone has a **per-CPU cache** to reduce contention.
- Allocation path:
1. Try per-CPU cache.
2. If empty, pull from the global freelist.
3. If freelist is empty, allocate a new slab (one or more pages).
- **Benefit**: This decentralization makes heap sprays less deterministic, since allocations may be satisfied from different CPUs’ caches.

### 3. Randomization inside zones
- Within a zone, freed elements are not handed back in simple FIFO/LIFO order.
- Modern XNU uses **encoded freelist pointers** (safe-linking like Linux, introduced ~iOS 14).
- Each freelist pointer is **XOR-encoded** with a per-zone secret cookie.
- This prevents attackers from forging a fake freelist pointer if they gain a write primitive.
- Some allocations are **randomized in their placement within a slab**, so spraying doesn’t guarantee adjacency.

### 4. Guarded Allocations
- Certain critical kernel objects (e.g., credentials, task structures) are allocated in **guarded zones**.
- These zones insert **guard pages** (unmapped memory) between slabs or use **redzones** around objects.
- Any overflow into the guard page triggers a fault → immediate panic instead of silent corruption.

### 5. Page Protection Layer (PPL) and SPTM
- Even if you control a freed object, you can’t modify all of kernel memory:
- **PPL (Page Protection Layer)** enforces that certain regions (e.g., code signing data, entitlements) are **read-only** even to the kernel itself.
- On **A15/M2+ devices**, this role is replaced/enhanced by **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- These hardware-enforced layers mean attackers can’t escalate from a single heap corruption to arbitrary patching of critical security structures.

### 6. Large Allocations
- Not all allocations go through `kalloc_type`.
- Very large requests (above ~16KB) bypass typed zones and are served directly from **kernel VM (kmem)** via page allocations.
- These are less predictable, but also less exploitable, since they don’t share slabs with other objects.

### 7. Allocation Patterns Attackers Target
Even with these protections, attackers still look for:
- **Reference count objects**: if you can tamper with retain/release counters, you may cause use-after-free.
- **Objects with function pointers (vtables)**: corrupting one still yields control flow.
- **Shared memory objects (IOSurface, Mach ports)**: these are still attack targets because they bridge user ↔ kernel.

But — unlike before — you can’t just spray `OSData` and expect it to neighbor a `task_t`. You need **type-specific bugs** or **info leaks** to succeed.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Each freed chunk stores the address of the next free chunk, but encoded with a secret key.
- Overwriting that field with attacker data won’t work unless you know the key.


## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

{{#include ../../banners/hacktricks-training.md}}
