# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOS Exploit Mitigations

### 1. **Code Signing** / Runtime Signature Verification
**Introduced early (iPhone OS → iOS)**
Dit is een van die fundamentele beskermings: **all executable code** (apps, dynamic libraries, JIT-ed code, extensions, frameworks, caches) moet kriptografies onderteken wees deur ’n sertifikaatsketting wat in Apple se trust wortelwortel. By runtime, voordat ’n binêre in geheue gelaai word (of voordat spronge oor sekere grense uitgevoer word), kontroleer die stelsel sy handtekening. As die kode gemodifiseer is (bit-flipped, gepatch) of ongeteken, misluk die laai.

- **Voorkom**: die “classic payload drop + execute” stadium in exploit chains; arbitrary code injection; die wysiging van ’n bestaande binêre om kwaadwillige logika in te sit.
- **Meganisme besonderhede**:
* Die Mach-O loader (en dynamic linker) kontroleer code pages, segments, entitlements, team IDs, en dat die signature die lêer se inhoud dek.
* Vir geheuegebiede soos JIT caches of dinamies gegenereerde kode, dwing Apple dat bladsye geteken of gevalideer word via spesiale APIs (bv. `mprotect` met code-sign checks).
* Die signature sluit entitlements en identifiers in; die OS dwing af dat sekere APIs of bevoorregte vermoëns spesifieke entitlements benodig wat nie vervals kan word nie.

<details>
<summary>Voorbeeld</summary>
Stel ’n exploit verkry code execution in ’n proses en probeer shellcode na ’n heap skryf en daarna daarnaartoe spring. Op iOS sal daardie bladsy uitgeken moet wees as executable **en** voldoen aan code-signature beperkings. Aangesien die shellcode nie deur Apple se sertifikaat geteken is nie, misluk die sprong of die stelsel weier om daardie geheuegebied executable te maak.
</details>


### 2. **CoreTrust**
**Introduced around iOS 14+ era (or gradually in newer devices / later iOS)**
CoreTrust is die subsisteem wat **runtime signature validation** van binaries uitvoer (insluitend system en user binaries) teen **Apple’s root certificate** eerder as om op gecachte userland trust stores te staatmaak.

- **Voorkom**: post-install tampering van binaries, jailbreaking-tegnieke wat probeer system libraries of user apps te ruil of te patch; die bedrieg van die stelsel deur vertroude binaries met kwaadwillige weergawe te vervang.
- **Meganisme besonderhede**:
* In plaas daarvan om ’n plaaslike trust-databasis of sertifikaat-cache te vertrou, haal CoreTrust of verwys na Apple se root direk of verifieer intermediate certificates in ’n veilige ketting.
* Dit verseker dat wysigings (bv. in die filesystem) aan bestaande binaries opgespoor en geweier word.
* Dit koppel entitlements, team IDs, code signing vlae, en ander metadata aan die binêre by laaityd.

<details>
<summary>Voorbeeld</summary>
’n Jailbreak mag probeer om `SpringBoard` of `libsystem` met ’n gepatchte weergawe te vervang om persistentie te kry. Maar wanneer die OS se loader of CoreTrust dit kontroleer, sien dit die signature mismatch (of gemodifiseerde entitlements) en weier om dit uit te voer.
</details>


### 3. **Data Execution Prevention (DEP / NX / W^X)**
**Introduced in many OSes earlier; iOS had NX-bit / w^x for a long time**
DEP dwing af dat bladsye gemerk as writable (vir data) **nie-executable** is, en bladsye gemerk as executable **nie-writable** is. Jy kan nie net shellcode in ’n heap of stack skryf en dit uitvoer nie.

- **Voorkom**: direkte shellcode-execution; klassieke buffer-overflow → sprong na ingevoegde shellcode.
- **Meganisme besonderhede**:
* Die MMU / memory protection flags (via page tables) dwing die skeiding af.
* Enige poging om ’n writable bladsy executable te maak, trigger ’n stelselkontrole (en is óf verbied óf vereis code-sign approval).
* In baie gevalle vereis dit dat bladsye executable gemaak word deur OS APIs wat addisionele beperkings of kontroles afdwing.

<details>
<summary>Voorbeeld</summary>
’n Overflow skryf shellcode op die heap. Die aanvaller probeer `mprotect(heap_addr, size, PROT_EXEC)` om dit executable te maak. Maar die stelsel weier of valideer dat die nuwe bladsy code-sign beperkings moet slaag (wat die shellcode nie kan nie).
</details>

### 4. **Address Space Layout Randomization (ASLR)**
**Introduced in iOS ~4–5 era (roughly iOS 4–5 timeframe)**
ASLR randomiseer die basisadresse van sleutel geheuegebiede: libraries, heap, stack, ens., by elke proses-ladingsessie. Gadget-adresse skuif tussen runs.

- **Voorkom**: hardcoding van gadget-adresse vir ROP/JOP; statiese exploit chains; blinde spronge na bekende offsets.
- **Meganisme besonderhede**:
* Elke geladen library / dynamic module word op ’n gerandomiseerde offset gebaseer.
* Stack en heap base pointers word gerandomiseer (binne sekere entropy-limiete).
* Soms word ander streke (bv. mmap allocations) ook gerandomiseer.
* In kombinasie met information-leak mitigations, dwing dit die aanvaller om eers ’n adres of pointer te leak om basisadresse by runtime te ontdek.

<details>
<summary>Voorbeeld</summary>
’n ROP-ketting verwag gadget by `0x….lib + offset`. Maar aangesien `lib` elke run anders gerebaseer word, misluk die hardcoded ketting. ’n Exploit moet eers die basisadres van die module leak voordat gadget-adresse bereken kan word.
</details>


### 5. **Kernel Address Space Layout Randomization (KASLR)**
**Introduced in iOS ~ (iOS 5 / iOS 6 timeframe)**
Analoog aan user ASLR, KASLR randomiseer die basis van die **kernel text** en ander kernel strukture by boottyd.

- **Voorkom**: kernel-level exploits wat op ’n vaste ligging van kernel kode of data staatmaak; statiese kernel exploits.
- **Meganisme besonderhede**:
* By elke boot word die kernel se base address gerandomiseer (binne ’n reeks).
* Kernel data strukture (soos `task_structs`, `vm_map`, ens.) mag ook herlokasie of offsets hê.
* Aanvallers moet eers kernel pointers leak of gebruik maak van information disclosure vulnerabiliteite om offsets te bereken voordat hulle kernel strukture of kode kan kap.

<details>
<summary>Voorbeeld</summary>
’n Lokale kwetsbaarheid mik om ’n kernel function pointer (bv. in ’n `vtable`) te korrupteer by `KERN_BASE + offset`. Maar aangesien `KERN_BASE` onbekend is, moet die aanvaller dit eers leak (bv. via ’n read primitive) voordat die korrekte adres vir korrupsie bereken kan word.
</details>


### 6. **Kernel Patch Protection (KPP / AMCC)**
**Introduced in newer iOS / A-series hardware (post around iOS 15–16 era or newer chips)**
KPP (aka AMCC) monitor kontinu kernel text pages se integriteit (via hash of checksum). As dit tampering (patches, inline hooks, code modifications) buite toegelate vensters opspoor, trigger dit ’n kernel panic of herbegin.

- **Voorkom**: persistent kernel patching (wysiging van kernel-instruksies), inline hooks, statiese funksie-overskrywings.
- **Meganisme besonderhede**:
* ’n Hardware of firmware module monitor die kernel text area.
* Dit herhash of validasieer periodes of op aanvraag die bladsye en vergelyk met verwagte waardes.
* As mismatches voorkom buite benign update-vensters, panikeer dit die toestel (om persistente kwaadwilligheid te voorkom).
* Aanvallers moet óf detectie-vensters vermy óf wettige patch-pade gebruik.

<details>
<summary>Voorbeeld</summary>
’n Exploit probeer om ’n kernel funksie-proloog (bv. `memcmp`) te patch om oproepe te onderskep. Maar KPP sien dat die code bladsy se hash nie meer met die verwagte waarde ooreenstem nie en trigger ’n kernel panic, wat die toestel laat crash voordat die patch kan stabiliseer.
</details>


### 7. **Kernel Text Read‐Only Region (KTRR)**
**Introduced in modern SoCs (post ~A12 / newer hardware)**
KTRR is ’n hardware-afgedwonge meganisme: sodra die kernel text vroeg tydens boot gelock word, word dit read-only vanaf EL1 (die kernel), wat verdere skryf na code pages verhoed.

- **Voorkom**: enige wysigings aan kernel kode na boot (bv. patching, in-place code injection) op EL1 privilege-vlak.
- **Meganisme besonderhede**:
* Tydens boot (in die secure/bootloader stadium) merk die memory controller (of ’n veilige hardware-eenheid) die fisiese bladsye wat kernel text bevat as read-only.
* Selfs as ’n exploit volle kernel voorregte verkry, kan dit nie daardie bladsye skryf om instruksies te patch nie.
* Om dit te wysig, moet die aanvaller eers die boot-ketting kompromitteer, of KTRR self subverteer.

<details>
<summary>Voorbeeld</summary>
’n Privilege-escalation exploit spring in EL1 en skryf ’n trampoline in ’n kernel funksie (bv. in die `syscall` handler). Maar omdat die bladsye deur KTRR as read-only gemerk is, misluk die skryf (of trigger ’n fout), sodat patches nie toegepas word nie.
</details>


### 8. **Pointer Authentication Codes (PAC)**
**Introduced with ARMv8.3 (hardware), Apple beginning with A12 / iOS ~12+**
- PAC is ’n hardware-funksie geïntroduseer in **ARMv8.3-A** om die tampering van pointer-waardes (return addresses, function pointers, sekere data pointers) te detect deur ’n klein kriptografiese signature (’n “MAC”) in die ongebruikte hoë-bits van die pointer in te vries.
- Die signature (“PAC”) word bereken oor die pointer-waarde plus ’n **modifier** (’n kontekswaarde, bv. stack pointer of sekere onderskeibare data). Op hierdie manier kry dieselfde pointer-waarde in verskillende kontekste ’n ander PAC.
- By gebruikstyd, voordat daar gedereferenceer of gebranch word via daardie pointer, kontroleer ’n **authenticate** instruksie die PAC. As geldig, word die PAC verwyder en die suiwer pointer bekom; as ongeldig, word die pointer “poisoned” (of ’n fout opgegooi).
- Die sleutels wat gebruik word om PACs te produseer/verifieer lê in bevoorregte registers (EL1, kernel) en is nie direk leesbaar vanuit user mode nie.
- Omdat nie alle 64 bits van ’n pointer in baie stelsels gebruik word nie (bv. 48-bit address space), is die boonste bits “spaar” en kan die PAC daar gehou word sonder om die effektiewe adres te verander.

#### Architectural Basis & Key Types

- ARMv8.3 bring in **vyf 128-bit sleutels** (elk geïmplementeer via twee 64-bit stelselregisters) vir pointer authentication.
- **APIAKey** — vir instruction pointers (domein “I”, sleutel A)
- **APIBKey** — tweede instruction pointer sleutel (domein “I”, sleutel B)
- **APDAKey** — vir data pointers (domein “D”, sleutel A)
- **APDBKey** — vir data pointers (domein “D”, sleutel B)
- **APGAKey** — “generic” sleutel, vir die ondertekening van nie-pointer data of ander generiese gebruike

- Hierdie sleutels word in bevoorregte stelselregisters gestoor (toeganklik slegs by EL1/EL2 ens.), nie toeganklik vanuit user mode nie.
- Die PAC word bereken via ’n kriptografiese funksie (ARM beveel QARMA as die algoritme aan) gebruik makend van:
1. Die pointer-waarde (kanoniese gedeelte)
2. ’n **modifier** (’n kontekswaarde, soos ’n salt)
3. Die geheime sleutel
4. Sekere interne tweak-logika
As die resulterende PAC ooreenstem met wat in die boonste bits van die pointer gestoor is, slaag authenticatie.

#### Instruction Families

Die naamgewing-konvensie is: **PAC** / **AUT** / **XPAC**, dan domeinletters.
- `PACxx` instruksies **sign** ’n pointer en sit ’n PAC in
- `AUTxx` instruksies **authenticate + strip** (valideer en verwyder die PAC)
- `XPACxx` instruksies **strip** sonder om te valideer

Domains / suffixes:

| Mnemonic     | Meaning / Domain                      | Key / Domain     | Example Usage in Assembly |
|--------------|-----------------------------------------|--------------------|-----------------------------|
| **PACIA**    | Sign instruction pointer with APIAKey   | “I, A”             | `PACIA X0, X1` — sign pointer in X0 using APIAKey with modifier X1|
| **PACIB**    | Sign instruction pointer with APIBKey   | “I, B”             | `PACIB X2, X3`              |
| **PACDA**    | Sign data pointer with APDAKey           | “D, A”             | `PACDA X4, X5`              |
| **PACDB**    | Sign data pointer with APDBKey           | “D, B”             | `PACDB X6, X7`              |
| **PACG / PACGA** | Generic (non-pointer) signing with APGAKey | “G”         | `PACGA X8, X9, X10` (sign X9 with modifier X10 into X8) |
| **AUTIA**    | Authenticate APIA-signed instruction pointer & strip PAC | “I, A” | `AUTIA X0, X1` — check PAC on X0 using modifier X1, then strip |
| **AUTIB**    | Authenticate APIB domain                 | “I, B”             | `AUTIB X2, X3`               |
| **AUTDA**    | Authenticate APDA-signed data pointer    | “D, A”             | `AUTDA X4, X5`               |
| **AUTDB**    | Authenticate APDB-signed data pointer    | “D, B”             | `AUTDB X6, X7`               |
| **AUTGA**    | Authenticate generic / blob (APGA)        | “G”               | `AUTGA X8, X9, X10` (validate generic) |
| **XPACI**     | Strip PAC (instruction pointer, no validation) | “I”         | `XPACI X0` — remove PAC from X0 (instruction domain) |
| **XPACD**     | Strip PAC (data pointer, no validation)    | “D”             | `XPACD X4` — remove PAC from data pointer in X4 |

Daar is gespesialiseerde / alias vorms:

- `PACIASP` is kortvorm vir `PACIA X30, SP` (sign the link register using SP as modifier)
- `AUTIASP` is `AUTIA X30, SP` (authenticate link register with SP)
- Gekombineerde vorms soos `RETAA`, `RETAB` (authenticate-and-return) of `BLRAA` (authenticate & branch) bestaan in ARM uitbreidings / compiler ondersteuning.
- Ook zero-modifier variante: `PACIZA` / `PACIZB` waar die modifier implisiet nul is, ens.

#### Modifiers

Die hoofdoel van die modifier is om die PAC **aan ’n spesifieke konteks te bind** sodat dieselfde adres geteken in verskillende kontekste verskillende PACs gee. Dit verhoed eenvoudige pointer-hergebruik oor rame of voorwerpe heen. Dit is soos om ’n **salt by ’n hash** te voeg.

Dus:
- Die **modifier** is ’n kontekswaarde (’n ander register) wat in die PAC-berekening gemeng word. Tipiese keuses: die stack pointer (`SP`), ’n frame pointer, of ’n object ID.
- Die gebruik van SP as modifier is algemeen vir return address signing: die PAC word aan daardie spesifieke stack frame vasgemaak. As jy probeer om die LR in ’n ander frame te hergebruik, verander die modifier, so PAC-validasie misluk.
- Dieselfde pointer-waarde wat onder verskillende modifiers geteken is, gee verskillende PACs.
- Die modifier hoef nie geheim te wees nie, maar idealiter is dit nie deur die aanvaller beheerbaar nie.
- Vir instruksies wat pointers teken of verifieer waar geen sinvolle modifier bestaan nie, gebruik sommige vorms nul of ’n implisiete konstante.

#### Apple / iOS / XNU Customizations & Observations

- Apple se PAC-implementering sluit **per-boot diversifiers** in sodat sleutels of tweaks by elke boot verander, wat hergebruik oor bootsessies heen verhoed.
- Hulle sluit ook **cross-domain mitigations** in sodat PACs wat in user mode geteken is nie maklik in kernel mode hergebruik kan word nie, ens.
- Op Apple M1 / Apple Silicon het reverse engineering getoon dat daar **nege modifier tipes** en Apple-spesifieke stelselregisters vir sleutelbeheer is.
- Apple gebruik PAC oor baie kernel subsisteme: return address signing, pointer integriteit in kernel data, gesignde thread contexts, ens.
- Google Project Zero het getoon hoe onder ’n kragtige memory read/write primitive in die kernel, iemand kernel PACs (vir A sleutels) op A12-era devices kon forge, maar Apple het baie van daardie paaie gepatch.
- In Apple se stelsel is sommige sleutels **globaal deur die kernel**, terwyl user prosesse per-proses sleutel randomness mag kry.

#### PAC Bypasses

1. **Kernel-mode PAC: theoretical vs real bypasses**

-   Omdat kernel PAC sleutels en logika styf beheer word (bevoorregte registers, diversifiers, domain isolasie), is dit baie moeilik om ewekansige gesigneerde kernel pointers te forge.
-   Azad se 2020 "iOS Kernel PAC, One Year Later" rapporteer dat in iOS 12-13 hy ’n paar gedeeltelike bypasses gevind het (signing gadgets, reuse van signed states, onbeveiligde indirect branches) maar geen volledige generiese bypass nie. [bazad.github.io](https://bazad.github.io/presentations/BlackHat-USA-2020-iOS_Kernel_PAC_One_Year_Later.pdf)
-   Apple se "Dark Magic" aanpassings verklein verder die aanvalsoppervlak (domain switching, per-key enabling bits). [i.blackhat.com](https://i.blackhat.com/BH-US-23/Presentations/US-23-Zec-Apple-PAC-Four-Years-Later.pdf)
-   Daar is ’n bekende **kernel PAC bypass CVE-2023-32424** op Apple silicon (M1/M2) gerapporteer deur Zecao Cai et al. [i.blackhat.com](https://i.blackhat.com/BH-US-23/Presentations/US-23-Zec-Apple-PAC-Four-Years-Later.pdf)
-   Maar hierdie bypasses berus dikwels op baie spesifieke gadgets of implementasie-bugs; hulle is nie generiese bypasses nie.

Dus word kernel PAC as **baie robuust** beskou, alhoewel nie perfek nie.

2. **User-mode / runtime PAC bypass techniques**

Hierdie is meer algemeen, en exploits imperfeksies in hoe PAC toegepas of gebruik word in dynamic linking / runtime frameworks. Hieronder is klasse, met voorbeelde.

2.1 **Shared Cache / A key issues**

-   Die **dyld shared cache** is ’n groot pre-linked blob van system frameworks en libraries. Omdat dit so wyd gedeel word, is funksie-pointers binne die shared cache "pre-signed" en word dan deur baie prosesse gebruik. Aanvallers mik na hierdie reeds-signed pointers as "PAC oracles".

-   Sommige bypass tegnieke probeer om A-key gesigneerde pointers in die shared cache uit te haal of te hergebruik en dit met gadgets te kombineer.

-   Die "No Clicks Required" praatjie beskryf die bou van ’n oracle oor die shared cache om relatiewe adresse af te lei en dit te kombineer met gesigneerde pointers om PAC te omseil. [saelo.github.io](https://saelo.github.io/presentations/offensivecon_20_no_clicks.pdf)

-   Ook is invoere van funksie-pointers vanaf shared libraries in userspace gevind dat hulle onvoldoende beskerm deur PAC, wat ’n aanvaller toelaat om funksie-pointers te kry sonder om hul signature te verander. (Project Zero bug entry) [bugs.chromium.org](https://bugs.chromium.org/p/project-zero/issues/detail?id=2044&utm_source=chatgpt.com)

2.2 **dlsym(3) / dynamic symbol resolution**

-   Een bekende bypass is om `dlsym()` te roep om ’n *already signed* function pointer (gesigneer met A-key, diversifier zero) te kry en dit dan te gebruik. Omdat `dlsym` ’n wettige gesigneerde pointer teruggee, omseil dit die behoefte om PAC te forge.

-   Epsilon se blog verduidelik hoe sommige bypasses dit uitbuit: die oproep `dlsym("someSym")` gee ’n gesigneerde pointer en kan gebruik word vir indirect calls. [blog.epsilon-sec.com](https://blog.epsilon-sec.com/tag/pac.html)

-   Synacktiv se "iOS 18.4 --- dlsym considered harmful" beskryf ’n fout: sommige simboles geresolve via `dlsym` op iOS 18.4 lei tot pointers wat verkeerdelik geteken is (of met buggy diversifiers), wat onbedoelde PAC bypass moontlik maak. [Synacktiv](https://www.synacktiv.com/en/publications/ios-184-dlsym-considered-harmful)

-   Die logika in dyld vir dlsym sluit in: wanneer `result->isCode`, teken hulle die teruggegewe pointer met `__builtin_ptrauth_sign_unauthenticated(..., key_asia, 0)`, d.w.s. konteks nul. [blog.epsilon-sec.com](https://blog.epsilon-sec.com/tag/pac.html)

Dus is `dlsym` ’n gereelde vektor in user-mode PAC bypasses.

2.3 **Other DYLD / runtime relocations**

-   Die DYLD loader en dinamiese relocasie-logika is kompleks en soms word bladsye tydelik as read/write gemap om relocations uit te voer, en dan teruggeskakel na read-only. Aanvallers gebruik hierdie vensters. Synacktiv se praatjie beskryf "Operation Triangulation", ’n timing-gebaseerde PAC bypass via dinamiese relocations. [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

-   DYLD bladsye word nou beskerm met SPRR / VM_FLAGS_TPRO (sekere protection flags vir dyld). Maar vroeër weergawes het swakker beskerming gehad. [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

-   In WebKit exploit chains is die DYLD loader dikwels ’n teikengroep vir PAC bypass. Die slides noem dat baie PAC bypasses die DYLD loader geteiken het (via relocasie, interposer hooks). [Synacktiv](https://www.synacktiv.com/sites/default/files/2024-05/escaping_the_safari_sandbox_slides.pdf)

2.4 **NSPredicate / NSExpression / ObjC / SLOP**

-   In userland exploit chains word Objective-C runtime-metodes soos `NSPredicate`, `NSExpression` of `NSInvocation` gebruik om control calls te smuggle sonder duidelike pointer forging.

-   Op ouer iOS (voor PAC) het ’n exploit gebruik gemaak van **fake NSInvocation** objects om arbitrary selectors op beheerde geheue te roep. Met PAC is wysigings nodig. Maar die tegniek SLOP (SeLector Oriented Programming) is onder PAC ook uitgebrei. [Project Zero](https://googleprojectzero.blogspot.com/2020/01/remote-iphone-exploitation-part-3.html)

-   Die oorspronklike SLOP-tegniek het die ketting van ObjC-oproepe toegelaat deur fake invocations te skep; die bypass berus op die feit dat ISA of selector pointers soms nie volledig deur PAC beskerm is nie. [Project Zero](https://googleprojectzero.blogspot.com/2020/01/remote-iphone-exploitation-part-3.html)

-   In omgewings waar pointer authentication slegs gedeeltelik toegepas is, mag metodes / selectors / target pointers nie altyd PAC-beskerming hê nie, wat ruimte vir bypass gee.

#### Example Flow

<details>
<summary>Voorbeeld Signing & Authenticating</summary>
```
; Example: function prologue / return address protection
my_func:
stp x29, x30, [sp, #-0x20]!        ; push frame pointer + LR
mov x29, sp
PACIASP                            ; sign LR (x30) using SP as modifier
; … body …
mov sp, x29
ldp x29, x30, [sp], #0x20         ; restore
AUTIASP                            ; authenticate & strip PAC
ret

; Example: indirect function pointer stored in a struct
; suppose X1 contains a function pointer
PACDA X1, X2     ; sign data pointer X1 with context X2
STR X1, [X0]      ; store signed pointer

; later retrieval:
LDR X1, [X0]
AUTDA X1, X2       ; authenticate & strip
BLR X1             ; branch to valid target

; Example: stripping for comparison (unsafe)
LDR X1, [X0]
XPACI X1           ; strip PAC (instruction domain)
CMP X1, #some_label_address
BEQ matched_label
```
</details>

<details>
<summary>Example</summary>
'n Buffer overflow oorskryf 'n return-adres op die stack. Die aanvaller skryf die teiken-gadget-adres maar kan nie die korrekte PAC bereken nie. Wanneer die funksie terugkeer, faal die CPU se `AUTIA` instruksie omdat die PAC nie ooreenstem nie. Die ketting misluk.
Project Zero’s analise op A12 (iPhone XS) het gewys hoe Apple se PAC gebruik word en metodes om PACs te valseer as 'n aanvaller 'n memory read/write primitive het.
</details>


### 9. **Branch Target Identification (BTI)**
**Introduced with ARMv8.5 (later hardware)**
BTI is 'n hardware-funksie wat **indirekte branch-teikens** kontroleer: wanneer `blr` of indirekte calls/jumps uitgevoer word, moet die teiken begin met 'n **BTI landing pad** (`BTI j` of `BTI c`). Om na gadget-adresse te spring wat nie die landing pad het nie, veroorsaak 'n uitsondering.

LLVM se implementering noem drie variante van BTI-instruksies en hoe hulle aan branch-tipes gekarteer word.

| BTI Variant | What it permits (which branch types) | Typical placement / use case |
|-------------|----------------------------------------|-------------------------------|
| **BTI C** | Targets of *call*-style indirect branches (e.g. `BLR`, or `BR` using X16/X17) | Put at entry of functions that may be called indirectly |
| **BTI J** | Targets of *jump*-style branches (e.g. `BR` used for tail calls) | Placed at the beginning of blocks reachable by jump tables or tail-calls |
| **BTI JC** | Acts as both C and J | Can be targeted by either call or jump branches |

- In code compiled with branch target enforcement, compilers insert a BTI instruction (C, J, or JC) at each valid indirect-branch target (function beginnings or blocks reachable by jumps) so that indirect branches only succeed to those places.
- **Direct branches / calls** (i.e. fixed-address `B`, `BL`) are **not restricted** by BTI. The assumption is that code pages are trusted and attacker cannot change them (so direct branches are safe).
- Also, **RET / return** instructions generally are not restricted by BTI because return addresses are protected via PAC or return signing mechanisms.

#### Mechanism and enforcement

- When the CPU decodes an **indirect branch (BLR / BR)** in a page marked as “guarded / BTI-enabled,” it checks whether the target address’s first instruction is a valid BTI (C, J, or JC as allowed). If not, a **Branch Target Exception** occurs.
- The BTI instruction encoding is designed to reuse opcodes previously reserved for NOPs (in earlier ARM versions). So BTI-enabled binaries remain backward-compatible: on hardware without BTI support, those instructions act as NOPs.
- The compiler passes that add BTIs insert them only where needed: functions that may be called indirectly, or basic blocks targeted by jumps.
- Some patches and LLVM code show that BTI is not inserted for *all* basic blocks — only those that are potential branch targets (e.g. from switch / jump tables).

#### BTI + PAC synergy

PAC protects the pointer value (the source) — ensures the chain of indirect calls / returns hasn't been tampered with.

BTI ensures that even a valid pointer must only target properly marked entry points.

Combined, an attacker needs both a valid pointer with correct PAC and that the target must have a BTI placed there. This increases the hardness of constructing exploit gadgets.

#### Example


<details>
<summary>Example</summary>
'n exploit probeer pivot na 'n gadget by `0xABCDEF` wat nie met `BTI c` begin nie. Die CPU, by die uitvoering van `blr x0`, kontroleer die teiken en gooi 'n fout omdat die instruksie-uitlijning nie 'n geldige landing pad insluit nie. Sodoende word baie gadgets onbruikbaar tensy hulle 'n BTI-prefix het.
</details>


### 10. **Privileged Access Never (PAN) & Privileged Execute Never (PXN)**
**Introduced in more recent ARMv8 extensions / iOS support (for hardened kernel)**

#### PAN (Privileged Access Never)

- **PAN** is 'n funksie ingevoer in **ARMv8.1-A** wat voorkom dat **privileged code** (EL1 of EL2) **lees of skryf** na geheue wat as **user-accessible (EL0)** gemerk is, tensy PAN uitdruklik gedeaktiveer word.
- Die idee: selfs al word die kernel mislei of gekompromitteer, kan dit nie arbitrêr user-space pointers dereferenceer sonder om eers PAN te *clear* nie, wat die risiko's van `ret2usr`-styl exploits of misbruik van user-beheerde buffers verminder.
- Wanneer PAN geaktiveer is (PSTATE.PAN = 1), veroorsaak enige privileged load/store instruksie wat 'n virtuele adres aanspreek wat “accessible at EL0” is 'n **permission fault**.
- Die kernel, wanneer dit geldige toegang tot user-space geheue nodig het (bv. kopieer data na/van user buffers), moet **tydelik PAN deaktiveer** (of omskakel na “unprivileged load/store” instruksies) om daardie toegang toe te laat.
- In Linux op ARM64 is PAN-ondersteuning bedoel rond 2015: kernel patches het funksiedetektering bygevoeg en `get_user` / `put_user` ens. vervang met variante wat PAN rondom user-geheue-toegange clear.

**Key nuance / limitation / bug**
- Soos deur Siguza en ander aangeteken, 'n spesifikasie-bug (of dubbelsinnige gedrag) in ARM se ontwerp beteken dat **execute-only user mappings** (`--x`) dalk **nie PAN trigger nie**. Met ander woorde, as 'n user bladsy uitvoerbaar is maar sonder lees-permissie, kan die kernel se leespoging PAN omseil omdat die argitektuur “accessible at EL0” beskou as vereisende lees-permissie, nie net execute nie. Dit lei tot 'n PAN-omseiling in sekere konfigurasies.
- As gevolg hiervan, as iOS / XNU execute-only user pages toelaat (soos sommige JIT of code-cache opstellings mag doen), kan die kernel per ongeluk van hulle lees selfs met PAN geaktiveer. Dit is 'n bekende subtiele aanvalsvlak in sekere ARMv8+ stelsels.

#### PXN (Privileged eXecute Never)

- **PXN** is 'n bladsy-tabel vlag (in die page table entries, leaf of block entries) wat aandui dat die bladsy **nie-uitvoerbaar is wanneer in privileged mode** (d.w.s. wanneer EL1 dit uitvoer).
- PXN voorkom dat die kernel (of enige privileged code) instruksies van user-space bladsye uitvoer, selfs al word beheer oorgeskakel. Effektief blokkeer dit kernel-vlak kontrolvloeikomskakeling na user geheue.
- Gesamentlik met PAN verseker dit dat:
1. Kernel nie (by verstek) user-space data kan lees of skryf nie (PAN)
2. Kernel nie user-space code kan uitvoer nie (PXN)
- In die ARMv8 page table formaat het die leaf entries 'n `PXN` bit (en ook `UXN` vir unprivileged execute-never) in hul attribuut-bits.

Selfs as die kernel 'n gekorrupte funksie-pointer na user geheue het, en dit probeer daarnatoe tak, sou die PXN-bit 'n fout veroorsaak.

#### Memory-permission model & how PAN and PXN map to page table bits

Om te verstaan hoe PAN / PXN werk, moet jy sien hoe ARM se vertaling- en permissie-model werk (vereenvoudig):

- Elke bladsy of blok entry het attribuut-velde insluitend **AP[2:1]** vir toegangspas (lees/skryf, privileged vs unprivileged) en **UXN / PXN** bits vir execute-never beperkings.
- Wanneer PSTATE.PAN 1 is (geaktiveer), handhaaf die hardware gemodifiseerde semantiek: privileged toegang tot bladsye gemerk as “accessible by EL0” (d.w.s. user-accessible) word geweier (fault).
- Weens die genoemde bug, mag bladsye wat slegs uitvoerbaar is (geen lees-perm nie) nie tel as “accessible by EL0” in sekere implementasies nie, en sodoende PAN omseil.
- Wanneer 'n bladsy se PXN-bit gestel is, is uitvoering verbode selfs al kom die instruksie-fetch vanaf 'n hoër privilegievlak.

#### Kernel usage of PAN / PXN in a hardened OS (e.g. iOS / XNU)

In 'n verhardte kernel-ontwerp (soos wat Apple moontlik gebruik):

- Die kernel skakel PAN standaard aan (sodat privileged code beperk word).
- In paaie wat regmatig user-space geheue moet lees of skryf (bv. syscall buffer copy, I/O, read/write user pointer), deaktiveer die kernel tydelik **PAN** of gebruik spesiale instruksies om dit te oorbrug.
- Na voltooiing van user-data toegang moet dit PAN weer aanskakel.
- PXN word via page tables afgedwing: user pages het PXN = 1 (sodat kernel nie daarin kan uitvoer nie), kernel pages het nie PXN nie (sodat kernel code kan uitvoer).
- Die kernel moet verseker dat geen kodepaadjies uitvoering na user-geheue-area's laat gebeur nie (wat PXN sou omseil) — dus exploit-kettings wat op “jump into user-controlled shellcode” staatmaak, word geblokkeer.

As gevolg van die genoemde PAN-omseiling via execute-only bladsye, kan 'n werklike stelsel Apple dwing om execute-only user pages te deaktiveer of om rond die spesifikasie-kwessie te patch.

#### Attack surfaces, bypasses, and mitigations

- **PAN bypass via execute-only pages**: soos bespreek, die spesifikaasie laat 'n gaping toe: user bladsye met execute-only (geen lees-perm) mag nie deur PAN geblokkeer word nie onder sekere implementasies. Dit gee 'n aanvaller 'n ongewone pad om data deur execute-only afdelings te lewer.
- **Temporal window exploit**: as die kernel PAN langer as nodig deaktiveer, kan 'n race of kwaadwillige pad daardie venster benut om onbedoelde user geheue toegang uit te voer.
- **Forgotten re-enable**: as kodepaaie versuim om PAN weer aan te skakel, kan daaropvolgende kernel-werksessies verkeerdelik user geheue benader.
- **Misconfiguration of PXN**: as page tables nie PXN op user bladsye stel nie of user code bladsye verkeerd kaarteer, kan die kernel mislei word om user-space kode uit te voer.
- **Speculation / side-channels**: analoog aan speculation-omseilings, kan daar mikroargitektoniese newe-effekte wees wat 'n tydelike skending van PAN / PXN-kontroles veroorsaak (alhoewel sulke aanvalle baie afhanklik is van CPU-ontwerp).
- **Complex interactions**: In meer gevorderde funksies (bv. JIT, shared memory, just-in-time code regions), het die kernel fynbeheer nodig om sekere geheue-toegange of uitvoering in user-gemapped streke toe te laat; dit veilig ontwerp binne PAN/PXN-beperkings is nie triviaal nie.

#### Example

<details>
<summary>Code Example</summary>
Here are illustrative pseudo-assembly sequences showing enabling/disabling PAN around user memory access, and how a fault might occur.
</details>
```  
// Suppose kernel entry point, PAN is enabled (privileged code cannot access user memory by default)

; Kernel receives a syscall with user pointer in X0
; wants to read an integer from user space
mov   X1, X0        ; X1 = user pointer

; disable PAN to allow privileged access to user memory
MSR   PSTATE.PAN, #0   ; clear PAN bit, disabling the restriction

ldr   W2, [X1]       ; now allowed load from user address

; re-enable PAN before doing other kernel logic
MSR   PSTATE.PAN, #1   ; set PAN

; ... further kernel work ...

; Later, suppose an exploit corrupts a pointer to a user-space code page and jumps there
BR    X3             ; branch to X3 (which points into user memory)

; Because the target page is marked PXN = 1 for privileged execution,
; the CPU throws an exception (fault) and rejects execution
```
As die kernel PXN nie op daardie gebruikersblad gestel het nie, kan die branch slaag — wat onveilig sou wees.

As die kernel vergeet om PAN weer aan te skakel na toegang tot gebruikersgeheue, ontstaan 'n venster waarin verdere kernlogika per ongeluk arbitrêre gebruikersgeheue kan lees/skryf.

As die gebruikerwyser na 'n execute-only blad wys (gebruikersblad met slegs execute-permissie, geen read/write nie), kan onder die PAN-spesifikasiebug `ldr W2, [X1]` moontlik **nie** foutgee selfs met PAN aangeskakel nie, wat 'n omseil-exploit moontlik maak, afhangend van die implementering.

</details>

<details>
<summary>Example</summary>
A kernel vulnerability probeer 'n deur gebruiker verskafte function pointer neem en dit in kernkonteks aanroep (d.w.s. `call user_buffer`). Onder PAN/PXN is daardie operasie verbode of sal dit 'n fout gee.
</details>

---

### 11. **Top Byte Ignore (TBI) / Pointer Tagging**
**Introduced in ARMv8.5 / newer (or optional extension)**
TBI beteken dat die topbyte (mees-betekenisvolle byte) van 'n 64-bit pointer deur adresvertaling geïgnoreer word. Dit laat die OS of hardware toe om **tag bits** in die pointer se topbyte in te sluit sonder om die werklike adres te beïnvloed.

- TBI stands for **Top Byte Ignore** (soms called *Address Tagging*). Dit is 'n hardware-funksie (beskikbaar in baie ARMv8+ implementasies) wat die **top 8 bits** (bits 63:56) van 'n 64-bit pointer ignoreer wanneer dit **adresvertaling / load/store / instruction fetch** uitvoer.
- In praktyk behandel die CPU 'n pointer `0xTTxxxx_xxxx_xxxx` (waar `TT` = top byte) as `0x00xxxx_xxxx_xxxx` vir die doeleindes van adresvertaling, deur die top byte te ignoreer (masker af). Die top byte kan deur sagteware gebruik word om **metadata / tag bits** te stoor.
- Dit gee sagteware “gratis” in-band ruimte om 'n byte tag in elke pointer in te sluit sonder om te verander na watter geheue-ligging dit verwys.
- Die argitektuur verseker dat loads, stores, en instruction fetch die pointer met sy top byte gemaskeer (d.w.s. tag verwyder) behandel voordat die werklike geheue-toegang uitgevoer word.

Dus ontkoppel TBI die **logiese pointer** (pointer + tag) van die **fisiese adres** wat vir geheue-operasies gebruik word.

#### Why TBI: Use cases and motivation

- **Pointer tagging / metadata**: Jy kan ekstra metadata (bv. object type, version, bounds, integriteits-tags) in daardie top byte stoor. Wanneer jy later die pointer gebruik, word die tag op hardewarevlak geïgnoreer, so jy hoef dit nie handmatig te verwyder vir geheue-toegang nie.
- **Memory tagging / MTE (Memory Tagging Extension)**: TBI is die basiese hardeware-meganisme waarop MTE bou. In ARMv8.5 gebruik die **Memory Tagging Extension** bits 59:56 van die pointer as 'n **logiese tag** en vergelyk dit met 'n **allocation tag** wat in geheue gestoor is.
- **Enhanced security & integrity**: Deur TBI te kombineer met pointer authentication (PAC) of runtime checks, kan jy nie net die pointer-waarde nie, maar ook die tag afdwing om korrek te wees. 'n Aanvaller wat 'n pointer oor skryf sonder die korrekte tag sal 'n ongelyke tag tot gevolg hê.
- **Compatibility**: Omdat TBI opsioneel is en tag bits deur hardeware geïgnoreer word, funksioneer bestaande ongetagde kode normaalweg. Die tag bits word effektief “don’t care” bits vir legacy-kode.

#### Example
<details>
<summary>Example</summary>
'n Function pointer het 'n tag in sy top byte gehad (bv. `0xAA`). 'n Exploit oor skryf die lae bits van die pointer maar verwaarloos die tag, so wanneer die kernel verifieer of sanitiseer, misluk of word die pointer geweier.
</details>

---

### 12. **Page Protection Layer (PPL)**
**Introduced in late iOS / modern hardware (iOS ~17 / Apple silicon / high-end models)** (sommige verslae wys PPL rondom macOS / Apple silicon, maar Apple bring analoog-beskerming na iOS)

- PPL is ontwerp as 'n **intra-kernel protection boundary**: selfs as die kernel (EL1) gekompromitteer is en lees/skryf vermoëns het, behoort dit nie vrylik sekere **sensitiewe bladsye** (veral page tables, code-signing metadata, kernel code pages, entitlements, trust caches, ens.) te kan wysig nie.
- Dit skep effektief 'n **“kernel binne die kernel”** — 'n kleiner vertroude komponent (PPL) met **verhoogde voorregte** wat alleen beskermde bladsye kan wysig. Ander kernel-kode moet in PPL routines aanroep om veranderinge te maak.
- Dit verminder die attack surface vir kernel-exploits: selfs met volledige arbitrêre R/W/execute in kernel-modus, moet exploit-kode ook op een of ander manier in die PPL-domein inkom (of PPL omseil) om kritieke strukture te wysig.
- Op nuwer Apple silicon (A15+ / M2+) skuif Apple na **SPTM (Secure Page Table Monitor)**, wat in baie gevalle PPL vervang vir page-table beskerming op daardie platforms.

Hier is hoe PPL vermoedelik werk, gebaseer op openbare ontleding:

#### Use of APRR / permission routing (APRR = Access Permission ReRouting)

- Apple-hardware gebruik 'n meganisme genaamd **APRR (Access Permission ReRouting)**, wat toelaat dat page table entries (PTEs) klein indekse bevat, in plaas van volle permissiebevele. Daardie indekse word via APRR-registers na effektiewe permissies gekarteer. Dit laat dinamiese remapping van permissies per domein toe.
- PPL benut APRR om privilegie binne kernel-konteks te segregeer: slegs die PPL-domein mag die mapping tussen indekse en effektiewe permissies opdateer. Dit beteken dat wanneer nie-PPL kernel-kode 'n PTE skryf of probeer permissie-bits verander, die APRR-logika dit verbied (of af dwing dat dit lees-only bly).
- PPL-kode self loop in 'n beperkte area (bv. `__PPLTEXT`) wat normaalweg nie-uitvoerbaar of nie-skrifbaar is totdat toegangspoorte tydelik dit toelaat. Die kernel roep PPL entry points (“PPL routines”) aan om sensitiewe operasies uit te voer.

#### Gate / Entry & Exit

- Wanneer die kernel 'n beskermde bladsy moet wysig (bv. om permissies van 'n kernel code page te verander, of page tables te wysig), roep dit 'n **PPL wrapper** routine aan, wat validering doen en dan na die PPL-domein oorskakel. Buite daardie domein is die beskermde bladsye effektief lees-only of nie-wysigbaar deur die hoofkernel.
- Tydens PPL entry word die APRR-mappings aangepas sodat geheuebladsye in die PPL-gebied binne PPL as **executable & writable** gestel word. By exit word hulle teruggestel na read-only / nie-skrifbaar. Dit verseker dat slegs goed-gekontroleerde PPL-routines beskermde bladsye kan skryf.
- Buite PPL sal pogings deur kernel-kode om daardie beskermde bladsye te skryf foutgee (permission denied) omdat die APRR-mapping vir daardie kode-domein nie skryf toelaat nie.

#### Protected page categories

Die bladsye wat PPL tipies beskerm sluit in:

- Page table strukture (translation table entries, mapping metadata)
- Kernel code pages, veral dié wat kritieke logika bevat
- Code-sign metadata (trust caches, signature blobs)
- Entitlement-tabelle, signature enforcement-tabelle
- Ander hoë-waarde kernel-strukture waar 'n patch die signature checks of credential-manipulasie sou kan omseil

Die idee is dat selfs as kerngeheue volledig beheer word, kan die aanvaller nie net eenvoudig hierdie bladsye patch of herlei nie, tensy hulle ook PPL-routines kompromitteer of PPL omseil.

#### Known Bypasses & Vulnerabilities

1. **Project Zero’s PPL bypass (stale TLB trick)**

- 'n Publieke uiteensetting deur Project Zero beskryf 'n omseiling wat betrokke is by **stale TLB entries**.
- Die idee:

1. Allokeer twee fisiese bladsye A en B, merk dit as PPL-bladsye (sodat hulle beskerm word).
2. Map twee virtuele adresse P en Q waarvan die L3 translation table bladsye van A en B kom.
3. Draai 'n thread om voortdurend Q te benader, om die TLB-entree lewend te hou.
4. Roep `pmap_remove_options()` aan om mappinge te verwyder beginnende by P; weens 'n bug verwyder die kode per ongeluk die TTEs vir beide P en Q, maar invalideer slegs die TLB-entree vir P, wat Q se stale entee lewend laat.
5. Hergebruik B (bladsy van Q se tabel) om arbitrêre geheue te map (bv. PPL-beskermde bladsye). Omdat die stale TLB-entree steeds Q se ou mapping map, bly daardie mapping geldig vir daardie konteks.
6. Deur dit kan die aanvaller 'n skryfbare mapping van PPL-beskermde bladsye in plek sit sonder om deur die PPL-koppelvlak te gaan.

- Hierdie exploit het fyn beheer van fisiese mapping en TLB-gedrag vereis. Dit demonstreer dat 'n sekuriteitsgrens wat op TLB / mapping korrekheid staatmaak, uiters versigtig moet wees oor TLB-invaliderings en mapping-konsistensie.

- Project Zero noem dat omseilings soos hierdie subtiel en skaars is, maar moontlik in komplekse stelsels. Hulle beskou PPL steeds as 'n stewige mitigasie.

2. **Other potential hazards & constraints**

- As 'n kernel-exploit direk PPL-routines kan betree (deur die PPL wrappers aan te roep), kan dit beperkings omseil. Dus is argument-validering krities.
- Bugs in die PPL-kode self (bv. aritmetiese overflow, grenskontroles) kan toelaat dat uit-die-grense wysigings binne PPL uitgevoer word. Project Zero het opgemerk dat so 'n bug in `pmap_remove_options_internal()` in hul omseiling uitgebuit is.
- Die PPL-grens is onherroeplik gebind aan hardeware-dwinging (APRR, memory controller), so dit is slegs so sterk as die hardeware-implementering.

#### Example
<details>
<summary>Code Example</summary>
Here’s a simplified pseudocode / logic showing how a kernel might call into PPL to modify protected pages:
```c
// In kernel (outside PPL domain)
function kernel_modify_pptable(pt_addr, new_entry) {
// validate arguments, etc.
return ppl_call_modify(pt_addr, new_entry)  // call PPL wrapper
}

// In PPL (trusted domain)
function ppl_call_modify(pt_addr, new_entry) {
// temporarily enable write access to protected pages (via APRR adjustments)
aprr_set_index_for_write(PPL_INDEX)
// perform the modification
*pt_addr = new_entry
// restore permissions (make pages read-only again)
aprr_restore_default()
return success
}

// If kernel code outside PPL does:
*pt_addr = new_entry  // a direct write
// It will fault because APRR mapping for non-PPL domain disallows write to that page
```
Die kernel kan baie normale operasies uitvoer, maar slegs deur `ppl_call_*`-roetines kan dit beskermde mappings verander of kode patch.
</details>

<details>
<summary>Voorbeeld</summary>
'n kernel exploit probeer die entitlement-tabel oorskryf, of die code-sign afdwinging deaktiveer deur 'n kernel signature blob te wysig. Omdat daardie bladsy PPL-beskerm is, word die skryf geblokkeer tensy dit deur die PPL-koppelvlak gebeur. Selfs met kernel-kode-uitvoering kan jy dus nie code-sign-beperkings omseil of credential data lukraak wysig nie.
Op iOS 17+ gebruik sekere toestelle SPTM om PPL-beheerde bladsye verder te isoleer.
</details>

#### PPL → SPTM / Vervangings / Toekoms

- Op Apple’s moderne SoCs (A15 of later, M2 of later) ondersteun Apple **SPTM** (Secure Page Table Monitor), wat **PPL vervang** vir bladsy-tabelbeskerming.
- Apple noem in dokumentasie: “Page Protection Layer (PPL) and Secure Page Table Monitor (SPTM) enforce execution of signed and trusted code … PPL manages the page table permission overrides … Secure Page Table Monitor replaces PPL on supported platforms.”
- Die SPTM-argitektuur skuif waarskynlik meer beleidsafdwinging na 'n hoër-geprivilegieerde monitor buite kernelbeheer, wat die vertrouensgrens verder verminder.

### MTE | EMTE | MIE

Hier is 'n hoërvlak beskrywing van hoe EMTE werk onder Apple se MIE-opstelling:

1. **Tag-toewysing**
- Wanneer geheue toegeken word (bv. in kernel of user space via veilige allokators), word 'n **geheime tag** aan daardie blok toegewys.
- Die pointer wat aan die gebruiker of kernel teruggegee word, sluit daardie tag in sy hoë bits in (gebruik TBI / top byte ignore meganismes).

2. **Tag-kontrole by toegang**
- Wanneer 'n load of store uitgevoer word met 'n pointer, kontroleer die hardeware dat die pointer se tag ooreenstem met die geheueblok se tag (allokasie-tag). Indien daar 'n mispassing is, gooi dit onmiddellik 'n fout (aangesien dit sinkronies is).
- Omdat dit sinkronies is, bestaan daar geen venster vir vertraagde opsporing nie.

3. **Her-tagging by vrylaat / hergebruik**
- Wanneer geheue vrygestel word, verander die allokator die blok se tag (sodat ouer pointers met ou tags nie meer ooreenstem nie).
- 'n use-after-free pointer sal dus 'n verouderde tag hê en mispas by toegang.

4. **Buurt-tag-differensiasie om oorvloei op te spoor**
- Aanliggende toewysings kry verskillende tags. As 'n buffer overflow oor in 'n buur se geheue mors, veroorsaak 'n tag-mispassing 'n fout.
- Dit is veral kragtig om klein oorvloei wat grense oorskry, op te spoor.

5. **Tag-konfidensialiteit afdwinging**
- Apple moet verhoed dat tag-waardes leaked word (want as 'n aanvaller die tag leer, kan hulle pointers met die korrekte tags maak).
- Hulle sluit beskermingsmaatreëls in (microarchitectural / speculative controls) om side-channel leakage van tag-bits te voorkom.

6. **Kernel- en user-space integrasie**
- Apple gebruik EMTE nie net in user-space nie, maar ook in kernel / OS-kritieke komponente (om die kernel teen geheue-korrupsie te beskerm).
- Die hardeware/OS verseker dat tag-reëls van toepassing is selfs wanneer die kernel namens user space uitgevoer word.

<details>
<summary>Voorbeeld</summary>
```
Allocate A = 0x1000, assign tag T1
Allocate B = 0x2000, assign tag T2

// pointer P points into A with tag T1
P = (T1 << 56) | 0x1000

// Valid store
*(P + offset) = value // tag T1 matches allocation → allowed

// Overflow attempt: P’ = P + size_of_A (into B region)
*(P' + delta) = value
→ pointer includes tag T1 but memory block has tag T2 → mismatch → fault

// Free A, allocator retags it to T3
free(A)

// Use-after-free:
*(P) = value
→ pointer still has old tag T1, memory region is now T3 → mismatch → fault
```
#### Beperkings & uitdagings

- **Intrablock overflows**: As 'n overflow binne dieselfde toewysing bly (dit steek nie oor die grens nie) en die tag dieselfde bly, vang tag mismatch dit nie op nie.
- **Tag width limitation**: Slegs 'n paar bits (bv. 4 bits, of 'n klein domein) is beskikbaar vir tag — beperkte naamruimte.
- **Side-channel leaks**: As tag bits geleaked kan word (via cache / speculative execution), kan 'n aanvaller geldige tags uitvind en omseil. Apple se tag confidentiality enforcement is bedoel om dit te beperk.
- **Performance overhead**: Tag-checks by elke load/store voeg koste by; Apple moet die hardware optimaliseer om die overhead laag te hou.
- **Compatibility & fallback**: Op ouer hardware of dele wat nie EMTE ondersteun nie, moet 'n fallback bestaan. Apple verklaar dat MIE slegs op toestelle met ondersteuning aangeskakel word.
- **Complex allocator logic**: Die allocator moet tags bestuur, retagging hanteer, grense uitlyn en mis-tag botsings vermy. Foute in allocator-logika kan nuwe kwesbaarhede inbring.
- **Mixed memory / hybrid areas**: Sommige geheue kan ongetag bly (legacy), wat interoperabiliteit moeiliker maak.
- **Speculative / transient attacks**: Soos met baie mikroargitektuur-beskermings kan speculative execution of mikro-op fusiess kortstondig kontroles omseil of tag bits leak.
- **Limited to supported regions**: Apple mag EMTE slegs afdwing in selektiewe, hoërisiko-gebiede (kernel, security-critical subsystems), en nie universieel nie.

---

## Sleutelverbeterings / verskille vergelyk met standaard MTE

Hier is die verbeterings en veranderinge waarop Apple klem lê:

| Funksie | Original MTE | EMTE (Apple’s enhanced) / MIE |
|---|---|---|
| **Check mode** | Supports synchronous and asynchronous modes. In async, tag mismatches are reported later (delayed) | Apple insists on **synchronous mode** by default—tag mismatches are caught immediately, no delay/race windows allowed. |
| **Coverage of non-tagged memory** | Accesses to non-tagged memory (e.g. globals) may bypass checks in some implementations | EMTE requires that accesses from a tagged region to non-tagged memory also validate tag knowledge, making it harder to bypass by mixing allocations. |
| **Tag confidentiality / secrecy** | Tags might be observable or leaked via side channels | Apple adds **Tag Confidentiality Enforcement**, which attempts to prevent leakage of tag values (via speculative side-channels etc.). |
| **Allocator integration & retagging** | MTE leaves much of allocator logic to software | Apple’s secure typed allocators (kalloc_type, xzone malloc, etc.) integrate with EMTE: when memory is allocated or freed, tags are managed at fine granularity. |
| **Always-on by default** | In many platforms, MTE is optional or off by default | Apple enables EMTE / MIE by default on supported hardware (e.g. iPhone 17 / A19) for kernel and many user processes. |

Omdat Apple beide die hardware en die sagteware-stapel beheer, kan dit EMTE streng afdwing, prestasie-valkuils vermy en side-channel-gate toemaak.

---

## Hoe EMTE in die praktyk werk (Apple / MIE)

Hier is 'n hoëvlak-beskrywing van hoe EMTE onder Apple se MIE-opstelling werk:

1. **Tag assignment**
- Wanneer geheue toegeken word (bv. in kernel of user space via secure allocators), word 'n **secret tag** aan daardie blok toegewys.
- Die pointer wat aan die gebruiker of kernel teruggegee word, bevat daardie tag in sy hoëbits (gebruik TBI / top byte ignore mechanisms).

2. **Tag checking on access**
- Wanneer 'n load of store uitgevoer word met 'n pointer, kontroleer die hardware dat die pointer se tag ooreenstem met die geheueblok se tag (allocation tag). By mismatch faal dit onmiddellik (aangesien synchronous).
- Omdat dit synchronous is, is daar geen “uitgestelde opsporing”-venster nie.

3. **Retagging on free / reuse**
- Wanneer geheue vrygestel word, verander die allocator die blok se tag (sodat ou pointers met ou tags nie meer ooreenstem nie).
- 'n Use-after-free pointer sal dus 'n verouderde tag hê en by toegang mismatch veroorsaak.

4. **Neighbor-tag differentiation to catch overflows**
- Aangrensende toewysings kry onderskeibare tags. As 'n buffer overflow in 'n buurman se geheue uitloop, veroorsaak tag mismatch 'n fault.
- Dit is veral kragtig om klein overflows wat oor 'n grens gaan te vang.

5. **Tag confidentiality enforcement**
- Apple moet voorkom dat tag-waardes geleaked word (want as 'n aanvaller die tag ken, kan hy pointers met korrekte tags maak).
- Hulle sluit beskerming in (mikroargitektuurlike / speculative kontroles) om side-channel leakage van tag bits te probeer voorkom.

6. **Kernel and user-space integration**
- Apple gebruik EMTE nie net in user-space nie, maar ook in kernel / OS-kritieke komponente (om die kernel teen geheuekorruptie te beskerm).
- Die hardware/OS verseker dat tag-reëls toegepas word selfs wanneer die kernel namens user space uitvoer.

Omdat EMTE in MIE ingebou is, gebruik Apple EMTE in synchronous mode oor sleutel-aanvalsoppervlakke, nie as opt-in of debugging mode nie.

---

## Exception handling in XNU

Wanneer 'n **exception** voorkom (bv. `EXC_BAD_ACCESS`, `EXC_BAD_INSTRUCTION`, `EXC_CRASH`, `EXC_ARM_PAC`, ens.), is die **Mach layer** van die XNU kernel verantwoordelik om dit te onderskep voordat dit 'n UNIX-styl **signal** word (soos `SIGSEGV`, `SIGBUS`, `SIGILL`, ...).

Hierdie proses behels verskeie lae van exception-propagasie en hantering voordat dit by user space uitkom of in 'n BSD signal omskep word.

### Exception Flow (High-Level)

1.  **CPU triggers a synchronous exception** (bv. ongeldig pointer-dereferensie, PAC failure, illegal instruction, ens.).
2.  **Low-level trap handler** runs (`trap.c`, `exception.c` in XNU source).
3.  Die trap handler roep **`exception_triage()`** aan, die kern van die Mach exception handling.
4.  `exception_triage()` besluit hoe om die exception te roeteer:

-   Eerstens na die **thread's exception port**.

-   Dan na die **task's exception port**.

-   Dan na die **host's exception port** (dikwels `launchd` of `ReportCrash`).

As geen van hierdie ports die exception hanteer nie, kan die kernel:

-   **Dit omskakel na 'n BSD signal** (vir user-space prosesse).

-   **Panic** (vir kernel-space exceptions).

### Core Function: `exception_triage()`

Die funksie `exception_triage()` roeteer Mach exceptions op die ketting van moontlike hanteerders totdat een dit hanteer of totdat dit uiteindelik fataal is. Dit is gedefinieer in `osfmk/kern/exception.c`.
```c
void exception_triage(exception_type_t exception, mach_exception_data_t code, mach_msg_type_number_t codeCnt);
```
**Tipiese oproepsvloei:**

`exception_triage()
└── exception_deliver()
├── exception_deliver_thread()
├── exception_deliver_task()
└── exception_deliver_host()`

As alles misluk → hanteer deur `bsd_exception()` → vertaal na 'n sein soos `SIGSEGV`.


### Uitsonderingspoorte

Elke Mach-objek (thread, task, host) kan **uitsonderingspoorte** registreer, waar uitsonderingsboodskappe heen gestuur word.

Hulle word deur die API gedefinieer:
```
task_set_exception_ports()
thread_set_exception_ports()
host_set_exception_ports()
```
Elke exception port het:

-   A **mask** (which exceptions it wants to receive)
-   A **port name** (Mach port to receive messages)
-   A **behavior** (how the kernel sends the message)
-   A **flavor** (which thread state to include)


### Debuggers and Exception Handling

A **debugger** (e.g., LLDB) sets an **exception port** on the target task or thread, usually using `task_set_exception_ports()`.

**When an exception occurs:**

-   Die Mach boodskap word na die debugger-proses gestuur.
-   Die debugger kan besluit om die exception te **handle** (herneem, registers wysig, instruksie oorslaan) of **nie te handle** nie.
-   As die debugger dit nie handle nie, propagseer die exception na die volgende vlak (task → host).


### Flow of `EXC_BAD_ACCESS`

1.  Thread dereferensieer 'n ongeldig pointer → CPU gooi 'n Data Abort.

2.  Kernel se trap handler roep `exception_triage(EXC_BAD_ACCESS, ...)` aan.

3.  Boodskap gestuur na:

-   Thread port → (debugger kan breakpoint onderskep).

-   As debugger ignoreer → Task port → (process-level handler).

-   As dit geïgnoreer word → Host port (gewoonlik ReportCrash).

4.  As niemand dit handle nie → `bsd_exception()` vertaal na `SIGSEGV`.


### PAC Exceptions

Wanneer **Pointer Authentication** (PAC) misluk (handtekening pas nie), word 'n **special Mach exception** gehou:

-   **`EXC_ARM_PAC`** (type)
-   Kodes kan besonderhede insluit (bv. sleuteltipe, pointertipe).

If the binary has the flag **`TFRO_PAC_EXC_FATAL`**, the kernel treats PAC failures as **fatal**, bypassing debugger interception. This is to prevent attackers from using debuggers to bypass PAC checks and it's enabled for **platform binaries**.


### Software Breakpoints

A software breakpoint (`int3` on x86, `brk` on ARM64) is implemented by **causing a deliberate fault**.\
Die debugger vang dit via die exception port op:

-   Wysig instruction pointer of geheue.
-   Herstel die oorspronklike instruksie.
-   Hernem uitvoering.

Dieselfde meganisme laat jou toe om 'n PAC-exception te "vang" --- **tensy `TFRO_PAC_EXC_FATAL`** gestel is, in welke geval dit nooit die debugger bereik nie.


### Conversion to BSD Signals

If no handler accepts the exception:

-   Kernel calls `task_exception_notify() → bsd_exception()`.

-   This maps Mach exceptions to signals:

| Mach Exception | Signal |
| --- | --- |
| EXC_BAD_ACCESS | SIGSEGV or SIGBUS |
| EXC_BAD_INSTRUCTION | SIGILL |
| EXC_ARITHMETIC | SIGFPE |
| EXC_SOFTWARE | SIGTRAP |
| EXC_BREAKPOINT | SIGTRAP |
| EXC_CRASH | SIGKILL |
| EXC_ARM_PAC | SIGILL (on non-fatal) |


### Key Files in XNU Source

-   `osfmk/kern/exception.c` → Kern van `exception_triage()`, `exception_deliver_*()`.
-   `bsd/kern/kern_sig.c` → Sein-afleweringslogika.
-   `osfmk/arm64/trap.c` → Laevlak trap handlers.
-   `osfmk/mach/exc.h` → Exception-kodes en strukture.
-   `osfmk/kern/task.c` → Opstelling van task exception port.

---

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

Die kernel het 'n **zone allocator** (`kalloc`) gebruik, verdeel in vaste-grootte "zones." Elke sone stoor slegs toewysings van 'n enkele grootteklas.

From the screenshot:

| Sone-naam            | Elementgrootte | Voorbeeldgebruik                                                                 |
|----------------------|----------------|----------------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes       | Baie klein kernel structs, pointers.                                             |
| `default.kalloc.32`  | 32 bytes       | Kleine structs, object headers.                                                  |
| `default.kalloc.64`  | 64 bytes       | IPC messages, klein kernel buffers.                                              |
| `default.kalloc.128` | 128 bytes      | Medium objects soos dele van `OSObject`.                                         |
| …                    | …              | …                                                                                |
| `default.kalloc.1280`| 1280 bytes     | Groot strukture, IOSurface/graphics metadata.                                   |

**Hoe dit gewerk het:**
- Elke toewysingsversoek word **opgerond** na die naaste sonegrootte. (Byv., 'n 50-byte versoek beland in die `kalloc.64` sone).
- Geheue in elke sone is bewaar in 'n **free list** — stukke wat deur die kernel vrygestel is, het terug in daardie sone gegaan.
- As jy 'n 64-byte buffer overflow het, sou jy die **volgende objek in dieselfde sone** oorskryf.

Dit is hoekom **heap spraying / feng shui** so effektief was: jy kon objek-buurtone voorspel deur toewysings van dieselfde grootteklas te spray.

### The freelist

Binne elke kalloc-sone is vrygestelde voorwerpe nie direk aan die stelsel teruggegee nie — hulle het in 'n freelist gegaan, 'n gekoppelde lys van beskikbare stukke.

- Wanneer 'n stuk vrygestel is, het die kernel 'n pointer by die begin van daardie stuk geskryf → die adres van die volgende gratis stuk in dieselfde sone.

- Die sone het 'n HEAD-pointer na die eerste gratis stuk gehou.

- Toewysing het altyd die huidige HEAD gebruik:

1. Pop HEAD (gee daardie geheue terug aan die aanroeper).

2. Werk HEAD by = HEAD->next (gestoor in die vrygestelde stuk se header).

- Vrymaak het stukke terug gedruk:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

Dus was die freelist net 'n gekoppelde lys gebou binne die vrygestelde geheue self.

Normale toestand:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### Uitbuiting van die freelist

Omdat die eerste 8 bytes van 'n free chunk = freelist pointer, kan 'n aanvaller dit korrupteer:

1. **Heap overflow** into an adjacent freed chunk → oorskryf sy “next” pointer.

2. **Use-after-free** write into a freed object → oorskryf sy “next” pointer.

Dan, by die volgende allocation van daardie grootte:

- Die allocator haal die gekorrupte chunk uit.
- Volg die deur die aanvaller verskafte “next” pointer.
- Gee 'n pointer terug na arbitrêre geheue, wat fake object primitives of targeted overwrite moontlik maak.

Visual example of freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist-ontwerp het uitbuiting baie effektief gemaak pre-hardening: voorspelbare bure van heap sprays, raw pointer freelist links, en geen tipe-separasie het aanvallers toegelaat om UAF/overflow-bugs op te skaal tot arbitrêre kernel-geheuebeheer.

### Heap Grooming / Feng Shui
Die doel van heap grooming is om die heap-layout te **vorm** sodat wanneer ’n aanvaller ’n overflow of use-after-free aktiveer, die teiken (slagoffer) objek direk langs ’n aanvaller-gekontroleerde objek lê.\
Sodoende kan die aanvaller, wanneer geheuekorruptie gebeur, betroubaar die slagoffer-objek oorskryf met beheerde data.

**Stappe:**

1. Spray allocations (fill the holes)
- Oor tyd raak die kernel heap gefragmenteer: sommige zones het gapings waar ou objekte vrygestel is.
- Die aanvaller maak eers baie dummy-allocations om hierdie gapings te vul, sodat die heap “gepak” en voorspelbaar raak.

2. Force new pages
- Sodra die gapings gevul is, moet die volgende allocations vanaf nuwe bladsye wat by die zone gevoeg word kom.
- Vars bladsye beteken dat objekte saam gegroepeer sal wees, nie deur ou gefragmenteerde geheue versprei nie.
- Dit gee die aanvaller baie beter beheer oor bure.

3. Place attacker objects
- Die aanvaller spray nou weer en skep baie aanvaller-gekontroleerde objekte in daardie nuwe bladsye.
- Hierdie objekte is voorspelbaar in grootte en posisionering (aangesien hulle almal by dieselfde zone hoort).

4. Free a controlled object (make a gap)
- Die aanvaller vrywillig een van hul eie objekte.
- Dit skep ’n “gaping” in die heap wat die allocator later vir die volgende allocation van daardie grootte sal hergebruik.

5. Victim object lands in the hole
- Die aanvaller trigger die kernel om die slagoffer-objek (die een wat hulle wil korrupteer) te allokeer.
- Aangesien die gaping die eerste beskikbare slot in die freelist is, word die slagoffer presies geplaas waar die aanvaller hul objek vrygestel het.

6. Overflow / UAF into victim
- Nou het die aanvaller aanvaller-gekontroleerde objekte rondom die slagoffer.
- Deur te oorvloei vanaf een van hul eie objekte (of ’n vrygestelde een weer te gebruik), kan hulle betroubaar die slagoffer se geheuevelde oorskryf met gekose waardes.

**Waarom dit werk**:

- Zone allocator voorspelbaarheid: allocations van dieselfde grootte kom altyd van dieselfde zone.
- Freelist gedrag: nuwe allocations hergebruik die mees onlangs vrygestelde chunk eerste.
- Heap sprays: aanvaller vul geheue met voorspelbare inhoud en beheer die layout.
- Eindresultaat: aanvaller beheer waar die slagoffer-objek land en watter data langs dit lê.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple het die allocator gehard en maak **heap grooming veel moeiliker**:

### 1. From Classic kalloc to kalloc_type
- **Before**: daar was ’n enkele `kalloc.<size>` zone vir elke size class (16, 32, 64, … 1280, ens.). Enige objek van daardie grootte is daar geplaas → aanvaller-objekte kon langs bevoorregte kernel-objekte sit.
- **Now**:
- Kernel-objekte word gealloceer vanaf **typed zones** (`kalloc_type`).
- Elke tipe objek (bv. `ipc_port_t`, `task_t`, `OSString`, `OSData`) het sy eie toegewyde zone, selfs al het hulle dieselfde grootte.
- Die koppelvlak tussen objektipe ↔ zone word by compile-tyd gegenereer deur die **kalloc_type system**.

’n Aanvaller kan nie meer waarborg dat beheerde data (`OSData`) langs sensitiewe kernel-objekte (`task_t`) van dieselfde grootte eindig nie.

### 2. Slabs and Per-CPU Caches
- Die heap is verdeel in **slabs** (bladsye geheue in vaste-grootte stukke opgesny vir daardie zone).
- Elke zone het ’n **per-CPU cache** om inhouding te verminder.
- Allocatiepad:
1. Probeer per-CPU cache.
2. As leeg, haal van die globale freelist.
3. As freelist leeg is, allokeer ’n nuwe slab (een of meer bladsye).
- **Voordeel**: hierdie desentralisering maak heap sprays minder deterministies, aangesien allocations moontlik vanaf verskillende CPU’s se caches bevredig word.

### 3. Randomization inside zones
- Binne ’n zone word vrygestelde elemente nie in eenvoudige FIFO/LIFO volgorde teruggegee nie.
- Moderne XNU gebruik **encoded freelist pointers** (safe-linking soortgelyk aan Linux, ingestel ~iOS 14).
- Elke freelist pointer is **XOR-encoded** met ’n per-zone geheime cookie.
- Dit keer aanvallers om ’n vals freelist pointer te vervals as hulle ’n write primitive verkry.
- Sommige allocations word **gerandomiseer in hul plasing binne ’n slab**, so spraying verseker nie adjacency nie.

### 4. Guarded Allocations
- Sekere kritieke kernel-objekte (bv. credentials, task structures) word in **guarded zones** gealloceer.
- Hierdie zones voeg **guard pages** (onmapped geheue) tussen slabs in of gebruik **redzones** rondom objekte.
- Enige overflow in die guard page sal ’n fout veroorsaak → onmiddellike panic in plaas van stille korrupsie.

### 5. Page Protection Layer (PPL) and SPTM
- Selfs as jy ’n vrygestelde objek beheer, kan jy nie al die kernel-geheue verander nie:
- **PPL (Page Protection Layer)** dwing af dat sekere streke (bv. code signing data, entitlements) **read-only** is selfs vir die kernel self.
- Op **A15/M2+ devices**, word hierdie rol vervang/verbeter deur **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- Hierdie hardware-afgedwonge lae beteken dat aanvallers nie van ’n enkele heap-korrupsie na arbitrêre patching van kritieke sekuriteitsstrukture kan eskaleer nie.
- **(Added / Enhanced)**: ook, **PAC (Pointer Authentication Codes)** word in die kernel gebruik om pointers (spesifiek function pointers, vtables) te beskerm sodat dit moeiliker word om hulle te vervals of te korrupteer.
- **(Added / Enhanced)**: zones kan **zone_require / zone enforcement** afdwing, d.w.s. dat ’n objek wat vrygestel is slegs deur sy korrekte typed zone teruggegee kan word; ongeldige cross-zone frees kan panics of verwerping veroorsaak. (Apple verwys hierna in hul memory safety poste)

### 6. Large Allocations
- Nie alle allocations gaan deur `kalloc_type` nie.
- Baie groot versoeke (bo ~16 KB) omseil typed zones en word direk uit **kernel VM (kmem)** via page allocations bedien.
- Hierdie is minder voorspelbaar, maar ook moeiliker uitbuitbaar, aangesien hulle nie slabs met ander objekte deel nie.

### 7. Allocation Patterns Attackers Target
Selfs met hierdie beskermings soek aanvallers steeds na:
- **Reference count objects**: as jy retain/release counters kan manipuleer, kan jy use-after-free veroorsaak.
- **Objects with function pointers (vtables)**: die korruptering van een gee nog steeds control flow.
- **Shared memory objects (IOSurface, Mach ports)**: hierdie bly fokusareas omdat hulle user ↔ kernel oorbruggings is.

Maar — in teenstelling met voorheen — jy kan nie net `OSData` spray en verwag dat dit ’n `task_t` sal neerlei nie. Jy het nodig vir **type-specific bugs** of **info leaks** om sukses te behaal.

### Example: Allocation Flow in Modern Heap

Stel userspace maak ’n call na IOKit om ’n `OSData` objek te allokeer:

1. **Type lookup** → `OSData` map na `kalloc_type_osdata` zone (grootte 64 bytes).
2. Check per-CPU cache vir free elements.
- As gevind → gee een terug.
- As leeg → gaan na globale freelist.
- As freelist leeg → allokeer ’n nuwe slab (bladsy van 4KB → 64 chunks van 64 bytes).
3. Gee chunk terug aan caller.

**Freelist pointer protection**:
- Elke vrygestelde chunk stoor die adres van die volgende vrye chunk, maar geënkodeer met ’n geheime sleutel.
- Oorskryf daardie veld met aanvaller-data sal nie werk tensy jy die sleutel ken nie.

---

## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages, and **PAC** protects pointers |
| Allocation reuse validation     | None (freelist pointers raw)                               | **zone_require / zone enforcement**             |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |
| Large allocations handling      | All small allocations managed equally                       | Large ones bypass zones → handled via VM         |

---

## Modern Userland Heap (iOS, macOS — type-aware / xzone malloc)

In onlangse Apple OS weergawes (veral iOS 17+), het Apple ’n meer veilige userland allocator geïntroduceer, **xzone malloc** (XZM). Dit is die user-space analoog van die kernel se `kalloc_type`, wat tipe-bewustheid, metadata-isolasie en memory tagging beskerming toepas.

### Goals & Design Principles

- **Type segregation / type awareness**: groepeer allocations per *type of gebruik (pointer vs data)* om type confusion en cross-type reuse te voorkom.
- **Metadata isolation**: skei heap metadata (bv. free lists, size/state bits) van objek-payloads sodat out-of-bounds skryfwerk minder waarskynlik metadata korrupteer.
- **Guard pages / redzones**: voeg unmapped bladsye of padding rondom allocations in om overflows te vang.
- **Memory tagging (EMTE / MIE)**: werk saam met hardware-tagging om use-after-free, out-of-bounds en ongeldige toegang te detecteer.
- **Scalable performance**: behou lae overhead, vermy oormatige fragmentasie, en ondersteun baie allocations per sekonde met lae latensie.

### Architecture & Components

Hier is die hoofelemente in die xzone allocator:

#### Segment Groups & Zones

- **Segment groups** deel die adresruimte op volgens gebruikskategorieë: bv. `data`, `pointer_xzones`, `data_large`, `pointer_large`.
- Elke segment group bevat **segments** (VM-reekse) wat allocations vir daardie kategorie huisves.
- Geassosieer met elke segment is ’n **metadata slab** (afsonderlike VM-area) wat metadata (bv. free/used bits, size classes) vir daardie segment stoor. Hierdie **out-of-line (OOL) metadata** verseker dat metadata nie met objek-payloads vermeng word nie, wat korrupsie van oorvloeie beperk.
- Segmente word opgesny in **chunks** (snyre) wat op hul beurt in **blocks** (allocation eenhede) verdeel is. ’n Chunk is gebind aan ’n spesifieke size class en segment group (d.w.s. alle blocks in ’n chunk deel dieselfde grootte & kategorie).
- Vir klein/middelgroot allocations sal dit vaste-grootte chunks gebruik; vir groot/huge kan dit apart map.

#### Chunks & Blocks

- ’n **Chunk** is ’n streek (gewoonlik verskeie bladsye) toegewy aan allocations van een size class binne ’n group.
- Binne ’n chunk is **blocks** s lots beskikbaar vir allocations. Vrygestelde blocks word getrap deur die metadata slab — bv. via bitmaps of free lists gestoor out-of-line.
- Tussen chunks (of binne-in) kan **guard slices / guard pages** ingevoeg word (bv. unmapped slices) om out-of-bounds skrywes te vang.

#### Type / Type ID

- Elke allocation site (of oproep na malloc, calloc, ens.) is geassosieer met ’n **type identifier** (’n `malloc_type_id_t`) wat kodeer watter soort objek gealloceer word. Daardie type ID word na die allocator gestuur, wat dit gebruik om te kies watter zone / segment die allocation moet dien.
- Danksy dit kan selfs twee allocations met dieselfde grootte heeltemal na verskillende zones gaan as hul tipes verskil.
- In vroeë iOS 17 weergawes was nie alle APIs (bv. CFAllocator) volledig type-aware nie; Apple het sommige van daardie swakpunte in iOS 18 aangespreek.

---

### Allocation & Freeing Workflow

Hier is ’n hoëvlak vloei van hoe allocation en deallokasie in xzone werk:

1. **malloc / calloc / realloc / typed alloc** word aangeroep met ’n grootte en type ID.
2. Die allocator gebruik die **type ID** om die korrekte segment group / zone te kies.
3. Binne daardie zone/segment soek dit ’n chunk met vrye blocks van die versoekte grootte.
- Dit kan **local caches / per-thread pools** of **free block lists** van metadata raadpleeg.
- As geen vrye block beskikbaar is nie, kan dit ’n nuwe chunk in daardie zone allokeer.
4. Die metadata slab word opgedateer (free bit verwyder, bookkeeping).
5. As memory tagging (EMTE) in werking is, kry die teruggegewe block ’n **tag** toegewys, en metadata word opgedateer om sy “live” toestand te wys.
6. Wanneer `free()` geroep word:
- Die block word as vrygestel in metadata gemerk (via OOL slab).
- Die block kan in ’n free list geplaas of gepool word vir hergebruik.
- Opsioneel kan block-inhouds gewist of gepoison word om data-lekkasies of use-after-free uitbuiting te verminder.
- Die hardware-tag geassosieer met die block kan ongeldig gemaak of her-getag word.
- As ’n hele chunk vrygestel raak (alle blocks vry), kan die allocator daardie chunk **hersei** (unmap of teruggee aan OS) onder geheue-druk.

---

### Security Features & Hardening

Hierdie is die verdediging ingebou in moderne userland xzone:

| Feature | Purpose | Notes |
|---|-------------------------------|-----------------------------------------|
| **Metadata decoupling** | Prevent overflow from corrupting metadata | Metadata lives in separate VM region (metadata slab)|
| **Guard pages / unmapped slices** | Catch out-of-bounds writes | Helps detect buffer overflows rather than silently corrupting adjacent blocks|
| **Type-based segregation** | Prevent cross-type reuse & type confusion | Even same-size allocations from different types go to different zones|
| **Memory Tagging (EMTE / MIE)** | Detect invalid access, stale references, OOB, UAF | xzone works in concert with hardware EMTE in synchronous mode (“Memory Integrity Enforcement”)|
| **Delayed reuse / poisoning / zap** | Reduce chance of use-after-free exploitation | Freed blocks may be poisoned, zeroed, or quarantined before reuse |
| **Chunk reclamation / dynamic unmapping** | Reduce memory waste and fragmentation | Entire chunks may be unmapped when unused |
| **Randomization / placement variation** | Prevent deterministic adjacency | Blocks in a chunk and chunk selection may have randomized aspects |
| **Segregation of “data-only” allocations** | Separate allocations that don’t store pointers | Reduces attacker control over metadata or control fields|

---

### Interaction with Memory Integrity Enforcement (MIE / EMTE)

- Apple se MIE (Memory Integrity Enforcement) is die hardware + OS raamwerk wat **Enhanced Memory Tagging Extension (EMTE)** in altyd-aan, sinchrone modus oor groot aanvalsvlakke bring.
- xzone allocator is ’n fundamentele grondslag van MIE in user space: allocations wat via xzone gemaak word kry tags, en toegang word deur hardware geverifieer.
- In MIE is die allocator, tag-toewysing, metadata-bestuur, en tag-privaatheid-integriteit geïntegreer om te verseker dat geheue-foute (bv. stale reads, OOB, UAF) dadelik gevang word, nie later uitgebuit nie.

---

If you like, I can also generate a cheat-sheet or diagram of xzone internals for your book. Do you want me to do that next?
::contentReference[oai:20]{index=20}


---

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


## JSKit-Based Safari Chains and PREYHUNTER Stagers

### Renderer RCE abstraction with JSKit
- **Reusable entry**: Recent in-the-wild chains abused a WebKit JIT bug (patched as CVE-2023-41993) purely to gain JavaScript-level arbitrary read/write. The exploit immediately pivots into a purchased framework called **JSKit**, so any future Safari bug only needs to deliver the same primitive.
- **Version abstraction & PAC bypasses**: JSKit bundles support for a wide range of iOS releases together with multiple, selectable Pointer Authentication Code bypass modules. The framework fingerprints the target build, selects the appropriate PAC bypass logic, and verifies every step (primitive validation, shellcode launch) before progressing.
- **Manual Mach-O mapping**: JSKit parses Mach-O headers directly from memory, resolves the symbols it needs inside dyld-cached images, and can manually map additional Mach-O payloads without writing them to disk. This keeps the renderer process in-memory only and evades code-signature checks tied to filesystem artifacts.
- **Portfolio model**: Debug strings such as *"exploit number 7"* show that the suppliers maintain multiple interchangeable WebKit exploits. Once the JS primitive matches JSKit’s interface, the rest of the chain is unchanged across campaigns.

### Kernel bridge: IPC UAF -> code-sign bypass pattern
- **Kernel IPC UAF (CVE-2023-41992)**: The second stage, still running inside the Safari context, triggers a kernel use-after-free in IPC code, re-allocates the freed object from userland, and abuses the dangling pointers to pivot into arbitrary kernel read/write. The stage also reuses PAC bypass material previously computed by JSKit instead of re-deriving it.
- **Code-signing bypass (CVE-2023-41991)**: With kernel R/W available, the exploit patches the trust cache / code-signing structures so unsigned payloads execute as `system`. The stage then exposes a lightweight kernel R/W service to later payloads.
- **Composed pattern**: This chain demonstrates a reusable recipe that defenders should expect going forward:
```
WebKit renderer RCE -> kernel IPC UAF -> kernel arbitrary R/W -> code-sign bypass -> unsigned system stager
```
### PREYHUNTER helper & watcher modules
- **Watcher anti-analysis**: 'n Toegewydde watcher binary profileer die toestel deurlopend en staak die kill-chain wanneer 'n navorsingsomgewing opgespoor word. Dit ondersoek `security.mac.amfi.developer_mode_status`, die teenwoordigheid van 'n `diagnosticd` console, lokales `US` of `IL`, jailbreak-spore soos **Cydia**, prosesse soos `bash`, `tcpdump`, `frida`, `sshd`, of `checkrain`, mobiele AV-apps (McAfee, AvastMobileSecurity, NortonMobileSecurity), aangepaste HTTP-proxy-instellings, en aangepaste root CAs. As enige kontrole misluk, word verdere payload-aflewering geblokkeer.
- **Helper surveillance hooks**: Die helper-komponent kommunikeer met ander fases via `/tmp/helper.sock`, en laad dan hook-sets genaamd **DMHooker** en **UMHooker**. Hierdie hooks taps VOIP-audio-paaie (opnames beland onder `/private/var/tmp/l/voip_%lu_%u_PART.m4a`), implementeer 'n stelselwye keylogger, neem foto's sonder UI, en hook SpringBoard om kennisgewings te onderdruk wat daardie aksies normaalweg sou veroorsaak. Die helper tree dus op as 'n diskrete validerings- en ligtoesiglaag voordat swaarder implants soos Predator afgewerp word.

### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

## Verwysings

- [Google Threat Intelligence – Intellexa zero-day exploits continue](https://cloud.google.com/blog/topics/threat-intelligence/intellexa-zero-day-exploits-continue)

{{#include ../../banners/hacktricks-training.md}}
