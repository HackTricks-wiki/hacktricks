# iOS Exploiting

{{#include ../../banners/hacktricks-training.md}}

## iOSのエクスプロイト緩和策

- **Code Signing** は、すべての実行可能コード（apps, libraries, extensions など）に対して Apple 発行の証明書で暗号的に署名することを要求します。コードがロードされると、iOS はデジタル署名を Apple の信頼済みルートに対して検証します。署名が無効、欠落、または改変されている場合、OS は実行を拒否します。これにより、攻撃者が正規アプリに悪意あるコードを注入したり、署名されていないバイナリを実行したりすることが防がれ、任意のコード実行に依存する多くのエクスプロイトチェーンが止められます。
- **CoreTrust** はランタイムでの code signing を強制する iOS サブシステムです。キャッシュされた信頼ストアに頼らず Apple のルート証明書で直接署名を検証するため、Apple によって署名されたバイナリ（または有効な entitlements を持つもの）だけが実行できます。CoreTrust により、攻撃者がインストール後にアプリを改ざんしたり、システムライブラリを変更したり、署名されていないコードを読み込もうとした場合でも、コードが適切に署名されていなければ実行がブロックされます。この厳格な強制により、古い iOS バージョンで弱かったり回避可能だった署名チェックを利用した多くのポストエクスプロイトベクターが封じられます。
- **Data Execution Prevention (DEP)** は、明示的にコードを含む場合を除いてメモリ領域を非実行にマークします。これにより、攻撃者がデータ領域（スタックやヒープなど）にシェルコードを注入して実行することが防がれ、攻撃者は ROP（Return-Oriented Programming）などのより複雑な手法に頼らざるを得なくなります。
- **ASLR (Address Space Layout Randomization)** は、コード、ライブラリ、スタック、ヒープのメモリアドレスを毎回ランダム化します。これにより、攻撃者が有用な命令やガジェットの位置を予測しにくくなり、固定メモリレイアウトに依存する多くのエクスプロイトチェーンが壊れます。
- **KASLR (Kernel ASLR)** は同じランダム化の概念を iOS カーネルに適用します。カーネルのベースアドレスを起動ごとにシャッフルすることで、攻撃者がカーネル関数や構造を確実に特定することを防ぎ、フルシステム制御を得るようなカーネルレベルのエクスプロイトの難易度を上げます。
- **Kernel Patch Protection (KPP)**（iOS では **AMCC (Apple Mobile File Integrity)** とも呼ばれる）は、カーネルのコードページが改変されていないかを継続的に監視します。もしカーネル関数をパッチしたり悪意あるコードを挿入するような改ざんが検出されると、デバイスは即座にpanicして再起動します。この保護により、永続的なカーネルエクスプロイトははるかに困難になります。攻撃者は単純にカーネル命令をフックしたりパッチしたりできなくなります。
- **Kernel Text Readonly Region (KTRR)** はハードウェアベースのセキュリティ機能で、ブート後にカーネルのコード（text）セクションを永久に読み取り専用としてマークします。一度ロックされると、カーネル自体であってもそのメモリ領域を修正できません。これにより、攻撃者や特権コードでさえカーネル命令を実行時にパッチすることが防がれ、カーネルコードを直接改変することで成立していた多くのエクスプロイトのクラスが閉じられます。
- **Pointer Authentication Codes (PAC)** は、ポインタの未使用ビットに埋め込まれた暗号署名を使って、その整合性を使用前に検証します。ポインタ（リターンアドレスや関数ポインタなど）が作成されると、CPU は秘密鍵でそれを署名し、逆参照の前に署名をチェックします。もしポインタが改ざんされていればチェックは失敗し、実行は止まります。これにより、攻撃者がメモリ破壊エクスプロイトでポインタを偽造または再利用することが難しくなり、ROP や JOP のような手法の実用性が大きく低下します。
- **Privilege Access never (PAN)** はハードウェア機能で、カーネル（特権モード）が明示的にアクセス許可を有効にしない限りユーザ空間メモリに直接アクセスすることを防ぎます。これにより、カーネルコード実行を獲得した攻撃者がユーザメモリを簡単に読み書きして権限を昇格させたり機密データを盗んだりすることが阻止されます。厳格な分離を強制することで、PAN はカーネルエクスプロイトの影響を減らし、よくある権限昇格手法の多くをブロックします。
- **Page Protection Layer (PPL)** は、code signing や entitlements に関連する重要なカーネル管理メモリ領域を保護する iOS のセキュリティ機構です。MMU（Memory Management Unit）と追加のチェックを使って厳格な書き込み保護を課し、特権のあるカーネルコードであっても敏感なページを任意に変更できないようにします。これにより、カーネルレベルの実行権を獲得した攻撃者がセキュリティに関わる構造を改ざんして永続化や code-signing 回避を行うのが著しく困難になります。

## Old Kernel Heap (Pre-iOS 15 / Pre-A12 era)

カーネルは固定サイズの「zones」に分割された **zone allocator** (`kalloc`) を使用していました。
各 zone は単一のサイズクラスの割り当てのみを保持します。

From the screenshot:

| Zone Name            | Element Size | Example Use                                                                 |
|----------------------|--------------|-----------------------------------------------------------------------------|
| `default.kalloc.16`  | 16 bytes     | 非常に小さなカーネル構造体、ポインタ。                                           |
| `default.kalloc.32`  | 32 bytes     | 小さな構造体、オブジェクトヘッダ。                                                |
| `default.kalloc.64`  | 64 bytes     | IPC メッセージ、極小のカーネルバッファ。                                           |
| `default.kalloc.128` | 128 bytes    | `OSObject` の一部など中程度のオブジェクト。                                      |
| …                    | …            | …                                                                           |
| `default.kalloc.1280`| 1280 bytes   | 大きな構造体、IOSurface/グラフィックスのメタデータ。                              |

どのように動作していたか:
- 各割り当て要求は最も近い zone サイズに向上（rounded up）されます。
(例: 50 バイトの要求は `kalloc.64` zone に入ります)。
- 各 zone のメモリは **freelist** に保持されていました — カーネルが解放したチャンクはその zone に戻されます。
- もし 64 バイトのバッファをオーバーフローさせると、**同じ zone の次のオブジェクト** を上書きすることになります。

これが heap spraying / feng shui が非常に効果的だった理由です: 同じサイズクラスの割り当てをスプレーすることで、オブジェクトの隣接関係を予測できました。

### The freelist

各 kalloc zone の内部では、解放されたオブジェクトは直接システムに返されず、利用可能チャンクの linked list（freelist）に入れられていました。

- チャンクが解放されると、カーネルはそのチャンクの先頭にポインタを書き込み → 同じ zone 内の次の free チャンクのアドレスを格納しました。

- zone は最初の free チャンクを指す HEAD ポインタを保持していました。

- 割り当ては常に現在の HEAD を使いました:

1. HEAD をポップ（そのメモリを呼び出し元に返す）。

2. HEAD = HEAD->next に更新（解放されたチャンクのヘッダに保存されている）。

- 解放はチャンクをプッシュしました:

- `freed_chunk->next = HEAD`

- `HEAD = freed_chunk`

つまり freelist は、解放されたメモリ自体の中に構築されたリンクリストに過ぎません。

Normal state:
```
Zone page (64-byte chunks for example):
[ A ] [ F ] [ F ] [ A ] [ F ] [ A ] [ F ]

Freelist view:
HEAD ──► [ F ] ──► [ F ] ──► [ F ] ──► [ F ] ──► NULL
(next ptrs stored at start of freed chunks)
```
### freelist を悪用する

free chunk の最初の8バイトが freelist pointer に等しいため、攻撃者はそれを破損させることができる:

1. **Heap overflow** で隣接する解放済みチャンクに侵入 → その “next” pointer を上書きする。
2. **Use-after-free** で解放済みオブジェクトに書き込む → その “next” pointer を上書きする。

そのサイズの次回の割り当て時に:

- allocator は破損したチャンクを pop する。
- 攻撃者が指定した “next” pointer に従う。
- 任意のメモリへのポインタを返し、fake object primitives や targeted overwrite を可能にする。

Visual example of freelist poisoning:
```
Before corruption:
HEAD ──► [ F1 ] ──► [ F2 ] ──► [ F3 ] ──► NULL

After attacker overwrite of F1->next:
HEAD ──► [ F1 ]
(next) ──► 0xDEAD_BEEF_CAFE_BABE  (attacker-chosen)

Next alloc of this zone → kernel hands out memory at attacker-controlled address.
```
This freelist design made exploitation highly effective pre-hardening: predictable neighbors from heap sprays, raw pointer freelist links, and no type separation allowed attackers to escalate UAF/overflow bugs into arbitrary kernel memory control.

### Heap Grooming / Feng Shui
The goal of heap grooming is to **shape the heap layout** so that when an attacker triggers an overflow or use-after-free, the target (victim) object sits right next to an attacker-controlled object.\
That way, when memory corruption happens, the attacker can reliably overwrite the victim object with controlled data.

**Steps:**

1. Spray allocations (fill the holes)
- Over time, the kernel heap gets fragmented: some zones have holes where old
objects were freed.
- The attacker first makes lots of dummy allocations to fill these gaps, so
the heap becomes “packed” and predictable.

2. Force new pages
- Once the holes are filled, the next allocations must come from new pages
added to the zone.
- Fresh pages mean objects will be clustered together, not scattered across
old fragmented memory.
- This gives the attacker much better control of neighbors.

3. Place attacker objects
- The attacker now sprays again, creating lots of attacker-controlled objects
in those new pages.
- These objects are predictable in size and placement (since they all belong
to the same zone).

4. Free a controlled object (make a gap)
- The attacker deliberately frees one of their own objects.
- This creates a “hole” in the heap, which the allocator will later reuse for
the next allocation of that size.

5. Victim object lands in the hole
- The attacker triggers the kernel to allocate the victim object (the one
they want to corrupt).
- Since the hole is the first available slot in the freelist, the victim is
placed exactly where the attacker freed their object.

6. Overflow / UAF into victim
- Now the attacker has attacker-controlled objects around the victim.
- By overflowing from one of their own objects (or reusing a freed one), they
can reliably overwrite the victim’s memory fields with chosen values.

**Why it works**:

- Zone allocator predictability: allocations of the same size always come from
the same zone.
- Freelist behavior: new allocations reuse the most recently freed chunk first.
- Heap sprays: attacker fills memory with predictable content and controls layout.
- End result: attacker controls where the victim object lands and what data sits
next to it.

---

## Modern Kernel Heap (iOS 15+/A12+ SoCs)

Apple hardened the allocator and made **heap grooming much harder**:

### 1. From Classic kalloc to kalloc_type
- **Before**: a single `kalloc.<size>` zone existed for each size class (16, 32, 64, … 1280, etc.). Any object of that size was placed there → attacker objects could sit next to privileged kernel objects.
- **Now**:
- Kernel objects are allocated from **typed zones** (`kalloc_type`).
- Each type of object (e.g., `ipc_port_t`, `task_t`, `OSString`, `OSData`) has its own dedicated zone, even if they’re the same size.
- The mapping between object type ↔ zone is generated from the **kalloc_type system** at compile time.

An attacker can no longer guarantee that controlled data (`OSData`) ends up adjacent to sensitive kernel objects (`task_t`) of the same size.

### 2. Slabs and Per-CPU Caches
- The heap is divided into **slabs** (pages of memory carved into fixed-size chunks for that zone).
- Each zone has a **per-CPU cache** to reduce contention.
- Allocation path:
1. Try per-CPU cache.
2. If empty, pull from the global freelist.
3. If freelist is empty, allocate a new slab (one or more pages).
- **Benefit**: This decentralization makes heap sprays less deterministic, since allocations may be satisfied from different CPUs’ caches.

### 3. Randomization inside zones
- Within a zone, freed elements are not handed back in simple FIFO/LIFO order.
- Modern XNU uses **encoded freelist pointers** (safe-linking like Linux, introduced ~iOS 14).
- Each freelist pointer is **XOR-encoded** with a per-zone secret cookie.
- This prevents attackers from forging a fake freelist pointer if they gain a write primitive.
- Some allocations are **randomized in their placement within a slab**, so spraying doesn’t guarantee adjacency.

### 4. Guarded Allocations
- Certain critical kernel objects (e.g., credentials, task structures) are allocated in **guarded zones**.
- These zones insert **guard pages** (unmapped memory) between slabs or use **redzones** around objects.
- Any overflow into the guard page triggers a fault → immediate panic instead of silent corruption.

### 5. Page Protection Layer (PPL) and SPTM
- Even if you control a freed object, you can’t modify all of kernel memory:
- **PPL (Page Protection Layer)** enforces that certain regions (e.g., code signing data, entitlements) are **read-only** even to the kernel itself.
- On **A15/M2+ devices**, this role is replaced/enhanced by **SPTM (Secure Page Table Monitor)** + **TXM (Trusted Execution Monitor)**.
- These hardware-enforced layers mean attackers can’t escalate from a single heap corruption to arbitrary patching of critical security structures.

### 6. Large Allocations
- Not all allocations go through `kalloc_type`.
- Very large requests (above ~16KB) bypass typed zones and are served directly from **kernel VM (kmem)** via page allocations.
- These are less predictable, but also less exploitable, since they don’t share slabs with other objects.

### 7. Allocation Patterns Attackers Target
Even with these protections, attackers still look for:
- **Reference count objects**: if you can tamper with retain/release counters, you may cause use-after-free.
- **Objects with function pointers (vtables)**: corrupting one still yields control flow.
- **Shared memory objects (IOSurface, Mach ports)**: these are still attack targets because they bridge user ↔ kernel.

But — unlike before — you can’t just spray `OSData` and expect it to neighbor a `task_t`. You need **type-specific bugs** or **info leaks** to succeed.

### Example: Allocation Flow in Modern Heap

Suppose userspace calls into IOKit to allocate an `OSData` object:

1. **Type lookup** → `OSData` maps to `kalloc_type_osdata` zone (size 64 bytes).
2. Check per-CPU cache for free elements.
- If found → return one.
- If empty → go to global freelist.
- If freelist empty → allocate a new slab (page of 4KB → 64 chunks of 64 bytes).
3. Return chunk to caller.

**Freelist pointer protection**:
- Each freed chunk stores the address of the next free chunk, but encoded with a secret key.
- Overwriting that field with attacker data won’t work unless you know the key.


## Comparison Table

| Feature                         | **Old Heap (Pre-iOS 15)**                                  | **Modern Heap (iOS 15+ / A12+)**                  |
|---------------------------------|------------------------------------------------------------|--------------------------------------------------|
| Allocation granularity          | Fixed size buckets (`kalloc.16`, `kalloc.32`, etc.)        | Size + **type-based buckets** (`kalloc_type`)    |
| Placement predictability         | High (same-size objects side by side)                     | Low (same-type grouping + randomness)            |
| Freelist management             | Raw pointers in freed chunks (easy to corrupt)             | **Encoded pointers** (safe-linking style)        |
| Adjacent object control         | Easy via sprays/frees (feng shui predictable)              | Hard — typed zones separate attacker objects      |
| Kernel data/code protections    | Few hardware protections                                   | **PPL / SPTM** protect page tables & code pages   |
| Exploit reliability             | High with heap sprays                                      | Much lower, requires logic bugs or info leaks     |

## (Old) Physical Use-After-Free via IOSurface

{{#ref}}
ios-physical-uaf-iosurface.md
{{#endref}}

---

## Ghidra Install BinDiff

Download BinDiff DMG from [https://www.zynamics.com/bindiff/manual](https://www.zynamics.com/bindiff/manual) and install it.

Open Ghidra with `ghidraRun` and go to `File` --> `Install Extensions`, press the add button and select the path `/Applications/BinDiff/Extra/Ghidra/BinExport` and click OK and isntall it even if there is a version mismatch.

### Using BinDiff with Kernel versions

1. Go to the page [https://ipsw.me/](https://ipsw.me/) and download the iOS versions you want to diff. These will be `.ipsw` files.
2. Decompress until you get the bin format of the kernelcache of both `.ipsw` files. You have information on how to do this on:

{{#ref}}
../../macos-hardening/macos-security-and-privilege-escalation/mac-os-architecture/macos-kernel-extensions.md
{{#endref}}

3. Open Ghidra with `ghidraRun`, create a new project and load the kernelcaches.
4. Open each kernelcache so they are automatically analyzed by Ghidra.
5. Then, on the project Window of Ghidra, right click each kernelcache, select `Export`, select format `Binary BinExport (v2) for BinDiff` and export them.
6. Open BinDiff, create a new workspace and add a new diff indicating as primary file the kernelcache that contains the vulnerability and as secondary file the patched kernelcache.

---

## Finding the right XNU version

If you want to check for vulnerabilities in a specific version of iOS, you can check which XNU release version the iOS version uses at [https://www.theiphonewiki.com/wiki/kernel]https://www.theiphonewiki.com/wiki/kernel).

For example, the versions `15.1 RC`, `15.1` and `15.1.1` use the version `Darwin Kernel Version 21.1.0: Wed Oct 13 19:14:48 PDT 2021; root:xnu-8019.43.1~1/RELEASE_ARM64_T8006`.


### iMessage/Media Parser Zero-Click Chains

{{#ref}}
imessage-media-parser-zero-click-coreaudio-pac-bypass.md
{{#endref}}

{{#include ../../banners/hacktricks-training.md}}
