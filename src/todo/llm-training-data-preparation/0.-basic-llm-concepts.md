# 0. Basic LLM Concepts

## Pretraining

Pretraining एक बुनियादी चरण है जिसमें एक बड़े भाषा मॉडल (LLM) को विशाल और विविध मात्रा में पाठ डेटा के संपर्क में लाया जाता है। इस चरण के दौरान, **LLM भाषा की बुनियादी संरचनाओं, पैटर्नों और बारीकियों को सीखता है**, जिसमें व्याकरण, शब्दावली, वाक्य रचना और संदर्भ संबंध शामिल हैं। इस व्यापक डेटा को संसाधित करके, मॉडल भाषा और सामान्य विश्व ज्ञान की एक व्यापक समझ प्राप्त करता है। यह व्यापक आधार LLM को सुसंगत और संदर्भ में प्रासंगिक पाठ उत्पन्न करने में सक्षम बनाता है। इसके बाद, यह पूर्व-प्रशिक्षित मॉडल फाइन-ट्यूनिंग के लिए जा सकता है, जहां इसे विशिष्ट कार्यों या क्षेत्रों के लिए अपनी क्षमताओं को अनुकूलित करने के लिए विशेष डेटा सेट पर और प्रशिक्षित किया जाता है, जिससे इसके प्रदर्शन और लक्षित अनुप्रयोगों में प्रासंगिकता में सुधार होता है।

## Main LLM components

आमतौर पर एक LLM को प्रशिक्षित करने के लिए उपयोग की जाने वाली कॉन्फ़िगरेशन द्वारा वर्णित किया जाता है। ये LLM को प्रशिक्षित करते समय सामान्य घटक हैं:

- **Parameters**: Parameters वे **सीखने योग्य वजन और पूर्वाग्रह** हैं जो न्यूरल नेटवर्क में होते हैं। ये वे संख्याएँ हैं जिन्हें प्रशिक्षण प्रक्रिया हानि फ़ंक्शन को न्यूनतम करने और कार्य पर मॉडल के प्रदर्शन में सुधार करने के लिए समायोजित करती है। LLMs आमतौर पर लाखों पैरामीटर का उपयोग करते हैं।
- **Context Length**: यह LLM को पूर्व-प्रशिक्षित करने के लिए उपयोग किए जाने वाले प्रत्येक वाक्य की अधिकतम लंबाई है।
- **Embedding Dimension**: प्रत्येक टोकन या शब्द का प्रतिनिधित्व करने के लिए उपयोग किए जाने वाले वेक्टर का आकार। LLMs आमतौर पर अरबों आयामों का उपयोग करते हैं।
- **Hidden Dimension**: न्यूरल नेटवर्क में छिपी परतों का आकार।
- **Number of Layers (Depth)**: मॉडल में कितनी परतें हैं। LLMs आमतौर पर दर्जनों परतों का उपयोग करते हैं।
- **Number of Attention Heads**: ट्रांसफार्मर मॉडल में, यह प्रत्येक परत में कितनी अलग-अलग ध्यान तंत्र का उपयोग किया जाता है। LLMs आमतौर पर दर्जनों सिरों का उपयोग करते हैं।
- **Dropout**: Dropout कुछ ऐसा है जैसे प्रशिक्षण के दौरान हटाए गए डेटा का प्रतिशत (संभावनाएँ 0 में बदल जाती हैं) जिसका उपयोग **ओवरफिटिंग को रोकने** के लिए किया जाता है। LLMs आमतौर पर 0-20% के बीच का उपयोग करते हैं।

Configuration of the GPT-2 model:
```json
GPT_CONFIG_124M = {
"vocab_size": 50257,  // Vocabulary size of the BPE tokenizer
"context_length": 1024, // Context length
"emb_dim": 768,       // Embedding dimension
"n_heads": 12,        // Number of attention heads
"n_layers": 12,       // Number of layers
"drop_rate": 0.1,     // Dropout rate: 10%
"qkv_bias": False     // Query-Key-Value bias
}
```
## PyTorch में टेन्सर

PyTorch में, एक **टेन्सर** एक मौलिक डेटा संरचना है जो एक बहु-आयामी सरणी के रूप में कार्य करती है, जो स्केलर, वेक्टर और मैट्रिस जैसे अवधारणाओं को संभावित रूप से उच्च आयामों में सामान्यीकृत करती है। टेन्सर PyTorch में डेटा का प्रतिनिधित्व और हेरफेर करने का प्राथमिक तरीका हैं, विशेष रूप से गहरे शिक्षण और न्यूरल नेटवर्क के संदर्भ में।

### टेन्सर का गणितीय अवधारणा

- **स्केलर**: रैंक 0 के टेन्सर, जो एकल संख्या का प्रतिनिधित्व करते हैं (शून्य-आयामी)। जैसे: 5
- **वेक्टर**: रैंक 1 के टेन्सर, जो संख्याओं की एक-आयामी सरणी का प्रतिनिधित्व करते हैं। जैसे: \[5,1]
- **मैट्रिस**: रैंक 2 के टेन्सर, जो पंक्तियों और स्तंभों के साथ दो-आयामी सरणियों का प्रतिनिधित्व करते हैं। जैसे: \[\[1,3], \[5,2]]
- **उच्च-रैंक टेन्सर**: रैंक 3 या अधिक के टेन्सर, जो उच्च आयामों में डेटा का प्रतिनिधित्व करते हैं (जैसे, रंगीन छवियों के लिए 3D टेन्सर)।

### डेटा कंटेनर के रूप में टेन्सर

गणनात्मक दृष्टिकोण से, टेन्सर बहु-आयामी डेटा के लिए कंटेनर के रूप में कार्य करते हैं, जहाँ प्रत्येक आयाम डेटा के विभिन्न विशेषताओं या पहलुओं का प्रतिनिधित्व कर सकता है। यह टेन्सरों को मशीन लर्निंग कार्यों में जटिल डेटा सेट को संभालने के लिए अत्यधिक उपयुक्त बनाता है।

### PyTorch टेन्सर बनाम NumPy एरे

हालांकि PyTorch टेन्सर संख्यात्मक डेटा को स्टोर और हेरफेर करने की अपनी क्षमता में NumPy एरे के समान हैं, वे गहरे शिक्षण के लिए महत्वपूर्ण अतिरिक्त कार्यक्षमताएँ प्रदान करते हैं:

- **स्वचालित विभेदन**: PyTorch टेन्सर स्वचालित रूप से ग्रेडिएंट्स (autograd) की गणना का समर्थन करते हैं, जो न्यूरल नेटवर्क को प्रशिक्षित करने के लिए आवश्यक व्युत्क्रम की गणना की प्रक्रिया को सरल बनाता है।
- **GPU त्वरक**: PyTorch में टेन्सर को GPUs पर स्थानांतरित और गणना की जा सकती है, जिससे बड़े पैमाने पर गणनाओं को काफी तेज किया जा सकता है।

### PyTorch में टेन्सर बनाना

आप `torch.tensor` फ़ंक्शन का उपयोग करके टेन्सर बना सकते हैं:
```python
pythonCopy codeimport torch

# Scalar (0D tensor)
tensor0d = torch.tensor(1)

# Vector (1D tensor)
tensor1d = torch.tensor([1, 2, 3])

# Matrix (2D tensor)
tensor2d = torch.tensor([[1, 2],
[3, 4]])

# 3D Tensor
tensor3d = torch.tensor([[[1, 2], [3, 4]],
[[5, 6], [7, 8]]])
```
### Tensor Data Types

PyTorch टेन्सर विभिन्न प्रकार के डेटा को स्टोर कर सकते हैं, जैसे कि पूर्णांक और फ्लोटिंग-पॉइंट नंबर।&#x20;

आप `.dtype` विशेषता का उपयोग करके एक टेन्सर के डेटा प्रकार की जांच कर सकते हैं:
```python
tensor1d = torch.tensor([1, 2, 3])
print(tensor1d.dtype)  # Output: torch.int64
```
- Python पूर्णांकों से बनाए गए टेन्सर का प्रकार `torch.int64` है।
- Python फ्लोट्स से बनाए गए टेन्सर का प्रकार `torch.float32` है।

टेन्सर के डेटा प्रकार को बदलने के लिए, `.to()` विधि का उपयोग करें:
```python
float_tensor = tensor1d.to(torch.float32)
print(float_tensor.dtype)  # Output: torch.float32
```
### सामान्य टेन्सर ऑपरेशन्स

PyTorch टेन्सर्स को संभालने के लिए विभिन्न ऑपरेशन्स प्रदान करता है:

- **आकार तक पहुँच**: टेन्सर के आयाम प्राप्त करने के लिए `.shape` का उपयोग करें।

```python
print(tensor2d.shape)  # Output: torch.Size([2, 2])
```

- **टेन्सर्स का आकार बदलना**: आकार बदलने के लिए `.reshape()` या `.view()` का उपयोग करें।

```python
reshaped = tensor2d.reshape(4, 1)
```

- **टेन्सर्स का ट्रांसपोज़ करना**: 2D टेन्सर को ट्रांसपोज़ करने के लिए `.T` का उपयोग करें।

```python
transposed = tensor2d.T
```

- **मैट्रिक्स गुणा**: `.matmul()` या `@` ऑपरेटर का उपयोग करें।

```python
result = tensor2d @ tensor2d.T
```

### गहरे शिक्षण में महत्व

टेन्सर्स PyTorch में न्यूरल नेटवर्क बनाने और प्रशिक्षित करने के लिए आवश्यक हैं:

- वे इनपुट डेटा, वेट्स और बायस को स्टोर करते हैं।
- वे प्रशिक्षण एल्गोरिदम में फॉरवर्ड और बैकवर्ड पास के लिए आवश्यक ऑपरेशन्स को सुविधाजनक बनाते हैं।
- ऑटोग्रेड के साथ, टेन्सर्स ग्रेडिएंट्स की स्वचालित गणना को सक्षम करते हैं, जिससे ऑप्टिमाइजेशन प्रक्रिया को सरल बनाया जा सकता है।

## स्वचालित विभेदन

स्वचालित विभेदन (AD) एक गणनात्मक तकनीक है जिसका उपयोग **कार्यात्मक व्युत्पत्तियों (ग्रेडिएंट्स)** का मूल्यांकन कुशलता और सटीकता से करने के लिए किया जाता है। न्यूरल नेटवर्क के संदर्भ में, AD ग्रेडिएंट्स की गणना को सक्षम करता है जो **ऑप्टिमाइजेशन एल्गोरिदम जैसे ग्रेडिएंट डिसेंट** के लिए आवश्यक हैं। PyTorch एक स्वचालित विभेदन इंजन प्रदान करता है जिसे **ऑटोग्रेड** कहा जाता है जो इस प्रक्रिया को सरल बनाता है।

### स्वचालित विभेदन का गणितीय स्पष्टीकरण

**1. चेन नियम**

स्वचालित विभेदन के केंद्र में कलन से **चेन नियम** है। चेन नियम कहता है कि यदि आपके पास कार्यों का संयोजन है, तो संयोजित कार्य का व्युत्पत्ति उन संयोजित कार्यों की व्युत्पत्तियों के गुणनफल के बराबर है।

गणितीय रूप से, यदि `y=f(u)` और `u=g(x)` है, तो `y` की `x` के सापेक्ष व्युत्पत्ति है:

<figure><img src="../../images/image (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

**2. गणनात्मक ग्राफ**

AD में, गणनाएँ **गणनात्मक ग्राफ** में नोड्स के रूप में प्रदर्शित की जाती हैं, जहाँ प्रत्येक नोड एक ऑपरेशन या एक चर के लिए होता है। इस ग्राफ को पार करके, हम व्युत्पत्तियों की गणना कुशलता से कर सकते हैं।

3. उदाहरण

आइए एक सरल कार्य पर विचार करें:

<figure><img src="../../images/image (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

जहाँ:

- `σ(z)` सिग्मॉइड फ़ंक्शन है।
- `y=1.0` लक्ष्य लेबल है।
- `L` हानि है।

हम हानि `L` की ग्रेडिएंट को वेट `w` और बायस `b` के सापेक्ष गणना करना चाहते हैं।

**4. मैन्युअल रूप से ग्रेडिएंट्स की गणना करना**

<figure><img src="../../images/image (2) (1) (1).png" alt=""><figcaption></figcaption></figure>

**5. संख्यात्मक गणना**

<figure><img src="../../images/image (3) (1) (1).png" alt=""><figcaption></figcaption></figure>

### PyTorch में स्वचालित विभेदन को लागू करना

अब, आइए देखें कि PyTorch इस प्रक्रिया को कैसे स्वचालित करता है।
```python
pythonCopy codeimport torch
import torch.nn.functional as F

# Define input and target
x = torch.tensor([1.1])
y = torch.tensor([1.0])

# Initialize weights with requires_grad=True to track computations
w = torch.tensor([2.2], requires_grad=True)
b = torch.tensor([0.0], requires_grad=True)

# Forward pass
z = x * w + b
a = torch.sigmoid(z)
loss = F.binary_cross_entropy(a, y)

# Backward pass
loss.backward()

# Gradients
print("Gradient w.r.t w:", w.grad)
print("Gradient w.r.t b:", b.grad)
```
**आउटपुट:**
```css
cssCopy codeGradient w.r.t w: tensor([-0.0898])
Gradient w.r.t b: tensor([-0.0817])
```
## Bigger Neural Networks में Backpropagation

### **1.Multilayer Networks के लिए विस्तार**

बड़े न्यूरल नेटवर्क में कई परतों के साथ, ग्रेडिएंट्स की गणना की प्रक्रिया अधिक जटिल हो जाती है क्योंकि पैरामीटर और ऑपरेशनों की संख्या बढ़ जाती है। हालाँकि, मौलिक सिद्धांत वही रहते हैं:

- **Forward Pass:** प्रत्येक परत के माध्यम से इनपुट पास करके नेटवर्क का आउटपुट गणना करें।
- **Compute Loss:** नेटवर्क के आउटपुट और लक्ष्य लेबल का उपयोग करके लॉस फ़ंक्शन का मूल्यांकन करें।
- **Backward Pass (Backpropagation):** आउटपुट परत से इनपुट परत तक श्रृंखला नियम को पुनरावृत्त रूप से लागू करके नेटवर्क में प्रत्येक पैरामीटर के सापेक्ष लॉस के ग्रेडिएंट्स की गणना करें।

### **2. Backpropagation Algorithm**

- **Step 1:** नेटवर्क पैरामीटर (वेट्स और बायस) को प्रारंभ करें।
- **Step 2:** प्रत्येक प्रशिक्षण उदाहरण के लिए, आउटपुट की गणना करने के लिए एक फॉरवर्ड पास करें।
- **Step 3:** लॉस की गणना करें।
- **Step 4:** श्रृंखला नियम का उपयोग करके प्रत्येक पैरामीटर के सापेक्ष लॉस के ग्रेडिएंट्स की गणना करें।
- **Step 5:** एक ऑप्टिमाइजेशन एल्गोरिदम (जैसे, ग्रेडिएंट डिसेंट) का उपयोग करके पैरामीटर को अपडेट करें।

### **3. Mathematical Representation**

एक साधारण न्यूरल नेटवर्क पर विचार करें जिसमें एक छिपी हुई परत है:

<figure><img src="../../images/image (5) (1).png" alt=""><figcaption></figcaption></figure>

### **4. PyTorch Implementation**

PyTorch इस प्रक्रिया को अपने ऑटोग्रेड इंजन के साथ सरल बनाता है।
```python
import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple neural network
class SimpleNet(nn.Module):
def __init__(self):
super(SimpleNet, self).__init__()
self.fc1 = nn.Linear(10, 5)  # Input layer to hidden layer
self.relu = nn.ReLU()
self.fc2 = nn.Linear(5, 1)   # Hidden layer to output layer
self.sigmoid = nn.Sigmoid()

def forward(self, x):
h = self.relu(self.fc1(x))
y_hat = self.sigmoid(self.fc2(h))
return y_hat

# Instantiate the network
net = SimpleNet()

# Define loss function and optimizer
criterion = nn.BCELoss()
optimizer = optim.SGD(net.parameters(), lr=0.01)

# Sample data
inputs = torch.randn(1, 10)
labels = torch.tensor([1.0])

# Training loop
optimizer.zero_grad()          # Clear gradients
outputs = net(inputs)          # Forward pass
loss = criterion(outputs, labels)  # Compute loss
loss.backward()                # Backward pass (compute gradients)
optimizer.step()               # Update parameters

# Accessing gradients
for name, param in net.named_parameters():
if param.requires_grad:
print(f"Gradient of {name}: {param.grad}")
```
इस कोड में:

- **Forward Pass:** नेटवर्क के आउटपुट की गणना करता है।
- **Backward Pass:** `loss.backward()` सभी पैरामीटर के सापेक्ष हानि के ग्रेडिएंट की गणना करता है।
- **Parameter Update:** `optimizer.step()` गणना किए गए ग्रेडिएंट के आधार पर पैरामीटर को अपडेट करता है।

### **5. Understanding Backward Pass**

पीछे की ओर पास के दौरान:

- PyTorch गणनात्मक ग्राफ को उल्टे क्रम में पार करता है।
- प्रत्येक ऑपरेशन के लिए, यह ग्रेडिएंट की गणना करने के लिए चेन नियम लागू करता है।
- ग्रेडिएंट प्रत्येक पैरामीटर टेन्सर के `.grad` विशेषता में संचित होते हैं।

### **6. Advantages of Automatic Differentiation**

- **Efficiency:** मध्यवर्ती परिणामों का पुन: उपयोग करके अनावश्यक गणनाओं से बचता है।
- **Accuracy:** मशीन सटीकता तक सटीक व्युत्पत्तियाँ प्रदान करता है।
- **Ease of Use:** व्युत्पत्तियों की मैनुअल गणना को समाप्त करता है।
