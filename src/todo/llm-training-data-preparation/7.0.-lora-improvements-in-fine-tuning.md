# 7.0. Mejoras de LoRA en el ajuste fino

## Mejoras de LoRA

> [!TIP]
> El uso de **LoRA reduce mucho la computación** necesaria para **ajustar finamente** modelos ya entrenados.

LoRA hace posible ajustar finamente **modelos grandes** de manera eficiente al cambiar solo una **pequeña parte** del modelo. Reduce el número de parámetros que necesitas entrenar, ahorrando **memoria** y **recursos computacionales**. Esto se debe a que:

1. **Reduce el Número de Parámetros Entrenables**: En lugar de actualizar toda la matriz de pesos en el modelo, LoRA **divide** la matriz de pesos en dos matrices más pequeñas (llamadas **A** y **B**). Esto hace que el entrenamiento sea **más rápido** y requiera **menos memoria** porque se necesitan actualizar menos parámetros.

1. Esto se debe a que, en lugar de calcular la actualización completa de pesos de una capa (matriz), la aproxima a un producto de 2 matrices más pequeñas, reduciendo la actualización a calcular:\

<figure><img src="../../images/image (9) (1).png" alt=""><figcaption></figcaption></figure>

2. **Mantiene los Pesos del Modelo Original Sin Cambios**: LoRA te permite mantener los pesos del modelo original iguales y solo actualizar las **nuevas matrices pequeñas** (A y B). Esto es útil porque significa que el conocimiento original del modelo se preserva y solo ajustas lo que es necesario.
3. **Ajuste Fino Específico de Tareas Eficiente**: Cuando deseas adaptar el modelo a una **nueva tarea**, puedes entrenar solo las **pequeñas matrices LoRA** (A y B) mientras dejas el resto del modelo tal como está. Esto es **mucho más eficiente** que volver a entrenar todo el modelo.
4. **Eficiencia de Almacenamiento**: Después del ajuste fino, en lugar de guardar un **modelo completamente nuevo** para cada tarea, solo necesitas almacenar las **matrices LoRA**, que son muy pequeñas en comparación con el modelo completo. Esto facilita la adaptación del modelo a muchas tareas sin usar demasiado almacenamiento.

Para implementar LoraLayers en lugar de capas Lineales durante un ajuste fino, se propone este código aquí [https://github.com/rasbt/LLMs-from-scratch/blob/main/appendix-E/01_main-chapter-code/appendix-E.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/appendix-E/01_main-chapter-code/appendix-E.ipynb):
```python
import math

# Create the LoRA layer with the 2 matrices and the alpha
class LoRALayer(torch.nn.Module):
def __init__(self, in_dim, out_dim, rank, alpha):
super().__init__()
self.A = torch.nn.Parameter(torch.empty(in_dim, rank))
torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization
self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))
self.alpha = alpha

def forward(self, x):
x = self.alpha * (x @ self.A @ self.B)
return x

# Combine it with the linear layer
class LinearWithLoRA(torch.nn.Module):
def __init__(self, linear, rank, alpha):
super().__init__()
self.linear = linear
self.lora = LoRALayer(
linear.in_features, linear.out_features, rank, alpha
)

def forward(self, x):
return self.linear(x) + self.lora(x)

# Replace linear layers with LoRA ones
def replace_linear_with_lora(model, rank, alpha):
for name, module in model.named_children():
if isinstance(module, torch.nn.Linear):
# Replace the Linear layer with LinearWithLoRA
setattr(model, name, LinearWithLoRA(module, rank, alpha))
else:
# Recursively apply the same function to child modules
replace_linear_with_lora(module, rank, alpha)
```
## Referencias

- [https://www.manning.com/books/build-a-large-language-model-from-scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)
