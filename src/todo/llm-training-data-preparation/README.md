# LLMトレーニング - データ準備

**これは非常に推奨される本** [**https://www.manning.com/books/build-a-large-language-model-from-scratch**](https://www.manning.com/books/build-a-large-language-model-from-scratch) **からの私のメモで、いくつかの追加情報が含まれています。**

## 基本情報

まず、知っておくべき基本概念についてこの投稿を読むべきです：

{{#ref}}
0.-basic-llm-concepts.md
{{#endref}}

## 1. トークン化

> [!TIP]
> この初期段階の目標は非常にシンプルです：**入力を意味のある方法でトークン（ID）に分割すること**。

{{#ref}}
1.-tokenizing.md
{{#endref}}

## 2. データサンプリング

> [!TIP]
> この第二段階の目標は非常にシンプルです：**入力データをサンプリングし、通常は特定の長さの文にデータセットを分け、期待される応答も生成することでトレーニング段階の準備をすること**。

{{#ref}}
2.-data-sampling.md
{{#endref}}

## 3. トークン埋め込み

> [!TIP]
> この第三段階の目標は非常にシンプルです：**語彙内の各トークンに対して、モデルをトレーニングするために必要な次元のベクトルを割り当てること**。語彙内の各単語はX次元の空間内の点になります。\
> 最初は、空間内の各単語の位置は「ランダムに」初期化され、これらの位置はトレーニング中に改善されるトレーニング可能なパラメータです。
>
> さらに、トークン埋め込みの間に**別の埋め込み層が作成され**、これは（この場合）**トレーニング文における単語の絶対位置を表します**。このように、文中の異なる位置にある単語は異なる表現（意味）を持ちます。

{{#ref}}
3.-token-embeddings.md
{{#endref}}

## 4. アテンションメカニズム

> [!TIP]
> この第四段階の目標は非常にシンプルです：**いくつかのアテンションメカニズムを適用すること**。これらは、**語彙内の単語と現在トレーニングに使用されている文中の隣接単語との関係を捉えるための多くの**繰り返し層**になります。\
> これには多くの層が使用されるため、多くのトレーニング可能なパラメータがこの情報を捉えることになります。

{{#ref}}
4.-attention-mechanisms.md
{{#endref}}

## 5. LLMアーキテクチャ

> [!TIP]
> この第五段階の目標は非常にシンプルです：**完全なLLMのアーキテクチャを開発すること**。すべてをまとめ、すべての層を適用し、テキストを生成したり、テキストをIDに変換したり逆に変換するためのすべての関数を作成します。
>
> このアーキテクチャは、トレーニング後のテキストのトレーニングと予測の両方に使用されます。

{{#ref}}
5.-llm-architecture.md
{{#endref}}

## 6. プレトレーニングとモデルの読み込み

> [!TIP]
> この第六段階の目標は非常にシンプルです：**モデルをゼロからトレーニングすること**。これには、定義された損失関数とオプティマイザを使用して、モデルのすべてのパラメータをトレーニングするために、前のLLMアーキテクチャが使用されます。

{{#ref}}
6.-pre-training-and-loading-models.md
{{#endref}}

## 7.0. LoRAによるファインチューニングの改善

> [!TIP]
> **LoRAの使用は、すでにトレーニングされたモデルをファインチューニングするために必要な計算を大幅に削減します**。

{{#ref}}
7.0.-lora-improvements-in-fine-tuning.md
{{#endref}}

## 7.1. 分類のためのファインチューニング

> [!TIP]
> このセクションの目標は、すでにプレトレーニングされたモデルをファインチューニングする方法を示すことです。新しいテキストを生成するのではなく、LLMが**与えられたテキストが各カテゴリに分類される確率を選択すること**（例えば、テキストがスパムかどうか）です。

{{#ref}}
7.1.-fine-tuning-for-classification.md
{{#endref}}

## 7.2. 指示に従うためのファインチューニング

> [!TIP]
> このセクションの目標は、**テキストを生成するのではなく、指示に従うためにすでにプレトレーニングされたモデルをファインチューニングする方法を示すこと**です。例えば、チャットボットとしてタスクに応答することです。

{{#ref}}
7.2.-fine-tuning-to-follow-instructions.md
{{#endref}}
