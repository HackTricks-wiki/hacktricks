# 7.2. 指示に従うためのファインチューニング

> [!TIP]
> このセクションの目的は、**テキストを生成するだけでなく、チャットボットとしてタスクに応答するなどの指示に従うように、すでに事前トレーニングされたモデルをファインチューニングする方法を示すことです。**

## データセット

指示に従うようにLLMをファインチューニングするには、指示と応答を含むデータセットが必要です。指示に従うようにLLMをトレーニングするためのさまざまな形式があります。例えば：

- Apply Alpacaプロンプトスタイルの例：
```csharp
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Calculate the area of a circle with a radius of 5 units.

### Response:
The area of a circle is calculated using the formula \( A = \pi r^2 \). Plugging in the radius of 5 units:

\( A = \pi (5)^2 = \pi \times 25 = 25\pi \) square units.
```
- Phi-3 プロンプトスタイルの例:
```vbnet
<|User|>
Can you explain what gravity is in simple terms?

<|Assistant|>
Absolutely! Gravity is a force that pulls objects toward each other.
```
トレーニングデータセットを生のテキストではなく、このようなデータセットでLLMをトレーニングすることで、LLMは受け取る質問に対して具体的な回答を提供する必要があることを理解するのに役立ちます。

したがって、リクエストと回答を含むデータセットで最初に行うべきことの1つは、そのデータを希望するプロンプト形式でモデル化することです。
```python
# Code from https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb
def format_input(entry):
instruction_text = (
f"Below is an instruction that describes a task. "
f"Write a response that appropriately completes the request."
f"\n\n### Instruction:\n{entry['instruction']}"
)

input_text = f"\n\n### Input:\n{entry['input']}" if entry["input"] else ""

return instruction_text + input_text

model_input = format_input(data[50])

desired_response = f"\n\n### Response:\n{data[50]['output']}"

print(model_input + desired_response)
```
そのため、常にデータセットをトレーニング、検証、テスト用のセットに分ける必要があります。

## バッチ処理とデータローダー

次に、トレーニング用のすべての入力と期待される出力をバッチ処理する必要があります。これには以下が必要です：

- テキストをトークン化する
- すべてのサンプルを同じ長さにパディングする（通常、長さはLLMの事前トレーニングに使用されたコンテキストの長さと同じくらい大きくなります）
- カスタムコレート関数で入力を1つシフトして期待されるトークンを作成する
- トレーニング損失から除外するために、いくつかのパディングトークンを-100に置き換える：最初の`endoftext`トークンの後、他のすべての`endoftext`トークンを-100に置き換えます（`cross_entropy(...,ignore_index=-100)`を使用することで、-100のターゲットを無視します）
- \[オプション\] LLMが回答を生成する方法のみを学習するように、質問に属するすべてのトークンも-100でマスクします。Apply Alpacaスタイルでは、`### Response:`までのすべてをマスクすることを意味します。

これが作成されたら、各データセット（トレーニング、検証、テスト）のデータローダーを作成する時です。

## 事前トレーニングされたLLMのロードとファインチューニングおよび損失チェック

ファインチューニングするために、事前トレーニングされたLLMをロードする必要があります。これは他のページで既に議論されています。その後、以前に使用したトレーニング関数を使用してLLMをファインチューニングできます。

トレーニング中は、エポック中にトレーニング損失と検証損失がどのように変化するかを確認して、損失が減少しているか、過学習が発生しているかを確認することも可能です。\
過学習は、トレーニング損失が減少しているが、検証損失が減少していないか、さらには増加している場合に発生します。これを避けるために、最も簡単な方法は、この挙動が始まるエポックでトレーニングを停止することです。

## 応答の質

これは分類ファインチューニングではないため、損失の変動をより信頼できるわけではありませんが、テストセットの応答の質を確認することも重要です。したがって、生成された応答をすべてのテストセットから集めて、**その質を手動で確認する**ことをお勧めします。間違った回答があるかどうかを確認します（LLMが応答文の形式と構文を正しく作成することは可能ですが、完全に間違った応答を返すことがあります。損失の変動はこの挙動を反映しません）。\
生成された応答と期待される応答を**他のLLMに渡して応答を評価させる**ことでも、このレビューを行うことが可能です。

応答の質を確認するために実行する他のテスト：

1. **大規模マルチタスク言語理解 (**[**MMLU**](https://arxiv.org/abs/2009.03300)**):** MMLUは、ヒューマニティーズ、サイエンスなど57の科目にわたるモデルの知識と問題解決能力を評価します。さまざまな難易度の選択肢問題を使用して理解を評価します。
2. [**LMSYS Chatbot Arena**](https://arena.lmsys.org): このプラットフォームでは、異なるチャットボットの応答を並べて比較できます。ユーザーがプロンプトを入力すると、複数のチャットボットが応答を生成し、直接比較できます。
3. [**AlpacaEval**](https://github.com/tatsu-lab/alpaca_eval)**:** AlpacaEvalは、自動評価フレームワークで、GPT-4のような高度なLLMが他のモデルの応答をさまざまなプロンプトに対して評価します。
4. **一般的な言語理解評価 (**[**GLUE**](https://gluebenchmark.com/)**):** GLUEは、感情分析、テキストの含意、質問応答など、9つの自然言語理解タスクのコレクションです。
5. [**SuperGLUE**](https://super.gluebenchmark.com/)**:** GLUEを基にして、SuperGLUEは現在のモデルにとって難しいとされるより挑戦的なタスクを含んでいます。
6. **模倣ゲームベンチマークを超えて (**[**BIG-bench**](https://github.com/google/BIG-bench)**):** BIG-benchは、推論、翻訳、質問応答などの分野でモデルの能力をテストする200以上のタスクを持つ大規模なベンチマークです。
7. **言語モデルの包括的評価 (**[**HELM**](https://crfm.stanford.edu/helm/lite/latest/)**):** HELMは、精度、堅牢性、公平性など、さまざまな指標にわたる包括的な評価を提供します。
8. [**OpenAI Evals**](https://github.com/openai/evals)**:** OpenAIによるオープンソースの評価フレームワークで、カスタムおよび標準化されたタスクでAIモデルをテストできます。
9. [**HumanEval**](https://github.com/openai/human-eval)**:** プログラミング問題のコレクションで、言語モデルのコード生成能力を評価するために使用されます。
10. **スタンフォード質問応答データセット (**[**SQuAD**](https://rajpurkar.github.io/SQuAD-explorer/)**):** SQuADは、Wikipediaの記事に関する質問で構成されており、モデルは正確に回答するためにテキストを理解する必要があります。
11. [**TriviaQA**](https://nlp.cs.washington.edu/triviaqa/)**:** トリビアの質問と回答の大規模データセットで、証拠文書も含まれています。

その他多数

## 指示に従ったファインチューニングコード

このファインチューニングを実行するためのコードの例は、[https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py)で見つけることができます。

## 参考文献

- [https://www.manning.com/books/build-a-large-language-model-from-scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)
