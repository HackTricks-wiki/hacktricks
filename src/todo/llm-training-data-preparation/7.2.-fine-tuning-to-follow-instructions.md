# 7.2. 指示に従うためのファインチューニング

> [!TIP]
> このセクションの目的は、**テキストを生成するだけでなく、チャットボットとしてタスクに応答するなどの指示に従うように、すでに事前トレーニングされたモデルをファインチューニングする方法を示すことです。**

## データセット

指示に従うようにLLMをファインチューニングするためには、指示と応答を含むデータセットが必要です。指示に従うようにLLMをトレーニングするためのさまざまなフォーマットがあります。例えば：

- Apply Alpacaプロンプトスタイルの例：
```csharp
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Calculate the area of a circle with a radius of 5 units.

### Response:
The area of a circle is calculated using the formula \( A = \pi r^2 \). Plugging in the radius of 5 units:

\( A = \pi (5)^2 = \pi \times 25 = 25\pi \) square units.
```
- Phi-3 プロンプトスタイルの例:
```vbnet
<|User|>
Can you explain what gravity is in simple terms?

<|Assistant|>
Absolutely! Gravity is a force that pulls objects toward each other.
```
トレーニングデータセットを生のテキストではなく、このようなデータセットでLLMをトレーニングすることで、LLMは受け取る質問に対して具体的な回答を提供する必要があることを理解するのに役立ちます。

したがって、リクエストと回答を含むデータセットで最初に行うべきことの1つは、そのデータを希望するプロンプト形式にモデル化することです。
```python
# Code from https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb
def format_input(entry):
instruction_text = (
f"Below is an instruction that describes a task. "
f"Write a response that appropriately completes the request."
f"\n\n### Instruction:\n{entry['instruction']}"
)

input_text = f"\n\n### Input:\n{entry['input']}" if entry["input"] else ""

return instruction_text + input_text

model_input = format_input(data[50])

desired_response = f"\n\n### Response:\n{data[50]['output']}"

print(model_input + desired_response)
```
データセットをトレーニング、バリデーション、テスト用のセットに分ける必要があります。

## バッチ処理とデータローダー

次に、トレーニングのためにすべての入力と期待される出力をバッチ処理する必要があります。これには以下が必要です：

- テキストをトークン化する
- すべてのサンプルを同じ長さにパディングする（通常、長さはLLMの事前トレーニングに使用されたコンテキストの長さと同じくらいになります）
- カスタムコレート関数で入力を1つシフトして期待されるトークンを作成する
- トレーニングロスから除外するために、いくつかのパディングトークンを-100に置き換える：最初の`endoftext`トークンの後、他のすべての`endoftext`トークンを-100に置き換えます（`cross_entropy(...,ignore_index=-100)`を使用することで、-100のターゲットを無視します）
- \[オプション\] LLMが回答を生成する方法のみを学習するように、質問に属するすべてのトークンも-100でマスクします。Apply Alpacaスタイルでは、`### Response:`までのすべてをマスクすることを意味します。

これが作成されたら、各データセット（トレーニング、バリデーション、テスト）のデータローダーを作成する時間です。

## 事前トレーニングされたLLMのロードとファインチューニングおよびロスチェック

ファインチューニングするために事前トレーニングされたLLMをロードする必要があります。これは他のページで既に議論されています。その後、以前に使用したトレーニング関数を使用してLLMをファインチューニングできます。

トレーニング中は、エポックごとにトレーニングロスとバリデーションロスがどのように変化するかを確認して、ロスが減少しているか、オーバーフィッティングが発生しているかを確認できます。\
オーバーフィッティングは、トレーニングロスが減少しているが、バリデーションロスが減少していないか、むしろ増加している場合に発生します。これを避けるために、最も簡単な方法は、この挙動が始まるエポックでトレーニングを停止することです。

## 応答の質

これは分類ファインチューニングではないため、ロスの変動をより信頼できるわけではありませんが、テストセットの応答の質を確認することも重要です。したがって、すべてのテストセットから生成された応答を集めて、**その質を手動で確認する**ことをお勧めします。間違った回答があるかどうかを確認します（LLMが応答文の形式と構文を正しく作成することは可能ですが、完全に間違った応答を返すことがあります。ロスの変動はこの挙動を反映しません）。\
生成された応答と期待される応答を**他のLLMに渡して応答を評価させる**ことでも、このレビューを行うことが可能です。

応答の質を検証するために実行する他のテスト：

1. **大規模マルチタスク言語理解 (**[**MMLU**](https://arxiv.org/abs/2009.03300)**):** MMLUは、57の科目（人文学、科学など）にわたるモデルの知識と問題解決能力を評価します。さまざまな難易度レベル（初級から上級専門職まで）の理解を評価するために選択肢形式の質問を使用します。
2. [**LMSYSチャットボットアリーナ**](https://arena.lmsys.org): このプラットフォームでは、異なるチャットボットの応答を並べて比較できます。ユーザーがプロンプトを入力すると、複数のチャットボットが応答を生成し、直接比較できます。
3. [**AlpacaEval**](https://github.com/tatsu-lab/alpaca_eval)**:** AlpacaEvalは、自動評価フレームワークで、GPT-4のような高度なLLMがさまざまなプロンプトに対する他のモデルの応答を評価します。
4. **一般的な言語理解評価 (**[**GLUE**](https://gluebenchmark.com/)**):** GLUEは、感情分析、テキストの含意、質問応答など、9つの自然言語理解タスクのコレクションです。
5. [**SuperGLUE**](https://super.gluebenchmark.com/)**:** GLUEを基にして、SuperGLUEは現在のモデルにとって難しいとされるより挑戦的なタスクを含んでいます。
6. **模倣ゲームベンチマークを超えて (**[**BIG-bench**](https://github.com/google/BIG-bench)**):** BIG-benchは、推論、翻訳、質問応答などの分野でモデルの能力をテストする200以上のタスクを持つ大規模なベンチマークです。
7. **言語モデルの包括的評価 (**[**HELM**](https://crfm.stanford.edu/helm/lite/latest/)**):** HELMは、精度、堅牢性、公平性など、さまざまな指標にわたる包括的な評価を提供します。
8. [**OpenAI Evals**](https://github.com/openai/evals)**:** OpenAIによるオープンソースの評価フレームワークで、カスタムおよび標準化されたタスクでAIモデルをテストできます。
9. [**HumanEval**](https://github.com/openai/human-eval)**:** 言語モデルのコード生成能力を評価するために使用されるプログラミング問題のコレクションです。
10. **スタンフォード質問応答データセット (**[**SQuAD**](https://rajpurkar.github.io/SQuAD-explorer/)**):** SQuADは、Wikipediaの記事に関する質問で構成されており、モデルは正確に回答するためにテキストを理解する必要があります。
11. [**TriviaQA**](https://nlp.cs.washington.edu/triviaqa/)**:** トリビアの質問と回答の大規模データセットで、証拠文書も含まれています。

その他多数

## 指示に従ったファインチューニングコード

このファインチューニングを実行するためのコードの例は、[https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py)で見つけることができます。

## 参考文献

- [https://www.manning.com/books/build-a-large-language-model-from-scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)
