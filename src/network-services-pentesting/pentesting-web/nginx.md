# Nginx

{{#include ../../banners/hacktricks-training.md}}


## Ubicación root faltante <a href="#missing-root-location" id="missing-root-location"></a>

Al configurar el servidor Nginx, la **directiva root** desempeña un papel crítico al definir el directorio base desde el cual se sirven los archivos. Considere el siguiente ejemplo:
```bash
server {
root /etc/nginx;

location /hello.txt {
try_files $uri $uri/ =404;
proxy_pass http://127.0.0.1:8080/;
}
}
```
En esta configuración, `/etc/nginx` está designado como el directorio root. Esta configuración permite el acceso a archivos dentro del directorio root especificado, como `/hello.txt`. Sin embargo, es crucial notar que solo se define una ubicación específica (`/hello.txt`). No existe configuración para la ubicación raíz (`location / {...}`). Esta omisión significa que la directiva root se aplica globalmente, permitiendo que las solicitudes a la ruta raíz `/` accedan a archivos bajo `/etc/nginx`.

Surge una consideración crítica de seguridad a partir de esta configuración. Una simple petición `GET`, como `GET /nginx.conf`, podría exponer información sensible al servir el archivo de configuración de Nginx ubicado en `/etc/nginx/nginx.conf`. Establecer el root a un directorio menos sensible, como `/etc`, podría mitigar este riesgo, pero aún así puede permitir el acceso no intencionado a otros archivos críticos, incluidos otros archivos de configuración, access logs y hasta credenciales cifradas usadas para HTTP basic authentication.

## Misconfiguración de Alias LFI <a href="#alias-lfi-misconfiguration" id="alias-lfi-misconfiguration"></a>

En los archivos de configuración de Nginx, conviene inspeccionar detenidamente las directivas "location". Una vulnerabilidad conocida como Local File Inclusion (LFI) puede introducirse inadvertidamente mediante una configuración que se parezca a la siguiente:
```
location /imgs {
alias /path/images/;
}
```
Esta configuración es vulnerable a ataques LFI debido a que el servidor interpreta solicitudes como `/imgs../flag.txt` como un intento de acceder a archivos fuera del directorio previsto, resolviendo efectivamente a `/path/images/../flag.txt`. Esta falla permite a los atacantes recuperar archivos del sistema de archivos del servidor que no deberían ser accesibles a través de la web.

Para mitigar esta vulnerabilidad, la configuración debe ajustarse a:
```
location /imgs/ {
alias /path/images/;
}
```
Más información: [https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/](https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/)

Pruebas de Accunetix:
```
alias../ => HTTP status code 403
alias.../ => HTTP status code 404
alias../../ => HTTP status code 403
alias../../../../../../../../../../../ => HTTP status code 400
alias../ => HTTP status code 403
```
## Restricción insegura de rutas <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

Consulta la siguiente página para aprender cómo hacer bypass a directivas como:
```plaintext
location = /admin {
deny all;
}

location = /admin/ {
deny all;
}
```
{{#ref}}
../../pentesting-web/proxy-waf-protections-bypass.md
{{#endref}}

## Uso inseguro de variables / HTTP Request Splitting <a href="#unsafe-variable-use" id="unsafe-variable-use"></a>

> [!CAUTION]
> Variables vulnerables `$uri` y `$document_ur`i; esto puede arreglarse reemplazándolas por `$request_uri`.
>
> A regex can also be vulnerable like:
>
> `location ~ /docs/([^/])? { … $1 … }` - Vulnerable
>
> `location ~ /docs/([^/\s])? { … $1 … }` - Not vulnerable (checking spaces)
>
> `location ~ /docs/(.*)? { … $1 … }` - Not vulnerable

Una vulnerabilidad en la configuración de Nginx se demuestra en el ejemplo siguiente:
```
location / {
return 302 https://example.com$uri;
}
```
Los caracteres \r (Carriage Return) y \n (Line Feed) indican caracteres de nueva línea en las peticiones HTTP, y sus formas codificadas en URL se representan como `%0d%0a`. Incluir estos caracteres en una petición (por ejemplo, `http://localhost/%0d%0aDetectify:%20clrf`) a un servidor mal configurado provoca que el servidor emita una nueva cabecera llamada `Detectify`. Esto ocurre porque la variable $uri decodifica los caracteres de nueva línea codificados en la URL, dando lugar a una cabecera inesperada en la respuesta:
```
HTTP/1.1 302 Moved Temporarily
Server: nginx/1.19.3
Content-Type: text/html
Content-Length: 145
Connection: keep-alive
Location: https://example.com/
Detectify: clrf
```
Aprende más sobre los riesgos de CRLF injection y response splitting en [https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/](https://blog.detectify.com/2019/06/14/http-response-splitting-exploitations-and-mitigations/).

Además, esta técnica está [**explicada en esta charla**](https://www.youtube.com/watch?v=gWQyWdZbdoY&list=PL0xCSYnG_iTtJe2V6PQqamBF73n7-f1Nr&index=77) con algunos ejemplos vulnerables y mecanismos de detección. Por ejemplo, para detectar esta misconfiguración desde una perspectiva blackbox podrías usar estas peticiones:

- `https://example.com/%20X` - Any HTTP code
- `https://example.com/%20H` - 400 Bad Request

Si es vulnerable, la primera devolverá algo válido ya que "X" puede ser cualquier método HTTP y la segunda devolverá un error porque H no es un método válido. Así el servidor recibirá algo como: `GET / H HTTP/1.1` y eso disparará el error.

Otros ejemplos de detección serían:

- `http://company.tld/%20HTTP/1.1%0D%0AXXXX:%20x` - Any HTTP code
- `http://company.tld/%20HTTP/1.1%0D%0AHost:%20x` - 400 Bad Request

Algunas configuraciones vulnerables encontradas y presentadas en esa charla fueron:

- Note how **`$uri`** is set as is in the final URL
```
location ^~ /lite/api/ {
proxy_pass http://lite-backend$uri$is_args$args;
}
```
- Observa cómo de nuevo **`$uri`** está en la URL (esta vez dentro de un parámetro)
```
location ~ ^/dna/payment {
rewrite ^/dna/([^/]+) /registered/main.pl?cmd=unifiedPayment&context=$1&native_uri=$uri break;
proxy_pass http://$back;
```
- Ahora en AWS S3
```
location /s3/ {
proxy_pass https://company-bucket.s3.amazonaws.com$uri;
}
```
### Cualquier variable

Se descubrió que los **datos proporcionados por el usuario** podrían tratarse como una **variable de Nginx** bajo ciertas circunstancias. La causa de este comportamiento sigue siendo algo difícil de dilucidar, aunque no es rara ni sencilla de verificar. Esta anomalía fue destacada en un informe de seguridad en HackerOne, que puede verse [aquí](https://hackerone.com/reports/370094). Una investigación adicional del mensaje de error condujo a identificar su aparición dentro del [módulo de filtro SSI del código de Nginx](https://github.com/nginx/nginx/blob/2187586207e1465d289ae64cedc829719a048a39/src/http/modules/ngx_http_ssi_filter_module.c#L365), señalando a Server Side Includes (SSI) como la causa raíz.

Para **detectar esta mala configuración**, puede ejecutarse el siguiente comando, que consiste en establecer una cabecera Referer para probar la impresión de variables:
```bash
$ curl -H ‘Referer: bar’ http://localhost/foo$http_referer | grep ‘foobar’
```
Los escaneos en busca de esta mala configuración en varios sistemas revelaron múltiples instancias donde variables de Nginx podían mostrarse a un usuario. Sin embargo, una disminución en el número de instancias vulnerables sugiere que los esfuerzos para parchear este problema han sido en cierta medida exitosos.

### Uso de try_files con variables $URI$ARGS

La siguiente mala configuración de Nginx puede conducir a una vulnerabilidad LFI:
```
location / {
try_files $uri$args $uri$args/ /index.html;
}
```
En nuestra configuración tenemos la directiva `try_files` que se usa para comprobar la existencia de archivos en un orden especificado. Nginx servirá el primero que encuentre. La sintaxis básica de la directiva `try_files` es la siguiente:
```
try_files file1 file2 ... fileN fallback;
```
Nginx comprobará la existencia de cada archivo en el orden especificado. Si un archivo existe, se servirá inmediatamente. Si ninguno de los archivos especificados existe, la solicitud se pasará a la opción de fallback, que puede ser otro URI o una página de error específica.

Sin embargo, al usar las variables `$uri$args` en esta directiva, Nginx intentará buscar un archivo que coincida con la URI de la solicitud combinada con cualquier argumento de la query string. Por lo tanto, podemos explotar esta configuración:
```
http {
server {
root /var/www/html/public;

location / {
try_files $uri$args $uri$args/ /index.html;
}
}
}
```
Con el siguiente payload:
```
GET /?../../../../../../../../etc/passwd HTTP/1.1
Host: example.com
```
Usando nuestro payload escaparemos del directorio raíz (definido en la configuración de Nginx) y cargaremos el archivo `/etc/passwd`. En los logs de depuración podemos observar cómo Nginx prueba los archivos:
```
...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 trying to use file: "/../../../../../../../../etc/passwd" "/var/www/html/public/../../../../../../../../etc/passwd"
2025/07/11 15:49:16 [debug] 79694#79694: *4 try file uri: "/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 http filename: "/var/www/html/public/../../../../../../../../etc/passwd"

...SNIP...

2025/07/11 15:49:16 [debug] 79694#79694: *4 HTTP/1.1 200 OK

```
PoC contra Nginx usando la configuración mencionada arriba:
![Ejemplo de petición de Burp](../../images/nginx_try_files.png)

## Lectura de la respuesta cruda del backend

Nginx ofrece una función mediante `proxy_pass` que permite interceptar errores y cabeceras HTTP generadas por el backend, con el objetivo de ocultar mensajes de error internos y cabeceras. Esto se logra haciendo que Nginx sirva páginas de error personalizadas en respuesta a errores del backend. Sin embargo, surgen problemas cuando Nginx encuentra una petición HTTP inválida. Dicha petición se reenvía al backend tal cual, y la respuesta cruda del backend se envía directamente al cliente sin la intervención de Nginx.

Considere un escenario de ejemplo que involucra una aplicación uWSGI:
```python
def application(environ, start_response):
start_response('500 Error', [('Content-Type', 'text/html'), ('Secret-Header', 'secret-info')])
return [b"Secret info, should not be visible!"]
```
Para gestionar esto, se usan directivas específicas en la configuración de Nginx:
```
http {
error_page 500 /html/error.html;
proxy_intercept_errors on;
proxy_hide_header Secret-Header;
}
```
- [**proxy_intercept_errors**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_intercept_errors): Esta directiva permite a Nginx servir una respuesta personalizada para respuestas del backend con un código de estado mayor que 300. Asegura que, para nuestra aplicación uWSGI de ejemplo, una respuesta `500 Error` sea interceptada y manejada por Nginx.
- [**proxy_hide_header**](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_hide_header): Como su nombre indica, esta directiva oculta cabeceras HTTP especificadas del cliente, mejorando la privacidad y la seguridad.

Cuando se realiza una solicitud `GET` válida, Nginx la procesa normalmente, devolviendo una respuesta de error estándar sin revelar ninguna cabecera secreta. Sin embargo, una solicitud HTTP inválida elude este mecanismo, lo que da como resultado la exposición de respuestas sin procesar del backend, incluidas cabeceras secretas y mensajes de error.

## merge_slashes configurado en off

Por defecto, la **directiva `merge_slashes`** de Nginx está establecida en **`on`**, lo que comprime múltiples barras (/) en una URL en una sola barra. Esta característica, aunque agiliza el procesamiento de URL, puede ocultar inadvertidamente vulnerabilidades en aplicaciones detrás de Nginx, particularmente aquellas propensas a local file inclusion (LFI) attacks. Los expertos en seguridad **Danny Robinson y Rotem Bar** han destacado los riesgos potenciales asociados con este comportamiento por defecto, especialmente cuando Nginx actúa como reverse-proxy.

Para mitigar dichos riesgos, se recomienda **desactivar la directiva `merge_slashes`** para aplicaciones susceptibles a estas vulnerabilidades. Esto asegura que Nginx reenvíe las solicitudes a la aplicación sin alterar la estructura de la URL, evitando enmascarar problemas de seguridad subyacentes.

For more information check [Danny Robinson and Rotem Bar](https://medium.com/appsflyer/nginx-may-be-protecting-your-applications-from-traversal-attacks-without-you-even-knowing-b08f882fd43d).

### **Maclicious Response Headers**

As shown in [**this writeup**](https://mizu.re/post/cors-playground), there are certain headers that if present in the response from the web server they will change the behaviour of the Nginx proxy. You can check them [**in the docs**](https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/):

- `X-Accel-Redirect`: Indica a Nginx redirigir internamente una solicitud a una ubicación especificada.
- `X-Accel-Buffering`: Controla si Nginx debe o no almacenar en búfer la respuesta.
- `X-Accel-Charset`: Establece el conjunto de caracteres para la respuesta cuando se usa X-Accel-Redirect.
- `X-Accel-Expires`: Establece el tiempo de expiración para la respuesta cuando se usa X-Accel-Redirect.
- `X-Accel-Limit-Rate`: Limita la tasa de transferencia de las respuestas cuando se usa X-Accel-Redirect.

Por ejemplo, el encabezado **`X-Accel-Redirect`** provocará una **redirect** interna en nginx. Así, tener una configuración de nginx con algo como **`root /`** y una respuesta del servidor web con **`X-Accel-Redirect: .env`** hará que nginx envíe el contenido de **`/.env`** (Path Traversal).

### **Valor por defecto en la directiva map**

En la **configuración de Nginx**, la directiva `map` a menudo juega un papel en el **control de autorización**. Un error común es no especificar un valor **default**, lo que podría conducir a acceso no autorizado. Por ejemplo:
```yaml
http {
map $uri $mappocallow {
/map-poc/private 0;
/map-poc/secret 0;
/map-poc/public 1;
}
}
```

```yaml
server {
location /map-poc {
if ($mappocallow = 0) {return 403;}
return 200 "Hello. It is private area: $mappocallow";
}
}
```
Sin un `default`, un **usuario malintencionado** puede eludir la seguridad accediendo a un **URI no definido** dentro de `/map-poc`. [The Nginx manual](https://nginx.org/en/docs/http/ngx_http_map_module.html) aconseja establecer un **valor por defecto** para evitar estos problemas.

### **DNS Spoofing Vulnerability**

El DNS spoofing contra Nginx es factible bajo ciertas condiciones. Si un atacante conoce el **DNS server** usado por Nginx y puede interceptar sus consultas DNS, puede falsificar registros DNS. Sin embargo, este método es ineficaz si Nginx está configurado para usar **localhost (127.0.0.1)** para la resolución DNS. Nginx permite especificar un DNS server de la siguiente manera:
```yaml
resolver 8.8.8.8;
```
### **`proxy_pass` y `internal` Directivas**

La directiva **`proxy_pass`** se utiliza para redirigir solicitudes a otros servidores, ya sea de forma interna o externa. La directiva **`internal`** asegura que ciertas ubicaciones solo sean accesibles desde Nginx. Aunque estas directivas no son vulnerabilidades por sí mismas, su configuración requiere un examen cuidadoso para prevenir fallos de seguridad.

## proxy_set_header Upgrade & Connection

Si el servidor nginx está configurado para reenviar los encabezados Upgrade y Connection, se podría realizar un [**h2c Smuggling attack**](../../pentesting-web/h2c-smuggling.md) para acceder a endpoints protegidos/internos.

> [!CAUTION]
> Esta vulnerabilidad permitiría a un atacante **establecer una conexión directa con el endpoint `proxy_pass`** (`http://backend:9999` en este caso) cuyo contenido no será verificado por nginx.

Example of vulnerable configuration to steal `/flag` from [here](https://bishopfox.com/blog/h2c-smuggling-request):
```
server {
listen       443 ssl;
server_name  localhost;

ssl_certificate       /usr/local/nginx/conf/cert.pem;
ssl_certificate_key   /usr/local/nginx/conf/privkey.pem;

location / {
proxy_pass http://backend:9999;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection $http_connection;
}

location /flag {
deny all;
}
```
> [!WARNING]
> Ten en cuenta que incluso si `proxy_pass` apuntaba a un **path** específico como `http://backend:9999/socket.io`, la conexión se establecerá con `http://backend:9999`, por lo que puedes **contactar cualquier otro path dentro de ese endpoint interno. Así que no importa si se especifica un path en la URL de proxy_pass.**

## HTTP/3 QUIC module remote DoS & leak (2024)

Durante 2024 Nginx divulgó CVE-2024-31079, CVE-2024-32760, CVE-2024-34161 y CVE-2024-35200, mostrando que una **single hostile QUIC session** puede crash worker processes o leak memory siempre que el experimental `ngx_http_v3_module` esté compilado y se exponga un socket `listen ... quic`. Las builds afectadas son 1.25.0–1.25.5 y 1.26.0, mientras que 1.27.0/1.26.1 incluyen los fixes; la memory disclosure (CVE-2024-34161) además requiere MTUs mayores de 4096 bytes para exponer datos sensibles (detalles en el 2024 nginx advisory referenciado abajo).

**Recon & exploitation hints**

- HTTP/3 es opt-in, así que scan for `Alt-Svc: h3=":443"` responses o brute-force UDP/443 QUIC handshakes; once confirmed, fuzz the handshake and STREAM frames con payloads personalizados de `quiche-client`/`nghttp3` para trigger worker crashes y forzar log leakage.
- Quickly fingerprint target support with:
```bash
nginx -V 2>&1 | grep -i http_v3
rg -n "listen .*quic" /etc/nginx/
```
## Bypass de reanudación de sesión TLS de la autenticación con certificado de cliente (CVE-2025-23419)

Un advisory de febrero de 2025 reveló que nginx 1.11.4–1.27.3 compilado con OpenSSL permite **reusar una sesión TLS 1.3** de un virtual host basado en nombre dentro de otro, por lo que un cliente que negoció un host sin certificado puede reproducir el ticket/PSK para entrar en un vhost protegido con `ssl_verify_client on;` y omitir mTLS por completo. El bug se desencadena cuando múltiples virtual hosts comparten la misma caché de sesión y tickets de TLS 1.3 (ver el advisory de nginx de 2025 referenciado más abajo).

**Playbook del atacante**
```bash
# 1. Create a TLS session on the public vhost and save the session ticket
openssl s_client -connect public.example.com:443 -sess_out ticket.pem

# 2. Replay that session ticket against the mTLS vhost before it expires
openssl s_client -connect admin.example.com:443 -sess_in ticket.pem -ign_eof
```
Si el objetivo es vulnerable, el segundo handshake se completa sin presentar un certificado de cliente, revelando ubicaciones protegidas.

**What to audit**

- Bloques `server_name` mixtos que comparten `ssl_session_cache shared:SSL` más `ssl_session_tickets on;`.
- Bloques Admin/API que esperan mTLS pero heredan la configuración compartida de caché/tickets de sesión desde hosts públicos.
- Automatización que habilita la reanudación de sesión TLS 1.3 globalmente (p. ej., roles de Ansible) sin considerar el aislamiento de vhost.

## Resiliencia frente a HTTP/2 Rapid Reset (comportamiento CVE-2023-44487)

The HTTP/2 Rapid Reset attack (CVE-2023-44487) todavía afecta a nginx cuando los operadores suben `keepalive_requests` o `http2_max_concurrent_streams` por encima de los valores por defecto: un atacante abre una conexión HTTP/2, la inunda con miles de streams y luego envía inmediatamente frames `RST_STREAM` de modo que el techo de concurrencia nunca se alcanza mientras la CPU sigue consumiéndose en la lógica de tear-down. Los valores por defecto de nginx (128 concurrent streams, 1000 keepalive requests) mantienen el radio de impacto pequeño; aumentar esos límites "sustancialmente" facilita agotar workers incluso desde un único cliente (ver el write-up de F5 referido más abajo).

**Detection tips**
```bash
# Highlight risky knobs
rg -n "http2_max_concurrent_streams" /etc/nginx/
rg -n "keepalive_requests" /etc/nginx/
```
Los hosts que muestran valores inusualmente altos para esas directivas son objetivos prioritarios: un HTTP/2 client puede iterar la creación de streams y enviar instantáneamente frames `RST_STREAM` para mantener la CPU al máximo sin activar el límite de concurrencia.

## Pruébalo tú mismo

Detectify ha creado un repositorio en GitHub donde puedes usar Docker para desplegar tu propio servidor de prueba de Nginx vulnerable con algunas de las misconfiguraciones discutidas en este artículo y tratar de encontrarlas tú mismo!

[https://github.com/detectify/vulnerable-nginx](https://github.com/detectify/vulnerable-nginx)

## Herramientas de análisis estático

### [GIXY](https://github.com/yandex/gixy)

Gixy es una herramienta para analizar la configuración de Nginx. El objetivo principal de Gixy es prevenir malconfiguraciones de seguridad y automatizar la detección de fallos.

### [Nginxpwner](https://github.com/stark0de/nginxpwner)

Nginxpwner es una herramienta sencilla para buscar misconfiguraciones comunes de Nginx y vulnerabilidades.

## Referencias

- [**https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/**](https://blog.detectify.com/2020/11/10/common-nginx-misconfigurations/)
- [**http://blog.zorinaq.com/nginx-resolver-vulns/**](http://blog.zorinaq.com/nginx-resolver-vulns/)
- [**https://github.com/yandex/gixy/issues/115**](https://github.com/yandex/gixy/issues/115)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html**](https://mailman.nginx.org/pipermail/nginx-announce/2024/GWH2WZDVCOC2A5X67GKIMJM4YRELTR77.html)
- [**https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html**](https://mailman.nginx.org/pipermail/nginx-announce/2025/NYEUJX7NCBCGJGXDFVXNMAAMJDFSE45G.html)
- [**https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products**](https://www.f5.com/company/blog/nginx/http-2-rapid-reset-attack-impacting-f5-nginx-products)


{{#include ../../banners/hacktricks-training.md}}
