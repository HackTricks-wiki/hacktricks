# 80,443 - Pentesting Web Methodology

{{#include ../../banners/hacktricks-training.md}}

## बुनियादी जानकारी

वेब सेवा सबसे **सामान्य और व्यापक सेवा** है और बहुत सारी **विभिन्न प्रकार की कमजोरियाँ** मौजूद हैं।

**Default port:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API मार्गदर्शन


{{#ref}}
web-api-pentesting.md
{{#endref}}

## कार्यप्रणाली सारांश

> इस कार्यप्रणाली में हम मानेंगे कि आप केवल एक domain (या subdomain) पर हमला कर रहे हैं। इसलिए, आपको इस कार्यप्रणाली को प्रत्येक खोजे गए domain, subdomain या scope के भीतर अनिर्धारित web server वाले IP पर लागू करना चाहिए।

- [ ] शुरू में web server द्वारा उपयोग की जा रही **technologies** की **पहचान** करें। यदि आप tech की सही पहचान कर लेते हैं तो टेस्ट के बाकी हिस्सों में ध्यान रखने के लिए **tricks** खोजें।
- [ ] क्या उस तकनीक के किसी version की कोई **known vulnerability** है?
- [ ] कोई **well known tech** उपयोग हो रहा है? अधिक जानकारी निकालने के लिए कोई **useful trick** है?
- [ ] कोई **specialised scanner** चलाने लायक है (जैसे wpscan)?
- [ ] **general purposes scanners** लॉन्च करें। पता नहीं वे कुछ पा लेंगे या कोई दिलचस्प जानकारी मिल जाएगी।
- [ ] **initial checks** से शुरू करें: **robots**, **sitemap**, **404** error और **SSL/TLS scan** (यदि HTTPS)।
- [ ] वेब पेज की **spidering** शुरू करें: अब समय है सभी संभव **files, folders** और **parameters being used** को **find** करने का। साथ ही **special findings** की जाँच करें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory मिलती है, उसे spidered किया जाना चाहिए।_
- [ ] **Directory Brute-Forcing**: खोजे गए सभी folders पर brute force करने की कोशिश करें ताकि नए **files** और **directories** मिल सकें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory मिलती है, उसे Brute-Forced किया जाना चाहिए।_
- [ ] **Backups checking**: सामान्य backup extensions जोड़कर खोजे गए **discovered files** के **backups** मिल रहे हैं या नहीं, टेस्ट करें।
- [ ] **Brute-Force parameters**: छुपे हुए **hidden parameters** को **find** करने की कोशिश करें।
- [ ] एक बार जब आपने सभी संभावित **endpoints** जो **user input** स्वीकार करते हैं **identified** कर लिए, तो उनसे जुड़ी सभी तरह की **vulnerabilities** के लिए जाँच करें।
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

जाँच करें कि चल रहे server के किसी भी **version** के लिए कोई **known vulnerabilities** तो नहीं हैं।\
प्रतिक्रिया के **HTTP headers and cookies** technologies और/या version को **identify** करने में बहुत उपयोगी हो सकते हैं। **Nmap scan** server version की पहचान कर सकता है, लेकिन साथ ही ये tools भी उपयोगी हो सकते हैं [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
खोजें **के लिए** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **चेक करें अगर कोई WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web tech tricks

कुछ ट्रिक्स जो अलग-अलग प्रसिद्ध technologies में vulnerabilities खोजने के लिए उपयोगी हो सकते हैं:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_ध्यान रखें कि वही same domain अलग-अलग technologies को अलग-अलग ports, folders और subdomains पर उपयोग कर सकता है._\
यदि web application किसी well known tech/platform (जो ऊपर सूचीबद्ध है) या किसी अन्य का उपयोग कर रही है, तो Internet पर नए tricks खोजना न भूलें (और मुझे बताएं!).

### Source Code Review

यदि एप्लिकेशन का **source code** github पर उपलब्ध है, तो आपके द्वारा एक **White box test** करने के अलावा कुछ जानकारी है जो वर्तमान **Black-Box testing** के लिए उपयोगी हो सकती है:

- क्या कोई **Change-log or Readme or Version** file या कोई ऐसी चीज़ है जिसमें **version info accessible** वेब के माध्यम से है?
- Credentials कैसे और कहाँ सेव होते हैं? क्या कोई (accessible?) **file** है जिसमें credentials (usernames या passwords) हैं?
- क्या **passwords** **plain text** में हैं, **encrypted** हैं या कौन सा **hashing algorithm** उपयोग हो रहा है?
- क्या कुछ encrypt करने के लिए कोई **master key** उपयोग हो रहा है? कौन सा **algorithm** इस्तेमाल हो रहा है?
- क्या आप किसी vulnerability को exploit करके इन में से किसी भी फ़ाइल तक access कर सकते हैं?
- क्या github के **issues** (solved और not solved) में कोई रोचक जानकारी है? या **commit history** में (शायद कोई पुराना commit जिसमें कोई **password** डाला गया हो)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### General purpose automatic scanners
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS scanners

अगर किसी CMS का उपयोग हो रहा है तो **run a scanner** करना न भूलें, शायद कुछ juicy मिल जाए:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** websites for Security issues. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **or** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> इस बिंदु पर आपके पास क्लाइंट द्वारा उपयोग किए जा रहे वेब सर्वर की कुछ जानकारी (यदि कोई डेटा दिया गया हो) और परीक्षण के दौरान ध्यान में रखने के लिए कुछ तरकीबें होनी चाहिए। अगर आप भाग्यशाली हैं तो आपने किसी CMS को भी ढूंढ लिया होगा और कोई scanner चला लिया होगा।

## चरण-दर-चरण वेब एप्लिकेशन की खोज

> इस बिंदु से हम वेब एप्लिकेशन के साथ इंटरैक्ट करना शुरू करेंगे।

### प्रारम्भिक जाँच

**दिलचस्प जानकारी वाले डिफ़ॉल्ट पेज:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- मुख्य और द्वितीयक पेजों में टिप्पणियाँ भी चेक करें।

**Forcing errors**

जब अजीब डेटा भेजा जाता है तो Web servers अप्रत्याशित रूप से व्यवहार कर सकते हैं। इससे vulnerabilities खुल सकती हैं या संवेदनशील जानकारी का खुलासा हो सकता है।

- /whatever_fake.php (.aspx,.html,.etc) जैसे **fake pages** तक पहुँचें
- **Add "[]", "]]", and "[["** को **cookie values** और **parameter** values में डालकर errors उत्पन्न करें
- **`/~randomthing/%s`** जैसा input देकर URL के **end** पर error जनरेट करें
- PATCH, DEBUG जैसे विभिन्न **HTTP Verbs** आज़माएँ या FAKE जैसे गलत verbs ट्राय करें

#### **जाँचें कि क्या आप फाइलें अपलोड कर सकते हैं (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

यदि आप पाते हैं कि **WebDav** **enabled** है लेकिन root folder में **uploading files** के लिए पर्याप्त permissions नहीं हैं तो कोशिश करें:

- **Brute Force** credentials
- WebDav के माध्यम से web page के अंदर पाए गए बाकी **found folders** में **Upload files** करें। हो सकता है कि आपके पास अन्य फोल्डर्स में files upload करने की permissions हों।

### **SSL/TLS vulnerabilities**

- यदि application किसी भी हिस्से में **HTTPS** के उपयोग को मजबूर नहीं कर रही है, तो यह **vulnerable to MitM** है
- यदि application संवेदनशील डेटा (passwords) को **HTTP** के माध्यम से भेज रही है, तो यह एक high vulnerability है।

Use [**testssl.sh**](https://github.com/drwetter/testssl.sh) to checks for **vulnerabilities** (In Bug Bounty programs probably these kind of vulnerabilities won't be accepted) और पुनः जाँच के लिए [**a2sv**](https://github.com/hahwul/a2sv) का उपयोग करें:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

वेब के अंदर किसी प्रकार का **spider** लॉन्च करें। spider का लक्ष्य टेस्ट किए जा रहे application से जितने संभव हो उतने **paths ढूँढना** है। इसलिए web crawling और बाहरी स्रोतों का उपयोग करके जितने संभव सत्यापित paths मिल सकें उन्हें ढूँढें।

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, JS files में LinkFinder और बाहरी स्रोतों (Archive.org, CommonCrawl.org, VirusTotal.com) का उपयोग।
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, JS files के लिए LinkFinder और Archive.org को external source के रूप में उपयोग करता है।
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, "juicy files" भी बताता है।
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider। यह Archive.org में भी खोज करता है।
- [**meg**](https://github.com/tomnomnom/meg) (go): यह टूल spider नहीं है पर उपयोगी हो सकता है। आप hosts की फ़ाइल और paths की फ़ाइल दे कर meg से हर host पर हर path fetch करवा कर response सेव करवा सकते हैं।
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS rendering क्षमताओं के साथ HTML spider। हालांकि ऐसा लगता है कि यह unmaintained है, precompiled version पुराना है और current code compile नहीं होता।
- [**gau**](https://github.com/lc/gau) (go): HTML spider जो external providers (wayback, otx, commoncrawl) का उपयोग करता है।
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): यह script parameter वाले URLs खोजेगा और उन्हें सूचीबद्ध करेगा।
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS rendering क्षमताओं के साथ HTML spider।
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, JS beautify क्षमताओं के साथ जो JS files में नए paths खोजने में सक्षम है। इसके wrapper [JSScanner](https://github.com/dark-warlord14/JSScanner) को भी देखना फायदेमंद हो सकता है।
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): HTML source और embedded javascript files दोनों से endpoints extract करने के लिए। bug hunters, red teamers, infosec ninjas के लिए उपयोगी।
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Tornado और JSBeautifier का उपयोग करने वाली python 2.7 script जो JavaScript files से relative URLs parse करती है। AJAX requests आसानी से खोजने में मददगार। लगता है unmaintained है।
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): किसी HTML फ़ाइल दिए जाने पर यह nifty regular expression का उपयोग करके relative URLs extract करेगा, खासकर minified files से।
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): कई tools का उपयोग करके JS files से interesting जानकारी इकट्ठा करता है।
- [**subjs**](https://github.com/lc/subjs) (go): JS files खोजने के लिए।
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): headless browser में page load करता है और page load करने के लिए जो URLs लोड हुए उन्हें print करता है।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool जो पहले के कई विकल्पों के फीचर्स मिलाता है।
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS files में path और params खोजने के लिए एक Burp extension।
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): यदि .js.map URL दिया गया हो तो यह beautified JS code प्राप्त करने का टूल।
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): किसी target के लिए endpoints खोजने हेतु टूल।
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** wayback machine से links discover करें (wayback में responses भी download कर के और भी links खोजता है)।
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (यहाँ तक कि forms भर कर भी) और specific regexes का उपयोग कर sensitive info भी खोजता है।
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite एक advance multi-feature GUI web security Crawler/Spider है जिसे साइबर सुरक्षा पेशेवरों के लिए डिजाइन किया गया है।
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): यह Go package और [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) है जो JavaScript source code से URLs, paths, secrets, और अन्य interesting data extract करता है।
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge एक simple **Burp Suite extension** है जो request से **parameters और endpoints extract** कर के fuzzing और enumeration के लिए custom wordlist बनाता है।
- [**katana**](https://github.com/projectdiscovery/katana) (go): इस काम के लिए एक शानदार टूल।
- [**Crawley**](https://github.com/s0rg/crawley) (go): यह हर link जो यह ढूंढ सके उसे print करता है।

### Brute Force directories and files

रूट फोल्डर से **brute-forcing** शुरू करें और सुनिश्चित करें कि आप **this method** और Spidering द्वारा मिले सभी **directories** पर brute-force करें (आप यह recursive रूप से कर सकते हैं और उपयोग की गई wordlist के शुरू में मिले हुए directories के नाम जोड़ सकते हैं)।\
Tools:

- **Dirb** / **Dirbuster** - Kali में included, **old** (और **slow**) पर functional। auto-signed certificates और recursive search की अनुमति देता है। अन्य विकल्पों की तुलना में बहुत slow।
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: यह auto-signed certificates allow नहीं करता पर recursive search allow करता है।
- [**Gobuster**](https://github.com/OJ/gobuster) (go): यह auto-signed certificates allow करता है, यह **recursive** search नहीं करता।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): यह spider नहीं है पर एक tool है जो मिले हुए URLs की list लेकर "duplicated" URLs हटाता है।
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension जो burp history से विभिन्न पृष्ठों के directories की सूची बनाता है।
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): js imports के आधार पर duplicated functionalities वाले URLs हटाता है।
- [**Chamaleon**](https://github.com/iustin24/chameleon): यह wapalyzer का उपयोग कर उपयोग की गई technologies detect करके शब्द सूचियाँ चुनता है।

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_ध्यान दें कि जब भी कोई नया directory brute-forcing या spidering के दौरान मिलता है, उसे Brute-Force किया जाना चाहिए।_

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTMLs के अंदर broken links खोजें जो takeover के लिए प्रवण हो सकते हैं।
- **File Backups**: एक बार जब आपने सभी files पा लीं, तो सभी executable files के backups देखें ("_.php_", "_.aspx_"...)। backup नामकरण के सामान्य वेरिएंट हैं: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp और file.old._ आप [**bfac**](https://github.com/mazen160/bfac) **या** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen) टूल भी उपयोग कर सकते हैं।
- **Discover new parameters**: आप hidden parameters खोजने के लिए [**Arjun**](https://github.com/s0md3v/Arjun), [**parameth**](https://github.com/maK-/parameth), [**x8**](https://github.com/sh1yo/x8) और [**Param Miner**](https://github.com/PortSwigger/param-miner) जैसे tools उपयोग कर सकते हैं। यदि संभव हो, तो प्रत्येक executable web file में hidden parameters खोजने की कोशिश करें।
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** सभी files की comments जांचें, आप वहाँ **credentials** या **hidden functionality** पा सकते हैं।
- यदि आप **CTF** खेल रहे हैं, तो एक "common" trick है पृष्ठ के source में दाएँ तरफ comments में जानकारी **छिपाना** (सैकड़ों spaces का उपयोग कर ताकि browser में स्रोत खोलने पर दिखाई न दे)। एक और संभावना कई new lines का उपयोग कर पृष्ठ के नीचे comment में जानकारी छिपाना है।
- **API keys**: यदि आप कोई API key पाते हैं तो विभिन्न प्लेटफ़ॉर्म की API keys उपयोग करने के तरीके के लिए यह गाइड देखें: [**keyhacks**](https://github.com/streaak/keyhacks), [**zile**](https://github.com/xyele/zile.git), [**truffleHog**](https://github.com/trufflesecurity/truffleHog), [**SecretFinder**](https://github.com/m4ll0k/SecretFinder), [**RegHex**](<https://github.com/l4yton/RegHex)/>), [**DumpsterDive**](https://github.com/securing/DumpsterDiver), [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: यदि आप कोई API key पाते हैं जो **AIza** से शुरू दिखती है जैसे AizaSyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik तो आप यह जांचने के लिए [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) प्रोजेक्ट उपयोग कर सकते हैं कि वह key किन APIs को access कर सकती है।
- **S3 Buckets**: spidering के दौरान देखें कि कोई **subdomain** या कोई **link** किसी S3 bucket से संबंधित तो नहीं। ऐसी स्थिति में, [**check** the **permissions** of the bucket](buckets/index.html)।

### Special findings

**Spidering** और **brute-forcing** करते समय आप कुछ **interesting** चीजें पा सकते हैं जिनका आपको **ध्यान** रखना चाहिए।

**Interesting files**

- CSS files के अंदर link किसी अन्य file की जांच करें।
- [यदि आप _**.git**_ फाइल पाते हैं तो कुछ जानकारी extract की जा सकती है](git.md)
- यदि आप _**.env**_ पाते हैं तो api keys, dbs passwords और अन्य जानकारी मिल सकती है।
- यदि आप **API endpoints** पाते हैं तो आप [उनका भी परीक्षण करना चाहिए](web-api-pentesting.md)। ये files नहीं हैं, पर दिखने में उन जैसा हो सकते हैं।
- **JS files**: spidering सेक्शन में कई tools का ज़िक्र किया गया जो JS files से path extract कर सकते हैं। इसके अलावा यह भी उपयोगी होगा कि आप प्रत्येक मिले JS file को monitor करें, क्योंकि कुछ मामलों में बदलाव यह संकेत दे सकता है कि कोड में कोई संभावित vulnerability आई है। उदाहरण के लिए आप [**JSMon**](https://github.com/robre/jsmon) का उपयोग कर सकते हैं।
- मिले हुए JS files को [**RetireJS**](https://github.com/retirejs/retire.js/) या [**JSHole**](https://github.com/callforpapers-source/jshole) से चेक करें कि क्या वे vulnerable हैं।
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- कई मौकों पर आपको उपयोग किए गए regular expressions को समझने की ज़रूरत पड़ेगी। इसके लिए यह उपयोगी होगा: [https://regex101.com/](https://regex101.com) या [https://pythonium.net/regex](https://pythonium.net/regex)
- आप उन फ़ाइलों की भी monitoring कर सकते हैं जहाँ forms detect हुए थे, क्योंकि parameters में बदलाव या किसी नए form का आना संभावित नई vulnerable functionality का संकेत दे सकता है।

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

यदि किसी पृष्ठ का response उस code के साथ आता है, तो संभवतः यह खराब configured proxy है। **यदि आप एक HTTP request भेजते हैं जैसे: `GET https://google.com HTTP/1.1`** (host header और अन्य सामान्य headers के साथ), तो proxy कोशिश करेगा _**google.com**_ को access करने की और आपने एक SSRF पा लिया होगा।

**NTLM Authentication - Info disclosure**

यदि running server authentication माँग रहा है और वह **Windows** है या आप ऐसा login देखें जो आपके **credentials** माँगता है (और **domain name** भी माँगता है), तो आप information disclosure को provoke कर सकते हैं।\
**Send** header: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` और NTLM authentication के काम करने के तरीके के कारण, server "WWW-Authenticate" header के अंदर internal info (IIS version, Windows version...) के साथ respond करेगा।\
आप इसे automate करने के लिए **nmap plugin** "_http-ntlm-info.nse_" का उपयोग कर सकते हैं।

**HTTP Redirect (CTF)**

Redirection के अंदर content रखना संभव है। यह content user को दिखाई नहीं देगा (क्योंकि browser redirection execute कर देगा) लेकिन वहाँ कुछ छिपा हुआ हो सकता है।

### Web Vulnerabilities Checking

अब जब web application का व्यापक enumeration हो चुका है तो कई संभावित vulnerabilities की जाँच करने का समय है। आप checklist यहाँ पा सकते हैं:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

web vulns के बारे में और जानकारी:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

आप [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) जैसे tools का उपयोग पृष्ठों में परिवर्तनों के लिए monitoring करने हेतु कर सकते हैं, जो संभावित vulnerabilities डालने वाले modifications का पता लगाने में मदद कर सकते हैं।

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
