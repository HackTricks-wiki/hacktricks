# 80,443 - Μεθοδολογία Web για Pentesting

{{#include ../../banners/hacktricks-training.md}}

## Βασικές Πληροφορίες

Η web υπηρεσία είναι η πιο **συνηθισμένη και εκτεταμένη υπηρεσία** και υπάρχουν πολλοί **διαφορετικοί τύποι ευπαθειών**.

**Προεπιλεγμένη θύρα:** 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Οδηγίες Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Σύνοψη μεθοδολογίας

> Σε αυτή τη μεθοδολογία θα υποθέσουμε ότι πρόκειται να επιτεθείτε σε ένα domain (ή subdomain) και μόνο σε αυτό. Επομένως, θα πρέπει να εφαρμόσετε αυτή τη μεθοδολογία σε κάθε ανακαλυφθέν domain, subdomain ή IP με αδιευκρίνιστο web server εντός του πεδίου.

- [ ] Ξεκινήστε με το **να αναγνωρίσετε** τις **τεχνολογίες** που χρησιμοποιεί ο web server. Ψάξτε για **tricks** που πρέπει να έχετε υπόψη κατά το υπόλοιπο της δοκιμής αν καταφέρετε να αναγνωρίσετε την tech.
- [ ] Υπάρχει κάποια **γνωστή vulnerability** στην έκδοση της τεχνολογίας;
- [ ] Χρησιμοποιείται κάποια **well known tech**; Υπάρχει κάποιο **useful trick** για να εξάγετε περισσότερες πληροφορίες;
- [ ] Υπάρχει κάποιος **specialised scanner** για να τρέξετε (π.χ. wpscan);
- [ ] Εκκινήστε **general purposes scanners**. Ποτέ δεν ξέρετε αν θα βρουν κάτι ή αν θα ανακαλύψουν χρήσιμες πληροφορίες.
- [ ] Ξεκινήστε με τους **initial checks**: **robots**, **sitemap**, **404** error και **SSL/TLS scan** (αν HTTPS).
- [ ] Ξεκινήστε **spidering** της σελίδας: Είναι ώρα να **βρείτε** όλα τα πιθανά **files, folders** και **parameters being used.** Επίσης, ελέγξτε για **special findings**.
- [ ] _Σημειώστε ότι κάθε φορά που ανακαλύπτεται ένας νέος κατάλογος κατά τη διάρκεια brute-forcing ή spidering, πρέπει να γίνει spidered._
- [ ] **Directory Brute-Forcing**: Προσπαθήστε να brute force όλους τους ανακαλυφθέντες φακέλους ψάχνοντας για νέα **files** και **directories**.
- [ ] _Σημειώστε ότι κάθε φορά που ανακαλύπτεται ένας νέος κατάλογος κατά τη διάρκεια brute-forcing ή spidering, πρέπει να γίνει Brute-Forced._
- [ ] **Backups checking**: Δοκιμάστε αν μπορείτε να βρείτε **backups** των **ανακαλυφθέντων files** προσθέτοντας κοινές επεκτάσεις backup.
- [ ] **Brute-Force parameters**: Προσπαθήστε να **βρείτε hidden parameters**.
- [ ] Μόλις έχετε **identified** όλα τα πιθανά **endpoints** που αποδέχονται **user input**, ελέγξτε για κάθε είδους **vulnerabilities** που σχετίζονται με αυτά.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Αναγνώριση

Ελέγξτε αν υπάρχουν **γνωστές vulnerabilities** για την έκδοση του server που τρέχει.\
Οι **HTTP headers and cookies of the response** μπορεί να είναι πολύ χρήσιμα για να **identify** τις **τεχνολογίες** και/ή την **έκδοση** που χρησιμοποιείται. Το **Nmap scan** μπορεί να εντοπίσει την έκδοση του server, αλλά επίσης μπορεί να είναι χρήσιμα τα εργαλεία [**whatweb**](https://github.com/urbanadventurer/WhatWeb), [**webtech**](https://github.com/ShielderSec/webtech) ή [**https://builtwith.com/**](https://builtwith.com):
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Αναζήτηση **για** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Έλεγχος αν υπάρχει WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Κόλπα Web τεχνολογιών

Μερικά **κόλπα** για **finding vulnerabilities** σε διάφορες γνωστές **technologies** που χρησιμοποιούνται:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Fortinet FortiWeb**](fortinet-fortiweb.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](https://github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Λάβετε υπόψη ότι ο **same domain** μπορεί να χρησιμοποιεί **different technologies** σε διαφορετικά **ports**, **folders** και **subdomains**._\
Εάν η εφαρμογή Web χρησιμοποιεί οποιοδήποτε γνωστό **tech/platform listed before** ή **any other**, μην ξεχάσετε να **search on the Internet** για νέα κόλπα (και ενημερώστε με!).

### Ανασκόπηση Source Code

Αν ο **source code** της εφαρμογής είναι διαθέσιμος στο **github**, εκτός από το να πραγματοποιήσετε από μόνοι σας ένα **your own a White box test** της εφαρμογής, υπάρχει **some information** που θα μπορούσε να είναι **useful** για το τρέχον **Black-Box testing**:

- Υπάρχει ένα **Change-log or Readme or Version** file ή κάτι με **version info accessible** μέσω web;
- Πώς και πού αποθηκεύονται τα **credentials**; Υπάρχει κάποιο (accessible?) **file** με credentials (usernames or passwords);
- Είναι τα **passwords** σε **plain text**, **encrypted** ή ποιος **hashing algorithm** χρησιμοποιείται;
- Χρησιμοποιεί κάποιο **master key** για την κρυπτογράφηση; Ποιος **algorithm** χρησιμοποιείται;
- Μπορείτε να **access any of these files** εκμεταλλευόμενοι κάποια vulnerability;
- Υπάρχει κάποια **interesting information in the github** (solved and not solved) **issues**; Ή στο **commit history** (maybe some **password introduced inside an old commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Αυτόματοι σαρωτές

#### Σαρωτές γενικού σκοπού
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Σαρωτές CMS

Αν χρησιμοποιείται CMS μην ξεχάσεις να **run a scanner**, ίσως βρεθεί κάτι ενδιαφέρον:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** ιστοτόπους για θέματα Security. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **ή** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Σε αυτό το σημείο θα πρέπει ήδη να έχετε κάποιες πληροφορίες για τον web server που χρησιμοποιεί ο πελάτης (αν παρέχονται δεδομένα) και μερικά κόλπα που πρέπει να θυμάστε κατά τη διάρκεια του τεστ. Αν είστε τυχεροί μπορεί να έχετε βρει ακόμα ένα CMS και να έχετε τρέξει κάποιο scanner.

## Step-by-step Web Application Discovery

> Από αυτό το σημείο θα αρχίσουμε να αλληλεπιδρούμε με την web εφαρμογή.

### Initial checks

**Default pages with interesting info:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Ελέγξτε επίσης σχόλια στις κύριες και δευτερεύουσες σελίδες.

**Forcing errors**

Οι web servers μπορεί να **συμπεριφέρονται απρόβλεπτα** όταν τους αποστέλλονται ασυνήθιστα δεδομένα. Αυτό μπορεί να ανοίξει **vulnerabilities** ή να **disclose sensitive information**.

- Πρόσβαση σε **fake pages** όπως /whatever_fake.php (.aspx,.html,.etc)
- **Add "[]", "]]", and "[["** σε **cookie values** και **parameter** values για να προκαλέσετε σφάλματα
- Δημιουργήστε σφάλμα δίνοντας είσοδο ως **`/~randomthing/%s`** στο **τέλος** του **URL**
- Δοκιμάστε **different HTTP Verbs** όπως PATCH, DEBUG ή λανθασμένα όπως FAKE

#### **Check if you can upload files (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Αν διαπιστώσετε ότι το **WebDav** είναι **enabled** αλλά δεν έχετε αρκετά permissions για το **uploading files** στον root φάκελο, δοκιμάστε να:

- Κάντε **Brute Force** στα credentials
- **Upload files** μέσω WebDav στο **υπόλοιπο** των **εντοπισμένων φακέλων** μέσα στη σελίδα. Μπορεί να έχετε δικαιώματα για να ανεβάσετε αρχεία σε άλλους φακέλους.

### **SSL/TLS vulnerabilites**

- Αν η εφαρμογή **δεν αναγκάζει τη χρήση του HTTPS** σε κάποιο σημείο, τότε είναι **vulnerable to MitM**
- Αν η εφαρμογή **στέλνει ευαίσθητα δεδομένα (passwords) χρησιμοποιώντας HTTP**. Τότε είναι υψηλή ευπάθεια.

Χρησιμοποιήστε [**testssl.sh**](https://github.com/drwetter/testssl.sh) για να ελέγξετε για **vulnerabilities** (Σε Bug Bounty προγράμματα πιθανότατα αυτού του είδους οι ευπάθειες δεν θα γίνουν αποδεκτές) και χρησιμοποιήστε [**a2sv** ](https://github.com/hahwul/a2sv) για να επανελέγξετε τις ευπάθειες:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Πληροφορίες για ευπάθειες SSL/TLS:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Εκκινήστε κάποιο είδος **spider** μέσα στο web. Ο στόχος του spider είναι να **βρει όσο γίνεται περισσότερα paths** από την εφαρμογή που ελέγχεται. Επομένως, web crawling και εξωτερικές πηγές πρέπει να χρησιμοποιηθούν για να εντοπιστούν όσο γίνεται περισσότερα έγκυρα paths.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files and external sources (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, with LinkFider for JS files and Archive.org as external source.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, also indicates "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. It also searches in Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): This tool isn't a spider but it can be useful. You can just indicate a file with hosts and a file with paths and meg will fetch each path on each host and save the response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider with JS rendering capabilities. However, it looks like it's unmaintained, the precompiled version is old and the current code doesn't compile
- [**gau**](https://github.com/lc/gau) (go): HTML spider that uses external providers (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): This script will find URLs with parameter and will list them.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider with JS rendering capabilities.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, with JS beautify capabilities capable of search new paths in JS files. It could be worth it also take a look to [JSScanner](https://github.com/dark-warlord14/JSScanner), which is a wrapper of LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): To extract endpoints in both HTML source and embedded javascript files. Useful for bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests. Looks like unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Given a file (HTML) it will extract URLs from it using nifty regular expression to find and extract the relative URLs from ugly (minify) files.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Gather interesting information from JS files using several tools.
- [**subjs**](https://github.com/lc/subjs) (go): Find JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Load a page in a headless browser and print out all the urls loaded to load the page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool mixing several options of the previous tools
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): A Burp extension to find path and params in JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): A tool that given the .js.map URL will get you the beatified JS code
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): This is a tool used to discover endpoints for a given target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Discover links from the wayback machine (also downloading the responses in the wayback and looking for more links)
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (even by filling forms) and also find sensitive info using specific regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite is an advance multi-feature GUI web security Crawler/Spider designed for cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): It's a Go package and [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) for extracting URLs, paths, secrets, and other interesting data from JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge is a simple **Burp Suite extension** to **extract the paramters and endpoints** from the request to create custom wordlist for fuzzing and enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Awesome tool for this.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Print every link it's able to find.

### Brute Force directories and files

Start **brute-forcing** from the root folder and be sure to brute-force **all** the **directories found** using **this method** and all the directories **discovered** by the **Spidering** (you can do this brute-forcing **recursively** and appending at the beginning of the used wordlist the names of the found directories).\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

Συστημένα λεξικά:

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Σημείωση: κάθε φορά που ανακαλύπτεται νέος κατάλογος κατά την brute-forcing ή spidering, πρέπει να γίνεται Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Find broken links inside HTMLs that may be prone to takeovers
- **File Backups**: Αφού βρείτε όλα τα αρχεία, ψάξτε για αντίγραφα ασφαλείας των εκτελέσιμων αρχείων ("_.php_", "_.aspx_"...). Συνηθισμένες παραλλαγές στο όνομα backup είναι: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ Μπορείτε επίσης να χρησιμοποιήσετε το εργαλείο [**bfac**](https://github.com/mazen160/bfac) **or** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **and** [**Param Miner**](https://github.com/PortSwigger/param-miner) **για να ανακαλύψετε κρυφούς παράμετρους. Όταν είναι δυνατόν, προσπαθήστε να ψάξετε** κρυφές παραμέτρους σε κάθε εκτελέσιμο web αρχείο.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Ελέγξτε τα comments όλων των αρχείων — μπορείτε να βρείτε **credentials** ή **hidden functionality**.
- Αν παίζετε **CTF**, ένα κοινό κόλπο είναι να **κρύψετε** **πληροφορίες** μέσα σε comments στη **δεξιά** πλευρά της **σελίδας** (χρησιμοποιώντας **εκατοντάδες** **spaces** ώστε να μην φαίνεται το περιεχόμενο αν ανοίξετε τον πηγαίο κώδικα στο browser). Άλλη δυνατότητα είναι να χρησιμοποιήσετε **πολλά new lines** και να **κρύψετε πληροφορίες** σε ένα comment στο **κάτω** μέρος της σελίδας.
- **API keys**: Αν **βρείτε κάποιο API key** υπάρχει οδηγός που δείχνει πώς να χρησιμοποιήσετε API keys από διάφορες πλατφόρμες: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](https://github.com/l4yton/RegHex)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Αν βρείτε κάποιο API key που μοιάζει με **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik μπορείτε να χρησιμοποιήσετε το project [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) για να δείτε ποιες apis μπορεί να προσπελάσει το key.
- **S3 Buckets**: Κατά το spidering κοιτάξτε αν κάποιος **subdomain** ή κάποιο **link** σχετίζεται με κάποιο **S3 bucket**. Σε αυτήν την περίπτωση, [**ελέγξτε** the **permissions** of the bucket](buckets/index.html).

### Special findings

Κατά την **spidering** και **brute-forcing** μπορεί να βρείτε **ενδιαφέροντα** **πράγματα** που πρέπει να προσέξετε.

**Interesting files**

- Ψάξτε για **links** σε άλλα αρχεία μέσα στα **CSS** αρχεία.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Αν βρείτε ένα _**.env**_ μπορούν να βρεθούν πληροφορίες όπως api keys, dbs passwords και άλλα.
- Αν βρείτε **API endpoints** θα [πρέπει επίσης να τα δοκιμάσετε](web-api-pentesting.md). Αυτά δεν είναι αρχεία, αλλά πιθανώς "μοιάζουν" με αυτά.
- **JS files**: Στην ενότητα spidering αναφέρθηκαν διάφορα εργαλεία που μπορούν να εξάγουν paths από JS files. Επίσης, είναι ενδιαφέρον να **monitor** κάθε JS αρχείο που βρέθηκε, καθώς σε ορισμένες περιπτώσεις, μια αλλαγή μπορεί να υποδηλώνει ότι εισήχθη μια πιθανή ευπάθεια στον κώδικα. Μπορείτε να χρησιμοποιήσετε για παράδειγμα [**JSMon**](https://github.com/robre/jsmon)**.**
- Θα πρέπει επίσης να ελέγξετε τα ανακαλυφθέντα JS αρχεία με [**RetireJS**](https://github.com/retirejs/retire.js/) ή [**JSHole**](https://github.com/callforpapers-source/jshole) για να δείτε αν είναι ευάλωτα.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Σε αρκετές περιπτώσεις θα χρειαστεί να **κατανοήσετε τις regular expressions** που χρησιμοποιούνται. Αυτό θα σας βοηθήσει: [https://regex101.com/](https://regex101.com) ή [https://pythonium.net/regex](https://pythonium.net/regex)
- Μπορείτε επίσης να **monitor** τα αρχεία όπου εντοπίστηκαν φόρμες, καθώς μια αλλαγή σε παράμετρο ή η εμφάνιση νέας φόρμας μπορεί να υποδηλώνει νέα ενδεχόμενη ευάλωτη λειτουργικότητα.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Αν κάποια σελίδα **απαντάει** με αυτόν τον **κωδικό**, πιθανότατα είναι **κακώς ρυθμισμένος proxy**. **Αν στείλετε ένα HTTP αίτημα όπως: `GET https://google.com HTTP/1.1`** (με το host header και άλλα κοινά headers), ο **proxy** θα προσπαθήσει να **προσπελάσει** το _**google.com**_ **και θα έχετε βρει ένα** SSRF.

**NTLM Authentication - Info disclosure**

Αν ο server που ζητά authentication είναι **Windows** ή βρείτε login που ζητάει τα **credentials** σας (και ζητάει **domain** **name**), μπορείτε να προκαλέσετε **διαρροή πληροφοριών**.\
**Στείλτε** το **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` και λόγω του πώς λειτουργεί το **NTLM authentication**, ο server θα απαντήσει με εσωτερικές πληροφορίες (IIS version, Windows version...) μέσα στο header "WWW-Authenticate".\
Μπορείτε να **αυτοματοποιήσετε** αυτό χρησιμοποιώντας το **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Είναι δυνατόν να **τοποθετηθεί περιεχόμενο** μέσα σε μια **Redirection**. Αυτό το περιεχόμενο **δεν θα εμφανιστεί στον χρήστη** (δεδομένου ότι ο browser θα εκτελέσει την ανακατεύθυνση) αλλά κάτι μπορεί να είναι **κρυμμένο** εκεί.

### Web Vulnerabilities Checking

Τώρα που έχει γίνει μια πλήρης απογραφή της web εφαρμογής, είναι ώρα να ελεγχθούν πολλές πιθανές ευπάθειες. Το checklist βρίσκεται εδώ:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Βρείτε περισσότερες πληροφορίες για web vulns σε:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) για να monitorάρετε σελίδες για αλλαγές που μπορεί να εισάγουν ευπάθειες.

### HackTricks Automatic Commands

<details>
<summary>HackTricks Automatic Commands</summary>
```yaml
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
</details>

{{#include ../../banners/hacktricks-training.md}}
