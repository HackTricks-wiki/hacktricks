# 80,443 - Pentesting Web Μεθοδολογία

{{#include ../../banners/hacktricks-training.md}}

## Βασικές Πληροφορίες

Η web υπηρεσία είναι η πιο **συνηθισμένη και εκτενής υπηρεσία** και υπάρχουν πολλές **διαφορετικοί τύποι ευπαθειών**.

**Default port:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Κατευθύνσεις για Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Περίληψη μεθοδολογίας

> Σε αυτή τη μεθοδολογία θα υποθέσουμε ότι πρόκειται να επιτεθείς σε ένα domain (ή subdomain) και μόνο αυτό. Συνεπώς, πρέπει να εφαρμόσεις αυτή τη μεθοδολογία για κάθε εντοπισμένο domain, subdomain ή IP με αδιευκρίνιστο web server εντός του πεδίου.

- [ ] Ξεκίνα με το **να αναγνωρίσεις** τις **τεχνολογίες** που χρησιμοποιεί ο web server. Ψάξε για **tricks** που αξίζει να θυμάσαι κατά την υπόλοιπη διάρκεια του τεστ αν μπορέσεις να αναγνωρίσεις την τεχνολογία.
- [ ] Υπάρχει κάποια **γνωστή ευπάθεια** στην έκδοση της τεχνολογίας;
- [ ] Χρησιμοποιεί κάποιο **well known tech**; Κάποιο **useful trick** για να εξάγεις περισσότερες πληροφορίες;
- [ ] Κάποιος **specialised scanner** που πρέπει να τρέξεις (π.χ. wpscan);
- [ ] Εκτέλεσε **general purposes scanners**. Ποτέ δεν ξέρεις αν θα βρουν κάτι ή αν θα αποκαλύψουν ενδιαφέρουσες πληροφορίες.
- [ ] Ξεκίνα με τους **αρχικούς ελέγχους**: **robots**, **sitemap**, **404** error και **SSL/TLS scan** (αν είναι HTTPS).
- [ ] Ξεκίνα **spidering** της σελίδας: Είναι ώρα να **βρεις** όλα τα πιθανά **files, folders** και **parameters being used.** Επίσης, έλεγξε για **special findings**.
- [ ] _Σημείωση ότι κάθε φορά που ενός νέος κατάλογος εντοπίζεται κατά τη διάρκεια brute-forcing ή spidering, θα πρέπει να spidered._
- [ ] **Directory Brute-Forcing**: Προσπάθησε να brute force όλους τους εντοπισμένους φακέλους αναζητώντας νέα **files** και **directories**.
- [ ] _Σημείωση ότι κάθε φορά που ένας νέος κατάλογος εντοπίζεται κατά τη διάρκεια brute-forcing ή spidering, θα πρέπει να Brute-Forced._
- [ ] **Backups checking**: Δοκίμασε αν μπορείς να βρεις **backups** των **discovered files** προσθέτοντας κοινές επεκτάσεις backup.
- [ ] **Brute-Force parameters**: Προσπάθησε να **βρείς hidden parameters**.
- [ ] Μόλις έχεις **αναγνωρίσει** όλα τα πιθανά **endpoints** που δέχονται **user input**, έλεγξε για κάθε είδους **vulnerabilities** που σχετίζονται με αυτά.
- [ ] [Ακολούθησε αυτό το checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

Έλεγξε αν υπάρχουν **γνωστές ευπάθειες** για την **έκδοση** του server που τρέχει.\
Τα **HTTP headers and cookies of the response** μπορεί να είναι πολύ χρήσιμα για να **αναγνωρίσεις** τις **τεχνολογίες** και/ή την **έκδοση** που χρησιμοποιείται. Το **Nmap scan** μπορεί να εντοπίσει την έκδοση του server, αλλά χρήσιμα μπορεί να είναι και τα εργαλεία [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech) ή [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Search **for** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Έλεγχος για WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web tech tricks

Μερικά κόλπα για την ανεύρεση ευπαθειών σε διάφορες γνωστές τεχνολογίες που χρησιμοποιούνται:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)

_Λάβετε υπόψη ότι το **ίδιο domain** μπορεί να χρησιμοποιεί **διαφορετικές τεχνολογίες** σε διαφορετικά **ports**, **folders** και **subdomains**._\
Αν η web εφαρμογή χρησιμοποιεί κάποια από τις γνωστές τεχνολογίες/πλατφόρμες που αναφέρονται παραπάνω ή κάποια άλλη, μην ξεχάσετε να αναζητήσετε στο Internet νέα κόλπα (και ενημερώστε με!).

### Source Code Review

Αν ο **source code** της εφαρμογής είναι διαθέσιμος στο **github**, πέρα από το να εκτελέσετε εσείς έναν White box test της εφαρμογής, υπάρχει κάποια **πληροφορία** που μπορεί να είναι **χρήσιμη** για το τρέχον **Black-Box testing**:

- Is there a **Change-log or Readme or Version** file or anything with **version info accessible** via web?
- How and where are saved the **credentials**? Is there any (accessible?) **file** with credentials (usernames or passwords)?
- Are **passwords** in **plain text**, **encrypted** or which **hashing algorithm** is used?
- Is it using any **master key** for encrypting something? Which **algorithm** is used?
- Can you **access any of these files** exploiting some vulnerability?
- Is there any **interesting information in the github** (solved and not solved) **issues**? Or in **commit history** (maybe some **password introduced inside an old commit**)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### Αυτόματοι σαρωτές γενικού σκοπού
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS scanners

Αν χρησιμοποιείται CMS, μην ξεχάσετε να **τρέξετε έναν scanner**, ίσως βρεθεί κάτι ενδιαφέρον:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** ιστότοποι για ζητήματα ασφάλειας. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **ή** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Σε αυτό το σημείο θα πρέπει ήδη να έχετε κάποιες πληροφορίες για τον web server που χρησιμοποιεί ο client (εφόσον υπάρχουν δεδομένα) και μερικά κόλπα να θυμάστε κατά τη διάρκεια του test. Αν έχετε τύχη ίσως έχετε βρει ακόμη ένα CMS και έχετε τρέξει κάποιο scanner.

## Βήμα-βήμα Ανακάλυψη Web Εφαρμογής

> Από εδώ και πέρα θα αρχίσουμε να αλληλεπιδρούμε με την web εφαρμογή.

### Αρχικοί έλεγχοι

**Προεπιλεγμένες σελίδες με ενδιαφέρουσες πληροφορίες:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Ελέγξτε επίσης τα σχόλια στις κύριες και δευτερεύουσες σελίδες.

**Πρόκληση σφαλμάτων**

Οι web servers μπορεί να **συμπεριφερθούν απρόβλεπτα** όταν τους αποστέλλονται περίεργα δεδομένα. Αυτό μπορεί να ανοίξει **vulnerabilities** ή να προκαλέσει την αποκάλυψη ευαίσθητων πληροφοριών.

- Πρόσβαση σε **ψεύτικες σελίδες** όπως /whatever_fake.php (.aspx,.html,.etc)
- **Προσθέστε "\[]", "]]", και "\[\["** στις **τιμές cookie** και **τιμές παραμέτρων** για να δημιουργήσετε σφάλματα
- Δημιουργήστε σφάλμα δίνοντας είσοδο ως **`/~randomthing/%s`** στο **τέλος** του **URL**
- Δοκιμάστε **διαφορετικά HTTP Verbs** όπως PATCH, DEBUG ή λάθος όπως FAKE

#### **Ελέγξτε αν μπορείτε να ανεβάσετε αρχεία (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Αν διαπιστώσετε ότι το **WebDav** είναι **ενεργοποιημένο** αλλά δεν έχετε επαρκή δικαιώματα για να ανεβάσετε αρχεία στον root φάκελο, δοκιμάστε να:

- **Brute Force** credentials
- Ανεβάστε αρχεία μέσω WebDav στους υπόλοιπους φακέλους που βρέθηκαν μέσα στη σελίδα. Μπορεί να έχετε δικαιώματα να ανεβάσετε αρχεία σε άλλους φακέλους.

### **SSL/TLS ευπάθειες**

- Αν η εφαρμογή **δεν επιβάλει τη χρήση HTTPS** σε κανένα σημείο, τότε είναι **ευάλωτη σε MitM**
- Αν η εφαρμογή **στέλνει ευαίσθητα δεδομένα (passwords) μέσω HTTP**. Τότε είναι υψηλή ευπάθεια.

Χρησιμοποιήστε [**testssl.sh**](https://github.com/drwetter/testssl.sh) για να ελέγξετε για **vulnerabilities** (σε Bug Bounty programs πιθανότατα αυτού του είδους οι vulnerabilities δεν θα γίνουν αποδεκτές) και χρησιμοποιήστε [**a2sv** ](https://github.com/hahwul/a2sv)to recheck the vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Ξεκινήστε κάποιο είδος **spider** μέσα στο web. Ο στόχος του spider είναι να **βρει όσες περισσότερες διαδρομές γίνεται** από την εφαρμογή που δοκιμάζεται. Συνεπώς, web crawling και εξωτερικές πηγές πρέπει να χρησιμοποιηθούν για να εντοπιστούν όσο το δυνατόν περισσότερες έγκυρες διαδρομές.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder σε JS αρχεία και εξωτερικές πηγές (Archive.org, CommonCrawl.org, VirusTotal.com, AlienVault.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, με LinkFider για JS αρχεία και Archive.org ως εξωτερική πηγή.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, επίσης δείχνει "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. Επίσης ψάχνει στο Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): Αυτό το εργαλείο δεν είναι spider αλλά μπορεί να είναι χρήσιμο. Αρκεί να υποδείξεις ένα αρχείο με hosts και ένα αρχείο με paths και το meg θα κάνει fetch κάθε path σε κάθε host και θα αποθηκεύσει την απάντηση.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider με δυνατότητες JS rendering. Ωστόσο, φαίνεται να μην συντηρείται, η προ-συμπιεσμένη έκδοση είναι παλιά και ο τρέχων κώδικας δεν μεταγλωττίζεται.
- [**gau**](https://github.com/lc/gau) (go): HTML spider που χρησιμοποιεί εξωτερικούς providers (wayback, otx, commoncrawl).
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Αυτό το script θα βρει URLs με παραμέτρους και θα τα απαριθμήσει.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider με δυνατότητες JS rendering.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, με δυνατότητες JS beautify ικανές να αναζητήσουν νέες διαδρομές σε JS αρχεία. Αξίζει επίσης να ρίξετε μια ματιά στο [JSScanner](https://github.com/dark-warlord14/JSScanner), που είναι wrapper του LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Για εξαγωγή endpoints τόσο από HTML source όσο και από embedded javascript αρχεία. Χρήσιμο για bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Ένα python 2.7 script που χρησιμοποιεί Tornado και JSBeautifier για να πάρει relative URLs από JavaScript αρχεία. Χρήσιμο για εύκολη ανακάλυψη AJAX requests. Φαίνεται μη συντηρούμενο.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Δίνοντας ένα αρχείο (HTML) θα εξάγει URLs χρησιμοποιώντας έξυπνα regular expressions για να βρει και να εξάγει relative URLs από μινιμαλιστικά (minify) αρχεία.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Συγκεντρώνει ενδιαφέρουσες πληροφορίες από JS αρχεία χρησιμοποιώντας διάφορα εργαλεία.
- [**subjs**](https://github.com/lc/subjs) (go): Βρίσκει JS αρχεία.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Φορτώνει μια σελίδα σε headless browser και εκτυπώνει όλα τα urls που φόρτωσε η σελίδα.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery εργαλείο που συνδυάζει επιλογές από προηγούμενα εργαλεία.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Μια Burp extension για να βρείτε paths και params σε JS αρχεία.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Εργαλείο που, δεδομένου του .js.map URL, θα σας επιστρέψει τον beautified JS κώδικα.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Εργαλείο για ανακάλυψη endpoints για έναν δεδομένο στόχο.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Ανακαλύπτει links από τη wayback machine (επίσης κατεβάζει τις απαντήσεις από τη wayback και ψάχνει για περισσότερα links).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (ακόμα και γεμίζοντας forms) και επίσης βρίσκει ευαίσθητες πληροφορίες χρησιμοποιώντας συγκεκριμένα regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite είναι ένα προχωρημένο multi-feature GUI web security Crawler/Spider σχεδιασμένο για επαγγελματίες της κυβερνοασφάλειας.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): Είναι ένα Go package και [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) για εξαγωγή URLs, paths, secrets και άλλων ενδιαφερόντων δεδομένων από JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge είναι ένα απλό **Burp Suite extension** για **εξαγωγή των parameters και endpoints** από τα request ώστε να δημιουργηθούν custom wordlist για fuzzing και enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Εξαιρετικό εργαλείο για αυτό.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Εκτυπώνει κάθε link που μπορεί να βρει.

### Brute Force directories and files

Ξεκινήστε το **brute-forcing** από το root folder και βεβαιωθείτε ότι θα brute-force **όλες** τις **directories που βρέθηκαν** χρησιμοποιώντας **αυτή τη μέθοδο** και όλες τις directories **που ανακαλύφθηκαν** από το **Spidering** (μπορείτε να κάνετε αυτό το brute-forcing **αναδρομικά** και να προσθέσετε στην αρχή του χρησιμοποιούμενου wordlist τα ονόματα των βρεθέντων directories).\
Tools:

- **Dirb** / **Dirbuster** - Περιλαμβάνονται στο Kali, **παλιά** (και **αργά**) αλλά λειτουργικά. Επιτρέπουν auto-signed certificates και αναδρομική αναζήτηση. Πολύ πιο αργά σε σύγκριση με τις άλλες επιλογές.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Δεν επιτρέπει auto-signed certificates αλλά** επιτρέπει αναδρομική αναζήτηση.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Επιτρέπει auto-signed certificates, **δεν** έχει **αναδρομική** αναζήτηση.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Γρήγορο, υποστηρίζει αναδρομική αναζήτηση.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Αυτό δεν είναι spider αλλά ένα εργαλείο που, δεδομένης της λίστας των βρεθέντων URLs, θα διαγράψει "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension για δημιουργία λίστας directories από το burp history διαφορετικών σελίδων.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Αφαιρεί URLs με duplicated λειτουργικότητες (βασισμένο σε js imports).
- [**Chamaleon**](https://github.com/iustin24/chameleon): Χρησιμοποιεί wapalyzer για να ανιχνεύσει τις τεχνολογίες που χρησιμοποιούνται και να επιλέξει τα wordlists που θα χρησιμοποιηθούν.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Σημειώστε ότι κάθε φορά που ένα νέο directory ανακαλύπτεται κατά το brute-forcing ή το spidering, θα πρέπει να γίνεται Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Βρείτε broken links μέσα σε HTMLs που μπορεί να είναι επιρρεπή σε takeovers.
- **File Backups**: Μόλις βρείτε όλα τα αρχεία, ψάξτε για backups όλων των εκτελέσιμων αρχείων ("_.php_", "_.aspx_"...). Κοινές παραλλαγές ονοματοδοσίας για backup είναι: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp και file.old._ Μπορείτε επίσης να χρησιμοποιήσετε το εργαλείο [**bfac**](https://github.com/mazen160/bfac) **ή** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **και** [**Param Miner**](https://github.com/PortSwigger/param-miner) **για να ανακαλύψετε κρυφές παραμέτρους. Αν μπορείτε, δοκιμάστε να αναζητήσετε** κρυφές παραμέτρους σε κάθε εκτελέσιμο web αρχείο.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Ελέγξτε τα comments όλων των αρχείων, μπορεί να βρείτε **διαπιστευτήρια** ή **κρυφές λειτουργικότητες**.
- Αν παίζετε **CTF**, ένα "κοινό" κόλπο είναι να **κρύψετε** **πληροφορίες** μέσα σε comments δεξιά της σελίδας (χρησιμοποιώντας **εκατοντάδες** spaces ώστε να μην φαίνεται το δεδομένο αν ανοίξετε τον source με τον browser). Άλλη πιθανότητα είναι να χρησιμοποιήσετε **πολλές νέες γραμμές** και να **κρύψετε πληροφορία** σε ένα comment στο **bottom** της σελίδας.
- **API keys**: Αν βρείτε κάποιο API key υπάρχει ένας οδηγός που δείχνει πώς να χρησιμοποιήσετε API keys από διαφορετικές πλατφόρμες: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Αν βρείτε κάποιο API key που μοιάζει με **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik μπορείτε να χρησιμοποιήσετε το project [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) για να ελέγξετε ποιες apis μπορεί να προσπελάσει το key.
- **S3 Buckets**: Κατά τη διάρκεια του spidering κοιτάξτε αν κάποιο **subdomain** ή κάποιο **link** σχετίζεται με κάποιο **S3 bucket**. Σε αυτή την περίπτωση, [**ελέγξτε** τα **permissions** του bucket](buckets/index.html).

### Special findings

Κατά την εκτέλεση του **spidering** και του **brute-forcing** μπορεί να βρείτε **ενδιαφέροντα** **πράγματα** που πρέπει να **σημειώσετε**.

**Interesting files**

- Ψάξτε για **links** προς άλλα αρχεία μέσα στα **CSS** αρχεία.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Αν βρείτε ένα _**.env**_ μπορεί να βρείτε πληροφορίες όπως api keys, dbs passwords και άλλες ευαίσθητες πληροφορίες.
- Αν βρείτε **API endpoints** θα πρέπει να [τους δοκιμάσετε επίσης](web-api-pentesting.md). Αυτά δεν είναι αρχεία, αλλά πιθανώς "θα μοιάζουν" με αρχεία.
- **JS files**: Στην ενότητα spidering αναφέρθηκαν πολλά εργαλεία που μπορούν να εξάγουν paths από JS αρχεία. Επίσης, είναι χρήσιμο να **παρακολουθείτε κάθε JS αρχείο που βρέθηκε**, καθώς σε κάποιες περιπτώσεις μια αλλαγή μπορεί να υποδηλώνει ότι εισήχθη μια ευπάθεια στον κώδικα. Μπορείτε για παράδειγμα να χρησιμοποιήσετε [**JSMon**](https://github.com/robre/jsmon)**.**
- Θα πρέπει επίσης να ελέγξετε τα ανακαλυφθέντα JS αρχεία με [**RetireJS**](https://github.com/retirejs/retire.js/) ή [**JSHole**](https://github.com/callforpapers-source/jshole) για να δείτε αν είναι ευάλωτα.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Σε πολλές περιπτώσεις θα χρειαστεί να **καταλάβετε τα regular expressions** που χρησιμοποιούνται. Αυτό θα σας φανεί χρήσιμο: [https://regex101.com/](https://regex101.com) ή [https://pythonium.net/regex](https://pythonium.net/regex)
- Μπορείτε επίσης να **παρακολουθείτε** τα αρχεία όπου ανιχνεύτηκαν φόρμες, καθώς μια αλλαγή στις παραμέτρους ή η εμφάνιση μιας νέας φόρμας μπορεί να υποδηλώνει μια νέα πιθανή ευπάθεια.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Αν κάποια σελίδα **απαντήσει** με αυτόν τον **κωδικό**, πιθανότατα είναι **κακώς ρυθμισμένος proxy**. **Αν στείλετε ένα HTTP request όπως: `GET https://google.com HTTP/1.1`** (με το host header και άλλα συνηθισμένα headers), ο **proxy** θα προσπαθήσει να **προσπελάσει** _**google.com**_ **και θα έχετε βρει ένα** SSRF.

**NTLM Authentication - Info disclosure**

Αν ο server που ζητά authentication είναι **Windows** ή βρείτε ένα login που ζητάει τα **credentials** σας (και ζητάει το **domain** **name**), μπορείτε να προκαλέσετε **information disclosure**.\
**Στείλτε** το **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` και λόγω του τρόπου που δουλεύει το **NTLM authentication**, ο server θα απαντήσει με εσωτερικές πληροφορίες (έκδοση IIS, έκδοση Windows...) μέσα στο header "WWW-Authenticate".\
Μπορείτε να **αυτοματοποιήσετε** αυτό χρησιμοποιώντας το **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Είναι πιθανό να **τοποθετήσετε περιεχόμενο** μέσα σε μια **Redirection**. Αυτό το περιεχόμενο **δεν θα εμφανιστεί στον χρήστη** (καθώς ο browser θα εκτελέσει το redirection) αλλά κάτι θα μπορούσε να είναι **κρυμμένο** μέσα εκεί.

### Web Vulnerabilities Checking

Τώρα που έχει γίνει μια ολοκληρωμένη enumeration της web εφαρμογής, είναι καιρός να ελέγξετε για πολλές πιθανές ευπάθειες. Μπορείτε να βρείτε το checklist εδώ:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Βρείτε περισσότερες πληροφορίες για web vulns σε:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) για να παρακολουθείτε σελίδες για αλλαγές που ενδέχεται να εισαγάγουν ευπάθειες.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
