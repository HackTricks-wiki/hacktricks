# 80,443 - Pentesting Web 方法论

{{#include ../../banners/hacktricks-training.md}}

## 基本信息

Web 服务是最 **常见且范围广泛的服务**，存在许多 **不同类型的漏洞**。

**默认端口：** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API 指南


{{#ref}}
web-api-pentesting.md
{{#endref}}

## 方法论摘要

> 在本方法论中，我们假定你将针对一个 domain（或 subdomain）进行攻击，仅针对该目标。因此，应当对范围内每个发现的 domain、subdomain 或运行不明 web server 的 IP 应用此方法论。

- [ ] 首先**识别** web server 使用的 **technologies**。如果能成功识别该 tech，请在后续测试中留意相关 **tricks**。
- [ ] 该 technology 的版本是否存在已知的 **known vulnerability**？
- [ ] 是否使用了任何 **well known tech**？是否有任何 **useful trick** 可用于提取更多信息？
- [ ] 是否有需要运行的 **specialised scanner**（例如 wpscan）？
- [ ] 运行 **general purposes scanners**。你永远不知道它们是否会发现什么或提供有价值的信息。
- [ ] 从 **initial checks** 开始：检查 **robots**、**sitemap**、**404** 错误以及 **SSL/TLS scan**（如果为 HTTPS）。
- [ ] 开始对网页进行 **spidering**：现在是时候 **find** 出所有可能的 **files, folders** 及正在使用的 **parameters**。同时，检查是否有 **special findings**。
- [ ] _注意：在 brute-forcing 或 spidering 过程中发现任何新目录时，应该对其进行 spidering。_
- [ ] **Directory Brute-Forcing**：尝试对所有已发现的文件夹进行 brute force，以寻找新的 **files** 和 **directories**。
- [ ] _注意：在 brute-forcing 或 spidering 过程中发现任何新目录时，应该对其进行 Brute-Forced。_
- [ ] **Backups checking**：通过附加常见的备份扩展名，测试是否能找到 **discovered files** 的 **backups**。
- [ ] **Brute-Force parameters**：尝试 **find hidden parameters**。
- [ ] 一旦你 **identified** 了所有可能接受 **user input** 的 **endpoints**，就要检查与之相关的各种 **vulnerabilities**。
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## 服务器版本（是否易受攻击？）

### 识别

检查正在运行的服务器 **version** 是否存在 **known vulnerabilities**。\
**HTTP headers and cookies of the response** 对 **identify** 所使用的 **technologies** 和/或 **version** 非常有帮助。**Nmap scan** 可以识别服务器版本，但工具 [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
搜索 **是否有** [**web 应用的漏洞** **版本信息**](../../generic-hacking/search-exploits.md)

### **检查是否有 WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web 技术 技巧

一些 **技巧** 用于在不同知名 **技术** 中 **发现漏洞**：

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)

_请注意，**同一域名** 可能在不同的 **端口**、**目录** 和 **子域** 上使用 **不同的技术**._\
如果该 web 应用 使用 之前列出的任何知名 **技术/平台** 或 **任何其他**，别忘了 **在互联网上搜索** 新的技巧（并告诉我！）。

### 源代码审查

如果应用的 **源代码** 可在 **github** 获取，除了你亲自对应用进行 **White box test** 外，还有一些 **信息** 可能对当前的 **Black-Box testing** 有用：

- 是否有 **Change-log 或 Readme 或 Version** 文件或任何通过 web 可访问的 **版本信息**？
- **凭据** 是如何以及在哪里保存的？是否有任何（可访问的？）**文件** 包含凭据（用户名或密码）？
- **密码** 是 **明文**、**加密** 还是使用了哪种 **哈希算法**？
- 是否使用任何 **master key** 来加密某些东西？使用了哪种 **算法**？
- 你能否通过利用某些漏洞 **访问这些文件中的任意一个**？
- 在 **github** 中是否有任何有趣的信息（已解决和未解决的）**issues**？或者在 **commit history** 中（可能某个旧提交中引入了某个 **密码**）？

{{#ref}}
code-review-tools.md
{{#endref}}

### 自动扫描器

#### 通用自动扫描器
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS 扫描器

如果使用了 CMS，别忘了**运行扫描器**，可能会发现有价值的内容：

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** 用于检测网站的安全问题。 (GUI)\  
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **或** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> 到此为止，你应该已经对客户端使用的 web server（如果有提供数据）有了一些了解，并掌握在测试中需注意的一些技巧。如果幸运的话，你甚至可能已经发现了 CMS 并运行了一些 scanner。

## 逐步 Web Application 发现

> 从这一点开始，我们将开始与 web application 交互。

### 初步检查

**带有有用信息的默认页面：**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- 也检查主页面和次要页面中的注释。

**触发错误**

当向 Web 服务器发送异常数据时，服务器可能会**异常行为**。这可能会打开 **vulnerabilities** 或 **泄露敏感信息**。

- 访问 **伪造页面**，例如 /whatever_fake.php (.aspx,.html,.etc)
- 在 **cookie 值** 和 **参数值** 中 **添加 "\[]", "]]", 和 "\[["** 以制造错误
- 通过在 **URL** 的 **末尾** 提供输入 **`/~randomthing/%s`** 来生成错误
- 尝试不同的 **HTTP Verbs**，例如 PATCH、DEBUG，或故意使用错误的 FAKE

#### **检查是否可以上传文件 (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

如果你发现 **WebDav** 已启用，但你在根目录没有足够的权限来 **上传文件**，尝试：

- **Brute Force** 凭证
- 通过 WebDav **Upload files** 到网页中已发现的其他文件夹。你可能对其他文件夹具有上传权限。

### **SSL/TLS 漏洞**

- 如果应用在任何部分**没有强制使用 HTTPS**，则容易受到 **MitM** 攻击。
- 如果应用**通过 HTTP 发送敏感数据（如密码）**，则这是一个高危漏洞。

使用 [**testssl.sh**](https://github.com/drwetter/testssl.sh) 检查 **vulnerabilities**（在 Bug Bounty 计划中这类漏洞可能不会被接受），并使用 [**a2sv**](https://github.com/hahwul/a2sv) 重新核实这些 vulnerabilities：
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

在 web 应用内启动某种 **spider**。spider 的目标是从被测试的应用中**找到尽可能多的路径**。因此，应使用 web 爬行和外部来源来发现尽可能多的有效路径。

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML 爬虫，可在 JS 文件中使用 LinkFinder，并使用外部来源 (Archive.org, CommonCrawl.org, VirusTotal.com)。
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HTML 爬虫，具有针对 JS 文件的 LinkFinder 并使用 Archive.org 作为外部来源。
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML 爬虫，同时标记“juicy files”。
- [**evine** ](https://github.com/saeeddhqan/evine)(go): 交互式 CLI HTML 爬虫。也会在 Archive.org 中搜索。
- [**meg**](https://github.com/tomnomnom/meg) (go): 该工具不是蜘蛛但很有用。你可以提供一个 hosts 文件和一个 paths 文件，meg 会对每个主机的每个路径进行抓取并保存响应。
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): 具有 JS 渲染能力的 HTML 爬虫。然而，看起来它没有维护，预编译版本较旧且当前代码无法编译。
- [**gau**](https://github.com/lc/gau) (go): 使用外部提供者（wayback, otx, commoncrawl）的 HTML 爬虫。
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): 该脚本会找到带参数的 URL 并列出它们。
- [**galer**](https://github.com/dwisiswant0/galer) (go): 具有 JS 渲染能力的 HTML 爬虫。
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML 爬虫，具备 JS 美化能力，可在 JS 文件中搜索新路径。也可以看看 [JSScanner](https://github.com/dark-warlord14/JSScanner)，它是 LinkFinder 的一个封装。
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): 从 HTML 源和嵌入的 javascript 文件中提取 endpoints。对 bug 猎人、red teamers、infosec ninjas 很有用。
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): 一个使用 Tornado 和 JSBeautifier 的 python 2.7 脚本，用于从 JavaScript 文件中解析相对 URL。对轻松发现 AJAX 请求很有用。似乎未维护。
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): 给定一个文件 (HTML)，它将使用巧妙的正则表达式从混淆（minify）文件中查找并提取相对 URL。
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): 使用多个工具从 JS 文件中收集有趣信息。
- [**subjs**](https://github.com/lc/subjs) (go): 查找 JS 文件。
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): 在 headless browser 中加载页面并打印出所有为加载页面所请求的 urls。
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): 内容发现工具，融合了前述工具的多种选项。
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): 一个 Burp 扩展，用于在 JS 文件中查找路径和参数。
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): 给定 .js.map URL 时，获取美化后的 JS 代码的工具。
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): 用于为给定目标发现 endpoints 的工具。
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** 从 wayback machine 发现链接（也会下载 wayback 中的响应并寻找更多链接）。
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): 爬取（甚至通过填写表单）并使用特定 regex 查找敏感信息。
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite 是为网络安全专家设计的高级多功能 GUI web 安全 Crawler/Spider。
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): 一个 Go 包和 [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice)，用于从 JavaScript 源代码中提取 URLs、paths、secrets 和其他有趣数据。
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge 是一个简单的 **Burp Suite extension**，用于从请求中**提取参数和 endpoints**，以为 fuzzing 和枚举创建自定义 wordlist。
- [**katana**](https://github.com/projectdiscovery/katana) (go): 对此非常棒的工具。
- [**Crawley**](https://github.com/s0rg/crawley) (go): 打印它能够找到的每个 link。

### Brute Force directories and files

从根目录开始进行 **brute-forcing**，并确保使用**此方法**对**发现的所有目录**进行 brute-force，也对通过 **Spidering** **发现的所有目录**进行 brute-force（你可以递归地进行 brute-forcing，并在所用 wordlist 开头添加已发现目录的名称）。\
工具：

- **Dirb** / **Dirbuster** - 包含在 Kali 中，**老旧**（且**慢**）但可用。允许 auto-signed certificates 和递归搜索。与其它选项相比太慢。
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: 它不允许 auto-signed certificates 但**允许递归搜索**。
- [**Gobuster**](https://github.com/OJ/gobuster) (go): 它允许 auto-signed certificates，但**不**支持**递归**搜索。
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- 快速，支持递归搜索。**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- 快速: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): 这不是蜘蛛，但给定已发现的 URL 列表后，它会删除“重复”的 URLs。
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp 扩展，从不同页面的 burp 历史中创建目录列表。
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): 基于 js imports 移除具有重复功能的 URLs。
- [**Chamaleon**](https://github.com/iustin24/chameleon): 使用 wapalyzer 检测使用的技术并选择要使用的 wordlists。

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_注意：每当在 brute-forcing 或 spidering 过程中发现新目录时，应该对其进行 Brute-Force。_

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): 在 HTML 中查找可能导致 takeover 的 broken links。
- **File Backups**: 找到所有文件后，查找所有可执行文件的备份（"_.php_", "_.aspx_"...）。常见的备份命名变体有： _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp 和 file.old._ 你也可以使用工具 [**bfac**](https://github.com/mazen160/bfac) **或** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**。**
- **Discover new parameters**: 你可以使用像 [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **和** [**Param Miner**](https://github.com/PortSwigger/param-miner) **这样的工具来发现隐藏参数。如果可能，试着在每个可执行的 web 文件上搜索隐藏参数。**
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** 检查所有文件的注释，你可能会发现 **credentials** 或 **隐藏功能**。
- 如果你在做 **CTF**，一个“常见”的技巧是将 **信息**隐藏在页面**右侧**的注释中（使用**数百个空格**，这样如果在浏览器中打开源码你就不会看到数据）。另一种可能是使用**多个换行**并在页面底部的注释中**隐藏信息**。
- **API keys**: 如果你**发现任何 API key**，有一些项目说明如何使用不同平台的 API keys： [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: 如果你发现任何看起来像 **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik 的 API key，可以使用项目 [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) 来检查该 key 可以访问哪些 apis。
- **S3 Buckets**: 在 spidering 时查看是否有任何 **subdomain** 或 **link** 与某个 **S3 bucket** 相关。如果是这种情况，去 [**check** the **permissions** of the bucket](buckets/index.html)。

### Special findings

在执行 **spidering** 和 **brute-forcing** 时，你可能会发现需要特别**注意**的**有趣**的**东西**。

**Interesting files**

- 在 **CSS** 文件中查找指向其他文件的 **links**。
- [If you find a _**.git**_ file some information can be extracted](git.md)
- 如果你发现 _**.env**_，可以找到诸如 api keys、db 密码和其他信息。
- 如果你发现 **API endpoints**，你[也应该测试它们](web-api-pentesting.md)。这些不是文件，但它们很可能“看起来像”文件。
- **JS files**: 在 spidering 部分列出了若干可以从 JS 文件中提取路径的工具。另外，监控每个发现的 JS 文件也很有意义，因为在某些情况下，文件的变化可能表明代码中引入了潜在的漏洞。你可以例如使用 [**JSMon**](https://github.com/robre/jsmon)**。**
- 你还应该使用 [**RetireJS**](https://github.com/retirejs/retire.js/) 或 [**JSHole**](https://github.com/callforpapers-source/jshole) 检查发现的 JS 文件以判断它们是否存在已知漏洞。
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- 在很多场景下，你需要**理解正则表达式**的用法，这会很有帮助： [https://regex101.com/](https://regex101.com) 或 [https://pythonium.net/regex](https://pythonium.net/regex)
- 你还可以**监控检测到表单的文件**，因为参数变化或新表单的出现可能表明潜在的新漏洞功能。

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

如果任何页面以该 **code** 响应，很可能是一个 **配置错误的 proxy**。**如果你发送一个像这样的 HTTP 请求： `GET https://google.com HTTP/1.1`**（包含 host header 和其他常见头），proxy 会尝试访问 _**google.com**_，那么你就发现了一个 **SSRF**。

**NTLM Authentication - Info disclosure**

如果要求认证的运行服务器是 **Windows**，或者你发现一个要求你输入 **credentials**（并要求 **domain** **name**）的登录，你可以触发一个**信息泄露**。\
**发送** 头：`“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”`，由于 **NTLM authentication** 的工作机制，服务器会在头 "WWW-Authenticate" 中返回内部信息（IIS 版本、Windows 版本...）。\
你可以使用 nmap 插件 "_http-ntlm-info.nse_" 来**自动化**此操作。

**HTTP Redirect (CTF)**

可以把内容放在 **Redirection** 中。这些内容**不会显示给用户**（因为浏览器会执行重定向），但有东西可能被**隐藏**在里面。

### Web Vulnerabilities Checking

在对 web 应用进行了全面枚举之后，就该检查大量可能的漏洞了。你可以在这里找到检查清单：


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Find more info about web vulns in:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

你可以使用像 [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) 这样的工具来监控页面修改，这些修改可能引入漏洞。

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
