# 80,443 - Pentesting Web Metodolojisi

{{#include ../../banners/hacktricks-training.md}}

## Temel Bilgiler

Web servisi en **yaygın ve kapsamlı servis** olup birçok **farklı türde vulnerabilities** bulunmaktadır.

**Varsayılan port:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API Rehberi


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Metodoloji özeti

> Bu metodolojide yalnızca bir domain (veya subdomain) üzerinde saldırı gerçekleştireceğinizi varsayacağız. Bu yüzden, kapsam içindeki her keşfedilen domain, subdomain veya web sunucusu belirlenmemiş IP için bu metodolojiyi uygulamalısınız.

- [ ] Önce web sunucusu tarafından kullanılan **teknolojileri** **tanımlayın**. Tekniği başarıyla tanımlayabilirseniz testin geri kalanında aklınızda tutmanız gereken **püf noktalarını** arayın.
- [ ] Teknolojinin sürümüne ait herhangi bir **bilinen zafiyet** var mı?
- [ ] Herhangi bir **bilinen teknoloji** mi kullanılıyor? Daha fazla bilgi çıkarmak için herhangi bir **faydalı püf noktası** var mı?
- [ ] Çalıştırılacak herhangi bir **özelleşmiş tarayıcı** var mı (örn. wpscan)?
- [ ] Genel amaçlı **tarayıcıları** çalıştırın. Ne bulacaklarını ya da ilginç bilgi tespit edip etmeyeceklerini bilemezsiniz.
- [ ] İlk olarak **başlangıç kontrolleri** ile başlayın: **robots**, **sitemap**, **404** hatası ve **SSL/TLS scan** (HTTPS ise).
- [ ] Sayfayı **spidering** ile taramaya başlayın: Tüm olası **dosyaları**, **klasörleri** ve **kullanılan parametreleri** bulma zamanı. Ayrıca **özel bulgular** için kontrol edin.
- [ ] _Yeni bir dizin brute-forcing veya spidering sırasında keşfedildiğinde, o dizin spidered edilmelidir._
- [ ] **Directory Brute-Forcing**: Keşfedilen tüm klasörlerde yeni **dosyalar** ve **dizinler** aramak için brute force yapmayı deneyin.
- [ ] _Yeni bir dizin brute-forcing veya spidering sırasında keşfedildiğinde, Brute-Forced yapılmalıdır._
- [ ] **Backups checking**: Ortaya çıkan **dosyaların yedeklerini** yaygın yedek uzantıları ekleyerek bulup bulamayacağınızı test edin.
- [ ] **Brute-Force parameters**: Gizli parametreleri **bulmaya** çalışın.
- [ ] Tüm olası **endpoints** içinde **user input** kabul edenleri **tanımladıktan** sonra, bunlarla ilişkili tüm türde **vulnerabilities** için kontrol edin.
- [ ] [Bu kontrol listesini takip edin](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Zayıf mı?)

### Tanımlama

Çalışan sunucu **sürümü** için herhangi bir **bilinen zafiyet** olup olmadığını kontrol edin.\
Yanıtın **HTTP headers and cookies**'i, kullanılan **teknolojileri** ve/veya **sürümü** tespit etmek için çok yararlı olabilir. **Nmap scan** sunucu sürümünü tespit edebilir, ancak [**whatweb**](https://github.com/urbanadventurer/WhatWeb), [**webtech**](https://github.com/ShielderSec/webtech) veya [**https://builtwith.com/**](https://builtwith.com) gibi araçlar da faydalı olabilir:
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Ara **için** [**web uygulamasının zafiyetleri** **sürümü**](../../generic-hacking/search-exploits.md)

### **Herhangi bir WAF olup olmadığını kontrol edin**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web teknoloji tüyoları

Kullanılmakta olan farklı, iyi bilinen **teknolojilerde** zafiyetleri **bulmak** için bazı **tüyolar**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)

_Take into account that the **same domain** can be using **different technologies** in different **ports**, **folders** and **subdomains**._\
Web uygulaması önceden listelenen herhangi bir iyi bilinen **teknoloji/platform** veya **başka bir şey** kullanıyorsa, yeni hileleri **İnternette aramayı** unutmayın (ve bana bildirin!).

### Source Code Review

Eğer uygulamanın **source code**'u **github** üzerinde erişilebilirse, uygulama üzerinde kendi başınıza bir **White box test** yapmanın yanı sıra mevcut **Black-Box testing** için faydalı olabilecek bazı bilgiler bulunabilir:

- Web üzerinden erişilebilir bir **Change-log** veya **Readme** ya da **Version** dosyası veya sürüm bilgisi içeren herhangi bir şey var mı?
- **Credentials** nasıl ve nerede saklanıyor? Erişilebilir herhangi bir **dosya** içinde credentials (kullanıcı adları veya parolalar) var mı?
- Parolalar düz metin mi, şifrelenmiş mi veya hangi **hashing** algoritması kullanılıyor?
- Bir şeyi şifrelemek için herhangi bir **master key** kullanılıyor mu? Hangi algoritma kullanılıyor?
- Bazı bir **vulnerability**'yi istismar ederek bu dosyalardan herhangi birine erişebilir misiniz?
- github'daki (çözülmüş veya çözülmemiş) **issues**'larda ilginç bilgiler var mı? Veya commit geçmişinde (belki eski bir commit içinde tanımlanmış bir parola) ilginç bir şey çıkıyor mu?


{{#ref}}
code-review-tools.md
{{#endref}}

### Otomatik tarayıcılar

#### Genel amaçlı otomatik tarayıcılar
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS tarayıcıları

Bir CMS kullanılıyorsa **run a scanner** yapmayı unutmayın; belki ilginç bir şey bulunur:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** web sitelerini güvenlik sorunları için tarar. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **veya** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Bu noktada, istemcinin kullandığı web sunucusu hakkında (veri verildiyse) bazı bilgilere ve test sırasında akılda tutulması gereken bazı püf noktalarına zaten sahip olmalısınız. Şanslıysanız bir CMS bulmuş ve bazı scanner'lar çalıştırmışsınızdır.

## Adım adım Web Uygulama Keşfi

> Bu noktadan itibaren web uygulamasıyla etkileşime geçmeye başlayacağız.

### İlk kontroller

**İlginç bilgi içerebilecek varsayılan sayfalar:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Ana ve ikincil sayfalardaki yorumları da kontrol edin.

**Hataları zorlamak**

Web sunucuları tuhaf veriler gönderildiğinde **beklenmedik şekilde davranabilir**. Bu, **güvenlik açıklarına** veya **hassas bilgilerin açığa çıkmasına** yol açabilir.

- /whatever_fake.php (.aspx,.html,.etc) gibi **sahte sayfalara** erişin
- **"\[]", "]]", ve "\[\["** ifadelerini **cookie values** ve **parameter** values içine ekleyin, hata oluşturmak için
- Hata üretmek için input'u URL'nin **sonuna** **`/~randomthing/%s`** olarak verin
- PATCH, DEBUG gibi **farklı HTTP Verbs** deneyin veya FAKE gibi yanlış bir verb kullanın

#### **Dosya yükleyip yükleyemeyeceğinizi kontrol edin (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Eğer **WebDav**'in **enabled** olduğunu fakat root klasörüne **uploading files** için yeterli izinleriniz olmadığını görürseniz şunları deneyin:

- **Brute Force** credentials
- Web sayfası içindeki bulunan diğer klasörlere **Upload files** via WebDav yapın. Diğer klasörlere dosya yükleme izniniz olabilir.

### **SSL/TLS zafiyetleri**

- Uygulama herhangi bir bölümde **kullanıcıyı HTTPS kullanmaya zorlamıyorsa**, o zaman **MitM'e karşı açıktır**
- Uygulama **hassas verileri (parolalar) HTTP üzerinden gönderiyorsa**, bu yüksek riskli bir zafiyettir.

Zafiyetleri kontrol etmek için [**testssl.sh**](https://github.com/drwetter/testssl.sh) kullanın (Bug Bounty programlarında muhtemelen bu tür zafiyetler kabul edilmeyecektir) ve zafiyetleri yeniden kontrol etmek için [**a2sv**](https://github.com/hahwul/a2sv) kullanın:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Web uygulaması üzerinde bir çeşit **spider** çalıştırın. Spider'ın amacı test edilen uygulamadan mümkün olduğunca çok yol **bulmaktır**. Bu yüzden web crawling ve harici kaynaklar kullanılarak mümkün olduğunca çok geçerli yol bulunmalıdır.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, JS dosyalarındaki LinkFinder ve harici kaynaklar (Archive.org, CommonCrawl.org, VirusTotal.com, AlienVault.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HTML spider, JS dosyaları için LinkFinder ve Archive.org'u harici kaynak olarak kullanır.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider; ayrıca "juicy files" gösterir.
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Etkileşimli CLI HTML spider. Ayrıca Archive.org'da arama yapar.
- [**meg**](https://github.com/tomnomnom/meg) (go): Bu araç bir spider değil ama faydalı olabilir. Hosts içeren bir dosya ve path'ler içeren bir dosya belirtirsiniz; meg her host üzerindeki her path'i çeker ve yanıtı kaydeder.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS render yetenekli HTML spider. Ancak bakımı yapılmıyor gibi görünüyor; önceden derlenmiş sürüm eski ve mevcut kod derlenmiyor.
- [**gau**](https://github.com/lc/gau) (go): Harici sağlayıcıları kullanan HTML spider (wayback, otx, commoncrawl).
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Parametre içeren URL'leri bulur ve listeler.
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS render yetenekli HTML spider.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider; JS beautify yetenekleriyle JS dosyalarında yeni path'ler arayabilir. Ayrıca LinkFinder'ın bir wrapper'ı olan [JSScanner](https://github.com/dark-warlord14/JSScanner) incelenmeye değer.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Hem HTML kaynağından hem gömülü javascript dosyalarından endpoint'leri çıkarmak için. Bug hunters, red teamer'lar ve infosec uzmanları için kullanışlı.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): JavaScript dosyalarından relatif URL'leri parse etmek için Tornado ve JSBeautifier kullanan python 2.7 scripti. AJAX isteklerini kolayca keşfetmek için faydalı. Bakımı yapılmıyor gibi görünüyor.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Verilen bir dosyadan (HTML) regex kullanarak minified dosyalardan relatif URL'leri bulup çıkarır.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): JS dosyalarından birkaç araç kullanarak ilginç bilgiler toplar.
- [**subjs**](https://github.com/lc/subjs) (go): JS dosyalarını bulur.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Bir sayfayı headless browser'da yükler ve sayfayı yüklemek için kullanılan tüm URL'leri yazdırır.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Önceki araçların çeşitli seçeneklerini harmanlayan içerik keşif aracı.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS dosyalarındaki path ve parametreleri bulmak için bir Burp extension.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Verilen .js.map URL'si sayesinde beautified JS kodunu elde eden araç.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Verilen hedef için endpoint'leri keşfetmek amacıyla kullanılan araç.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Wayback Machine'den linkleri keşfeder (wayback'teki yanıtları indirip daha fazla link arar).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Form doldurma dahil tarama yapar ve özel regex'lerle hassas bilgi bulur.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite, siber güvenlik profesyonelleri için tasarlanmış gelişmiş çok özellikli GUI web güvenlik Crawler/Spider.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): JavaScript kaynak kodundan URL'ler, path'ler, secret'lar ve diğer ilginç verileri çıkarmak için bir Go paketi ve [komut-satırı aracı](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice).
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge, fuzzing ve enumeration için özel wordlist oluşturmak amacıyla isteklerden parametreleri ve endpoint'leri çıkarmak üzere basit bir Burp Suite extension'ıdır.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Bunun için harika bir araç.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Bulabildiği her linki yazdırır.

### Brute Force directories and files

Kök dizinden **brute-forcing** ile başlayın ve bu yöntemle bulunan tüm dizinleri ve **Spidering** ile keşfedilen tüm dizinleri **brute-force** yaptığınızdan emin olun (bunu **rekürsif** olarak yapabilir ve bulunan dizinlerin adlarını kullanılan wordlist'in başına ekleyebilirsiniz).\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Auto-signed sertifikalara izin verir ve recursive arama yapar. Diğer seçeneklere göre çok yavaş.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Auto-signed sertifikalara izin vermez ama recursive aramaya izin verir.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Auto-signed sertifikalara izin verir; **recursive** arama yok.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Bu bir spider değil; bulunan URL listesini alıp "çift" URL'leri silen bir araç.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension; farklı sayfaların burp geçmişinden dizin listesi oluşturur.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): JS import'larına göre fonksiyonu tekrar eden URL'leri kaldırır.
- [**Chamaleon**](https://github.com/iustin24/chameleon): Kullanılan teknolojileri tespit etmek ve kullanılacak wordlist'leri seçmek için wapalyzer kullanır.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Not: Brute-forcing veya spidering sırasında yeni bir dizin keşfedildiğinde, o dizin mutlaka brute-force edilmelidir._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTML içindeki kırık linkleri bulur; takeover'a açık olabilecek linkleri tespit eder.
- **File Backups**: Tüm dosyaları bulduktan sonra, yürütülebilir dosyaların (".php", ".aspx"...) yedeklerini arayın. Yedekleme için yaygın isimlendirme çeşitleri: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp ve file.old._ Ayrıca [**bfac**](https://github.com/mazen160/bfac) veya [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen) araçlarını kullanabilirsiniz.
- **Discover new parameters**: Gizli parametreleri keşfetmek için [**Arjun**](https://github.com/s0md3v/Arjun), [**parameth**](https://github.com/maK-/parameth), [**x8**](https://github.com/sh1yo/x8) ve [**Param Miner**](https://github.com/PortSwigger/param-miner) gibi araçlar kullanılabilir. Mümkünse her yürütülebilir web dosyasında gizli parametreleri aramaya çalışın.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Tüm dosyaların yorumlarını kontrol edin; credential'lar veya gizli fonksiyonlar bulunabilir.
- Eğer **CTF** oynuyorsanız, yaygın bir hile sayfa kaynağında sayfanın sağ tarafına (çokça boşluk kullanarak) veya sayfanın en altına bir yorum içinde bilgi saklamaktır; tarayıcıda görüntülemek zor olabilir.
- **API keys**: Bir API key bulursanız, farklı platformlardaki API key'lerin nasıl kullanılacağını gösteren rehberler var: [**keyhacks**](https://github.com/streaak/keyhacks), [**zile**](https://github.com/xyele/zile.git), [**truffleHog**](https://github.com/trufflesecurity/truffleHog), [**SecretFinder**](https://github.com/m4ll0k/SecretFinder), [**RegHex**](<https://github.com/l4yton/RegHex)/>), [**DumpsterDive**](https://github.com/securing/DumpsterDiver), [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: **AIza** ile başlayan bir API key bulursanız (ör. **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik), hangi API'lere erişimi olduğunu kontrol etmek için [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) projesini kullanabilirsiniz.
- **S3 Buckets**: Spidering sırasında herhangi bir subdomain veya link'in bir S3 bucket ile ilişkili olup olmadığını kontrol edin. Böyle bir durum varsa, bucket'ın [**permissions**'ını kontrol edin](buckets/index.html).

### Special findings

**Spidering** ve **brute-forcing** gerçekleştirirken dikkat etmeniz gereken ilginç bulgularla karşılaşabilirsiniz.

**Interesting files**

- CSS dosyaları içinde diğer dosyalara yapılan **link**leri arayın.
- [Eğer bir _**.git**_ dosyası bulursanız bazı bilgiler çıkarılabilir](git.md)
- Eğer bir _**.env**_ dosyası bulursanız API key'ler, DB parolaları ve diğer bilgileri içerebilir.
- Eğer **API endpoints** bulursanız bunları [test etmelisiniz](web-api-pentesting.md). Bunlar dosya olmayabilir ama dosya gibi görünebilirler.
- **JS files**: Spidering bölümünde JS dosyalarından path çıkarabilen birçok araç listelendi. Ayrıca bulunan her JS dosyasını izlemek ilginç olabilir; bazı durumlarda bir değişiklik kodda yeni bir zafiyetin ortaya çıktığını gösterebilir. Örneğin [**JSMon**](https://github.com/robre/jsmon) kullanılabilir.
- Bulunan JS dosyalarını zafiyet için kontrol etmek üzere [**RetireJS**](https://github.com/retirejs/retire.js/) veya [**JSHole**](https://github.com/callforpapers-source/jshole) ile tarayın.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Birçok durumda kullanılan regular expression'ları anlamanız gerekir. Bunun için faydalı kaynaklar: [https://regex101.com/](https://regex101.com) veya [https://pythonium.net/regex](https://pythonium.net/regex)
- Form tespit edilen dosyaları da izleyebilirsiniz; parametredeki bir değişiklik veya yeni bir formun ortaya çıkması potansiyel bir yeni zafiyeti gösterebilir.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Eğer herhangi bir sayfa bu kodla cevap veriyorsa muhtemelen yanlış yapılandırılmış bir proxy söz konusudur. Eğer şu şekilde bir HTTP isteği gönderirseniz: `GET https://google.com HTTP/1.1` (host header ve diğer yaygın header'lar ile), proxy _google.com_'a erişmeye çalışacak ve böylece bir SSRF bulmuş olabilirsiniz.

**NTLM Authentication - Info disclosure**

Eğer authentication isteyen sunucu **Windows** ise veya domain adı soran bir login görürseniz, bilgi sızması provokasyonu yapılabilir.\
Şu header'ı gönderin: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` ve NTLM authentication'ın çalışma şekli nedeniyle sunucu "WWW-Authenticate" header'ında iç ağ bilgilerini (IIS sürümü, Windows sürümü...) döndürebilir.\
Bunu otomatikleştirmek için nmap plugin'i "_http-ntlm-info.nse_" kullanılabilir.

**HTTP Redirect (CTF)**

Bir Redirection içine içerik koymak mümkündür. Bu içerik kullanıcıya gösterilmeyecektir (tarayıcı yönlendirmeyi uygulayacağı için) ancak içeriğe gizli bilgi yerleştirilebilir.

### Web Vulnerabilities Checking

Web uygulamasının kapsamlı bir enumerate işlemi yapıldıktan sonra birçok olası zafiyeti kontrol etme zamanı gelmiştir. Kontrol listesi burada bulunabilir:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Web zafiyetleri hakkında daha fazla bilgi:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Sayfalardaki değişiklikleri izlemek için [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) gibi araçlar kullanılabilir; bu sayede yapılacak değişiklikler yeni zafiyetler ekleyebilir.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
