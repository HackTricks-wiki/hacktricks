# 80,443 - Méthodologie de Pentesting Web

{{#include ../../banners/hacktricks-training.md}}

## Infos de base

Le service web est le service le plus **courant et étendu** et de nombreux **types de vulnérabilités** existent.

**Port par défaut :** 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Guide des API Web


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Résumé de la méthodologie

> Dans cette méthodologie, nous allons supposer que vous allez attaquer un domaine (ou sous-domaine) et uniquement celui-ci. Donc, vous devez appliquer cette méthodologie à chaque domaine, sous-domaine ou IP découvert avec un serveur web indéterminé dans le scope.

- [ ] Commencez par **identifier** les **technologies** utilisées par le serveur web. Cherchez des **trucs** à garder en tête pendant le reste du test si vous parvenez à identifier la tech.
- [ ] Existe-t-il une **vulnérabilité connue** pour la version de la technologie ?
- [ ] Utilisez-vous une **technologie bien connue** ? Une **astuce utile** pour extraire plus d'informations ?
- [ ] Y a-t-il un **scanner spécialisé** à exécuter (comme wpscan) ?
- [ ] Lancez des **scanners à usage général**. On ne sait jamais s'ils vont trouver quelque chose ou des informations intéressantes.
- [ ] Commencez par les **vérifications initiales** : **robots**, **sitemap**, erreur **404** et **SSL/TLS scan** (si HTTPS).
- [ ] Commencez le **spidering** de la page web : il est temps de **trouver** tous les **fichiers, dossiers** et **paramètres utilisés.** Vérifiez aussi les **trouvailles particulières**.
- [ ] _Notez que chaque fois qu'un nouveau répertoire est découvert lors de brute-forcing ou de spidering, il doit être spidered._
- [ ] **Directory Brute-Forcing**: Essayez de brute-forcer tous les dossiers découverts pour rechercher de nouveaux **fichiers** et **répertoires**.
- [ ] _Notez que chaque fois qu'un nouveau répertoire est découvert lors de brute-forcing ou de spidering, il doit être Brute-Forced._
- [ ] **Backups checking**: Testez si vous pouvez trouver des **backups** des **fichiers découverts** en ajoutant des extensions de backup courantes.
- [ ] **Brute-Force parameters**: Essayez de **trouver des paramètres cachés**.
- [ ] Une fois que vous avez **identifié** tous les **endpoints** possibles acceptant des **entrées utilisateur**, vérifiez tous les types de **vulnérabilités** qui leur sont liés.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Version du serveur (Vulnérable ?)

### Identifier

Vérifiez s'il existe des **vulnérabilités connues** pour la **version** du serveur en cours d'exécution.\
Les **en-têtes HTTP et les cookies de la réponse** peuvent être très utiles pour **identifier** les **technologies** et/ou la **version** utilisée. **Nmap scan** peut identifier la version du serveur, mais les outils [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)ou [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Rechercher **les** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Vérifier s'il y a un WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Astuces pour les technologies Web

Quelques **astuces** pour **trouver des vulnérabilités** dans différentes **technologies** bien connues utilisées :

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)

_Tenez compte que le **même domaine** peut utiliser **différentes technologies** sur différents **ports**, **dossiers** et **sous-domaines**._\
Si l'application web utilise une **tech/plateforme** bien connue listée ci-dessus ou **toute autre**, n'oubliez pas de **chercher sur Internet** de nouvelles astuces (et informez-moi !).

### Source Code Review

Si le **code source** de l'application est disponible sur **github**, en plus d'effectuer par **vous-même un White box test** de l'application, il existe **des informations** qui pourraient être **utiles** pour le **Black-Box testing** en cours :

- Y a-t-il un **Change-log or Readme or Version** file ou tout élément avec des **version info accessible** via le web ?
- How and where are saved the **credentials**? Is there any (accessible?) **file** with credentials (usernames or passwords)?
- Are **passwords** in **plain text**, **encrypted** or which **hashing algorithm** is used?
- Is it using any **master key** for encrypting something? Which **algorithm** is used?
- Can you **access any of these files** exploiting some vulnerability?
- Is there any **interesting information in the github** (solved and not solved) **issues**? Or in **commit history** (maybe some **password introduced inside an old commit**)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### Scanners automatiques à usage général
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Scanners de CMS

Si un CMS est utilisé, n'oubliez pas de **lancer un scanner**, il se peut que quelque chose d'intéressant soit trouvé :

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** sites web pour des failles de sécurité. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **ou** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> À ce stade, vous devriez déjà disposer de certaines informations sur le serveur web utilisé par le client (si des données sont fournies) et de quelques astuces à garder à l'esprit pendant le test. Si vous avez de la chance, vous avez même trouvé un CMS et lancé un scanner.

## Découverte étape par étape de l'application Web

> À partir de ce point, nous allons commencer à interagir avec l'application Web.

### Vérifications initiales

**Pages par défaut contenant des informations intéressantes :**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Vérifiez également les commentaires dans les pages principales et secondaires.

**Forcer des erreurs**

Les serveurs web peuvent **se comporter de manière inattendue** lorsque des données étranges leur sont envoyées. Cela peut ouvrir des **vulnérabilités** ou provoquer une **disclosure sensitive information**.

- Accédez à des **fake pages** comme /whatever_fake.php (.aspx,.html,.etc)
- **Ajoutez "\[]", "]]", et "\[["** dans les **valeurs des cookies** et les **valeurs des paramètres** pour créer des erreurs
- Générez une erreur en donnant comme entrée **`/~randomthing/%s`** à la **fin** de l'**URL**
- Essayez différents **verbes HTTP** comme PATCH, DEBUG ou incorrects comme FAKE

#### **Vérifiez si vous pouvez téléverser des fichiers (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Si vous constatez que **WebDav** est **activé** mais que vous n'avez pas suffisamment de permissions pour **téléverser des fichiers** dans le dossier racine, essayez de :

- **Brute Force** les identifiants
- **Téléverser des fichiers** via WebDav dans le **reste** des **dossiers trouvés** à l'intérieur de la page web. Vous pouvez avoir la permission de téléverser des fichiers dans d'autres dossiers.

### **Vulnérabilités SSL/TLS**

- Si l'application **n'impose pas l'utilisation de HTTPS** dans une quelconque partie, alors elle est **vulnérable aux attaques MitM**
- Si l'application **envoie des données sensibles (mots de passe) via HTTP**, c'est une vulnérabilité élevée.

Utilisez [**testssl.sh**](https://github.com/drwetter/testssl.sh) pour vérifier les **vulnérabilités** (dans les programmes Bug Bounty, probablement ce type de vulnérabilités ne sera pas accepté) et utilisez [**a2sv**](https://github.com/hahwul/a2sv) pour revérifier les vulnérabilités:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Lancez une sorte de **spider** sur le site web. L'objectif du spider est de **trouver autant de chemins que possible** à partir de l'application testée. Pour cela, le crawling et les sources externes doivent être utilisés afin de découvrir le plus de chemins valides possible.

- [**gospider**](https://github.com/jaeles-project/gospider) (go) : HTML spider, LinkFinder dans les fichiers JS et sources externes (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go) : HML spider, avec LinkFider pour les fichiers JS et Archive.org comme source externe.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python) : HTML spider, indique aussi les "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go) : CLI interactive HTML spider. Il recherche également dans Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go) : Cet outil n'est pas un spider mais peut être utile. Vous pouvez indiquer un fichier avec des hosts et un fichier avec des paths et meg ira fetch chaque path sur chaque host et enregistrera la réponse.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go) : HTML spider avec capacités de rendering JS. Cependant, il semble non maintenu, la version précompilée est ancienne et le code actuel ne compile pas.
- [**gau**](https://github.com/lc/gau) (go) : HTML spider qui utilise des fournisseurs externes (wayback, otx, commoncrawl).
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider) : Ce script va trouver les URLs avec paramètres et les lister.
- [**galer**](https://github.com/dwisiswant0/galer) (go) : HTML spider avec capacités de rendering JS.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python) : HTML spider, avec capacités de JS beautify capable de rechercher de nouveaux chemins dans les fichiers JS. Il peut être utile aussi de jeter un œil à [JSScanner](https://github.com/dark-warlord14/JSScanner), qui est un wrapper de LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go) : Pour extraire des endpoints dans le source HTML et les fichiers javascript embarqués. Utile pour bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7) : Script python 2.7 utilisant Tornado et JSBeautifier pour parser les URLs relatives des fichiers JavaScript. Utile pour découvrir facilement les requêtes AJAX. Semble non maintenu.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby) : Étant donné un fichier (HTML) il extraira les URLs en utilisant des expressions régulières pour trouver et extraire les URLs relatives de fichiers minifiés.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, plusieurs outils) : Rassemble des informations intéressantes depuis les fichiers JS en utilisant plusieurs outils.
- [**subjs**](https://github.com/lc/subjs) (go) : Trouve les fichiers JS.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go) : Charge une page dans un headless browser et affiche toutes les urls chargées pour rendre la page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust) : Outil de discovery de contenu mélangeant plusieurs options des outils précédents.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions) : Extension Burp pour trouver paths et params dans les fichiers JS.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper) : Outil qui, donné l'URL .js.map, récupère le code JS beautifié.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder) : Outil utilisé pour découvrir des endpoints pour une cible donnée.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Découvre des liens depuis la wayback machine (télécharge aussi les réponses dans la wayback et cherche plus de liens).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go) : Crawl (même en remplissant des forms) et trouve aussi des infos sensibles en utilisant des regex spécifiques.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite) : Spider Suite est un crawler/spider GUI multi-fonction avancé conçu pour les professionnels de la cybersécurité.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go) : Package Go et [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) pour extraire URLs, paths, secrets et autres données intéressantes depuis le source JavaScript.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge) : ParaForge est une simple **Burp Suite extension** pour **extraire les paramètres et endpoints** depuis les requêtes afin de créer des wordlists personnalisées pour le fuzzing et l'énumération.
- [**katana**](https://github.com/projectdiscovery/katana) (go) : Outil excellent pour cela.
- [**Crawley**](https://github.com/s0rg/crawley) (go) : Affiche chaque lien qu'il est capable de trouver.

### Brute Force directories and files

Commencez le **brute-forcing** depuis le dossier racine et assurez-vous de brute-forcer **tous** les **répertoires trouvés** en utilisant **cette méthode** et tous les répertoires **découverts** par le **Spidering** (vous pouvez faire ce brute-forcing **récursivement** en préfixant dans le wordlist utilisé les noms des répertoires trouvés).\
Outils :

- **Dirb** / **Dirbuster** - Inclus dans Kali, **ancien** (et **lent**) mais fonctionnel. Permet certificats auto-signés et recherche recursive. Trop lent comparé aux autres options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Il n'autorise pas les certificats auto-signés mais** permet la recherche recursive.
- [**Gobuster**](https://github.com/OJ/gobuster) (go) : Il permet les certificats auto-signés, il **n'a pas** de recherche **récursive**.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Rapide, supporte la recherche récursive.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Rapide: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python) : Ce n'est pas un spider mais un outil qui, donné la liste d'URLs trouvées, supprime les URLs "dupliquées".
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger) : Burp Extension pour créer une liste de répertoires depuis l'historique Burp de différentes pages.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor) : Remove les URLs avec des fonctionnalités dupliquées (basé sur les imports js).
- [**Chamaleon**](https://github.com/iustin24/chameleon) : Utilise wapalyzer pour détecter les technologies utilisées et sélectionner les wordlists à utiliser.

**Dictionnaires recommandés :**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker) : Trouve les liens brisés dans les HTML qui peuvent être susceptibles de takeover.
- **File Backups** : Une fois que vous avez trouvé tous les fichiers, cherchez des backups de tous les fichiers exécutables ("_.php_", "_.aspx_"...). Variations communes pour nommer un backup : _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ Vous pouvez aussi utiliser l'outil [**bfac**](https://github.com/mazen160/bfac) **ou** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters** : Vous pouvez utiliser des outils comme [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **et** [**Param Miner**](https://github.com/PortSwigger/param-miner) **pour découvrir des paramètres cachés. Si possible, essayez de chercher** des paramètres cachés sur chaque fichier web exécutable.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments :** Vérifiez les commentaires de tous les fichiers, vous pouvez y trouver des **credentials** ou des **fonctionnalités cachées**.
- Si vous jouez en **CTF**, une astuce "classique" est de **cacher** des **informations** dans des commentaires à droite de la **page** (en utilisant des **centaines** d'**espaces** pour que les données ne soient pas visibles si vous ouvrez le source avec le navigateur). Autre possibilité : utiliser **plusieurs lignes** et **cacher des informations** dans un commentaire en bas de la page web.
- **API keys** : Si vous **trouvez une API key** il existe des guides qui indiquent comment utiliser les API keys pour différentes plateformes : [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys : Si vous trouvez une API key qui ressemble à **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik vous pouvez utiliser le projet [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) pour vérifier à quelles APIs la key donne accès.
- **S3 Buckets** : Pendant le spidering, regardez si un **subdomain** ou un **lien** est lié à un **S3 bucket**. Dans ce cas, [**vérifiez** les **permissions** du bucket](buckets/index.html).

### Special findings

**Pendant** le **spidering** et le **brute-forcing** vous pouvez trouver des **éléments intéressants** qu'il faut **noter**.

**Fichiers intéressants**

- Cherchez des **liens** vers d'autres fichiers à l'intérieur des fichiers **CSS**.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Si vous trouvez un _**.env**_ des informations telles que api keys, mots de passe db et autres peuvent être trouvées.
- Si vous trouvez des **API endpoints** vous [should also test them](web-api-pentesting.md). Ce ne sont pas des fichiers, mais ressembleront probablement à tels.
- **JS files** : Dans la section spidering plusieurs outils capables d'extraire des paths depuis les fichiers JS ont été mentionnés. Il serait aussi intéressant de **monitorer chaque fichier JS trouvé**, car dans certaines occasions un changement peut indiquer qu'une vulnérabilité potentielle a été introduite dans le code. Vous pouvez utiliser par exemple [**JSMon**](https://github.com/robre/jsmon)**.**
- Vous devriez aussi vérifier les JS découverts avec [**RetireJS**](https://github.com/retirejs/retire.js/) ou [**JSHole**](https://github.com/callforpapers-source/jshole) pour voir s'ils sont vulnérables.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Dans plusieurs cas, vous devrez **comprendre les expressions régulières** utilisées. Cela peut être utile : [https://regex101.com/](https://regex101.com) ou [https://pythonium.net/regex](https://pythonium.net/regex)
- Vous pouvez aussi **monitorer les fichiers contenant des forms**, car un changement de paramètre ou l'apparition d'un nouveau form peut indiquer une nouvelle fonctionnalité potentiellement vulnérable.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Si une page **répond** avec ce **code**, c'est probablement un **proxy mal configuré**. **Si vous envoyez une requête HTTP comme : `GET https://google.com HTTP/1.1`** (avec le header host et d'autres headers courants), le **proxy** tentera d'**accéder** à _**google.com**_ **et vous aurez trouvé un** SSRF.

**NTLM Authentication - Info disclosure**

Si le serveur qui demande l'authentification est **Windows** ou si vous trouvez un login demandant vos **credentials** (et demandant le **nom** de **domaine**), vous pouvez provoquer une **divulgation d'information**.\
**Envoyez** le **header** : `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` et à cause du fonctionnement de l'**NTLM authentication**, le serveur répondra avec des infos internes (version IIS, version Windows...) dans le header "WWW-Authenticate".\
Vous pouvez **automatiser** cela avec le **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Il est possible de **mettre du contenu** à l'intérieur d'une **Redirection**. Ce contenu **ne sera pas montré à l'utilisateur** (le navigateur effectuera la redirection) mais quelque chose peut être **caché** dedans.

### Web Vulnerabilities Checking

Maintenant qu'une énumération complète de l'application web a été effectuée, il est temps de vérifier de nombreuses vulnérabilités possibles. Vous pouvez trouver la checklist ici :


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Trouvez plus d'infos sur les vuln web dans :

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Vous pouvez utiliser des outils comme [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) pour monitorer des pages et détecter des modifications qui pourraient introduire des vulnérabilités.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
