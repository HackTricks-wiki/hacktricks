# 80,443 - Pentesting Web Methodology

{{#include ../../banners/hacktricks-training.md}}

## बुनियादी जानकारी

Web service सबसे अधिक **common and extensive service** है और बहुत से **different types of vulnerabilities** मौजूद हैं।

**डिफ़ॉल्ट पोर्ट:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API मार्गदर्शन


{{#ref}}
web-api-pentesting.md
{{#endref}}

## कार्यप्रणाली सारांश

> इस कार्यप्रणाली में हम मानकर चलेंगे कि आप एक डोमेन (या सबडोमेन) पर ही हमला कर रहे हैं और केवल उसे ही। इसलिए, इस कार्यप्रणाली को दायर में पाए गए हर डोमेन, सबडोमेन या अनिश्चित वेब सर्वर वाले IP पर लागू करें।

- [ ] शुरू करें: वेब सर्वर द्वारा उपयोग की जाने वाली **प्रौद्योगिकियों** की **पहचान** करें। यदि आप सफलतापूर्वक tech की पहचान कर लेते हैं तो बाकी टेस्ट के दौरान ध्यान में रखने के लिए कुछ **tricks** खोजें।
- [ ] उस प्रौद्योगिकी के संस्करण की कोई **known vulnerability** तो नहीं?
- [ ] कोई **well known tech** उपयोग में है? अधिक जानकारी निकालने के लिए कोई उपयोगी **trick** तो नहीं?
- [ ] चलाने के लिए कोई **specialised scanner** उपलब्ध है (जैसे wpscan)?
- [ ] सामान्य प्रयोजन के **scanners** चलाएँ। पता नहीं वे कुछ खोज पाएं या कुछ रोचक जानकारी दें।
- [ ] प्रारम्भिक चेक्स से शुरू करें: **robots**, **sitemap**, **404** error और **SSL/TLS scan** (यदि HTTPS)।
- [ ] वेब पेज की **spidering** शुरू करें: अब सभी संभावित **files, folders** और उपयोग में आने वाले **parameters** खोजने का समय है। साथ ही **special findings** की जाँच करें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory मिलता है, तो उसे spider किया जाना चाहिए।_
- [ ] **Directory Brute-Forcing**: खोजे गए सभी folders पर brute force करके नए **files** और **directories** तलाशें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory मिलता है, तो उसे Brute-Forced किया जाना चाहिए।_
- [ ] **Backups checking**: सामान्य backup extensions जोड़कर खोजे गए फाइलों के **backups** मिलते हैं या नहीं, जाँचें।
- [ ] **Brute-Force parameters**: छिपे हुए parameters खोजने की कोशिश करें।
- [ ] एक बार जब आपने सभी संभावित **endpoints** को जो **user input** स्वीकार करते हैं पहचान लिया, तो उनसे संबंधित सभी प्रकार की **vulnerabilities** की जाँच करें।
- [ ] [इस चेकलिस्ट का पालन करें](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

जाँचें कि चल रहे सर्वर के उस **version** के लिए कोई **known vulnerabilities** तो नहीं।\
प्रत्युत्तर के **HTTP headers and cookies** technologies और/या version की **identify** करने में बहुत उपयोगी हो सकते हैं। **Nmap scan** सर्वर संस्करण की पहचान कर सकता है, लेकिन निम्न tools भी उपयोगी हो सकते हैं: [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech**](https://github.com/ShielderSec/webtech) या [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
खोजें **के लिए** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **जाँचें क्या कोई WAF है**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### वेब तकनीक तरकीबें

इस्तेमाल हो रही विभिन्न प्रसिद्ध **technologies** में **finding vulnerabilities** के लिए कुछ **tricks**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_ध्यान रखें कि वही **same domain** विभिन्न **different technologies** अलग-अलग **ports**, **folders** और **subdomains** में उपयोग कर सकता है._\
यदि वेब एप्लिकेशन किसी ज्ञात **tech/platform listed before** या **any other** का उपयोग कर रही है, तो नए tricks के लिए इंटरनेट पर खोजना न भूलें (और मुझे बताएं!).

### Source Code Review

यदि एप्लिकेशन का **source code** GitHub पर उपलब्ध है, तो अपने द्वारा एप्लिकेशन का **White box test** करने के अलावा कुछ जानकारी है जो वर्तमान **Black-Box testing** के लिए उपयोगी हो सकती है:

- क्या कोई **Change-log or Readme or Version** file या कोई भी चीज़ है जिसमें **version info accessible** वेब के माध्यम से उपलब्ध हो?
- **credentials** कैसे और कहाँ सेव हैं? क्या कोई (accessible?) **file** है जिसमें credentials (usernames or passwords) हैं?
- क्या **passwords** **plain text** में हैं, **encrypted** हैं या कौन सा **hashing algorithm** उपयोग किया गया है?
- क्या यह किसी चीज़ को encrypt करने के लिए किसी **master key** का उपयोग कर रहा है? कौन सा **algorithm** उपयोग किया जा रहा है?
- क्या आप किसी vulnerability का exploit करके **access any of these files** कर सकते हैं?
- क्या **interesting information in the github** (solved and not solved) **issues** में है? या **commit history** में (शायद कोई **password introduced inside an old commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### General purpose automatic scanners
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS स्कैनर

यदि CMS का उपयोग किया गया है तो **एक स्कैनर चलाना** न भूलें — शायद कुछ दिलचस्प मिल जाए:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** वेबसाइट्स के सुरक्षा मुद्दों के लिए। (GUI)\  
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **या** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> इस बिंदु पर आपके पास पहले से ही client द्वारा उपयोग किए जा रहे web server के बारे में कुछ जानकारी होनी चाहिए (यदि कोई डेटा दिया गया है) और टेस्ट के दौरान ध्यान में रखने के लिए कुछ ट्रिक्स। अगर आप भाग्यशाली हैं तो आपने किसी CMS को भी ढूँढ लिया होगा और कोई scanner चला रखा होगा।

## चरण-दर-चरण Web Application Discovery

> इस बिंदु से हम web application के साथ इंटरैक्ट करना शुरू करेंगे।

### प्रारंभिक जाँच

**रुचिकर जानकारी वाले डिफ़ॉल्ट पृष्ठ:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- मुख्य और द्वितीयक पृष्ठों में टिप्पणियाँ भी जांचें।

**त्रुटियाँ उत्पन्न करना**

Web servers अजीब data मिलने पर **बेहद असामान्य व्यवहार** कर सकते हैं। इससे **vulnerabilities** खुल सकती हैं या **sensitive जानकारी का disclosure** हो सकता है।

- ऐसे **fake pages** को एक्सेस करें जैसे /whatever_fake.php (.aspx,.html,.etc)
- **Add "[]", "]]", and "[["** को **cookie values** और **parameter** values में डालकर errors बनाएं
- **`/~randomthing/%s`** जैसा input देकर URL के **end** पर error जनरेट करें
- PATCH, DEBUG जैसे विभिन्न **HTTP Verbs** ट्राई करें या FAKE जैसे गलत verbs भेजकर देखें

#### **Check if you can upload files (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

यदि आपको पता चलता है कि **WebDav** **enabled** है पर root folder में **uploading files** की पर्याप्त permissions नहीं हैं तो प्रयास करें:

- **Brute Force** credentials
- WebDav के माध्यम से **Upload files** करें वे हिस्से में जो web page के अंदर मिले हुए अन्य folders हैं। हो सकता है कि अन्य folders में upload करने की permissions हों।

### **SSL/TLS कमजोरियाँ**

- यदि application किसी भी हिस्से में user को **HTTPS** के उपयोग के लिए मजबूर नहीं कर रही है, तो यह **MitM** के लिए vulnerable है
- यदि application **HTTP** का उपयोग करके **sensitive data (passwords)** भेज रही है, तो यह एक उच्च vulnerability है।

[**testssl.sh**](https://github.com/drwetter/testssl.sh) का उपयोग **vulnerabilities** के लिए जांच करने के लिए करें (Bug Bounty programs में संभवतः इस तरह की vulnerabilities स्वीकार नहीं की जाएंगी) और vulnerabilities को फिर से चेक करने के लिए [**a2sv**](https://github.com/hahwul/a2sv) का उपयोग करें:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

वेब के अंदर किसी तरह का **spider** लॉन्च करें। spider का उद्देश्य टेस्ट किए गए एप्लिकेशन से जितने संभव हो उतने paths खोजना है। इसलिए, web crawling और external sources का उपयोग करके जितने भी valid paths मिल सकें उन्हें इकट्ठा किया जाना चाहिए।

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, JS files में LinkFinder और external sources (Archive.org, CommonCrawl.org, VirusTotal.com) को देखता है।
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HTML spider, JS files के लिए LinkFinder और Archive.org को external source के रूप में उपयोग करता है।
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, और "juicy files" भी इंगित करता है।
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider। यह Archive.org में भी खोज करता है।
- [**meg**](https://github.com/tomnomnom/meg) (go): यह टूल spider नहीं है पर उपयोगी हो सकता है। आप hosts की सूची और paths की फाइल दे सकते हैं और meg हर host पर हर path को fetch करके response सहेज लेगा।
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS rendering capabilities वाला HTML spider। हालांकि लगता है यह unmaintained है, precompiled version पुराना है और current code compile नहीं होता।
- [**gau**](https://github.com/lc/gau) (go): HTML spider जो external providers (wayback, otx, commoncrawl) का उपयोग करता है।
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): यह script URLs में parameters ढूंढेगा और उन्हें list करेगा।
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS rendering capabilities वाला HTML spider।
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, JS beautify क्षमताओं के साथ जो JS files में नए paths खोज सकता है। [JSScanner](https://github.com/dark-warlord14/JSScanner) भी देखकर लें, यह LinkFinder का wrapper है।
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): HTML source और embedded javascript files दोनों से endpoints निकालने के लिए। bug hunters, red teamers, infosec ninjas के लिए उपयोगी।
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Tornado और JSBeautifier का उपयोग करके JavaScript files से relative URLs parse करने वाली python 2.7 script। AJAX requests ढूंढने में उपयोगी। लगता है unmaintained है।
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): किसी file (HTML) को लेकर उसमें से relative URLs निकालने के लिए nifty regular expression का उपयोग करता है, खासकर minified files से।
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): कई tools का उपयोग करके JS files से interesting information इकट्ठा करता है।
- [**subjs**](https://github.com/lc/subjs) (go): JS files ढूंढता है।
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): headless browser में एक page load करके उस page को load करने वाले सभी urls print करता है।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): content discovery tool जो ऊपर के कई विकल्पों का मिश्रण है।
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS files में path और params खोजने के लिए Burp extension।
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): यदि .js.map URL दिया हो तो beautified JS code लेकर आता है।
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): किसी target के लिए endpoints खोजने वाला टूल।
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** wayback machine से links खोजें (wayback में responses को download करके और वहां और links खोजकर)।
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl करता है (forms भरकर भी) और specific regexes का उपयोग करके sensitive info भी ढूंढता है।
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite एक advanced multi-feature GUI web security Crawler/Spider है जो cyber security professionals के लिए डिज़ाइन किया गया है।
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): Go package और [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) है जो JavaScript source code से URLs, paths, secrets और अन्य interesting data निकालता है।
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge एक simple **Burp Suite extension** है जो request से parameters और endpoints **extract** करके fuzzing और enumeration के लिए custom wordlist बनाने में मदद करता है।
- [**katana**](https://github.com/projectdiscovery/katana) (go): इस कार्य के लिए एक बढ़िया tool।
- [**Crawley**](https://github.com/s0rg/crawley) (go): यह हर link को print करता है जो यह ढूंढ पाए।

### Brute Force directories and files

root folder से **brute-forcing** शुरू करें और सुनिश्चित करें कि इस method से मिले सभी directories और **Spidering** द्वारा discovered सभी directories को brute-force किया गया है (आप इसे recursively करके कर सकते हैं और उपयोग की गई wordlist के शुरू में मिले हुए directories के नाम जोड़ सकते हैं).\
Tools:

- **Dirb** / **Dirbuster** - Kali में शामिल, **old** (और **slow**) पर functional। auto-signed certificates और recursive search allow करते हैं। दूसरों के मुकाबले बहुत slow।
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: यह auto-signed certificates allow नहीं करता पर recursive search allow करता है।
- [**Gobuster**](https://github.com/OJ/gobuster) (go): auto-signed certificates allow करता है, पर इसमें **recursive** search नहीं है।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): यह spider नहीं है पर यह दिए गए URLs की list लेकर "duplicated" URLs हटाने का काम करता है।
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension जो burp history से directories की list बनाता है।
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): js imports के आधार पर duplicated functionalities वाले URLs हटाता है।
- [**Chamaleon**](https://github.com/iustin24/chameleon): यह wapalyzer का उपयोग करके technologies detect करता है और उपयुक्त wordlists चुनता है।

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_नोट: जब भी कोई नया directory brute-forcing या spidering के दौरान मिलता है, उसे भी Brute-Force किया जाना चाहिए._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTMLs के अंदर broken links खोजें जो takeover के लिए prone हो सकते हैं।
- **File Backups**: सभी files मिल जाने के बाद, executable files के backups ढूंढें ("_.php_", "_.aspx_"...). backup नामकरण के सामान्य variations हैं: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp और file.old._ आप tool [**bfac**](https://github.com/mazen160/bfac) **या** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)** का भी उपयोग कर सकते हैं।  
- **Discover new parameters**: आप छिपे हुए parameters खोजने के लिए [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **और** [**Param Miner**](https://github.com/PortSwigger/param-miner) का उपयोग कर सकते हैं। यदि संभव हो तो प्रत्येक executable web file में hidden parameters खोजने की कोशिश करें।
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** सभी files के comments जाँचें, आप वहां से **credentials** या **hidden functionality** पा सकते हैं।
- यदि आप **CTF** खेल रहे हैं, तो एक सामान्य trick यह है कि page के source में comments में जानकारी छिपा दी जाए (सही तरफ सैकड़ों spaces का उपयोग करके ताकि browser में source खोलने पर दिखाई न दे)। एक और तरीका कई नए lines का उपयोग कर पेज के नीचे comment में जानकारी छिपाना है।
- **API keys**: अगर आपको कोई API key मिलती है तो विभिन्न platforms की API keys कैसे उपयोग की जाए पर मार्गदर्शक मौजूद हैं: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: अगर आपको कोई API key जो **AIza** से शुरू होती दिखे जैसे **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik तो आप यह देखने के लिए [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) का उपयोग कर सकते हैं कि key किन APIs को access कर सकती है।
- **S3 Buckets**: spidering के दौरान देखें कि कोई subdomain या कोई link किसी S3 bucket से संबंधित तो नहीं। ऐसी स्थिति में, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**Spidering** और **brute-forcing** करते समय आपको कुछ **interesting** चीजें मिल सकती हैं जिनका ध्यान रखना आवश्यक है।

**Interesting files**

- CSS files के अंदर अन्य files के **links** खोजें।
- [If you find a _**.git**_ file some information can be extracted](git.md)
- यदि आपको _**.env**_ मिलती है तो उसमें api keys, dbs passwords और अन्य जानकारी मिल सकती है।
- यदि आपको **API endpoints** मिलते हैं तो आप [उन्हें भी टेस्ट करें](web-api-pentesting.md). ये files नहीं हैं, पर अक्सर ऐसा दिखते हैं।
- **JS files**: spidering section में कई tools बताए गए हैं जो JS files से paths निकाल सकते हैं। इसके अलावा, यह उपयोगी होगा कि हर मिले JS file की monitoring की जाए, क्योंकि कुछ मामलों में किसी फ़ाइल में बदलाव यह दिखा सकता है कि कोड में संभावित vulnerability आ गई है। आप उदाहरण के लिए [**JSMon**](https://github.com/robre/jsmon)** का उपयोग कर सकते हैं।**
- आप मिलने वाली JS files को [**RetireJS**](https://github.com/retirejs/retire.js/) या [**JSHole**](https://github.com/callforpapers-source/jshole) से भी जाँचें कि क्या वे vulnerable हैं।
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- कई बार आपको उपयोग की गई regular expressions को समझना होगा। यह उपयोगी होगा: [https://regex101.com/](https://regex101.com) या [https://pythonium.net/regex](https://pythonium.net/regex)
- आप उन files की भी monitoring कर सकते हैं जहाँ forms detect हुए थे, क्योंकि किसी parameter में बदलाव या नई form की उपस्थिति यह इंगित कर सकती है कि कोई नई vulnerable functionality आ गई है।

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

अगर किसी page का response वही code देता है, तो हो सकता है कि proxy गलत तरीके से configured हो। अगर आप एक HTTP request भेजें जैसे: `GET https://google.com HTTP/1.1` (host header और अन्य सामान्य headers के साथ), तो proxy कोशिश करेगा _**google.com**_ तक पहुँचने की और इस तरह आप एक SSRF पा सकते हैं।

**NTLM Authentication - Info disclosure**

यदि running server authentication माँग रहा है और वह **Windows** है या आपको ऐसा login दिखाई दे रहा है जो आपके **credentials** मांगता है (और **domain** **name** पूछता है), तो आप information disclosure provoke कर सकते हैं।\
`“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` header भेजें और NTLM authentication के काम करने के तरीके के कारण server header "WWW-Authenticate" के अंदर internal info (IIS version, Windows version...) बताएगा।\
आप इसे automate करने के लिए **nmap plugin** "_http-ntlm-info.nse_" का उपयोग कर सकते हैं।

**HTTP Redirect (CTF)**

Redirection के अंदर content डालना संभव है। यह content user को दिखाई नहीं देगा (क्योंकि browser redirection execute कर देगा) पर वहां कुछ छिपा हुआ हो सकता है।

### Web Vulnerabilities Checking

अब जब web application का comprehensive enumeration हो चुका है तो अब बहुत सी संभावित vulnerabilities की जाँच करने का समय है। आप checklist यहाँ पाएंगे:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Web vulns के बारे में और जानकारी:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

आप modifications के लिए pages को monitor करने के लिए [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) जैसे tools का उपयोग कर सकते हैं, जो vulnerabilities डालने वाले बदलावों का पता लगा सकते हैं।

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
