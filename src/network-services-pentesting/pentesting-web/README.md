# 80,443 - Pentesting Web Metodolojisi

{{#include ../../banners/hacktricks-training.md}}

## Temel Bilgiler

Web hizmeti en **yaygın ve kapsamlı servis**dir ve birçok **farklı türde zafiyet** mevcuttur.

**Varsayılan port:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API Kılavuzu


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Metodoloji özeti

> Bu metodolojide bir domain (veya subdomain) ve yalnızca ona saldıracağınızı varsayacağız. Bu nedenle, bu metodolojiyi kapsam içindeki her keşfedilen domain, subdomain veya web sunucusu belirsiz olan IP için uygulamalısınız.

- [ ] Başlangıç olarak web sunucusu tarafından kullanılan **teknolojileri** **tanımlayın**. Teknolojiyi başarılı bir şekilde tespit edebilirseniz testin geri kalanında akılda tutulması gereken **püf noktalarını** arayın.
- [ ] Teknolojinin sürümünde bilinen herhangi bir **zafiyet** var mı?
- [ ] Herhangi bir **iyi bilinen teknoloji** mi kullanılıyor? Daha fazla bilgi çıkarmak için herhangi bir **yararlı püf noktası** var mı?
- [ ] Çalıştırılması gereken herhangi bir **özel tarayıcı** var mı (ör. wpscan)?
- [ ] Genel amaçlı **tarayıcıları** çalıştırın. Bir şeyler bulup bulmayacaklarını veya ilginç bilgi elde edip etmeyeceklerini bilemezsiniz.
- [ ] **İlk kontroller** ile başlayın: **robots**, **sitemap**, **404** hatası ve **SSL/TLS scan** (HTTPS ise).
- [ ] Web sayfasını **spidering** ile taramaya başlayın: Kullanılan tüm olası **dosyaları, dizinleri** ve **parametreleri** bulma zamanı. Ayrıca **özel bulguları** kontrol edin.
- [ ] _Unutmayın: brute-forcing veya spidering sırasında yeni bir dizin keşfedildiğinde, bu dizin spidering ile taranmalıdır._
- [ ] **Directory Brute-Forcing**: Keşfedilen tüm klasörleri brute-force ile tarayarak yeni **dosyalar** ve **dizinler** arayın.
- [ ] _Unutmayın: brute-forcing veya spidering sırasında yeni bir dizin keşfedildiğinde, bu dizin Brute-Forced edilmelidir._
- [ ] **Backups checking**: Keşfedilen dosyaların yaygın yedek uzantıları ekleyerek **yedeklerini** bulup bulamayacağınızı test edin.
- [ ] **Brute-Force parameters**: Gizli parametreleri **bulmaya** çalışın.
- [ ] Tüm olası **kullanıcı girişi kabul eden uç noktaları** belirledikten sonra, bunlarla ilgili tüm türdeki **zafiyetleri** kontrol edin.
- [ ] [Bu kontrol listesini takip edin](../../pentesting-web/web-vulnerabilities-methodology.md)

## Sunucu Sürümü (Kırılgan mı?)

### Tespit

Çalışan sunucu **sürümü** için bilinen herhangi bir **zafiyet** olup olmadığını kontrol edin.\
**HTTP headers** ve yanıtın **cookies**'leri, kullanılan **teknolojileri** ve/veya **sürümü** **tanımlamak** için çok faydalı olabilir. **Nmap scan** sunucu sürümünü tespit edebilir, ancak [**whatweb**](https://github.com/urbanadventurer/WhatWeb), [**webtech**](https://github.com/ShielderSec/webtech) veya [**https://builtwith.com/**](https://builtwith.com) gibi araçlar da faydalı olabilir:
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Ara **için** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Herhangi bir WAF var mı**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web teknoloji hileleri

Kullanılan farklı ve iyi bilinen **teknolojilerde** **zafiyetleri bulma** için bazı **hileler**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Take into account that the **same domain** can be using **different technologies** in different **ports**, **folders** and **subdomains**._\
Eğer web uygulaması listelenen herhangi bir tanınmış **teknoloji/platform** veya başka bir teknoloji kullanıyorsa, yeni hileleri İnternette **aramayı** unutmayın (ve bana bildirin!).

### Kaynak Kod İncelemesi

Eğer uygulamanın **source code**'u **github** üzerinde erişilebilir durumdaysa, kendi yaptığınız bir **White box** testinin dışında mevcut **Black-Box testing** için faydalı olabilecek **bazı bilgiler** bulunabilir:

- Web üzerinde erişilebilir bir **Change-log or Readme or Version** dosyası ya da herhangi bir **version info accessible** var mı?
- **credentials** nasıl ve nerede saklanıyor? Herhangi bir (erişilebilir?) **file** içinde credentials (kullanıcı adları veya parolalar) var mı?
- **passwords** **plain text** halinde mi, **encrypted** mi yoksa hangi **hashing algorithm** kullanılmış?
- Bir şeyi şifrelemek için herhangi bir **master key** kullanılıyor mu? Hangi **algorithm** kullanılmış?
- Bazı zafiyetleri kullanarak bu **dosyalardan herhangi birine erişebiliyor musunuz**?
- **github**'de (çözülen ve çözülmeyen) **issues** içinde ilginç bilgiler var mı? Veya **commit history**'de (belki eski bir commit içinde tanımlanmış bir **password**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Otomatik tarayıcılar

#### Genel amaçlı otomatik tarayıcılar
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS scanners

Eğer bir CMS kullanılıyorsa **run a scanner** yapmayı unutmayın; belki işe yarar bir şey bulunur:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** web sitelerini güvenlik sorunları için tarar. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **veya** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Bu noktada, eğer herhangi bir veri verilmişse, muhtemelen istemcinin kullandığı web sunucusu hakkında bazı bilgilere ve test sırasında akılda tutulması gereken birkaç püf noktasına sahipsiniz. Şanslıysanız bir CMS bulmuş ve bir scanner çalıştırmışsınızdır.

## Adım adım Web Uygulaması Keşfi

> Bu noktadan itibaren web uygulamasıyla etkileşime geçmeye başlayacağız.

### İlk kontroller

**İlginç bilgi içeren varsayılan sayfalar:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Ana ve ikincil sayfalardaki yorumları da kontrol edin.

**Hata oluşturma**

Web sunucuları garip veri gönderildiğinde **beklenmedik şekilde davranabilir**. Bu, **zafiyetlere** veya **hassas bilgilerin açığa çıkmasına** neden olabilir.

- /whatever_fake.php (.aspx,.html,.etc) gibi **sahte sayfalara** erişin
- Hata oluşturmak için **cookie değerlerine** ve **parametre** değerlerine "[]", "]]" ve "[[" ekleyin
- URL'nin **sonuna** **`/~randomthing/%s`** gibi bir girdi vererek hata üretin
- PATCH, DEBUG gibi farklı HTTP verb'larını deneyin veya FAKE gibi yanlış verb'lar kullanın

#### **Check if you can upload files (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Eğer **WebDav**'ın **aktif** olduğunu fakat kök dizine dosya yüklemek için yeterli izniniz olmadığını görürseniz şunları deneyin:

- **Brute Force** credentials
- Web sayfası içindeki bulunan diğer klasörlerin **rest**ine WebDav ile **dosya yükleyin**. Diğer klasörlere dosya yükleme izniniz olabilir.

### **SSL/TLS zafiyetleri**

- Uygulama herhangi bir bölümde **HTTPS kullanımını zorlamıyorsa**, o zaman **MitM'e karşı savunmasızdır**
- Uygulama **hassas verileri (passwords) HTTP üzerinden gönderiyorsa**, bu yüksek dereceli bir zafiyettir.

Zafiyetleri kontrol etmek için [**testssl.sh**](https://github.com/drwetter/testssl.sh) kullanın (Bug Bounty programlarında muhtemelen bu tür zafiyetler kabul edilmeyecektir) ve zafiyetleri yeniden kontrol etmek için [**a2sv**](https://github.com/hahwul/a2sv) kullanın:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Web içinde bir tür **spider** başlatın. Spider'ın amacı test edilen uygulamadan mümkün olduğunca çok yol **bulmaktır**. Bu nedenle, web crawling ve harici kaynaklar kullanılarak mümkün olduğunca çok geçerli yol bulunmalıdır.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, JS dosyalarındaki LinkFinder ve harici kaynaklar (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, JS dosyaları için LinkFider ile ve Archive.org'u harici kaynak olarak kullanır.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, ayrıca "juicy files" gösterir.
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Etkileşimli CLI HTML spider. Ayrıca Archive.org'da arama yapar.
- [**meg**](https://github.com/tomnomnom/meg) (go): Bu araç bir spider değil ama faydalı olabilir. Bir hosts dosyası ve bir paths dosyası belirtebilir, meg her host üzerindeki her path'i çeker ve yanıtı kaydeder.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS render yeteneklerine sahip HTML spider. Ancak, bakılınca bakım yapılmıyor gibi görünüyor, önceden derlenmiş sürüm eski ve mevcut kod derlenmiyor.
- [**gau**](https://github.com/lc/gau) (go): Harici sağlayıcıları (wayback, otx, commoncrawl) kullanan HTML spider.
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): URL'lerde parametreleri bulur ve listeler.
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS render yeteneklerine sahip HTML spider.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, JS beautify yetenekleriyle JS dosyalarında yeni yollar arayabilir. Ayrıca LinkFinder'ın bir sarmalayıcısı olan [JSScanner](https://github.com/dark-warlord14/JSScanner)'a da bakmak faydalı olabilir.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Hem HTML kaynağından hem gömülü javascript dosyalarından endpoint çıkarmak için. Bug avcıları, red team ve infosec profesyonelleri için faydalı.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Tornado ve JSBeautifier kullanan, JavaScript dosyalarından relatif URL'leri parse eden python 2.7 scripti. AJAX isteklerini keşfetmek için kullanışlı. Bakımı yapılmıyor gibi görünüyor.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Verilen bir dosyadan (HTML) minify edilmiş dosyalardan relatif URL'leri çıkarmak için düzenli ifadeler kullanır.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Birkaç araç kullanarak JS dosyalarından ilginç bilgiler toplar.
- [**subjs**](https://github.com/lc/subjs) (go): JS dosyalarını bulur.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Bir sayfayı headless browser'da yükler ve sayfayı yüklemek için kullanılan tüm url'leri yazdırır.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Önceki araçların çeşitli seçeneklerini harmanlayan content discovery aracı.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS dosyalarında path ve param bulmak için bir Burp extension.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): .js.map URL'si verildiğinde beautified JS kodunu almanızı sağlayan araç.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Belirli bir hedef için endpoint keşfetmekte kullanılan araç.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** wayback machine'den linkler keşfeder (aynı zamanda wayback'teki yanıtları indirir ve daha fazla link arar).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Formları doldurmaya kadar tarama yapar ve ayrıca belirli regex'ler kullanarak hassas bilgileri bulur.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite, siber güvenlik profesyonelleri için tasarlanmış gelişmiş çok özellikli GUI web security Crawler/Spider'dır.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): JS kaynak kodundan URL, path, secret ve diğer ilginç verileri çıkarmak için Go paketi ve bir [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice).
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge, isteklerden parametreleri ve endpointleri çıkarmak için basit bir **Burp Suite extension**'dır; fuzzing ve enumeration için custom wordlist oluşturur.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Bu iş için müthiş bir araç.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Bulabildiği her linki yazdırır.

### Brute Force directories and files

Kök klasörden **brute-forcing** yapmaya başlayın ve bu yöntemle bulunan tüm **dizinleri** ve **Spidering** ile keşfedilen tüm dizinleri brute-force ettiğinizden emin olun (bunu **rekürsif** olarak yapabilir ve bulunan dizinlerin isimlerini kullanılan wordlist'in başına ekleyebilirsiniz).\
Araçlar:

- **Dirb** / **Dirbuster** - Kali'de dahil, **eski** (ve **yavaş**) ama işlevsel. Auto-signed sertifikalara izin verir ve recursive search destekler. Diğer seçeneklerle karşılaştırıldığında çok yavaş.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Auto-signed sertifikalara izin vermez ama recursive search sağlar.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Auto-signed sertifikalara izin verir, ancak **recursive** search özelliği **yoktur**.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Hızlı, recursive search destekler.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Hızlı: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Bu bir spider değil ama bulunan URL listesi verildiğinde "duplikat" URL'leri siler.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp geçmişinden farklı sayfaların dizin listesini oluşturmak için Burp Extension.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): JS importlarına dayalı olarak fonksiyonalite açısından duplikat URL'leri kaldırır.
- [**Chamaleon**](https://github.com/iustin24/chameleon): Wappalyzer kullanarak kullanılan teknolojileri tespit eder ve kullanılacak wordlistleri seçer.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Not: Yeni bir dizin brute-forcing ya da spidering sırasında keşfedildiğinde, o dizin her zaman Brute-Force edilmelidir._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTML içindeki kırık linkleri bulun; bunlar takeover'a yatkın olabilir.
- **File Backups**: Tüm dosyaları bulduktan sonra, yürütülebilir dosyaların (".php", ".aspx"...) yedeklerini arayın. Yedek isimlendirmede yaygın varyasyonlar: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp ve file.old._ Ayrıca [**bfac**](https://github.com/mazen160/bfac) **veya** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen) araçlarını kullanabilirsiniz.
- **Discover new parameters**: Gizli parametreleri keşfetmek için [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **ve** [**Param Miner**](https://github.com/PortSwigger/param-miner) gibi araçları kullanabilirsiniz. Mümkünse her yürütülebilir web dosyasında gizli parametreleri arayın.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Tüm dosyaların yorumlarını kontrol edin; burada **credentials** veya **gizli fonksiyonellik** bulunabilir.
- Eğer **CTF** oynuyorsanız, yaygın bir hile sayfa kaynağında sağ tarafa çok sayıda boşluk (veya birkaç yeni satır) koyup yorum içinde **bilgi gizlemek** olabilir; böylece tarayıcıda sayfayı açtığınızda bu veri görünmez.
- **API keys**: Herhangi bir API key bulursanız, farklı platformların API key'lerinin nasıl kullanılacağını gösteren rehberler vardır: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Eğer **AIza** ile başlayan bir API key bulursanız (ör. **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik), bu anahtarın hangi API'lere erişebildiğini kontrol etmek için [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) projesini kullanabilirsiniz.
- **S3 Buckets**: Spidering sırasında herhangi bir **subdomain** veya herhangi bir **link**in bir **S3 bucket** ile ilişkili olup olmadığına bakın. Böyle bir durum varsa, bucket izinlerini [**kontrol edin**](buckets/index.html).

### Special findings

**Spidering** ve **brute-forcing** yaparken fark etmeniz gereken **ilginç** **bulgular** olabilir.

**Interesting files**

- CSS dosyaları içinde diğer dosyalara **linkler** arayın.
- [Eğer bir _**.git**_ dosyası bulursanız bazı bilgiler çıkarılabilir](git.md)
- Eğer bir _**.env**_ bulursanız, api key'ler, db parolaları ve diğer bilgiler bulunabilir.
- Eğer **API endpoints** bulursanız, bunları [test etmelisiniz](web-api-pentesting.md). Bunlar dosya olmayabilir ama dosya gibi "görünebilir".
- **JS files**: Spidering bölümünde JS dosyalarından path çıkarabilen birçok araçtan bahsedildi. Ayrıca bulunan her JS dosyasını **monitor** etmek ilginç olabilir; çünkü bazı durumlarda bir değişiklik kodda potansiyel bir zafiyetin eklenmiş olmasına işaret edebilir. Örneğin [**JSMon**](https://github.com/robre/jsmon) kullanılabilir.
- Ayrıca keşfedilen JS dosyalarını zafiyet kontrolü için [**RetireJS**](https://github.com/retirejs/retire.js/) veya [**JSHole**](https://github.com/callforpapers-source/jshole) ile kontrol edin.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Birçok durumda kullanılan regular expression'ları anlamanız gerekecektir. Bu konuda faydalı siteler: [https://regex101.com/](https://regex101.com) veya [https://pythonium.net/regex](https://pythonium.net/regex)
- Formların tespit edildiği dosyaları da **monitor** edebilirsiniz; bir parametredeki değişiklik veya yeni bir formun ortaya çıkması potansiyel yeni bir zafiyete işaret edebilir.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Eğer herhangi bir sayfa bu **kodu** ile cevap veriyorsa, muhtemelen **kötü yapılandırılmış bir proxy** vardır. **Eğer** şu şekilde bir HTTP isteği gönderirseniz: `GET https://google.com HTTP/1.1` (host header ve diğer yaygın header'larla), **proxy** _**google.com**_'a erişmeye çalışacak ve bir SSRF bulmuş olacaksınız.

**NTLM Authentication - Info disclosure**

Eğer authentication isteyen sunucu **Windows** ise veya domain adı da isteyen bir login görürseniz, bir **bilgi sızıntısı** tetikleyebilirsiniz.\
Aşağıdaki **header**'ı gönderin: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` ve NTLM authentication'ın çalışma şekli nedeniyle, sunucu "WWW-Authenticate" header'ı içinde iç ağ bilgilerini (IIS versiyonu, Windows versiyonu...) cevap olarak döndürecektir.\
Bunu otomatikleştirmek için nmap plugin'i "_http-ntlm-info.nse_" kullanabilirsiniz.

**HTTP Redirect (CTF)**

Bir **Redirection** içine içerik koymak mümkündür. Bu içerik kullanıcıya gösterilmeyebilir (tarayıcı redirection'ı uygulayacağından) ama orada bir şey **gizlenmiş** olabilir.

### Web Vulnerabilities Checking

Web uygulamasının kapsamlı bir şekilde enumerasyonu yapıldıktan sonra, birçok olası zafiyet için kontroller yapılmalıdır. Kontrol listesi burada bulunabilir:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Web zafiyetleri hakkında daha fazla bilgi:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Sayfalardaki değişiklikleri izlemek için [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) gibi araçları kullanabilirsiniz; bu, sayfalara eklenen değişikliklerin zafiyet oluşturup oluşturmadığını takip etmenize yardımcı olur.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
