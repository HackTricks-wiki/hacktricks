# 80,443 - Méthodologie de pentesting Web

{{#include ../../banners/hacktricks-training.md}}

## Informations de base

Le service web est le service le plus **courant et étendu** et de nombreux **types différents de vulnérabilités** existent.

Port par défaut : 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Conseils pour Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Résumé de la méthodologie

> Dans cette méthodologie, nous supposerons que vous allez attaquer un domaine (ou sous-domaine) et uniquement celui-ci. Vous devez donc appliquer cette méthodologie à chaque domaine, sous-domaine ou IP découvert(e) avec un serveur web indéterminé dans le scope.

- [ ] Commencez par **identifier** les **technologies** utilisées par le serveur web. Cherchez des **tricks** à garder en tête pendant le reste du test si vous parvenez à identifier la tech.
- [ ] Existe-t-il une **known vulnerability** pour la version de la technologie ?
- [ ] Utilisez-vous une **well known tech** ? Un **useful trick** pour extraire plus d'informations ?
- [ ] Y a-t-il un **specialised scanner** à lancer (comme wpscan) ?
- [ ] Lancez des **general purposes scanners**. On ne sait jamais s'ils vont trouver quelque chose ou des informations intéressantes.
- [ ] Commencez par les **initial checks** : **robots**, **sitemap**, erreur **404** et **SSL/TLS scan** (si HTTPS).
- [ ] Commencez le **spidering** de la page web : c'est le moment de **trouver** tous les **fichiers, dossiers** et **paramètres utilisés.** Vérifiez aussi les **trouvailles particulières**.
- [ ] _Notez que chaque fois qu'un nouveau répertoire est découvert lors du brute-forcing ou du spidering, il doit être spidered._
- [ ] **Directory Brute-Forcing** : Essayez de brute-forcer tous les dossiers découverts en recherchant de nouveaux **fichiers** et **répertoires**.
- [ ] _Notez que chaque fois qu'un nouveau répertoire est découvert lors du brute-forcing ou du spidering, il doit être Brute-Forced._
- [ ] **Backups checking** : Testez si vous pouvez trouver des **backups** des **fichiers découverts** en ajoutant des extensions de sauvegarde courantes.
- [ ] **Brute-Force parameters** : Essayez de **trouver des paramètres cachés**.
- [ ] Une fois que vous avez **identifié** tous les **endpoints** possibles acceptant **user input**, vérifiez tous les types de **vulnerabilities** qui leur sont liés.
- [ ] [Suivez cette checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Version du serveur (Vulnérable ?)

### Identification

Vérifiez s'il existe des **known vulnerabilities** pour la version du serveur en cours d'exécution.\
Les **HTTP headers and cookies of the response** peuvent être très utiles pour **identifier** les **technologies** et/ou la **version** utilisée. Un **Nmap scan** peut identifier la version du serveur, mais les outils [**whatweb**](https://github.com/urbanadventurer/WhatWeb), [**webtech** ](https://github.com/ShielderSec/webtech) ou [**https://builtwith.com/**](https://builtwith.com) peuvent également être utiles :
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Rechercher **pour** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Vérifier s'il y a un WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Astuces techniques Web

Quelques **astuces** pour **trouver des vulnérabilités** dans différentes **technologies** bien connues utilisées :

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)

_Prenez en compte que le **même domaine** peut utiliser **différentes technologies** sur différents **ports**, **dossiers** et **sous-domaines**._\
Si l'application web utilise l'une des **technologies/plateformes listées ci‑dessus** ou **une autre**, n'oubliez pas de **chercher sur Internet** de nouvelles astuces (et faites‑m'en part !).

### Revue du code source

Si le **code source** de l'application est disponible sur **github**, en plus d'effectuer par vous‑même un White box test de l'application, il existe **des informations** qui pourraient être **utiles** pour le présent **Black-Box testing** :

- Existe‑t‑il un fichier **Change-log or Readme or Version** ou autre contenant des **version info accessible** via le web ?
- Comment et où sont sauvegardées les **credentials** ? Y a‑t‑il un (fichier accessible ?) **file** avec des credentials (usernames or passwords) ?
- Les **passwords** sont‑ils en **plain text**, **encrypted** ou quel **hashing algorithm** est utilisé ?
- Utilise‑t‑elle une **master key** pour chiffrer quelque chose ? Quel **algorithm** est utilisé ?
- Pouvez‑vous **access any of these files** en exploitant une vulnérabilité ?
- Y a‑t‑il des **informations intéressantes dans le github** (issues résolues ou non) ? Ou dans l'**commit history** (peut‑être un **password** introduit dans un ancien commit) ?

{{#ref}}
code-review-tools.md
{{#endref}}

### Scanners automatiques

#### Scanners automatiques à usage général
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Scanners CMS

Si un CMS est utilisé, n'oubliez pas de **lancer un scanner**, vous pourriez y trouver quelque chose d'intéressant :

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** sites web pour détecter des problèmes de sécurité. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **ou** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> À ce stade vous devriez déjà disposer de certaines informations sur le serveur web utilisé par le client (si des données sont fournies) et de quelques astuces à garder en tête pendant le test. Si vous avez de la chance, vous avez même trouvé un CMS et exécuté un scanner.

## Step-by-step Web Application Discovery

> From this point we are going to start interacting with the web application.

### Initial checks

**Default pages with interesting info:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Check also comments in the main and secondary pages.

**Forcing errors**

Web servers may **behave unexpectedly** when weird data is sent to them. This may open **vulnerabilities** or **disclosure sensitive information**.

- Access **fake pages** like /whatever_fake.php (.aspx,.html,.etc)
- **Add "\[]", "]]", and "\[["** in **cookie values** and **parameter** values to create errors
- Generate error by giving input as **`/~randomthing/%s`** at the **end** of **URL**
- Try **different HTTP Verbs** like PATCH, DEBUG or wrong like FAKE

#### **Vérifiez si vous pouvez téléverser des fichiers (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

If you find that **WebDav** is **enabled** but you don't have enough permissions for **uploading files** in the root folder try to:

- **Brute Force** des identifiants
- **Téléversez des fichiers** via WebDav dans les **autres** **dossiers trouvés** sur la page web. Vous pourriez avoir la permission de téléverser des fichiers dans d'autres dossiers.

### **Vulnérabilités SSL/TLS**

- If the application **isn't forcing the user of HTTPS** in any part, then it's **vulnerable to MitM**
- If the application is **sending sensitive data (passwords) using HTTP**. Then it's a high vulnerability.

Use [**testssl.sh**](https://github.com/drwetter/testssl.sh) to checks for **vulnerabilities** (In Bug Bounty programs probably these kind of vulnerabilities won't be accepted) and use [**a2sv** ](https://github.com/hahwul/a2sv)to recheck the vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Informations sur les vulnérabilités SSL/TLS :

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Lancez une sorte de **spider** sur le web. L'objectif du spider est de **trouver autant de chemins que possible** depuis l'application testée. Par conséquent, web crawling et les sources externes doivent être utilisés pour trouver le plus de chemins valides possible.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder dans les fichiers JS et des sources externes (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, avec LinkFider pour les fichiers JS et Archive.org comme source externe.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, indique aussi les "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): CLI interactif HTML spider. Cherche aussi dans Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): Cet outil n'est pas un spider mais peut être utile. Vous pouvez indiquer un fichier avec hosts et un fichier avec paths et meg récupérera chaque path sur chaque host et sauvegardera la réponse.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider avec capacités de rendu JS. Cependant, il semble non maintenu, la version précompilée est vieille et le code courant ne compile pas.
- [**gau**](https://github.com/lc/gau) (go): HTML spider qui utilise des providers externes (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Ce script trouvera les URLs avec paramètres et les listera.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider avec rendu JS.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, avec capacités de JS beautify capable de rechercher de nouveaux chemins dans les fichiers JS. Il peut valoir le coup de jeter un œil à [JSScanner](https://github.com/dark-warlord14/JSScanner), qui est un wrapper de LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Pour extraire des endpoints à la fois dans le source HTML et dans les fichiers javascript embarqués. Utile pour bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Un script python 2.7 utilisant Tornado et JSBeautifier pour parser les URLs relatives depuis les fichiers JavaScript. Utile pour découvrir facilement les requêtes AJAX. Semble non maintenu.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Donné un fichier (HTML) il extrait les URLs en utilisant une regex astucieuse pour trouver et extraire les URLs relatives depuis des fichiers minifiés.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, plusieurs outils): Rassemble des informations intéressantes depuis les fichiers JS en utilisant plusieurs outils.
- [**subjs**](https://github.com/lc/subjs) (go): Trouve les fichiers JS.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Charge une page dans un headless browser et affiche toutes les urls chargées pour afficher la page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Outil de découverte de contenu mélangeant plusieurs options des outils précédents
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Une extension Burp pour trouver paths et params dans les fichiers JS.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Un outil qui, donné l'URL .js.map, vous récupérera le code JS beautifié
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Outil utilisé pour découvrir des endpoints pour une target donnée.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Découvre des liens depuis la wayback machine (télécharge aussi les réponses dans la wayback et cherche plus de liens)
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (même en remplissant des forms) et trouve aussi des infos sensibles en utilisant des regex spécifiques.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite est un GUI crawler/spider multi-fonction avancé conçu pour les professionnels de la cybersécurité.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): C'est un package Go et un [outil en ligne de commande](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) pour extraire URLs, paths, secrets et autres données intéressantes depuis le code source JavaScript.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge est une simple **Burp Suite extension** pour **extraire les paramètres et endpoints** des requêtes afin de créer des wordlists personnalisées pour le fuzzing et l'énumération.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Outil excellent pour cela.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Affiche chaque link qu'il est capable de trouver.

### Brute Force directories and files

Commencez le **brute-forcing** depuis le dossier racine et assurez-vous de brute-forcer **tous** les **répertoires trouvés** en utilisant **cette méthode** ainsi que tous les répertoires **découverts** par le **Spidering** (vous pouvez faire ce brute-forcing **récursivement** en préfixant au début de la wordlist utilisée les noms des répertoires trouvés).\
Outils :

- **Dirb** / **Dirbuster** - Inclus dans Kali, **old** (et **slow**) mais fonctionnel. Permet les certificats auto-signés et la recherche récursive. Trop lent comparé aux autres options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Il n'autorise pas les certificats auto-signés mais** permet la recherche récursive.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Permet les certificats auto-signés, il **n'a pas** de recherche **récursive**.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Ce n'est pas un spider mais un outil qui, donné la liste des URLs trouvées, supprimera les URLs "dupliquées".
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension pour créer une liste de répertoires depuis l'historique Burp de différentes pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Supprime les URLs avec des fonctionnalités dupliquées (basé sur les imports js)
- [**Chamaleon**](https://github.com/iustin24/chameleon): Utilise wapalyzer pour détecter les technologies utilisées et sélectionner les wordlists à utiliser.

Dictionnaires recommandés :

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Notez que chaque fois qu'un nouveau répertoire est découvert pendant le brute-forcing ou le spidering, il doit être Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Trouve des liens cassés dans les HTML qui peuvent être susceptibles de takeovers
- **File Backups**: Une fois que vous avez trouvé tous les fichiers, recherchez des backups de tous les fichiers exécutables ("_.php_", "_.aspx_"...). Variantes communes pour nommer un backup : _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp et file.old._ Vous pouvez aussi utiliser l'outil [**bfac**](https://github.com/mazen160/bfac) **ou** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Vous pouvez utiliser des outils comme [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **et** [**Param Miner**](https://github.com/PortSwigger/param-miner) **pour découvrir des paramètres cachés. Si possible, essayez de rechercher des paramètres cachés dans chaque fichier web exécutable.**
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Vérifiez les commentaires de tous les fichiers, vous pouvez y trouver des **credentials** ou des **fonctionnalités cachées**.
- Si vous jouez un **CTF**, une astuce courante est de **cacher** des **informations** dans des commentaires à droite de la **page** (en utilisant des **centaines** d'espaces pour que vous ne voyiez pas les données si vous ouvrez le source avec le navigateur). Autre possibilité : utiliser plusieurs nouvelles lignes et **cacher des informations** dans un commentaire en bas de la page web.
- **API keys**: Si vous **trouvez une API key** il existe des guides indiquant comment utiliser les API keys pour différentes plateformes : [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Si vous trouvez une API key ressemblant à **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik vous pouvez utiliser le projet [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) pour vérifier quelles apis la key peut accéder.
- **S3 Buckets**: Pendant le Spidering regardez si un sous-domaine ou un lien est lié à un S3 bucket. Dans ce cas, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**While** performing the **spidering** and **brute-forcing** you could find **interesting** **things** that you have to **notice**.

**Interesting files**

- Cherchez des **links** vers d'autres fichiers à l'intérieur des fichiers **CSS**.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Si vous trouvez un _**.env**_ des informations comme des api keys, des mots de passe db et d'autres informations peuvent être trouvées.
- Si vous trouvez des **API endpoints** vous [should also test them](web-api-pentesting.md). Ce ne sont pas des fichiers, mais ressembleront probablement à des fichiers.
- **JS files**: Dans la section spidering plusieurs outils capables d'extraire des paths depuis les fichiers JS ont été mentionnés. De plus, il serait intéressant de **monitor** chaque fichier JS trouvé, car parfois un changement peut indiquer qu'une potentielle vulnérabilité a été introduite dans le code. Vous pouvez par exemple utiliser [**JSMon**](https://github.com/robre/jsmon)**.**
- Vous devriez aussi vérifier les fichiers JS découverts avec [**RetireJS**](https://github.com/retirejs/retire.js/) ou [**JSHole**](https://github.com/callforpapers-source/jshole) pour voir s'ils sont vulnérables.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Dans plusieurs cas, vous aurez besoin de **comprendre les expressions régulières** utilisées. Ceci sera utile : [https://regex101.com/](https://regex101.com) ou [https://pythonium.net/regex](https://pythonium.net/regex)
- Vous pourriez aussi **monitor** les fichiers où des forms ont été détectés, car un changement de paramètre ou l'apparition d'un nouveau form peut indiquer une nouvelle fonctionnalité potentiellement vulnérable.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Si une page **répond** avec ce **code**, c'est probablement un **proxy mal configuré**. **Si vous envoyez une requête HTTP comme : `GET https://google.com HTTP/1.1`** (avec le header host et d'autres headers courants), le **proxy** essaiera d'**accéder** à _**google.com**_ **et vous aurez trouvé un** SSRF.

**NTLM Authentication - Info disclosure**

Si le serveur en cours demandant l'authentification est **Windows** ou si vous trouvez un login demandant vos **credentials** (et demandant le **domain** **name**), vous pouvez provoquer une **information disclosure**.\
**Envoyez** le **header** : `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` et à cause du fonctionnement de l'**NTLM authentication**, le serveur répondra avec des infos internes (version IIS, version Windows...) dans le header "WWW-Authenticate".\
Vous pouvez **automatiser** cela en utilisant le plugin nmap "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Il est possible de **mettre du contenu** à l'intérieur d'une **Redirection**. Ce contenu **ne sera pas affiché à l'utilisateur** (le navigateur exécutera la redirection) mais quelque chose pourrait y être **caché**.

### Web Vulnerabilities Checking

Maintenant qu'une énumération complète de l'application web a été effectuée, il est temps de vérifier un grand nombre de vulnérabilités possibles. Vous pouvez trouver la checklist ici :


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Trouvez plus d'infos sur les vulnérabilités web sur :

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Vous pouvez utiliser des outils tels que [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) pour monitorer des pages afin de détecter des modifications qui pourraient insérer des vulnérabilités.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
