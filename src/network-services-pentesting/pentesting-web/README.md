# 80,443 - Pentesting Web-Methodik

{{#include ../../banners/hacktricks-training.md}}

## Grundlegende Informationen

Der Web-Service ist der **häufigste und umfangreichste Dienst** und es existieren viele **verschiedene Arten von Schwachstellen**.

**Standardport:** 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web-API-Leitfaden


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Zusammenfassung der Methodik

> In dieser Methodik gehen wir davon aus, dass Sie eine Domain (oder Subdomain) und nur diese angreifen. Daher sollten Sie diese Methodik auf jede entdeckte Domain, Subdomain oder IP mit unbestimmtem Webserver im Scope anwenden.

- [ ] Beginnen Sie damit, die vom Webserver verwendeten **technologies** zu **identifying**. Suchen Sie nach **tricks**, die Sie während des weiteren Tests beachten sollten, falls Sie die Tech erfolgreich identifizieren können.
- [ ] Gibt es eine **known vulnerability** in der Version der Technologie?
- [ ] Wird eine **well known tech** verwendet? Gibt es einen **useful trick**, um mehr Informationen zu extrahieren?
- [ ] Gibt es einen **specialised scanner** der ausgeführt werden sollte (z. B. wpscan)?
- [ ] Starten Sie **general purposes scanners**. Man weiß nie, ob sie etwas finden oder interessante Informationen liefern.
- [ ] Beginnen Sie mit den **initial checks**: **robots**, **sitemap**, **404** error und **SSL/TLS scan** (falls HTTPS).
- [ ] Starten Sie das **spidering** der Webseite: Es ist Zeit, alle möglichen **files, folders** und **parameters being used** zu **find**. Prüfen Sie auch auf **special findings**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: Versuchen Sie, alle entdeckten Ordner zu brute-forcen, um neue **files** und **directories** zu suchen.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **Backups checking**: Prüfen Sie, ob Sie **backups** von **discovered files** finden können, indem Sie gängige Backup-Erweiterungen anhängen.
- [ ] **Brute-Force parameters**: Versuchen Sie, **hidden parameters** zu **find**.
- [ ] Sobald Sie alle möglichen **endpoints** identifiziert haben, die **user input** akzeptieren, prüfen Sie auf alle Arten von damit zusammenhängenden **vulnerabilities**.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server-Version (Vulnerable?)

### Identifizieren

Prüfen Sie, ob es **known vulnerabilities** für die aktuell laufende Server-**version** gibt.\
Die **HTTP headers and cookies of the response** können sehr nützlich sein, um die verwendeten **technologies** und/oder die **version** zu **identify**. Ein **Nmap scan** kann die Server-Version identifizieren, aber auch die Tools [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech) oder [**https://builtwith.com/**](https://builtwith.com)** können nützlich sein:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Search **nach** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Prüfe, ob ein WAF vorhanden ist**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web-Technik-Tricks

Einige **Tricks**, um **Schwachstellen** in verschiedenen bekannten **Technologien** zu finden, die verwendet werden:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Custom UDP RPC Protocols**](custom-protocols.md)
- [**Dotnet SOAP WSDL client exploitation**](dotnet-soap-wsdl-client-exploitation.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Fortinet FortiWeb**](fortinet-fortiweb.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](https://github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Berücksichtige, dass dieselbe **Domain** unterschiedliche **Technologien** auf verschiedenen **Ports**, **Ordnern** und **Subdomains** verwenden kann._\
Wenn die Webanwendung eine der zuvor genannten **Tech/Plattformen** oder eine andere verwendet, vergiss nicht, im Internet nach neuen Tricks zu suchen (und gib mir Bescheid!).

### Quellcode-Review

Wenn der **source code** der Anwendung auf **github** verfügbar ist, gibt es neben der Durchführung eines **White box test** durch dich selbst einige Informationen, die für das aktuelle **Black-Box testing** nützlich sein könnten:

- Gibt es eine **Change-log**- oder **Readme**- oder **Version**-Datei oder irgendetwas mit über das Web zugänglichen **Versionsinformationen**?
- Wie und wo werden die **credentials** gespeichert? Gibt es eine (zugängliche?) **Datei** mit credentials (Benutzernamen oder Passwörtern)?
- Sind **Passwörter** im **Klartext**, **verschlüsselt** oder welcher **Hashing-Algorithmus** wird verwendet?
- Wird ein **Master-Key** zum Verschlüsseln verwendet? Welcher **Algorithmus** wird genutzt?
- Kannst du auf eine dieser Dateien zugreifen, indem du eine Schwachstelle ausnutzt?
- Gibt es interessante Informationen in den **github**-**issues** (gelöst und ungelöst)? Oder in der **commit history** (vielleicht wurde ein **Passwort** in einem alten Commit eingeführt)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Automatische Scanner

#### Allgemeine automatische Scanner
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS scanners

Wenn ein CMS verwendet wird, vergiss nicht, **einen Scanner auszuführen**, vielleicht wird etwas Interessantes gefunden:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** Websites auf Sicherheitsprobleme prüfen. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **oder** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Zu diesem Zeitpunkt solltest du bereits einige Informationen über den vom Client verwendeten Webserver haben (falls Daten vorliegen) und einige Tricks, die du während des Tests beachten solltest. Wenn du Glück hast, hast du sogar ein CMS gefunden und einen Scanner ausgeführt.

## Schritt-für-Schritt Web-Anwendungs-Erkennung

> Ab diesem Punkt werden wir anfangen, mit der Webanwendung zu interagieren.

### Erste Prüfungen

**Default pages with interesting info:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Überprüfe auch Kommentare in den Haupt- und Unterseiten.

**Fehler erzwingen**

Webserver können sich **behave unexpectedly** verhalten, wenn ihnen ungewöhnliche Daten geschickt werden. Das kann zu **vulnerabilities** führen oder **vertrauliche Informationen preisgeben**.

- Rufe **fake pages** wie /whatever_fake.php (.aspx,.html,.etc) auf
- **Füge "[]", "]]" und "[["** in **cookie values** und **parameter values** ein, um Fehler zu erzeugen
- Erzeuge Fehler, indem du Eingabe wie **`/~randomthing/%s`** am **Ende** der **URL** angibst
- Probiere **different HTTP Verbs** wie PATCH, DEBUG oder falsche wie FAKE

#### **Prüfe, ob du Dateien hochladen kannst (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Wenn du feststellst, dass **WebDav** aktiviert ist, du aber nicht genügend Berechtigungen hast, um Dateien im Root-Ordner hochzuladen, versuche:

- **Brute Force credentials**
- **Upload files** via WebDav in die übrigen gefundenen Ordner der Webseite. Möglicherweise hast du Berechtigungen, Dateien in anderen Ordnern hochzuladen.

### **SSL/TLS vulnerabilites**

- Wenn die Anwendung **isn't forcing the user of HTTPS** in irgendeinem Teil, dann ist sie **vulnerable to MitM**
- Wenn die Anwendung **sending sensitive data (passwords) using HTTP**. Dann ist das eine hohe vulnerability.

Benutze [**testssl.sh**](https://github.com/drwetter/testssl.sh) um nach **vulnerabilities** zu prüfen (In Bug Bounty programs werden solche Arten von vulnerabilities wahrscheinlich nicht akzeptiert) und benutze [**a2sv**](https://github.com/hahwul/a2sv) um die vulnerabilities erneut zu prüfen:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Starte irgendeine Art von **spider** innerhalb der Webanwendung. Ziel des spider ist es, **so viele Pfade wie möglich** von der getesteten Anwendung zu **finden**. Daher sollten Web-Crawling und externe Quellen genutzt werden, um möglichst viele valide Pfade zu entdecken.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files und externe Quellen (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, mit LinkFider für JS files und Archive.org als externe Quelle.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, zeigt außerdem "juicy files" an.
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interaktiver CLI HTML spider. Sucht ebenfalls in Archive.org.
- [**meg**](https://github.com/tomnomnom/meg) (go): Dieses Tool ist kein Spider, kann aber nützlich sein. Du kannst eine Datei mit Hosts und eine Datei mit Pfaden angeben; meg holt dann jeden Pfad von jedem Host und speichert die Response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider mit JS-Rendering-Fähigkeiten. Sieht aber unmaintained aus, die vorkompilierte Version ist alt und der aktuelle Code kompiliert nicht.
- [**gau**](https://github.com/lc/gau) (go): HTML spider, der externe Provider verwendet (wayback, otx, commoncrawl).
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Dieses Script findet URLs mit Parametern und listet sie auf.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider mit JS-Rendering-Fähigkeiten.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider mit JS-Beautify-Fähigkeiten, der neue Pfade in JS files suchen kann. Es lohnt sich auch, einen Blick auf [JSScanner](https://github.com/dark-warlord14/JSScanner) zu werfen, das eine Wrapper-Umgebung für LinkFinder ist.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Extrahiert Endpoints sowohl aus HTML-Quellcode als auch eingebetteten Javascript-Dateien. Nützlich für Bug Hunter, Red Teamer und Infosec-Ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Ein Python-2.7-Script, das Tornado und JSBeautifier verwendet, um relative URLs aus JavaScript-Dateien zu parsen. Nützlich, um AJAX-Requests einfach zu entdecken. Scheint unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Nimmt eine Datei (HTML) und extrahiert URLs mit einem cleveren Regex, um relative URLs aus unformatierten (minified) Dateien zu finden.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, mehrere Tools): Sammelt interessante Informationen aus JS files mittels mehrerer Tools.
- [**subjs**](https://github.com/lc/subjs) (go): Findet JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Lädt eine Seite in einem headless Browser und gibt alle URLs aus, die geladen wurden, um die Seite darzustellen.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content-Discovery-Tool, das mehrere Optionen der vorherigen Tools kombiniert.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Eine Burp-Erweiterung, um Pfade und Params in JS files zu finden.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Ein Tool, das, gegeben die .js.map URL, den beautified JS-Code ausliefert.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Tool zum Entdecken von Endpoints für ein gegebenes Ziel.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Entdeckt Links aus der Wayback Machine (lädt auch die Responses in der Wayback herunter und sucht dort nach weiteren Links).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawlt (auch durch Ausfüllen von Formularen) und findet außerdem sensitive Infos mittels spezifischer Regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite ist ein fortgeschrittener Multi-Feature GUI Web Security Crawler/Spider für Cyber-Security-Professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): Ein Go-Paket und [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) zum Extrahieren von URLs, Pfaden, Secrets und anderen interessanten Daten aus JavaScript-Quellcode.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge ist eine einfache **Burp Suite extension**, um **Parameter und Endpoints zu extrahieren**, um benutzerdefinierte Wordlists für Fuzzing und Enumeration zu erstellen.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Hervorragendes Tool dafür.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Gibt jeden Link aus, den es finden kann.

### Brute Force directories and files

Beginne mit dem **brute-forcing** ab dem Root-Verzeichnis und stelle sicher, dass du **alle** gefundenen **Verzeichnisse** mittels **dieser Methode** und alle durch **Spidering** entdeckten Verzeichnisse brute-forcest (du kannst das **rekursiv** durchführen und die Namen der gefundenen Verzeichnisse am Anfang der verwendeten Wordlist anfügen).\
Tools:

- **Dirb** / **Dirbuster** - In Kali enthalten, **alt** (und **langsam**) aber funktional. Erlaubt selbst-signierte Zertifikate und rekursive Suche. Im Vergleich zu anderen Optionen zu langsam.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Es erlaubt keine selbst-signierten Zertifikate, bietet aber rekursive Suche.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Erlaubt selbst-signierte Zertifikate, hat jedoch **keine rekursive** Suche.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Schnell, unterstützt rekursive Suche.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Schnell: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Kein Spider, aber ein Tool, das aus einer Liste gefundener URLs "duplizierte" URLs entfernt.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp-Extension, um eine Liste von Verzeichnissen aus dem Burp-History verschiedener Seiten zu erstellen.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Entfernt URLs mit duplizierten Funktionalitäten (basierend auf JS-Imports).
- [**Chamaleon**](https://github.com/iustin24/chameleon): Nutzt Wappalyzer, um verwendete Technologien zu erkennen und passende Wordlists auszuwählen.

**Empfohlene Wordlists:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Beachte, dass jedes Mal, wenn während des brute-forcing oder spidering ein neues Verzeichnis entdeckt wird, dieses ebenfalls brute-forced werden sollte._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Findet defekte Links in HTML-Dateien, die anfällig für takeovers sein könnten.
- **File Backups**: Sobald du alle Dateien gefunden hast, suche nach Backups aller ausführbaren Dateien ("_.php_", "_.aspx_" ...). Übliche Varianten zur Benennung einer Sicherung sind: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp und file.old._ Du kannst auch die Tools [**bfac**](https://github.com/mazen160/bfac) **oder** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**** verwenden.
- **Discover new parameters**: Du kannst Tools wie [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **und** [**Param Miner**](https://github.com/PortSwigger/param-miner) **verwenden, um versteckte Parameter zu entdecken. Wenn möglich, solltest du auf jeder ausführbaren Web-Datei nach versteckten Parametern suchen.**
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Kommentare:** Prüfe die Kommentare aller Dateien; du kannst dort **Credentials** oder **versteckte Funktionalität** finden.
- Wenn du an einem **CTF** teilnimmst, ist ein gängiger Trick, **Informationen** in Kommentaren am **rechten Rand** der **Seite** zu verstecken (mit **Hunderten** von **Spaces**, sodass du die Daten nicht siehst, wenn du den Sourcecode im Browser öffnest). Eine andere Möglichkeit ist, mehrere neue Zeilen zu verwenden und Informationen in einem Kommentar am **Ende** der Seite zu verstecken.
- **API keys**: Wenn du **API keys** findest, gibt es Projekte, die zeigen, wie man API keys verschiedener Plattformen nutzt: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](https://github.com/l4yton/RegHex)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Wenn du einen API key findest, der wie **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik aussieht, kannst du das Projekt [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) verwenden, um zu prüfen, auf welche APIs der Key Zugriff hat.
- **S3 Buckets**: Während des spidering prüfe, ob eine **Subdomain** oder ein **Link** mit einem S3 bucket in Verbindung steht. In diesem Fall [prüfe die Berechtigungen des Buckets](buckets/index.html).

### Special findings

**Während** du das **spidering** und **brute-forcing** durchführst, kannst du **interessante** **Dinge** finden, die du **notieren** musst.

**Interessante Dateien**

- Suche nach **Links** zu anderen Dateien innerhalb von **CSS**-Dateien.
- [Wenn du eine _**.git**_ Datei findest, können Informationen extrahiert werden](git.md)
- Wenn du eine _**.env**_ Datei findest, können dort API-Keys, DB-Passwörter und andere Informationen stehen.
- Wenn du **API endpoints** findest, solltest du diese [auch testen](web-api-pentesting.md). Diese sind zwar keine Dateien, sehen aber oft so aus.
- **JS files**: In der Spidering-Sektion wurden mehrere Tools genannt, die Pfade aus JS files extrahieren können. Es wäre außerdem interessant, jede gefundene JS-Datei zu **überwachen**, da eine Änderung in manchen Fällen anzeigen kann, dass eine potenzielle Schwachstelle in den Code eingeführt wurde. Du könntest z.B. [**JSMon**](https://github.com/robre/jsmon)** verwenden.**
- Du solltest gefundene JS files auch mit [**RetireJS**](https://github.com/retirejs/retire.js/) oder [**JSHole**](https://github.com/callforpapers-source/jshole) prüfen, um zu sehen, ob sie verwundbar sind.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript mit Zeichen:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- In vielen Fällen musst du die verwendeten regulären Ausdrücke verstehen. Nützlich dafür sind: [https://regex101.com/](https://regex101.com) oder [https://pythonium.net/regex](https://pythonium.net/regex)
- Du könntest außerdem die Dateien überwachen, in denen Formularfelder erkannt wurden, da eine Änderung der Parameter oder das Erscheinen eines neuen Formulars auf eine potenzielle neue verwundbare Funktionalität hinweisen kann.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Wenn eine Seite mit diesem **Statuscode** antwortet, ist wahrscheinlich ein **schlecht konfigurierter Proxy** vorhanden. **Wenn du eine HTTP-Anfrage wie: `GET https://google.com HTTP/1.1`** (mit dem Host-Header und anderen üblichen Headern) sendest, wird der **Proxy** versuchen, auf _**google.com**_ zuzugreifen — und du hast möglicherweise ein SSRF gefunden.

**NTLM Authentication - Info disclosure**

Wenn der laufende Server zur Authentifizierung **Windows** ist oder du ein Login findest, das nach deinen **Credentials** (und nach dem **Domain**-**Namen**) fragt, kannst du eine **Informationsweitergabe** provozieren.\
**Sende** den **Header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` und aufgrund der Funktionsweise der **NTLM-Authentifizierung** wird der Server mit internen Infos (IIS-Version, Windows-Version...) im Header "WWW-Authenticate" antworten.\
Du kannst dies mit dem **nmap plugin** "_http-ntlm-info.nse_" automatisieren.

**HTTP Redirect (CTF)**

Es ist möglich, **Inhalt** innerhalb einer **Redirect** unterzubringen. Dieser Inhalt wird **nicht für den Benutzer angezeigt** (da der Browser die Weiterleitung ausführt), aber es könnte etwas **darin versteckt** sein.

### Web Vulnerabilities Checking

Nachdem eine umfassende Enumeration der Webanwendung durchgeführt wurde, ist es Zeit, auf viele mögliche Schwachstellen zu prüfen. Du findest die Checkliste hier:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Mehr Infos zu Web-Vulnerabilities:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Du kannst Tools wie [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) verwenden, um Seiten auf Änderungen zu überwachen, die neue Schwachstellen einführen könnten.

### HackTricks Automatic Commands

<details>
<summary>HackTricks Automatic Commands</summary>
```yaml
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
</details>

{{#include ../../banners/hacktricks-training.md}}
