# 80,443 - Pentesting Web Methodology

{{#include ../../banners/hacktricks-training.md}}

## बुनियादी जानकारी

The web service is the most **सामान्य और व्यापक सेवा** और कई तरह की **vulnerabilities** मौजूद हैं।

**डिफ़ॉल्ट पोर्ट:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API मार्गदर्शन


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Methodology summary

> इस कार्यप्रणाली में हम यह मानेंगे कि आप एक domain (या subdomain) पर ही हमला कर रहे हैं और केवल उसी पर। इसलिए, आपको इस कार्यप्रणाली को दायरे में पाए गए प्रत्येक खोजे गए domain, subdomain या IP पर लागू करना चाहिए जहाँ web server अनिर्धारित है।

- [ ] सबसे पहले web server द्वारा उपयोग की जा रही **technologies** की पहचान करें। यदि आप tech को सफलतापूर्वक पहचान लेते हैं तो टेस्ट के बाकी हिस्सों के दौरान ध्यान रखने के लिए किसी भी **tricks** की तलाश करें।
- [ ] क्या technology के version में कोई **known vulnerability** है?
- [ ] क्या कोई **well known tech** उपयोग हो रही है? अधिक जानकारी निकालने के लिए कोई **useful trick** है?
- [ ] क्या चलाने के लिए कोई **specialised scanner** है (जैसे wpscan)?
- [ ] **general purposes scanners** लॉन्च करें। पता नहीं वे कुछ पाएंगे या कुछ रोचक जानकारी ढूँढेंगे।
- [ ] **initial checks** से शुरू करें: **robots**, **sitemap**, **404** error और **SSL/TLS scan** (यदि HTTPS)।
- [ ] वेब पेज पर **spidering** शुरू करें: अब समय है कि सभी संभावित **files, folders** और **parameters being used.** को **find** किया जाए। साथ ही **special findings** के लिए भी जाँच करें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory मिलता है, तो उसे spidered किया जाना चाहिए._
- [ ] **Directory Brute-Forcing**: खोजे गए सभी folders को brute force करके नए **files** और **directories** खोजने का प्रयास करें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory मिलता है, उसे Brute-Forced किया जाना चाहिए._
- [ ] **Backups checking**: सामान्य backup extensions जोड़कर देखें कि क्या आप **discovered files** के **backups** पा सकते हैं।
- [ ] **Brute-Force parameters**: छुपे हुए **parameters** को **find** करने का प्रयास करें।
- [ ] एक बार जब आपने सभी संभावित **endpoints** जिन्हें **user input** स्वीकार है, की **identified** कर लिया हो, तो उनसे संबंधित सभी प्रकार की **vulnerabilities** की जांच करें।
- [ ] [इस चेकलिस्ट का पालन करें](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### पहचान

यह जाँचें कि चल रहे server के **version** के लिए कोई **known vulnerabilities** हैं या नहीं.\
प्रतिक्रिया के **HTTP headers and cookies of the response** server पर उपयोग की जा रही **technologies** और/या **version** की **identify** करने में बहुत उपयोगी हो सकते हैं। **Nmap scan** server version को पहचान सकता है, लेकिन यह tools [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
खोजें **के लिए** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **जांचें कि कोई WAF तो नहीं**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### वेब टेक ट्रिक्स

विभिन्न प्रसिद्ध **technologies** में **finding vulnerabilities** के लिए कुछ **tricks**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_ध्यान रखें कि **सही domain** विभिन्न **प्रौद्योगिकियों** का उपयोग कर सकता है अलग-अलग **ports**, **folders** और **subdomains** में._\
यदि वेब एप्लिकेशन किसी भी प्रसिद्ध **tech/platform listed before** या **अन्य** का उपयोग कर रही है, तो इंटरनेट पर नए ट्रिक्स खोजना न भूलें (और मुझे बताएं!).

### Source Code Review

यदि एप्लिकेशन का **source code** github पर उपलब्ध है, तो अपनी तरफ़ से एक **White box test** करने के अलावा ऐसी कुछ जानकारी हो सकती है जो वर्तमान **Black-Box testing** के लिए उपयोगी हो सकती है:

- क्या कोई **Change-log or Readme or Version** file या कोई चीज़ है जिसमें **version info accessible** वेब के माध्यम से मिलती हो?
- credentials कैसे और कहाँ सेव होते हैं? क्या कोई (accessible?) **file** है जिसमें credentials (usernames या passwords) हैं?
- क्या **passwords** **plain text** में हैं, **encrypted** हैं या किस **hashing algorithm** का उपयोग किया गया है?
- क्या कुछ एन्क्रिप्ट करने के लिए कोई **master key** उपयोग में है? कौन सा **algorithm** इस्तेमाल हो रहा है?
- क्या आप किसी vulnerability का उपयोग करके इन फ़ाइलों में से किसी तक पहुंच सकते हैं?
- क्या github में कोई दिलचस्प जानकारी है (solved और not solved) **issues** में? या **commit history** में (शायद कोई **password introduced inside an old commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### General purpose automatic scanners
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS स्कैनर्स

यदि कोई CMS उपयोग में है तो **run a scanner** करना न भूलें — शायद कुछ दिलचस्प मिल जाए:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** वेबसाइट्स में Security issues के लिए। (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **or** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> इस बिंदु पर आपके पास उस web server के बारे में कुछ जानकारी पहले से होनी चाहिए जो client इस्तेमाल कर रहा है (यदि कोई डेटा दिया गया हो) और टेस्ट के दौरान ध्यान में रखने के लिए कुछ tricks। यदि आप भाग्यशाली हैं तो आपने एक CMS भी ढूंढ लिया होगा और कुछ scanner चला होगा।

## चरण-दर-चरण Web Application Discovery

> यहाँ से हम वेब एप्लिकेशन के साथ इंटरैक्ट करना शुरू करेंगे।

### प्रारंभिक जाँच

**Default pages with interesting info:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- मुख्य और secondary पृष्ठों में comments भी जाँचें।

**Forcing errors**

Web servers may **behave unexpectedly** when weird data is sent to them. This may open **vulnerabilities** or **disclosure sensitive information**.

- Access **fake pages** like /whatever_fake.php (.aspx,.html,.etc)
- **Add "[]", "]]", and "[["** in **cookie values** and **parameter** values to create errors
- Generate error by giving input as **`/~randomthing/%s`** at the **end** of **URL**
- Try **different HTTP Verbs** like PATCH, DEBUG or wrong like FAKE

#### **Check if you can upload files (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

If you find that **WebDav** is **enabled** but you don't have enough permissions for **uploading files** in the root folder try to:

- **Brute Force** credentials
- **Upload files** via WebDav to the **rest** of **found folders** inside the web page. You may have permissions to upload files in other folders.

### **SSL/TLS vulnerabilites**

- If the application **isn't forcing the user of HTTPS** in any part, then it's **vulnerable to MitM**
- If the application is **sending sensitive data (passwords) using HTTP**. Then it's a high vulnerability.

Use [**testssl.sh**](https://github.com/drwetter/testssl.sh) to checks for **vulnerabilities** (In Bug Bounty programs probably these kind of vulnerabilities won't be accepted) and use [**a2sv** ](https://github.com/hahwul/a2sv)to recheck the vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

वेब में किसी प्रकार का **spider** लॉन्च करें। spider का लक्ष्य टेस्ट किए जा रहे application से जितने संभव हो उतने **paths** **find** करना है। इसलिए web crawling और external sources का उपयोग करके जितने संभव वैध paths मिल सकें उन्हें ढूँढा जाना चाहिए।

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files और external sources (Archive.org, CommonCrawl.org, VirusTotal.com) में खोज।
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, JS फाइलों के लिए LinkFider और external source के रूप में Archive.org।
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, "juicy files" भी इंगित करता है।
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider। यह Archive.org में भी खोज करता है।
- [**meg**](https://github.com/tomnomnom/meg) (go): यह tool spider तो नहीं है पर उपयोगी हो सकता है। आप hosts वाली फ़ाइल और paths वाली फ़ाइल दे सकते हैं और meg हर host पर हर path को fetch करके response सेव कर देगा।
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS rendering capabilities के साथ HTML spider। हालांकि, ऐसा दिखता है कि यह unmaintained है, precompiled version पुराना है और current code compile नहीं होता।
- [**gau**](https://github.com/lc/gau) (go): external providers (wayback, otx, commoncrawl) का उपयोग करने वाला HTML spider।
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): यह script URL में parameters ढूँढेगा और उन्हें list करेगा।
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS rendering क्षमताओं वाला HTML spider।
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, JS beautify capabilities के साथ JS फाइलों में नए paths खोजने में सक्षम। इसके wrapper [JSScanner](https://github.com/dark-warlord14/JSScanner) को भी देखना उपयोगी हो सकता है।
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): HTML source और embedded javascript फाइलों दोनों में endpoints निकालने के लिए। bug hunters, red teamers, infosec ninjas के लिए उपयोगी।
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Tornado और JSBeautifier का उपयोग करके JavaScript फाइलों से relative URLs parse करने वाला python 2.7 script। AJAX requests आसानी से खोजने के लिए उपयोगी। लगता है unmaintained है।
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): किसी HTML फ़ाइल दिए जाने पर यह उस में से relative URLs निकालने के लिए regex इस्तेमाल करता है, खासकर minified फाइलों से।
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): कई tools का उपयोग करके JS फाइलों से interesting जानकारी इकट्ठा करता है।
- [**subjs**](https://github.com/lc/subjs) (go): JS फाइलें ढूँढें।
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): headless browser में एक page load करता है और page को load करने के लिए लोड किए गए सभी urls print करता है।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool जो पहले बताए गए कई options को मिलाता है।
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS फाइलों में path और params खोजने के लिए एक Burp extension।
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): .js.map URL दिए जाने पर beautified JS code प्राप्त करने वाला tool।
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): किसी target के लिए endpoints discover करने में उपयोगी tool।
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** wayback machine से links discover करना (wayback के responses डाउनलोड करना और उनमें और links खोजना भी)।
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (यहाँ तक कि forms भरके भी) और specific regexes से sensitive info भी ढूँढे।
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite एक advanced multi-feature GUI web security Crawler/Spider है जो cyber security professionals के लिए डिजाइन किया गया है।
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): यह Go package और [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) है जो JavaScript source code से URLs, paths, secrets, और अन्य दिलचस्प data निकालता है।
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge एक simple **Burp Suite extension** है जो request से **parameters और endpoints** extract करके fuzzing और enumeration के लिए custom wordlist बनाता है।
- [**katana**](https://github.com/projectdiscovery/katana) (go): इस काम के लिए एक शानदार tool।
- [**Crawley**](https://github.com/s0rg/crawley) (go): यह हर link को print करता है जो यह ढूँढ पाता है।

### Brute Force directories and files

रूट फ़ोल्डर से **brute-forcing** शुरू करें और यह सुनिश्चित करें कि आप **all** उन **directories found** पर भी brute-force चलाएँ जो **this method** से और Spidering द्वारा **discovered** हुई हैं (आप यह brute-forcing **recursively** कर सकते हैं और उपयोग किए जा रहे wordlist के शुरुआत में मिले हुए directories के नाम जोड़ सकते हैं)।\
Tools:

- **Dirb** / **Dirbuster** - Kali में शामिल, **old** (और **slow**) पर functional। auto-signed certificates और recursive search allow करते हैं। अन्य options के मुकाबले बहुत slow।
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: यह auto-signed certificates allow नहीं करता पर** recursive search allow करता है।
- [**Gobuster**](https://github.com/OJ/gobuster) (go): auto-signed certificates allow करता है, यह **doesn't** have **recursive** search।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): यह spider नहीं है पर एक tool है जो मिले हुए URLs की list लेकर "duplicated" URLs हटाता है।
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension जो burp history से directories की list बनाता है।
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): js imports के आधार पर duplicated functionalities वाले URLs हटाता है।
- [**Chamaleon**](https://github.com/iustin24/chameleon): यह wapalyzer का उपयोग करके इस्तेमाल की गई technologies detect करता है और उन के अनुसार wordlists चुनता है।

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_ध्यान दें कि जब भी कोई नया directory brute-forcing या spidering के दौरान मिलता है, उसे भी Brute-Force किया जाना चाहिए।_

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTMLs के अंदर broken links खोजें जो takeover के लिये prone हो सकते हैं।
- **File Backups**: एक बार जब आप सभी फाइलें ढूँढ लें, तो सभी executable files के backups ढूँढें ("_.php_", "_.aspx_"...). backups के नामकरण के सामान्य variations हैं: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ आप [**bfac**](https://github.com/mazen160/bfac) **या** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen) का उपयोग भी कर सकते हैं।
- **Discover new parameters**: आप hidden parameters खोजने के लिए [**Arjun**](https://github.com/s0md3v/Arjun), [**parameth**](https://github.com/maK-/parameth), [**x8**](https://github.com/sh1yo/x8) और [**Param Miner**](https://github.com/PortSwigger/param-miner) जैसे tools का उपयोग कर सकते हैं। यदि संभव हो तो प्रत्येक executable web file पर hidden parameters खोजने की कोशिश करें।
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** सभी फाइलों के comments चेक करें, वहाँ आपको **credentials** या **hidden functionality** मिल सकती है।
- अगर आप **CTF** खेल रहे हैं, तो एक सामान्य trick यह है कि पेज के source में comments के दाहिनी तरफ (page के दाईं ओर) कई spaces का उपयोग करके information **hide** कर दी जाती है ताकि ब्राउज़र से source खोलने पर आप उसे न देखें। दूसरी संभावना कई new lines का उपयोग करके पेज के नीचे comment में information छिपाना है।
- **API keys**: अगर आपको कोई API key मिलती है तो विभिन्न platforms की API keys का उपयोग कैसे किया जाए इसके लिए मार्गदर्शन मौजूद है: [**keyhacks**](https://github.com/streaak/keyhacks), [**zile**](https://github.com/xyele/zile.git), [**truffleHog**](https://github.com/trufflesecurity/truffleHog), [**SecretFinder**](https://github.com/m4ll0k/SecretFinder), [**RegHex**](<https://github.com/l4yton/RegHex)/>), [**DumpsterDive**](https://github.com/securing/DumpsterDiver), [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: अगर आपको कोई API key ऐसी दिखती है जो **AIza** से शुरू होती है (उदा. **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik) तो आप यह चेक करने के लिए [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) उपयोग कर सकते हैं कि वह key किन APIs तक access कर सकती है।
- **S3 Buckets**: spidering के दौरान देखें कि क्या कोई **subdomain** या कोई **link** किसी **S3 bucket** से जुड़ा हुआ है। उस स्थिति में, [**check** the **permissions** of the bucket](buckets/index.html) करें।

### Special findings

**While** performing the **spidering** and **brute-forcing** आप कुछ **interesting** **things** पा सकते हैं जिन पर आपको ध्यान देना होगा।

**Interesting files**

- CSS फाइलों के अंदर दूसरे files के लिए **links** ढूँढें।
- [If you find a _**.git**_ file some information can be extracted](git.md)
- अगर आपको _**.env**_ मिलता है तो उसमें api keys, dbs passwords और अन्य जानकारी मिल सकती है।
- अगर आपको **API endpoints** मिलते हैं तो आपको उन्हें [should also test them](web-api-pentesting.md) करना चाहिए। ये फाइलें नहीं हैं, पर दिखने में फाइल जैसी लग सकती हैं।
- **JS files**: spidering सेक्शन में कई tools का उल्लेख था जो JS फाइलों से paths निकाल सकते हैं। साथ ही, यह भी उपयोगी होगा कि हर मिले हुए JS file की monitoring की जाए, क्योंकि कुछ मामलों में कोई बदलाव यह संकेत दे सकता है कि code में संभावित vulnerability आई है। आप उदाहरण के लिए [**JSMon**](https://github.com/robre/jsmon) का उपयोग कर सकते हैं।
- आप discovered JS files को [**RetireJS**](https://github.com/retirejs/retire.js/) या [**JSHole**](https://github.com/callforpapers-source/jshole) से भी चेक करें कि क्या वे vulnerable हैं।
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- कई मौकों पर, आपको उपयोग किए गए regular expressions को समझने की आवश्यकता होगी। यह उपयोगी होगा: [https://regex101.com/](https://regex101.com) या [https://pythonium.net/regex](https://pythonium.net/regex)
- आप उन फाइलों की भी monitoring कर सकते हैं जिनमें forms detect हुए थे, क्योंकि parameter में बदलाव या नए form की उपस्थिति संभावित नई vulnerable functionality का संकेत दे सकती है।

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

अगर किसी पेज का response वही **code** देता है, तो संभवत: यह एक **bad configured proxy** है। **यदि आप एक HTTP request भेजते हैं जैसे: `GET https://google.com HTTP/1.1`** (host header और अन्य सामान्य headers के साथ), तो **proxy** प्रयास करेगा _**google.com**_ तक पहुंचने का और इस तरह आप एक SSRF पाएंगे।

**NTLM Authentication - Info disclosure**

अगर running server जो authentication मांग रहा है वह **Windows** है या आप किसी ऐसे login को पाते हैं जो आपके **credentials** मांग रहा है (और **domain** **name** पूछ रहा है), तो आप एक **information disclosure** उत्पन्न कर सकते हैं।\
**Send** करें header: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` और NTLM authentication के तरीके के कारण, server header "WWW-Authenticate" के अंदर internal info (IIS version, Windows version...) के साथ response देगा।\
आप इसे automate करने के लिए **nmap plugin** "_http-ntlm-info.nse_" का उपयोग कर सकते हैं।

**HTTP Redirect (CTF)**

Redirection के अंदर content डालना possible है। यह content user को show नहीं होगा (क्योंकि browser redirection execute कर देगा) पर वहाँ कुछ **hidden** किया जा सकता है।

### Web Vulnerabilities Checking

अब जब web application का comprehensive enumeration किया जा चुका है तो कई संभावित vulnerabilities की जाँच करने का समय है। आप checklist यहाँ पा सकते हैं:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Web vulns के बारे में और जानकारी:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

आप pages में modifications monitor करने के लिए [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) जैसे tools का उपयोग कर सकते हैं ताकि उन परिवर्तनों की पहचान हो सके जो vulnerabilities का कारण बन सकते हैं।

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
