# 80,443 - Pentesting Web 方法論

{{#include ../../banners/hacktricks-training.md}}

## 基本情報

Webサービスは最も**一般的で広範なサービス**であり、**多くの異なる種類の脆弱性**が存在します。

**デフォルトポート:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API ガイダンス


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Methodology summary

> この手順では、攻撃対象が単一のドメイン（またはサブドメイン）に限定されることを想定します。したがって、この手順はスコープ内で発見された各ドメイン、サブドメイン、または未判定の web サーバを持つ IP ごとに適用してください。

- [ ] Start by **identifying** the **technologies** used by the web server. Look for **tricks** to keep in mind during the rest of the test if you can successfully identify the tech.
- [ ] Any **known vulnerability** of the version of the technology?
- [ ] Using any **well known tech**? Any **useful trick** to extract more information?
- [ ] Any **specialised scanner** to run (like wpscan)?
- [ ] Launch **general purposes scanners**. You never know if they are going to find something or if the are going to find some interesting information.
- [ ] Start with the **initial checks**: **robots**, **sitemap**, **404** error and **SSL/TLS scan** (if HTTPS).
- [ ] Start **spidering** the web page: It's time to **find** all the possible **files, folders** and **parameters being used.** Also, check for **special findings**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: Try to brute force all the discovered folders searching for new **files** and **directories**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **Backups checking**: Test if you can find **backups** of **discovered files** appending common backup extensions.
- [ ] **Brute-Force parameters**: Try to **find hidden parameters**.
- [ ] Once you have **identified** all the possible **endpoints** accepting **user input**, check for all kind of **vulnerabilities** related to it.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

実行中のサーバーの**バージョン**に対して既知の**脆弱性**がないか確認してください。\
レスポンスの**HTTPヘッダとクッキー**は、使用されている**技術**や**バージョン**を**識別**するのに非常に役立ちます。**Nmap scan**はサーバーのバージョンを識別できますが、[**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
検索 **する** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **WAFが存在するか確認**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web技術のトリック

使用されているさまざまなよく知られた**技術**で**脆弱性を発見する**ためのいくつかの**トリック**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_同じ**ドメイン**が異なる**ポート**、**フォルダ**、**サブドメイン**で**異なる技術**を使用している場合があることを考慮してください._\
もしWebアプリケーションが前述のよく知られた**技術/プラットフォーム**や**その他**を使用している場合は、新しいトリックを**インターネットで検索する**ことを忘れないでください（そして教えてください！）。

### ソースコードレビュー

アプリケーションの**ソースコード**が**github**で入手可能な場合、アプリケーションに対して**自身による White box test**を行うことに加え、現在の**Black-Box testing**に**有用**である可能性のある**いくつかの情報**があります:

- Web上でアクセス可能な**Change-log or Readme or Version**ファイルや、**バージョン情報にアクセスできる**何かはありますか？
- **credentials**はどのように、どこに保存されていますか？資格情報（ユーザ名やパスワード）が含まれる（アクセス可能な）**file**はありますか？
- **passwords**は**plain text**ですか、**encrypted**ですか、どの**hashing algorithm**が使用されていますか？
- 暗号化に何らかの**master key**を使用していますか？どの**algorithm**が使われていますか？
- 脆弱性を悪用して、これらのファイルの**いずれかにアクセスできますか？**
- githubの**issues**（解決済み・未解決問わず）に**興味深い情報**はありますか？または**commit history**に（古いコミット内にパスワードが含まれているなど）何かありますか？

{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### General purpose automatic scanners
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS スキャナー

CMS が使われている場合は **run a scanner** を忘れないでください。思わぬ発見があるかもしれません:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** ウェブサイトのセキュリティ問題を検出します。(GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **または** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> この時点で、クライアントが使用しているウェブサーバーに関するある程度の情報（データが提供されていれば）と、テスト中に覚えておくべきいくつかのコツがあるはずです。運が良ければCMSを見つけてスキャナを実行しているかもしれません。

## ステップバイステップのWebアプリケーション探索

> ここからはWebアプリケーションとのやり取りを開始します。

### 初期チェック

**興味深い情報を含むデフォルトページ:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- メインページやセカンダリページのコメントも確認する。

**エラーの強制発生**

Webサーバーは、奇妙なデータが送られると**予期せぬ動作をすることがある**。これにより**脆弱性**が生じたり、**機密情報の開示**が起きる可能性がある。

- /whatever_fake.php のような**偽ページ**にアクセスする（.aspx、.html、など）
- **"[]", "]]", "[["** を **cookie値** や **パラメータ値** に追加してエラーを発生させる
- **URL**の**末尾**に **`/~randomthing/%s`** のような入力を与えてエラーを発生させる
- PATCH、DEBUG のような**異なる HTTP メソッド**を試す、または FAKE のような無効なものを試す

#### **アップロード可能か確認する (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

もし**WebDav**が**有効**で、ルートフォルダに**ファイルをアップロードする**十分な権限がない場合は、以下を試す:

- **Brute Force**で認証情報を試す
- Webページ内の見つかったフォルダの**残り**に対してWebDav経由で**ファイルをアップロードする**。他のフォルダにはアップロード権限があるかもしれない。

### **SSL/TLS の脆弱性**

- アプリケーションがどの部分でも**HTTPSの使用を強制していない**場合、**MitMに対して脆弱**である
- アプリケーションが**HTTPで機密データ（パスワードなど）を送信している**場合、それは高い脆弱性である

脆弱性のチェックには [**testssl.sh**](https://github.com/drwetter/testssl.sh) を使う（Bug Bountyプログラムではおそらくこの種の脆弱性は受け付けられない）そして再チェックには [**a2sv** ](https://github.com/hahwul/a2sv) を使う:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

ウェブ内で何らかの **spider** を起動します。spider の目的は、テスト対象アプリケーションから可能なかぎり多くのパスを見つけることです。したがって、web crawling と外部ソースを使って、できるだけ多くの有効なパスを見つけるべきです。

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider、JS ファイル内の LinkFinder と外部ソース (Archive.org, CommonCrawl.org, VirusTotal.com) を使用します。
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider、JS ファイル用の LinkFider と Archive.org を外部ソースとして使用します。
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider、"juicy files" を示してくれます。
- [**evine** ](https://github.com/saeeddhqan/evine)(go): 対話型 CLI の HTML spider。Archive.org も検索します。
- [**meg**](https://github.com/tomnomnom/meg) (go): このツールは厳密には spider ではありませんが有用です。hosts のファイルと paths のファイルを指定すると、meg は各ホストの各パスをフェッチしてレスポンスを保存します。
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS レンダリング機能付きの HTML spider。しかしメンテナンスされていないように見え、事前コンパイルされたバイナリは古く、現在のコードはコンパイルできません。
- [**gau**](https://github.com/lc/gau) (go): 外部プロバイダ (wayback, otx, commoncrawl) を使う HTML spider。
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): パラメータ付きの URL を見つけ、一覧化します。
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS レンダリング機能付きの HTML spider。
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider、JS beautify 機能があり JS ファイル内の新しいパスを検索できます。LinkFinder のラッパーである [JSScanner](https://github.com/dark-warlord14/JSScanner) も見る価値があります。
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): HTML ソースと埋め込み JavaScript ファイルの両方からエンドポイントを抽出します。bug hunters、red teamers、infosec ninjas に有用です。
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Tornado と JSBeautifier を使って JavaScript ファイルから相対 URL を解析する python 2.7 スクリプト。AJAX リクエストの発見に便利。メンテされていないようです。
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): ファイル (HTML) を与えると、ミニファイされたファイルなどの汚いファイルから相対 URL を抽出するための便利な正規表現で URL を抽出します。
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): 複数ツールを使って JS ファイルから興味深い情報を収集します。
- [**subjs**](https://github.com/lc/subjs) (go): JS ファイルを検出します。
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Headless browser でページをロードし、ページをロードする際に読み込まれるすべての URL を出力します。
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): 既出のツールのいくつかのオプションを組み合わせた content discovery ツール。
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS ファイル内のパスやパラメータを見つける Burp extension。
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): .js.map の URL を与えると beautified な JS コードを取得するツール。
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): 指定ターゲットのエンドポイントを発見するツール。
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** wayback machine からリンクを発見（wayback のレスポンスをダウンロードしてさらにリンクを探す）。
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): フォームの自動記入などでクローリングし、特定の正規表現で機密情報も発見します。
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): GUI ベースの多機能 web security Crawler/Spider（サイバーセキュリティ専門家向け）。
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): JavaScript ソースコードから URL、パス、シークレット、その他興味深いデータを抽出する Go パッケージと [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice)。
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): リクエストからパラメータとエンドポイントを抽出して fuzzing や列挙用のカスタム wordlist を作成する簡単な **Burp Suite extension**。
- [**katana**](https://github.com/projectdiscovery/katana) (go): この用途に優れたツール。
- [**Crawley**](https://github.com/s0rg/crawley) (go): 見つけられるすべてのリンクを出力します。

### Brute Force directories and files

ルートフォルダから **brute-forcing** を開始し、**この方法**で見つかったすべてのディレクトリと、**Spidering** によって見つかったすべてのディレクトリを必ず brute-force してください（見つかったディレクトリ名を使用するワードリストの先頭に追加して、再帰的に brute-forcing を行うことができます）。\
ツール:

- **Dirb** / **Dirbuster** - Kali に含まれる、**古い**（かつ **遅い**）が機能します。自己署名証明書を許可し、再帰検索が可能。他のオプションと比べて遅すぎます。
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: 自己署名証明書を許可しませんが**、再帰検索をサポートします。
- [**Gobuster**](https://github.com/OJ/gobuster) (go): 自己署名証明書を許可しますが、**recursive** 検索はありません。
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- 高速で、recursive 検索をサポートします。**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- 高速: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): 見つかった URL のリストを与えると "重複" URL を削除するツール（spider ではありません）。
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp の履歴からディレクトリ一覧を作成する Burp Extension。
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): js import に基づいて機能が重複する URL を削除します。
- [**Chamaleon**](https://github.com/iustin24/chameleon): wapalyzer を使用して利用技術を検出し、使用するワードリストを選択します。

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_注意: brute-forcing や spidering 中に新しいディレクトリが見つかった場合は、その都度 Brute-Force を行ってください。_

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTML 内の壊れたリンクを見つけます。これらは takeover の対象になり得ます。
- **File Backups**: すべてのファイルを見つけたら、実行可能ファイルのバックアップ（"_.php_", "_.aspx_"...）を探します。バックアップ命名の一般的なバリエーションには: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ また、ツール [**bfac**](https://github.com/mazen160/bfac) **や** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen) を使えます。
- **Discover new parameters**: [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **や** [**Param Miner**](https://github.com/PortSwigger/param-miner) のようなツールを使って隠れたパラメータを発見できます。可能であれば、各実行可能な web ファイルに対して隠れたパラメータを検索してください。
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** すべてのファイルのコメントをチェックしてください。**credentials** や **hidden functionality** が見つかることがあります。
- CTF をプレイしている場合、よくあるトリックはページのソース右側に情報を **隠す** ことです（ブラウザでソースを開くと見えないように多数のスペースを使う）。別の方法として複数の改行を挿入し、ページ下部のコメントに情報を隠すこともあります。
- **API keys**: もし API key を見つけたら、さまざまなプラットフォームの API key の使い方を示すプロジェクトがあります: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: **AIza** で始まるような API key を見つけた場合、[**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) を使ってそのキーがどの API にアクセスできるか確認できます。
- **S3 Buckets**: spidering 中にサブドメインやリンクが S3 bucket に関連しているか確認してください。その場合は、[**check** the **permissions** of the bucket](buckets/index.html) を実行してください。

### Special findings

**spidering** と **brute-forcing** を実行している間に、**注意すべき興味深いもの**が見つかることがあります。

**Interesting files**

- CSS ファイル内の他のファイルへの **links** を探してください。
- [If you find a _**.git**_ file some information can be extracted](git.md)
- _**.env**_ ファイルを見つけた場合、api keys、db パスワードやその他の情報が含まれている可能性があります。
- **API endpoints** を見つけた場合は、[should also test them](web-api-pentesting.md)。これらはファイルではありませんが、見た目はファイルのように見えることがあります。
- **JS files**: spidering セクションで JS ファイルからパスを抽出するツールをいくつか紹介しました。また、発見した各 JS ファイルを**監視**するのも興味深いです。場合によっては、コードの変更が脆弱性の導入を示すことがあります。例えば [**JSMon**](https://github.com/robre/jsmon) を使えます。
- 発見した JS ファイルは [**RetireJS**](https://github.com/retirejs/retire.js/) や [**JSHole**](https://github.com/callforpapers-source/jshole) で脆弱性がないかチェックするべきです。
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- 多くの場合、使用されている正規表現を理解する必要があります。これは役立ちます: [https://regex101.com/](https://regex101.com) や [https://pythonium.net/regex](https://pythonium.net/regex)
- フォームが検出されたファイルを監視することも有用です。パラメータの変更や新しいフォームの出現は、新たな脆弱な機能の兆候かもしれません。

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

任意のページがその **コード** で応答する場合、設定の悪いプロキシである可能性が高いです。**`GET https://google.com HTTP/1.1` のような HTTP リクエストを送ると**（Host ヘッダやその他の一般的なヘッダを含めて）、その **proxy** は _**google.com**_ にアクセスしようとし、SSRF を発見できます。

**NTLM Authentication - Info disclosure**

要求しているサーバが **Windows** の場合、またはドメイン名を要求するログインを見つけた場合、**情報漏洩** を引き起こすことができます。\
`“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` ヘッダを送ると、NTLM 認証の動作によりサーバはヘッダ "WWW-Authenticate" の中に内部情報（IIS バージョン、Windows バージョン...）を返すことがあります。\
この動作は nmap のプラグイン "_http-ntlm-info.nse_" で自動化できます。

**HTTP Redirect (CTF)**

リダイレクト内にコンテンツを**入れる**ことが可能です。このコンテンツはブラウザがリダイレクトを実行するため **ユーザには表示されません** が、そこに **何かを隠せる** 可能性があります。

### Web Vulnerabilities Checking

web アプリケーションの包括的な列挙が完了したら、多くの可能性のある脆弱性をチェックする時です。チェックリストはこちら:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Web 脆弱性に関する詳細:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

ページの変更を監視して脆弱性が挿入される可能性を検出するために、例えば [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) のようなツールを使えます。

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
