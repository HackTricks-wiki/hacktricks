# 80,443 - Metodologia di Pentesting Web

{{#include ../../banners/hacktricks-training.md}}

## Informazioni di Base

Il servizio web è il servizio più **comune ed esteso** e esistono molti **tipi diversi di vulnerabilità**.

**Porta predefinita:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API Guidance

{{#ref}}
web-api-pentesting.md
{{#endref}}

## Riepilogo della metodologia

> In questa metodologia supponiamo che tu stia attaccando un dominio (o sottodominio) e solo quello. Quindi, dovresti applicare questa metodologia a ciascun dominio, sottodominio o IP scoperto con server web indeterminato all'interno dell'ambito.

- [ ] Inizia **identificando** le **tecnologie** utilizzate dal server web. Cerca **trucchi** da tenere a mente durante il resto del test se riesci a identificare con successo la tecnologia.
- [ ] Qualche **vulnerabilità nota** della versione della tecnologia?
- [ ] Stai usando qualche **tecnologia ben nota**? Qualche **trucco utile** per estrarre più informazioni?
- [ ] Qualche **scanner specializzato** da eseguire (come wpscan)?
- [ ] Avvia **scanner di uso generale**. Non sai mai se troveranno qualcosa o se troveranno informazioni interessanti.
- [ ] Inizia con i **controlli iniziali**: **robots**, **sitemap**, errore **404** e **scansione SSL/TLS** (se HTTPS).
- [ ] Inizia a **spiderare** la pagina web: È tempo di **trovare** tutti i possibili **file, cartelle** e **parametri utilizzati.** Controlla anche eventuali **risultati speciali**.
- [ ] _Nota che ogni volta che viene scoperta una nuova directory durante il brute-forcing o lo spidering, dovrebbe essere spiderata._
- [ ] **Brute-Forcing delle directory**: Prova a forzare tutte le cartelle scoperte cercando nuovi **file** e **directory**.
- [ ] _Nota che ogni volta che viene scoperta una nuova directory durante il brute-forcing o lo spidering, dovrebbe essere forzata._
- [ ] **Controllo dei backup**: Verifica se riesci a trovare **backup** di **file scoperti** aggiungendo estensioni di backup comuni.
- [ ] **Brute-Force dei parametri**: Prova a **trovare parametri nascosti**.
- [ ] Una volta che hai **identificato** tutti i possibili **endpoint** che accettano **input dell'utente**, controlla tutti i tipi di **vulnerabilità** ad essi correlate.
- [ ] [Segui questa checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Versione del server (Vulnerabile?)

### Identificare

Controlla se ci sono **vulnerabilità note** per la **versione** del server in esecuzione.\
Le **intestazioni HTTP e i cookie della risposta** potrebbero essere molto utili per **identificare** le **tecnologie** e/o la **versione** utilizzata. La **scansione Nmap** può identificare la versione del server, ma potrebbero essere utili anche gli strumenti [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)o [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Cerca **per** [**vulnerabilità dell'applicazione web** **versione**](../../generic-hacking/search-exploits.md)

### **Controlla se ci sono WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Trucchi tecnologici web

Alcuni **trucchi** per **trovare vulnerabilità** in diverse **tecnologie** ben note utilizzate:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php ha molti trucchi interessanti che potrebbero essere sfruttati)**](php-tricks-esp/)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS a RCE)**](electron-desktop-apps/)

_Tieni presente che il **stesso dominio** può utilizzare **tecnologie diverse** su **porte**, **cartelle** e **sottodomini** diversi._\
Se l'applicazione web utilizza qualche **tecnologia/piattaforma ben nota elencata prima** o **qualsiasi altra**, non dimenticare di **cercare su Internet** nuovi trucchi (e fammi sapere!).

### Revisione del codice sorgente

Se il **codice sorgente** dell'applicazione è disponibile su **github**, oltre a eseguire un **test White box** dell'applicazione, ci sono **alcune informazioni** che potrebbero essere **utili** per il **test Black-Box** attuale:

- C'è un file **Change-log o Readme o Version** o qualsiasi cosa con **informazioni sulla versione accessibili** via web?
- Come e dove sono salvate le **credenziali**? C'è qualche **file** (accessibile?) con credenziali (nomi utente o password)?
- Le **password** sono in **testo semplice**, **crittografate** o quale **algoritmo di hashing** è utilizzato?
- Viene utilizzata qualche **chiave master** per crittografare qualcosa? Quale **algoritmo** è utilizzato?
- Puoi **accedere a uno di questi file** sfruttando qualche vulnerabilità?
- Ci sono informazioni **interessanti su github** (problemi risolti e non risolti)? O nella **cronologia dei commit** (forse qualche **password introdotta in un vecchio commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Scanner automatici

#### Scanner automatici di uso generale
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Scanner CMS

Se viene utilizzato un CMS, non dimenticare di **eseguire uno scanner**, potrebbe essere trovato qualcosa di succoso:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/), **Joomla**, **vBulletin** siti web per problemi di sicurezza. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/) **o** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> A questo punto dovresti già avere alcune informazioni sul server web utilizzato dal cliente (se sono disponibili dati) e alcuni trucchi da tenere a mente durante il test. Se sei fortunato, hai persino trovato un CMS e eseguito qualche scanner.

## Scoperta dell'applicazione web passo dopo passo

> Da questo punto inizieremo a interagire con l'applicazione web.

### Controlli iniziali

**Pagine predefinite con informazioni interessanti:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Controlla anche i commenti nelle pagine principali e secondarie.

**Forzare errori**

I server web possono **comportarsi in modo imprevisto** quando dati strani vengono inviati loro. Questo può aprire **vulnerabilità** o **divulgare informazioni sensibili**.

- Accedi a **pagine false** come /whatever_fake.php (.aspx,.html,.etc)
- **Aggiungi "\[]", "]]", e "\[\["** nei **valori dei cookie** e nei **valori dei parametri** per creare errori
- Genera errori fornendo input come **`/~randomthing/%s`** alla **fine** dell'**URL**
- Prova **diversi verbi HTTP** come PATCH, DEBUG o errati come FAKE

#### **Controlla se puoi caricare file (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Se scopri che **WebDav** è **abilitato** ma non hai abbastanza permessi per **caricare file** nella cartella radice, prova a:

- **Brute Force** le credenziali
- **Carica file** tramite WebDav nel **resto** delle **cartelle trovate** all'interno della pagina web. Potresti avere permessi per caricare file in altre cartelle.

### **Vulnerabilità SSL/TLS**

- Se l'applicazione **non costringe l'uso di HTTPS** in nessuna parte, allora è **vulnerabile a MitM**
- Se l'applicazione **invia dati sensibili (password) utilizzando HTTP**. Allora è una vulnerabilità alta.

Usa [**testssl.sh**](https://github.com/drwetter/testssl.sh) per controllare le **vulnerabilità** (nei programmi di Bug Bounty probabilmente questo tipo di vulnerabilità non sarà accettato) e usa [**a2sv**](https://github.com/hahwul/a2sv) per ricontrollare le vulnerabilità:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Informazioni sulle vulnerabilità SSL/TLS:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Lanciare qualche tipo di **spider** all'interno del web. L'obiettivo dello spider è **trovare il maggior numero possibile di percorsi** dall'applicazione testata. Pertanto, dovrebbero essere utilizzati web crawling e fonti esterne per trovare il maggior numero possibile di percorsi validi.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): spider HTML, LinkFinder in file JS e fonti esterne (Archive.org, CommonCrawl.org, VirusTotal.com, AlienVault.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): spider HML, con LinkFinder per file JS e Archive.org come fonte esterna.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): spider HTML, indica anche "file succulenti".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): spider HTML interattivo da CLI. Cerca anche in Archive.org.
- [**meg**](https://github.com/tomnomnom/meg) (go): Questo strumento non è uno spider ma può essere utile. Puoi semplicemente indicare un file con host e un file con percorsi e meg recupererà ogni percorso su ogni host e salverà la risposta.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): spider HTML con capacità di rendering JS. Tuttavia, sembra che non sia mantenuto, la versione precompilata è vecchia e il codice attuale non si compila.
- [**gau**](https://github.com/lc/gau) (go): spider HTML che utilizza fornitori esterni (wayback, otx, commoncrawl).
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Questo script troverà URL con parametri e li elencherà.
- [**galer**](https://github.com/dwisiswant0/galer) (go): spider HTML con capacità di rendering JS.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): spider HTML, con capacità di abbellimento JS in grado di cercare nuovi percorsi in file JS. Potrebbe valere la pena dare un'occhiata anche a [JSScanner](https://github.com/dark-warlord14/JSScanner), che è un wrapper di LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Per estrarre endpoint sia nel codice sorgente HTML che nei file javascript incorporati. Utile per cacciatori di bug, red teamers, ninja dell'infosec.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Uno script python 2.7 che utilizza Tornado e JSBeautifier per analizzare URL relativi da file JavaScript. Utile per scoprire facilmente richieste AJAX. Sembra non essere mantenuto.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Dato un file (HTML) estrarrà URL da esso utilizzando espressioni regolari per trovare ed estrarre gli URL relativi da file brutti (minificati).
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, diversi strumenti): Raccogliere informazioni interessanti da file JS utilizzando diversi strumenti.
- [**subjs**](https://github.com/lc/subjs) (go): Trova file JS.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Carica una pagina in un browser headless e stampa tutti gli URL caricati per caricare la pagina.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Strumento di scoperta dei contenuti che mescola diverse opzioni degli strumenti precedenti.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Un'estensione di Burp per trovare percorsi e parametri in file JS.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Uno strumento che dato l'URL .js.map ti fornirà il codice JS abbellito.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Questo è uno strumento utilizzato per scoprire endpoint per un dato target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Scoprire link dalla wayback machine (scaricando anche le risposte nella wayback e cercando ulteriori link).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (anche compilando moduli) e trova anche informazioni sensibili utilizzando regex specifici.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite è un avanzato crawler/spider web GUI multi-funzionale progettato per professionisti della sicurezza informatica.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): È un pacchetto Go e [strumento da riga di comando](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) per estrarre URL, percorsi, segreti e altri dati interessanti dal codice sorgente JavaScript.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge è una semplice **estensione di Burp Suite** per **estrarre i parametri e gli endpoint** dalla richiesta per creare una wordlist personalizzata per fuzzing ed enumerazione.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Strumento fantastico per questo.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Stampa ogni link che riesce a trovare.

### Brute Force directory e file

Inizia a **brute-forzare** dalla cartella radice e assicurati di brute-forzare **tutte** le **directory trovate** utilizzando **questo metodo** e tutte le directory **scoperte** dallo **Spidering** (puoi fare questo brute-forcing **ricorsivamente** e aggiungendo all'inizio della wordlist utilizzata i nomi delle directory trovate).\
Strumenti:

- **Dirb** / **Dirbuster** - Inclusi in Kali, **vecchi** (e **lenti**) ma funzionali. Consentono certificati auto-firmati e ricerca ricorsiva. Troppo lenti rispetto ad altre opzioni.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Non consente certificati auto-firmati ma** consente ricerca ricorsiva.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Consente certificati auto-firmati, **non ha** ricerca **ricorsiva**.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Veloce, supporta ricerca ricorsiva.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Veloce: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Questo non è uno spider ma uno strumento che dato l'elenco di URL trovati eliminerà gli URL "duplicati".
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Estensione di Burp per creare un elenco di directory dalla cronologia di burp di diverse pagine.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Rimuove URL con funzionalità duplicate (basato su importazioni js).
- [**Chamaleon**](https://github.com/iustin24/chameleon): Utilizza wapalyzer per rilevare le tecnologie utilizzate e selezionare le wordlist da utilizzare.

**Dizionari consigliati:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** dizionario incluso](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Nota che ogni volta che viene scoperta una nuova directory durante il brute-forcing o lo spidering, dovrebbe essere Brute-Forzata._

### Cosa controllare su ogni file trovato

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Trova link rotti all'interno degli HTML che potrebbero essere soggetti a takeover.
- **File di backup**: Una volta trovati tutti i file, cerca i backup di tutti i file eseguibili ("_.php_", "_.aspx_"...). Le variazioni comuni per nominare un backup sono: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp e file.old._ Puoi anche utilizzare lo strumento [**bfac**](https://github.com/mazen160/bfac) **o** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Scoprire nuovi parametri**: Puoi utilizzare strumenti come [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **e** [**Param Miner**](https://github.com/PortSwigger/param-miner) **per scoprire parametri nascosti. Se puoi, potresti provare a cercare** parametri nascosti in ciascun file web eseguibile.
- _Arjun tutte le wordlist predefinite:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Commenti:** Controlla i commenti di tutti i file, puoi trovare **credenziali** o **funzionalità nascoste**.
- Se stai partecipando a un **CTF**, un trucco "comune" è **nascondere** **informazioni** all'interno dei commenti a destra della **pagina** (utilizzando **centinaia** di **spazi** in modo da non vedere i dati se apri il codice sorgente con il browser). Un'altra possibilità è utilizzare **diverse nuove righe** e **nascondere informazioni** in un commento in fondo alla pagina web.
- **Chiavi API**: Se **trovi una chiave API** c'è una guida che indica come utilizzare le chiavi API di diverse piattaforme: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird).
- Chiavi API di Google: Se trovi una chiave API che assomiglia a **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik puoi utilizzare il progetto [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) per controllare quali API la chiave può accedere.
- **S3 Buckets**: Durante lo spidering controlla se qualche **sottodominio** o qualche **link** è correlato a qualche **S3 bucket**. In tal caso, [**controlla** le **permissive** del bucket](buckets/).

### Scoperte speciali

**Mentre** esegui lo **spidering** e il **brute-forcing** potresti trovare **cose** **interessanti** che devi **notare**.

**File interessanti**

- Cerca **link** ad altri file all'interno dei file **CSS**.
- [Se trovi un file _**.git**_ alcune informazioni possono essere estratte](git.md).
- Se trovi un _**.env**_ informazioni come chiavi API, password db e altre informazioni possono essere trovate.
- Se trovi **endpoint API** dovresti [testarli anche](web-api-pentesting.md). Questi non sono file, ma probabilmente "sembreranno" tali.
- **File JS**: Nella sezione spidering sono stati menzionati diversi strumenti che possono estrarre percorsi da file JS. Inoltre, sarebbe interessante **monitorare ogni file JS trovato**, poiché in alcune occasioni, una modifica può indicare che una potenziale vulnerabilità è stata introdotta nel codice. Potresti utilizzare ad esempio [**JSMon**](https://github.com/robre/jsmon)**.**
- Dovresti anche controllare i file JS scoperti con [**RetireJS**](https://github.com/retirejs/retire.js/) o [**JSHole**](https://github.com/callforpapers-source/jshole) per scoprire se è vulnerabile.
- **Deobfuscator e Unpacker Javascript:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator).
- **Beautifier Javascript:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org).
- **Deobfuscazione JsFuck** (javascript con caratteri:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/)).
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- In diverse occasioni, sarà necessario **comprendere le espressioni regolari** utilizzate. Questo sarà utile: [https://regex101.com/](https://regex101.com) o [https://pythonium.net/regex](https://pythonium.net/regex).
- Potresti anche **monitorare i file in cui sono stati rilevati moduli**, poiché una modifica nel parametro o l'apparizione di un nuovo modulo può indicare una potenziale nuova funzionalità vulnerabile.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**

{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Se qualche pagina **risponde** con quel **codice**, è probabilmente un **proxy mal configurato**. **Se invii una richiesta HTTP come: `GET https://google.com HTTP/1.1`** (con l'intestazione host e altre intestazioni comuni), il **proxy** cercherà di **accedere** a _**google.com**_ **e avrai trovato un** SSRF.

**Autenticazione NTLM - Informazioni riservate**

Se il server in esecuzione richiede autenticazione è **Windows** o trovi un login che richiede le tue **credenziali** (e richiede il **nome del dominio**), puoi provocare una **divulgazione di informazioni**.\
**Invia** l'**intestazione**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` e a causa di come funziona l'**autenticazione NTLM**, il server risponderà con informazioni interne (versione IIS, versione Windows...) all'interno dell'intestazione "WWW-Authenticate".\
Puoi **automatizzare** questo utilizzando il **plugin nmap** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

È possibile **inserire contenuti** all'interno di una **Redirection**. Questo contenuto **non sarà mostrato all'utente** (poiché il browser eseguirà la redirezione) ma qualcosa potrebbe essere **nascosto** lì dentro.

### Controllo delle vulnerabilità web

Ora che è stata eseguita un'ampia enumerazione dell'applicazione web, è tempo di controllare molte possibili vulnerabilità. Puoi trovare la checklist qui:

{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Trova ulteriori informazioni sulle vulnerabilità web in:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitorare le pagine per modifiche

Puoi utilizzare strumenti come [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) per monitorare le pagine per modifiche che potrebbero inserire vulnerabilità.

### HackTricks Comandi Automatici
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.xyz/pentesting/pentesting-web

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
