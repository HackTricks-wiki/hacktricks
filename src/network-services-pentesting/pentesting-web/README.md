# 80,443 - Pentesting 웹 방법론

{{#include ../../banners/hacktricks-training.md}}

## 기본 정보

웹 서비스는 가장 **일반적이고 광범위한 서비스**이며 많은 **다양한 유형의 취약점**이 존재합니다.

**기본 포트:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API 안내


{{#ref}}
web-api-pentesting.md
{{#endref}}

## 방법론 요약

> 이 방법론에서는 도메인(또는 서브도메인) 하나만 공격한다고 가정합니다. 따라서 범위 내에서 발견된 각 도메인, 서브도메인 또는 웹 서버가 불확실한 IP에 대해 이 방법론을 적용해야 합니다.

- [ ] 먼저 **식별**할 것: 웹 서버가 사용하는 **기술(technologies)**을 파악하세요. 기술을 정확히 식별할 수 있다면 이후 테스트에서 유의할 **트릭(tricks)**을 찾아두세요.
- [ ] 해당 기술 버전에 알려진 **알려진 취약점(known vulnerability)**이 있나요?
- [ ] 잘 알려진 **기술(well known tech)**을 사용 중인가요? 정보를 더 얻기 위한 **유용한 기법(useful trick)**이 있나요?
- [ ] 실행할 **전문화된 스캐너(specialised scanner)**가 있나요(예: wpscan)?
- [ ] **일반 목적 스캐너(general purposes scanners)**를 실행하세요. 뭔가를 찾아낼지 또는 흥미로운 정보를 얻을지 모릅니다.
- [ ] **초기 점검(initial checks)**부터 시작하세요: **robots**, **sitemap**, **404** error 및 **SSL/TLS scan**(HTTPS일 경우).
- [ ] 웹 페이지 **spidering**을 시작하세요: 사용 중인 가능한 모든 **파일(files)**, **폴더(folders)** 및 **파라미터(parameters being used)**를 **찾아(find)** 보세요. 또한 **특이사항(special findings)**을 점검하세요.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: 발견된 모든 폴더를 brute force하여 새로운 **파일(files)** 및 **디렉터리(directories)**를 찾아보세요.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **백업 확인(Backups checking)**: 발견된 **파일(discovered files)**의 **백업(backups)**을 찾을 수 있는지 일반적인 백업 확장자를 붙여 테스트하세요.
- [ ] **Brute-Force parameters**: 숨겨진 **파라미터(hidden parameters)**를 찾아보세요.
- [ ] 모든 가능한 **엔드포인트(endpoints)** 중 **사용자 입력(user input)**을 받는 항목을 **식별(identified)**한 후, 관련된 모든 종류의 **취약점(vulnerabilities)**을 검사하세요.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### 식별

실행 중인 서버 **버전(version)**에 대한 **알려진 취약점(known vulnerabilities)**이 있는지 확인하세요.\
응답의 **HTTP headers and cookies of the response**는 사용 중인 **technologies** 및/또는 **version**을 **identify**하는 데 매우 유용할 수 있습니다. **Nmap scan**은 서버 버전을 식별할 수 있지만, [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech**](https://github.com/ShielderSec/webtech) 또는 [**https://builtwith.com/**](https://builtwith.com)**와 같은 도구들도 유용할 수 있습니다:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Search **for** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **WAF가 있는지 확인하기**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web tech tricks

사용 중인 다양한 잘 알려진 **기술**에서 **취약점 찾기**를 위한 몇 가지 **트릭**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)

_같은 도메인이 서로 다른 **포트**, **폴더**, **서브도메인**에서 **다른 기술**을 사용하고 있을 수 있음을 고려하세요._\
웹 애플리케이션이 앞서 나열된 잘 알려진 **tech/platform listed before** 또는 **any other**를 사용하고 있다면, 새로운 트릭을 인터넷에서 반드시 검색하세요(그리고 알려주세요!).

### 소스 코드 리뷰

앱의 **source code**가 **github**에 공개되어 있다면, 애플리케이션에 대해 직접 **White box test**를 수행하는 것 외에도 현재의 **Black-Box testing**에 **유용한** 몇 가지 정보가 있을 수 있습니다:

- 웹에서 접근 가능한 **Change-log or Readme or Version** 파일이나 **version info accessible** 같은 것이 있는가?
- **credentials**는 어떻게 어디에 저장되어 있는가? (접근 가능한) **file**에 credentials(사용자명 또는 비밀번호)가 있는가?
- **passwords**가 **plain text**로 되어 있는가, **encrypted** 되어 있는가, 아니면 어떤 **hashing algorithm**이 사용되는가?
- 뭔가를 암호화하기 위해 **master key**를 사용하고 있는가? 어떤 **algorithm**이 사용되는가?
- 어떤 취약점을 악용하여 이러한 **files**에 접근할 수 있는가?
- **interesting information in the github**(해결된 것과 해결되지 않은 것 모두)이 **issues**에 있는가? 또는 **commit history**에 있는가(예: 오래된 커밋에 **password introduced inside an old commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### 자동 스캐너

#### 범용 자동 스캐너
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS 스캐너

CMS를 사용 중이라면 **스캐너를 실행하세요**, 의외로 흥미로운 결과가 나올 수 있습니다:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** 웹사이트의 보안 문제를 탐지합니다. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **또는** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> 이 시점에서 이미 클라이언트가 사용 중인 웹 서버에 대한 일부 정보(데이터가 제공된 경우)와 테스트 중 유의할 트릭들을 가지고 있어야 합니다. 운이 좋다면 CMS를 발견하고 스캐너를 실행했을 수도 있습니다.

## 단계별 Web Application 발견

> 이제부터 웹 애플리케이션과 상호작용을 시작합니다.

### 초기 점검

**흥미로운 정보를 담고 있는 기본 페이지:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- 메인 및 보조 페이지의 주석도 확인하세요.

**오류 유도**

웹 서버는 이상한 데이터를 전송했을 때 **예상치 못하게 동작**할 수 있습니다. 이는 **취약점**을 열어주거나 **민감한 정보 노출**을 유발할 수 있습니다.

- /whatever_fake.php (.aspx,.html,.etc) 같은 **가짜 페이지**에 접근
- **"\[]", "]]", 및 "\[["** 를 **cookie values** 및 **parameter values**에 추가하여 오류 생성
- **URL**의 **끝**에 **`/~randomthing/%s`** 같은 입력을 줘서 오류 생성
- PATCH, DEBUG 같은 **다른 HTTP Verbs**를 시도하거나 FAKE 같은 잘못된 것 시도

#### **파일 업로드 가능 여부 확인하기 (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

WebDav가 **활성화되어 있지만** 루트 폴더에 **uploading files** 권한이 없다면 다음을 시도하세요:

- **Brute Force**로 자격증명 공격
- WebDav를 통해 웹 페이지 내에서 발견된 **다른 폴더들(rest of found folders)**에 **Upload files**. 다른 폴더에는 업로드 권한이 있을 수 있습니다.

### **SSL/TLS 취약점**

- 애플리케이션이 어느 부분에서도 **HTTPS 사용을 강제하지 않으면**, MitM에 취약합니다.
- 애플리케이션이 **HTTP**로 민감한 데이터(비밀번호)를 전송하면 심각한 취약점입니다.

[**testssl.sh**](https://github.com/drwetter/testssl.sh)를 사용해 **취약점**을 확인하고 (Bug Bounty 프로그램에서는 이러한 유형의 취약점이 인정되지 않는 경우가 많습니다) [**a2sv**](https://github.com/hahwul/a2sv)를 사용해 취약점을 재검토하세요:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

웹 내부에 어떤 형태든 **spider**를 실행하세요. spider의 목표는 테스트 중인 애플리케이션에서 가능한 한 많은 경로를 **찾는 것**입니다. 따라서 웹 크롤링과 외부 소스를 사용해 가능한 많은 유효한 경로를 찾아야 합니다.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files and external sources (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, with LinkFider for JS files and Archive.org as external source.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, also indicates "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. It also searches in Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): This tool isn't a spider but it can be useful. You can just indicate a file with hosts and a file with paths and meg will fetch each path on each host and save the response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider with JS rendering capabilities. However, it looks like it's unmaintained, the precompiled version is old and the current code doesn't compile
- [**gau**](https://github.com/lc/gau) (go): HTML spider that uses external providers (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): This script will find URLs with parameter and will list them.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider with JS rendering capabilities.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, with JS beautify capabilities capable of search new paths in JS files. It could be worth it also take a look to [JSScanner](https://github.com/dark-warlord14/JSScanner), which is a wrapper of LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): To extract endpoints in both HTML source and embedded javascript files. Useful for bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests. Looks like unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Given a file (HTML) it will extract URLs from it using nifty regular expression to find and extract the relative URLs from ugly (minify) files.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Gather interesting information from JS files using several tools.
- [**subjs**](https://github.com/lc/subjs) (go): Find JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Load a page in a headless browser and print out all the urls loaded to load the page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool mixing several options of the previous tools
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): A Burp extension to find path and params in JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): A tool that given the .js.map URL will get you the beatified JS code
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): This is a tool used to discover endpoints for a given target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Discover links from the wayback machine (also downloading the responses in the wayback and looking for more links
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (even by filling forms) and also find sensitive info using specific regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite is an advance multi-feature GUI web security Crawler/Spider designed for cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): It's a Go package and [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) for extracting URLs, paths, secrets, and other interesting data from JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge is a simple **Burp Suite extension** to **extract the paramters and endpoints** from the request to create custom wordlist for fuzzing and enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Awesome tool for this.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Print every link it's able to find.

### Brute Force directories and files

루트 폴더에서 **brute-forcing**을 시작하고, **이 방법**으로 찾은 모든 디렉토리와 Spidering으로 **발견된 모든 디렉토리**를 반드시 brute-force하세요 (이 과정을 **재귀적으로** 수행하고 사용한 wordlist의 앞부분에 발견한 디렉토리 이름을 추가하면 됩니다).\
도구:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_새 디렉토리가 brute-forcing 또는 spidering 도중 발견되면, 그 디렉토리도 항상 Brute-Forced 해야 합니다._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTML 내부의 깨진 링크를 찾아 takeover에 취약할 수 있는 부분을 식별합니다.
- **File Backups**: 모든 파일을 찾은 후에는 실행 파일들의 백업(예: "_.php_", "_.aspx_"...)을 찾아보세요. 백업 파일명으로 흔히 사용되는 변형은: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ 또한 [**bfac**](https://github.com/mazen160/bfac) **또는** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)를 사용할 수 있습니다.
- **Discover new parameters**: 숨겨진 파라미터를 찾기 위해 [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **및** [**Param Miner**](https://github.com/PortSwigger/param-miner) 같은 도구를 사용할 수 있습니다. 가능하다면 각 실행 가능한 웹 파일에서 숨겨진 파라미터를 찾아보세요.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** 모든 파일의 주석을 확인하세요. 주석에서 **credentials**나 **hidden functionality**를 찾을 수 있습니다.
- 만약 **CTF**를 진행 중이라면, 흔한 트릭으로 페이지의 **오른쪽**에 수백 개의 **공백**을 넣어 브라우저로 소스 코드를 열었을 때 보이지 않게 정보를 **주석**으로 숨기거나, 여러 개의 줄바꿈을 사용해 페이지 하단의 주석에 정보를 숨기는 방식이 있습니다.
- **API keys**: API 키를 찾으면 다양한 플랫폼의 API 키 사용 방법을 안내하는 프로젝트들을 참고하세요: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: **AIza**로 시작하는 API 키(예: **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik)를 찾으면 [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner)를 사용해 해당 키가 접근 가능한 API를 확인할 수 있습니다.
- **S3 Buckets**: spidering 중에 어떤 **subdomain**이나 **link**가 S3 bucket과 관련되어 있는지 확인하세요. 그런 경우 [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**spidering**과 **brute-forcing**을 수행하는 동안 **주의**해야 할 **흥미로운** 항목들이 발견될 수 있습니다.

**Interesting files**

- CSS 파일 내부의 **links**로 연결된 다른 파일들을 찾아보세요.
- [_**.git**_ 파일을 찾으면 일부 정보를 추출할 수 있습니다](git.md)
- _**.env**_ 파일을 찾으면 API 키, DB 패스워드 등 여러 정보를 얻을 수 있습니다.
- **API endpoints**를 찾으면 해당 엔드포인트들도 [테스트해야 합니다](web-api-pentesting.md). 이들은 파일은 아니지만 파일처럼 보일 가능성이 높습니다.
- **JS files**: spidering 섹션에서 JS 파일에서 경로를 추출하는 여러 도구를 언급했습니다. 또한 발견한 각 JS 파일을 **모니터링**하는 것이 좋습니다. 일부 경우 코드 변경이 잠재적 취약점의 도입을 의미할 수 있습니다. 예를 들어 [**JSMon**](https://github.com/robre/jsmon)을 사용할 수 있습니다.
- 발견한 JS 파일을 [**RetireJS**](https://github.com/retirejs/retire.js/) 또는 [**JSHole**](https://github.com/callforpapers-source/jshole)로 검사해 취약한 라이브러리가 있는지 확인하세요.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- 정규 표현식(regular expressions)을 이해해야 하는 경우가 자주 있습니다. 이는 도움이 될 것입니다: [https://regex101.com/](https://regex101.com) 또는 [https://pythonium.net/regex](https://pythonium.net/regex)
- 폼이 감지된 파일들을 모니터링하는 것도 좋습니다. 파라미터의 변경이나 새로운 폼의 등장은 잠재적 취약한 기능의 출현을 의미할 수 있습니다.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

어떤 페이지가 해당 **코드**로 응답하면, 이는 잘못 구성된 프록시일 가능성이 큽니다. **만약 다음과 같은 HTTP 요청을 보낸다면: `GET https://google.com HTTP/1.1`** (Host 헤더 및 기타 일반 헤더 포함), 프록시는 _**google.com**_에 접근하려 시도하며 이는 SSRF를 발견한 경우일 수 있습니다.

**NTLM Authentication - Info disclosure**

실행 중인 서버가 인증을 요구하고 그 서버가 **Windows**이거나 로그인에서 **도메인 이름**을 요구하면 정보 누출을 유도할 수 있습니다.\
다음 **헤더**를 전송하세요: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` 그러면 NTLM 인증 방식 때문에 서버가 "WWW-Authenticate" 헤더 안에 내부 정보(IIS 버전, Windows 버전 등)를 응답으로 보내게 됩니다.\
이를 자동화하려면 **nmap plugin** "_http-ntlm-info.nse_"를 사용할 수 있습니다.

**HTTP Redirect (CTF)**

리다이렉션 안에 콘텐츠를 넣을 수 있습니다. 이 콘텐츠는 브라우저가 리다이렉션을 실행하기 때문에 사용자에게 **보여지지 않지만**, 그 안에 **무언가를 숨길 수** 있습니다.

### Web Vulnerabilities Checking

웹 애플리케이션에 대한 포괄적 열거가 완료되었으면 이제 다양한 취약점을 점검할 차례입니다. 체크리스트는 다음에서 확인하세요:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

웹 취약점에 대한 추가 정보:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

변경으로 인해 취약점이 생길 수 있는지 페이지 수정을 모니터링하려면 [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) 같은 도구를 사용할 수 있습니다.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
