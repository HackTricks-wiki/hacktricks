# 80,443 - Pentesting Web Methodology

{{#include ../../banners/hacktricks-training.md}}

## Taarifa za Msingi

Web service ni **huduma inayotumika zaidi na yenye wigo mpana** na kuna **aina mbalimbali za vulnerabilities**.

**Porti chaguo-msingi:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Mwongozo wa Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Muhtasari wa Mbinu

> Katika methodology hii tutaweka dhana kwamba unataka kuattack domain (au subdomain) na hiyo tu. Kwa hivyo, unapaswa kutumia methodology hii kwa kila domain, subdomain au IP iliyogunduliwa ndani ya scope ikiwa kuna web server isiyojulikana ndani yake.

- [ ] Anza kwa **kutambua** **technologies** zinazotumika na web server. Tafuta **tricks** za kuzingatia wakati wa mtihani ikiwa utaweza kutambua tech kwa ufanisi.
- [ ] Kuna **known vulnerability** yoyote ya version ya technology?
- [ ] Unatumia **well known tech**? Kuna **useful trick** yoyote ya kupata taarifa zaidi?
- [ ] Kuna **specialised scanner** yoyote ya kuendesha (kama wpscan)?
- [ ] Endesha **general purposes scanners**. Hujui kabisa kama zitatoka na kitu au zitakuletea taarifa za kuvutia.
- [ ] Anza na **initial checks**: **robots**, **sitemap**, **404** error na **SSL/TLS scan** (ikiwa HTTPS).
- [ ] Anza **spidering** tovuti: Ni wakati wa **kutafuta** faili zote, folda na **parameters being used.** Pia, angalia kwa **special findings**.
- [ ] _Kumbuka kwamba kila wakati directory mpya inapogunduliwa wakati wa brute-forcing au spidering, inapaswa ku-spider._
- [ ] **Directory Brute-Forcing**: Jaribu kuvunja (brute force) folders zote zilizogunduliwa ukitafuta **files** na **directories** mpya.
- [ ] _Kumbuka kwamba kila wakati directory mpya inapogunduliwa wakati wa brute-forcing au spidering, inapaswa kufanyiwa Brute-Force._
- [ ] **Backups checking**: Jaribu kama unaweza kupata **backups** za **discovered files** kwa kuongezea extensions za backup za kawaida.
- [ ] **Brute-Force parameters**: Jaribu **kutafuta hidden parameters**.
- [ ] Ukimaliza kutambua endpoint zote zinazoweza kupokea **user input**, angalia aina zote za **vulnerabilities** zinazohusiana nazo.
- [ ] [Fuata orodha hii ya ukaguzi](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Tambua

Angalia kama kuna **known vulnerabilities** kwa server **version** inayokimbia.\
The **HTTP headers and cookies of the response** zinaweza kuwa muhimu sana kutambua **technologies** na/au **version** zinazotumika. **Nmap scan** inaweza kutambua server version, lakini inaweza pia kuwa muhimu kutumia zana kama [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech**](https://github.com/ShielderSec/webtech) au [**https://builtwith.com/**](https://builtwith.com) **:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Tafuta **kwa** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Angalia kama kuna WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Mbinu za teknolojia za wavuti

Baadhi ya **mbinu** za **kutafuta udhaifu** katika **teknolojia** mbalimbali maarufu zinazotumika:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Custom UDP RPC Protocols**](custom-protocols.md)
- [**Dotnet SOAP WSDL client exploitation**](dotnet-soap-wsdl-client-exploitation.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Fortinet FortiWeb**](fortinet-fortiweb.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](https://github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Chukua katika akaunti kwamba **domaini ile ile** inaweza kutumia **teknolojia tofauti** katika **bandari**, **folda** na **subdomains**._\
Ikiwa web application inatumia yoyote ya **tech/platform** iliyojulikana iliyoorodheshwa hapo juu au **nyingine yoyote**, usisahau **kutafuta mtandaoni** mbinu mpya (na nijulishe!).

### Mapitio ya Source Code

Ikiwa **source code** ya application inapatikana kwenye **github**, mbali na kufanya mwenyewe **White box test** ya application kuna **maelezo kadhaa** ambayo yanaweza kuwa **muhimu** kwa **Black-Box testing** ya sasa:

- Je, kuna faili ya **Change-log au Readme au Version** au kitu chochote chenye **taarifa za version zinazopatikana** kupitia wavuti?
- Je, **credentials** zinawekwa wapi na jinsi gani? Je, kuna **file** (inayopatikana?) yenye credentials (usernames au passwords)?
- Je, **passwords** ziko kwa **plain text**, **encrypted**, au ni algorithmi gani ya **hashing** inayotumika?
- Je, inatumia **master key** ili ku-encrypt kitu chochote? Ni **algorithm** gani inayotumika?
- Je, unaweza **kupata faili yoyote kati ya hizi** ukitumia udhaifu wowote?
- Je, kuna **maelezo ya kuvutia kwenye github** (issues zilizotatuliwa na zisizotatuliwa)? Au katika **commit history** (labda kuna **password** iliyowekwa katika commit ya zamani)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Scanners za otomatiki

#### Scanners za madhumuni ya jumla automatic scanners
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Skana za CMS

Ikiwa CMS inatumiwa, usisahau **endesha scanner**, labda utakuta kitu cha kuvutia:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** tovuti kwa masuala ya usalama. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **au** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Katika hatua hii unapaswa tayari kuwa na baadhi ya taarifa kuhusu web server inayotumika na client (ikiwa data yoyote imetolewa) na mbinu za kuzingatia wakati wa test. Ikiwa una bahati unaweza hata kuwa umepata CMS na kumfanya scanner.

## Ugunduzi wa Programu za Wavuti hatua kwa hatua

> Kuanzia hapa tutaanza kuingiliana na web application.

### Ukaguzi wa awali

**Kurasa za chaguo-msingi zilizo na taarifa za kuvutia:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Angalia pia maoni kwenye kurasa kuu na za ziada.

**Kulazimisha makosa**

Web servers zinaweza **kutenda kwa njia isiyotegemewa** wakati data ya ajabu inapotumwa kwao. Hii inaweza kufungua **vulnerabilities** au **kuonyesha taarifa nyeti**.

- Fikia **kurasa za uongo** kama /whatever_fake.php (.aspx,.html,.etc)
- **Ongeza "[]", "]]", na "[["** katika **cookie values** na **parameter values** ili kusababisha makosa
- Tengeneza kosa kwa kutoa input kama **`/~randomthing/%s`** mwishoni mwa **URL**
- Jaribu **HTTP Verbs tofauti** kama PATCH, DEBUG au hata mbaya kama FAKE

#### **Check if you can upload files (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

If you find that **WebDav** is **enabled** but you don't have enough permissions for **uploading files** in the root folder try to:

- **Brute Force** credentials
- **Upload files** via WebDav to the **rest** of **found folders** inside the web page. You may have permissions to upload files in other folders.

### **Udhaifu za SSL/TLS**

- Ikiwa application **hainalazimisha matumizi ya HTTPS** sehemu yoyote, basi iko **vulnerable to MitM**
- Ikiwa application inatuma data nyeti (nywila) kwa kutumia HTTP, basi ni vulnerability kubwa.

Use [**testssl.sh**](https://github.com/drwetter/testssl.sh) to checks for **vulnerabilities** (In Bug Bounty programs probably these kind of vulnerabilities won't be accepted) and use [**a2sv** ](https://github.com/hahwul/a2sv)to recheck the vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Lanzua aina fulani ya spider ndani ya tovuti. Lengo la spider ni kupata njia nyingi iwezekanavyo kutoka kwa application inayoendekwa. Kwa hiyo, web crawling na vyanzo vya nje vinapaswa kutumika kupata njia nyingi sahihi iwezekanavyo.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files and external sources (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, with LinkFider for JS files and Archive.org as external source.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, also indicates "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. It also searches in Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): This tool isn't a spider but it can be useful. You can just indicate a file with hosts and a file with paths and meg will fetch each path on each host and save the response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider with JS rendering capabilities. However, it looks like it's unmaintained, the precompiled version is old and the current code doesn't compile
- [**gau**](https://github.com/lc/gau) (go): HTML spider that uses external providers (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): This script will find URLs with parameter and will list them.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider with JS rendering capabilities.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, with JS beautify capabilities capable of search new paths in JS files. It could be worth it also take a look to [JSScanner](https://github.com/dark-warlord14/JSScanner), which is a wrapper of LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): To extract endpoints in both HTML source and embedded javascript files. Useful for bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests. Looks like unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Given a file (HTML) it will extract URLs from it using nifty regular expression to find and extract the relative URLs from ugly (minify) files.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Gather interesting information from JS files using several tools.
- [**subjs**](https://github.com/lc/subjs) (go): Find JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Load a page in a headless browser and print out all the urls loaded to load the page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool mixing several options of the previous tools
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): A Burp extension to find path and params in JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): A tool that given the .js.map URL will get you the beatified JS code
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): This is a tool used to discover endpoints for a given target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Discover links from the wayback machine (also downloading the responses in the wayback and looking for more links)
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (even by filling forms) and also find sensitive info using specific regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite is an advance multi-feature GUI web security Crawler/Spider designed for cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): It's a Go package and [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) for extracting URLs, paths, secrets, and other interesting data from JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge is a simple **Burp Suite extension** to **extract the paramters and endpoints** from the request to create custom wordlist for fuzzing and enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Awesome tool for this.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Print every link it's able to find.

### Brute Force directories and files

Anza kufanya **brute-forcing** kutoka kwenye root folder na hakikisha kufufua **brute-force** kwenye **directories zote zilizopatikana** ukitumia **hii method** na pia directories zote **zilizoonekana** wakati wa **Spidering** (unaweza kufanya brute-forcing hii **recursively** na kuongezea mwanzoni wa wordlist iliyotumika majina ya directories uliyopata).\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

**Dictionaries zinazopendekezwa:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Kumbuka kuwa kila wakati katalogi mpya inapogunduliwa wakati wa brute-forcing au spidering, inapaswa kufanyiwa Brute-Force._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Find broken links inside HTMLs that may be prone to takeovers
- **File Backups**: Mara utakapo pata mafaili yote, angalia backups za mafaili yote yanayoendeshwa ("_.php_", "_.aspx_"...). Vipengele vya kawaida vya majina ya backup ni: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ Unaweza pia kutumia tool [**bfac**](https://github.com/mazen160/bfac) **au** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Unaweza kutumia zana kama [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **na** [**Param Miner**](https://github.com/PortSwigger/param-miner) **kutambua vigezo vifichwa. Ikiwa inawezekana, jaribu kutafuta** vigezo vilivyofichwa kwenye kila faili za web zinazotekelezwa.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Kagua comments za mafaili yote, unaweza kupata **credentials** au **hidden functionality**.
- Ikiwa unapiga **CTF**, mbinu ya kawaida ni **kuficha** **taarifa** ndani ya comments upande wa **kulia** wa **page** (kutumia **mashauri mia** za **spaces** ili usione data ukiifungua source code kwa browser). Njia nyingine ni kutumia **mitaala mingi ya newline** na **kuficha taarifa** katika comment chini ya ukurasa wa web.
- **API keys**: Ikiwa **unapata API key** kuna mwongozo unaoelezea jinsi ya kutumia API keys za platform mbalimbali: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](https://github.com/l4yton/RegHex)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Ikiwa unapata API key inayofanana na **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik unaweza kutumia project [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) kubaini ni APIs gani key inaweza kufikia.
- **S3 Buckets**: Wakati wa spidering angalia kama subdomain au link yoyote inahusiana na S3 bucket. Katika kesi hiyo, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**Wakati** unafanya **spidering** na **brute-forcing** unaweza kugundua vitu **vya kusisimua** ambavyo unapaswa kuyatambua.

**Interesting files**

- Tafuta **links** kwenda kwa mafaili mengine ndani ya mafaili ya **CSS**.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Ikiwa unapata _**.env**_ taarifa kama api keys, dbs passwords na taarifa nyingine zinaweza kupatikana.
- Ikiwa unapata **API endpoints** unapaswa [pia kuyaweka kwenye test](web-api-pentesting.md). Haya sio mafaili, lakini huenda "yaonekana kama" mafaili.
- **JS files**: Katika sehemu ya spidering zilitajwa zana kadhaa zinazoweza kutoa path kutoka kwa JS files. Pia, itakuwa muhimu **kufuatilia kila JS file iliyopatikana**, kwa sababu kwenye matukio kadhaa, mabadiliko yanaweza kuonyesha kuwa udhaifu mpya umeingizwa kwenye code. Unaweza kutumia kwa mfano [**JSMon**](https://github.com/robre/jsmon)**.**
- Pia unapaswa kuangalia JS files zilizogunduliwa na [**RetireJS**](https://github.com/retirejs/retire.js/) au [**JSHole**](https://github.com/callforpapers-source/jshole) kuona kama zina udhaifu.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Katika matukio mengi, utahitaji **kuelewa regular expressions** zinazotumika. Hii itakuwa muhimu: [https://regex101.com/](https://regex101.com) au [https://pythonium.net/regex](https://pythonium.net/regex)
- Unaweza pia **kufuatilia mafaili ambapo fomu ziligunduliwa**, kwani mabadiliko kwenye parameter au kuonekana kwa fomu mpya kunaweza kuashiria functionality mpya yenye udhaifu.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Ikiwa ukurasa wowote unarepond na code hiyo, kawaida ni proxy iliyopangwa vibaya. **Ikiwa utatuma HTTP request kama: `GET https://google.com HTTP/1.1`** (na host header na vichwa vingine vya kawaida), proxy itajaribu kufikia _**google.com**_ **na utakuwa umepata** SSRF.

**NTLM Authentication - Info disclosure**

Ikiwa server inayouliza authentication ni **Windows** au ukiona login inayouliza **credentials** zako (na kuonyesha jina la **domain**), unaweza kusababisha **information disclosure**.\
**Tuma** **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` na kutokana na jinsi **NTLM authentication inavyofanya kazi**, server itajibu na info za ndani (version ya IIS, version ya Windows...) ndani ya header "WWW-Authenticate".\
Unaweza **kuendesha kiotomatiki** hili ukiwa unatumia **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Inawezekana **kuweka content** ndani ya **Redirection**. Content hii **haitaonyeshwa kwa mtumiaji** (kwa sababu browser itatekeleza redirection) lakini kitu kinaweza **kufichwa** ndani yake.

### Web Vulnerabilities Checking

Sasa baada ya kuendesha enumeration kamili ya web application ni wakati wa kuangalia udhaifu mwingi unaowezekana. Unaweza kupata checklist hapa:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Pata habari zaidi kuhusu web vulns katika:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Unaweza kutumia zana kama [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) kufuatilia mabadiliko ya kurasa ambayo yanaweza kuingiza udhaifu.

### HackTricks Automatic Commands

<details>
<summary>HackTricks Automatic Commands</summary>
```yaml
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
</details>

{{#include ../../banners/hacktricks-training.md}}
