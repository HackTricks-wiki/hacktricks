# 80,443 - Pentesting Web Μεθοδολογία

{{#include ../../banners/hacktricks-training.md}}

## Βασικές Πληροφορίες

Η web υπηρεσία είναι η πιο **συνηθισμένη και εκτενής υπηρεσία** και υπάρχουν πολλά **διαφορετικά είδη ευπαθειών**.

**Προεπιλεγμένη θύρα:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Οδηγίες Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Περίληψη μεθοδολογίας

> Σε αυτή τη methodology θα υποθέσουμε ότι πρόκειται να επιτεθείς σε ένα domain (ή subdomain) και μόνο αυτό. Επομένως, πρέπει να εφαρμόσεις αυτή τη methodology σε κάθε εντοπισμένο domain, subdomain ή IP με ακαθόριστο web server εντός του scope.

- [ ] Ξεκίνα με το **identifying** των **technologies** που χρησιμοποιεί ο web server. Ψάξε για **tricks** που να έχεις υπόψη σου κατά την υπόλοιπη δοκιμή αν μπορέσεις να αναγνωρίσεις το tech.
- [ ] Υπάρχει οποιαδήποτε **known vulnerability** στην έκδοση της technology;
- [ ] Χρησιμοποιείται κάποια **well known tech**; Κάποιο **useful trick** για να εξάγεις περισσότερες πληροφορίες;
- [ ] Κάποιος **specialised scanner** να τρέξεις (όπως wpscan);
- [ ] Εκτέλεσε **general purposes scanners**. Ποτέ δεν ξέρεις αν θα βρουν κάτι ή αν θα αποκαλύψουν κάποια ενδιαφέρουσα πληροφορία.
- [ ] Ξεκίνα με τους **initial checks**: **robots**, **sitemap**, **404** error και **SSL/TLS scan** (αν είναι HTTPS).
- [ ] Ξεκίνα το **spidering** της σελίδας: Είναι ώρα να **βρεις** όλα τα πιθανά **files, folders** και **parameters being used.** Επίσης, έλεγξε για **special findings**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: Προσπάθησε να brute force όλα τα εντοπισμένα folders αναζητώντας νέα **files** και **directories**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **Backups checking**: Έλεγξε αν μπορείς να βρεις **backups** των **discovered files** προσθέτοντας κοινές backup extensions.
- [ ] **Brute-Force parameters**: Προσπάθησε να **βρεις hidden parameters**.
- [ ] Μόλις έχεις **identified** όλα τα πιθανά **endpoints** που δέχονται **user input**, έλεγξε για κάθε είδους **vulnerabilities** που σχετίζονται με αυτά.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

Έλεγξε αν υπάρχουν **known vulnerabilities** για την έκδοση του server (**version**) που τρέχει.\
Οι **HTTP headers and cookies of the response** μπορούν να είναι πολύ χρήσιμες για να **identify** τις **technologies** και/ή την **version** που χρησιμοποιείται. Το **Nmap scan** μπορεί να αναγνωρίσει την έκδοση του server, αλλά χρήσιμα μπορεί να είναι και τα εργαλεία [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)ή [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Αναζήτηση **για** [**ευπάθειες της έκδοσης της web εφαρμογής**](../../generic-hacking/search-exploits.md)

### **Έλεγχος αν υπάρχει κάποιος WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Κόλπα τεχνολογιών Web

Μερικά **κόλπα** για **εντοπισμό ευπαθειών** σε διάφορες γνωστές **τεχνολογίες** που χρησιμοποιούνται:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)

_Λάβετε υπόψη ότι το **ίδιο domain** μπορεί να χρησιμοποιεί **διαφορετικές τεχνολογίες** σε διαφορετικές **πόρτες**, **φακέλους** και **υποτομείς**._\
Αν η web εφαρμογή χρησιμοποιεί κάποια γνωστή **τεχνολογία/πλατφόρμα που αναφέρθηκε παραπάνω** ή **κάποια άλλη**, μην ξεχάσετε να **αναζητήσετε στο Internet** νέα κόλπα (και ενημερώστε με!).

### Επισκόπηση Πηγαίου Κώδικα

Αν ο **πηγαίος κώδικας** της εφαρμογής είναι διαθέσιμος στο **github**, εκτός από το να κάνετε μόνοι σας έναν White box test της εφαρμογής, υπάρχουν **κάποιες πληροφορίες** που θα μπορούσαν να είναι **χρήσιμες** για το τρέχον **Black-Box testing**:

- Υπάρχει ένα **Change-log or Readme or Version** αρχείο ή κάτι με **πληροφορίες έκδοσης προσβάσιμες** μέσω web;
- Πώς και πού αποθηκεύονται τα **credentials**; Υπάρχει κάποιο (προσβάσιμο;) **αρχείο** με credentials (usernames ή passwords);
- Είναι οι **passwords** σε **plain text**, **encrypted** ή ποιος **hashing algorithm** χρησιμοποιείται;
- Χρησιμοποιεί κάποιο **master key** για την κρυπτογράφηση κάτι; Ποιος **algorithm** χρησιμοποιείται;
- Μπορείτε να **προσπελάσετε κάποια από αυτά τα αρχεία** εκμεταλλευόμενοι κάποια ευπάθεια;
- Υπάρχουν **ενδιαφέρουσες πληροφορίες στο github** (solved και not solved) **issues**; Ή στο **commit history** (ίσως κάποιο **password εισήχθη σε παλιό commit**)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Αυτόματοι σαρωτές

#### Αυτόματοι σαρωτές γενικής χρήσης
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Σαρωτές CMS

Αν χρησιμοποιείται ένα CMS μην ξεχάσετε να **run a scanner**, ίσως βρεθεί κάτι ενδιαφέρον:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** ιστότοποι για θέματα ασφάλειας. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **ή** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Σε αυτό το σημείο θα πρέπει ήδη να έχετε κάποιες πληροφορίες για τον web server που χρησιμοποιεί ο client (αν υπάρχουν δεδομένα) και μερικά κόλπα που πρέπει να έχετε στο μυαλό σας κατά τη διάρκεια του test. Αν είστε τυχεροί ίσως έχετε βρει ένα CMS και έχετε τρέξει κάποιο scanner.

## Βήμα-βήμα Ανακάλυψη Web Εφαρμογής

> Από αυτό το σημείο θα αρχίσουμε να αλληλεπιδρούμε με την web εφαρμογή.

### Αρχικοί έλεγχοι

**Προεπιλεγμένες σελίδες με ενδιαφέρουσες πληροφορίες:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Ελέγξτε επίσης τα σχόλια στις κύριες και δευτερεύουσες σελίδες.

**Πρόκληση σφαλμάτων**

Οι web servers μπορεί να **συμπεριφερθούν απρόβλεπτα** όταν τους αποστέλλονται περίεργα δεδομένα. Αυτό μπορεί να ανοίξει **vulnerabilities** ή να αποκαλύψει ευαίσθητες πληροφορίες.

- Πρόσβαση σε **ψεύτικες σελίδες** όπως /whatever_fake.php (.aspx,.html,.etc)
- **Add "\[]", "]]", and "\[["** σε **τιμές cookie** και **τιμές παραμέτρων** για να δημιουργήσετε σφάλματα
- Δημιουργήστε σφάλμα δίνοντας είσοδο ως **`/~randomthing/%s`** στο **τέλος** του **URL**
- Δοκιμάστε **διαφορετικά HTTP Verbs** όπως PATCH, DEBUG ή λάθος όπως FAKE

#### **Ελέγξτε αν μπορείτε να ανεβάσετε αρχεία (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Αν διαπιστώσετε ότι το **WebDav** είναι **ενεργοποιημένο** αλλά δεν έχετε αρκετά δικαιώματα για το **ανέβασμα αρχείων** στον root φάκελο δοκιμάστε:

- **Brute Force** credentials
- **Upload files** μέσω WebDav σε άλλα βρεθέντα folders μέσα στην ιστοσελίδα. Μπορεί να έχετε δικαιώματα να ανεβάσετε αρχεία σε αυτούς τους φακέλους.

### **SSL/TLS vulnerabilites**

- Αν η εφαρμογή **δεν αναγκάζει τη χρήση HTTPS** σε κανένα σημείο, τότε είναι **vulnerable to MitM**
- Αν η εφαρμογή **στέλνει ευαίσθητα δεδομένα (passwords) μέσω HTTP** τότε είναι υψηλή ευπάθεια.

Χρησιμοποιήστε [**testssl.sh**](https://github.com/drwetter/testssl.sh) για έλεγχο για **vulnerabilities** (Σε Bug Bounty προγράμματα πιθανότατα αυτού του είδους οι ευπάθειες δεν θα γίνουν δεκτές) και χρησιμοποιήστε [**a2sv** ](https://github.com/hahwul/a2sv)to recheck the vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Πληροφορίες για SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Εκκινήστε κάποιο είδος **spider** στο web. Ο στόχος του spider είναι να **βρει όσο το δυνατόν περισσότερα paths** από την εφαρμογή που δοκιμάζεται. Επομένως, web crawling και εξωτερικές πηγές πρέπει να χρησιμοποιηθούν για να εντοπιστούν όσο το δυνατόν περισσότερα έγκυρα paths.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder σε JS files και εξωτερικές πηγές (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, με LinkFider για JS files και Archive.org ως εξωτερική πηγή.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, επίσης επισημαίνει "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. Επίσης ψάχνει στο Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): Αυτό το εργαλείο δεν είναι spider αλλά μπορεί να είναι χρήσιμο. Μπορείτε να δώσετε ένα αρχείο με hosts και ένα αρχείο με paths και το meg θα κάνει fetch κάθε path σε κάθε host και θα αποθηκεύσει την απόκριση.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider με JS rendering δυνατότητες. Ωστόσο, φαίνεται ότι δεν συντηρείται, η προ-συμπιεσμένη έκδοση είναι παλιά και ο τρέχων κώδικας δεν μεταγλωττίζεται.
- [**gau**](https://github.com/lc/gau) (go): HTML spider που χρησιμοποιεί εξωτερικούς παρόχους (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Αυτό το script θα βρει URLs με parameter και θα τα καταγράψει.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider με JS rendering δυνατότητες.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, με JS beautify δυνατότητες ικανές να αναζητήσουν νέα paths σε JS files. Αξίζει επίσης να δείτε το [JSScanner](https://github.com/dark-warlord14/JSScanner), που είναι wrapper του LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Εξαγωγή endpoints τόσο από HTML source όσο και από embedded javascript files. Χρήσιμο για bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Ένα python 2.7 script που χρησιμοποιεί Tornado και JSBeautifier για να κάνει parse relative URLs από JavaScript files. Χρήσιμο για εύκολη ανακάλυψη AJAX requests. Φαίνεται μη συντηρημένο.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Δίνοντας ένα αρχείο (HTML) θα εξάγει URLs χρησιμοποιώντας καλοφτιαγμένα regular expressions για να βρει και να εξάγει relative URLs από ugly (minify) αρχεία.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Συλλέγει ενδιαφέρουσες πληροφορίες από JS files χρησιμοποιώντας πολλά εργαλεία.
- [**subjs**](https://github.com/lc/subjs) (go): Βρίσκει JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Φορτώνει μια σελίδα σε headless browser και τυπώνει όλα τα urls που φορτώνονται για τη σελίδα.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool που συνδυάζει πολλές επιλογές από τα προηγούμενα εργαλεία.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Μια Burp extension για να βρει path και params σε JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Ένα εργαλείο που, δεδομένου του .js.map URL, θα σας φέρει τον beautified JS κώδικα.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Εργαλείο για ανακάλυψη endpoints για έναν στόχο.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Ανακαλύπτει links από το wayback machine (επίσης κατεβάζει τις αποκρίσεις στο wayback και ψάχνει για περισσότερα links).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (ακόμα και συμπληρώνοντας forms) και βρίσκει επίσης sensitive info χρησιμοποιώντας συγκεκριμένα regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite είναι ένα advanced multi-feature GUI web security Crawler/Spider σχεδιασμένο για cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): Είναι ένα Go package και [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) για εξαγωγή URLs, paths, secrets και άλλων ενδιαφερουσών πληροφοριών από JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge είναι ένα απλό **Burp Suite extension** για **εξαγωγή των parameters και endpoints** από τα requests για να δημιουργήσει custom wordlist για fuzzing και enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Εξαιρετικό εργαλείο για αυτό.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Τυπώνει κάθε link που μπορεί να βρει.

### Brute Force directories and files

Αρχίστε το **brute-forcing** από τον root φάκελο και βεβαιωθείτε ότι θα brute-force **όλους** τους **directories** που βρέθηκαν χρησιμοποιώντας **this method** και όλους τους directories **ανακαλυφθέντες** από το **Spidering** (μπορείτε να κάνετε αυτό το brute-forcing **recursively** και να προσθέσετε στην αρχή της used wordlist τα ονόματα των φακέλων που βρέθηκαν).\
Εργαλεία:

- **Dirb** / **Dirbuster** - Περιλαμβάνεται στο Kali, **παλιά** (και **αργή**) αλλά λειτουργική. Επιτρέπει auto-signed certificates και recursive search. Πολύ αργή σε σύγκριση με τις άλλες επιλογές.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Δεν επιτρέπει auto-signed certificates αλλά** επιτρέπει recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Επιτρέπει auto-signed certificates, δεν έχει **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): Αυτό δεν είναι spider αλλά ένα εργαλείο που, δεδομένης της λίστας με τα βρεθέντα URLs, θα διαγράψει "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension για να δημιουργεί λίστα directories από το burp history διαφορετικών σελίδων.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Αφαιρεί URLs με duplicated λειτουργικότητες (βασισμένο σε js imports).
- [**Chamaleon**](https://github.com/iustin24/chameleon): Χρησιμοποιεί wapalyzer για να εντοπίσει τις τεχνολογίες που χρησιμοποιούνται και να επιλέξει τις κατάλληλες wordlists.

**Συνιστώμενα dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Σημείωση ότι κάθε φορά που ανακαλύπτεται ένας νέος directory κατά τη διάρκεια του brute-forcing ή του spidering, θα πρέπει να γίνεται Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Βρείτε broken links μέσα σε HTMLs που μπορεί να είναι επιρρεπή σε takeovers
- **File Backups**: Μόλις έχετε βρει όλα τα αρχεία, ψάξτε για backups όλων των εκτελέσιμων αρχείων ("_.php_", "_.aspx_"...). Κοινές παραλλαγές ονομάτων backup είναι: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp και file.old._ Μπορείτε επίσης να χρησιμοποιήσετε το εργαλείο [**bfac**](https://github.com/mazen160/bfac) **ή** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **και** [**Param Miner**](https://github.com/PortSwigger/param-miner) **για να ανακαλύψετε κρυφά parameters. Αν μπορείτε, δοκιμάστε να αναζητήσετε** κρυφά parameters σε κάθε εκτελέσιμο web αρχείο.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Ελέγξτε τα comments όλων των αρχείων, μπορεί να βρείτε **credentials** ή **hidden functionality**.
- Αν παίζετε **CTF**, ένα "κοινό" κόλπο είναι να **κρύψετε** **πληροφορία** μέσα σε comments στα δεξιά της **σελίδας** (χρησιμοποιώντας **εκατοντάδες** **spaces** ώστε να μην φαίνεται το δεδομένο αν ανοίξετε τον source με τον browser). Άλλη πιθανότητα είναι να χρησιμοποιήσετε **αρκετά new lines** και να **κρύψετε πληροφορία** σε ένα comment στο **bottom** της σελίδας.
- **API keys**: Αν βρείτε κάποιο API key υπάρχει οδηγός που δείχνει πώς να χρησιμοποιήσετε API keys από διάφορες πλατφόρμες: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Αν βρείτε οποιοδήποτε API key που μοιάζει με **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik μπορείτε να χρησιμοποιήσετε το project [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) για να ελέγξετε ποιες apis μπορεί να προσπελάσει το key.
- **S3 Buckets**: Καθ' όλη τη διάρκεια του spidering δείτε αν οποιοδήποτε **subdomain** ή οποιοδήποτε **link** σχετίζεται με κάποιο **S3 bucket**. Σε αυτή την περίπτωση, [**ελέγξτε** τα **permissions** του bucket](buckets/index.html).

### Special findings

Κατά την εκτέλεση του **spidering** και του **brute-forcing** μπορεί να βρείτε **ενδιαφέροντα** **πράγματα** που πρέπει να προσέξετε.

**Interesting files**

- Ψάξτε για **links** προς άλλα αρχεία μέσα σε **CSS** files.
- [Αν βρείτε ένα _**.git**_ αρχείο κάποιες πληροφορίες μπορούν να εξαχθούν](git.md)
- Αν βρείτε ένα _**.env**_ μπορεί να βρεθούν πληροφορίες όπως api keys, dbs passwords και άλλες ευαίσθητες πληροφορίες.
- Αν βρείτε **API endpoints** θα πρέπει να [τα δοκιμάσετε επίσης](web-api-pentesting.md). Αυτά δεν είναι αρχεία, αλλά πιθανότατα "θα μοιάζουν" με αρχεία.
- **JS files**: Στην ενότητα spidering αναφέρθηκαν διάφορα εργαλεία που μπορούν να εξάγουν paths από JS files. Επίσης, είναι ενδιαφέρον να **παρακολουθείτε κάθε JS file που βρέθηκε**, καθώς σε κάποιες περιπτώσεις μια αλλαγή μπορεί να υποδεικνύει ότι εισήχθη μια πιθανή ευπάθεια στον κώδικα. Μπορείτε για παράδειγμα να χρησιμοποιήσετε το [**JSMon**](https://github.com/robre/jsmon)**.**
- Πρέπει επίσης να ελέγξετε τα ανακαλυφθέντα JS files με [**RetireJS**](https://github.com/retirejs/retire.js/) ή [**JSHole**](https://github.com/callforpapers-source/jshole) για να δείτε αν είναι ευάλωτα.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Σε πολλές περιπτώσεις, θα χρειαστεί να **κατανοήσετε τις regular expressions** που χρησιμοποιούνται. Αυτό θα βοηθήσει: [https://regex101.com/](https://regex101.com) ή [https://pythonium.net/regex](https://pythonium.net/regex)
- Μπορείτε επίσης να **παρακολουθείτε τα αρχεία όπου εντοπίζονται forms**, καθώς μια αλλαγή σε ένα parameter ή η εμφάνιση ενός νέου form μπορεί να υποδεικνύει νέα πιθανή ευπάθεια.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Αν κάποια σελίδα **απαντά** με αυτόν τον **κωδικό**, πιθανότατα είναι **κακώς διαμορφωμένος proxy**. **Αν στείλετε ένα HTTP request όπως: `GET https://google.com HTTP/1.1`** (με το host header και άλλα κοινά headers), ο **proxy** θα προσπαθήσει να **προσπελάσει** το _**google.com**_ **και θα έχετε βρει ένα** SSRF.

**NTLM Authentication - Info disclosure**

Αν ο server που ζητάει authentication είναι **Windows** ή βρείτε μια σελίδα login που ζητάει τα **credentials** σας (και ζητάει **domain name**), μπορείτε να προκαλέσετε **information disclosure**.\
**Στείλτε** το **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` και λόγω του τρόπου που λειτουργεί η **NTLM authentication**, ο server θα απαντήσει με εσωτερικές πληροφορίες (IIS version, Windows version...) μέσα στο header "WWW-Authenticate".\
Μπορείτε να **αυτοματοποιήσετε** αυτό χρησιμοποιώντας το **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Είναι δυνατόν να **τοποθετήσετε περιεχόμενο** μέσα σε μια **Redirection**. Αυτό το περιεχόμενο **δεν θα εμφανιστεί στον χρήστη** (καθώς ο browser θα εκτελέσει την ανακατεύθυνση) αλλά κάτι μπορεί να είναι **κρυμμένο** εκεί μέσα.

### Web Vulnerabilities Checking

Τώρα που έχει πραγματοποιηθεί μια πλήρης καταγραφή της web εφαρμογής, είναι ώρα να ελεγχθούν πολλές πιθανές ευπάθειες. Μπορείτε να βρείτε το checklist εδώ:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Βρείτε περισσότερες πληροφορίες για web vulns σε:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) για να παρακολουθείτε σελίδες για τροποποιήσεις που μπορεί να εισάγουν ευπάθειες.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
