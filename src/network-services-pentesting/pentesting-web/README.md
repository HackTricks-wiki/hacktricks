# 80,443 - Pentesting Web Μεθοδολογία

{{#include ../../banners/hacktricks-training.md}}

## Βασικές Πληροφορίες

Η web υπηρεσία είναι η πιο **συνηθισμένη και εκτεταμένη υπηρεσία** και υπάρχουν πολλοί **διαφορετικοί τύποι ευπαθειών**.

**Προεπιλεγμένη θύρα:** 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Οδηγίες Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Σύνοψη μεθοδολογίας

> Σε αυτή τη μεθοδολογία θα υποθέσουμε ότι πρόκειται να επιτεθείς σε ένα domain (ή subdomain) και μόνο αυτό. Επομένως, πρέπει να εφαρμόσεις αυτή τη μεθοδολογία σε κάθε ανακαλυφθέν domain, subdomain ή IP με ακαθόριστο web server εντός του scope.

- [ ] Ξεκίνα με το **να εντοπίσεις** τις **τεχνολογίες** που χρησιμοποιεί ο web server. Αναζήτησε **tricks** που πρέπει να θυμάσαι κατά το υπόλοιπο του test αν καταφέρεις να αναγνωρίσεις την τεχνολογία.
- [ ] Υπάρχει κάποια **known vulnerability** στην έκδοση της τεχνολογίας;
- [ ] Χρησιμοποιείται κάποια **well known tech**; Υπάρχει κάποιο **useful trick** για να εξάγεις περισσότερες πληροφορίες;
- [ ] Υπάρχει κάποιος **specialised scanner** που πρέπει να τρέξεις (π.χ. wpscan);
- [ ] Ξεκίνα **general purposes scanners**. Δεν ξέρεις αν θα βρουν κάτι ή αν θα αποκαλύψουν ενδιαφέρουσες πληροφορίες.
- [ ] Ξεκίνα με τους **initial checks**: **robots**, **sitemap**, **404** error και **SSL/TLS scan** (αν HTTPS).
- [ ] Ξεκίνα **spidering** της σελίδας: Είναι ώρα να **βρεις** όλα τα πιθανά **files, folders** και **parameters being used.** Επίσης, έλεγξε για **special findings**.
- [ ] _Σημείωση ότι κάθε φορά που ανακαλύπτεται ένας νέος κατάλογος κατά το brute-forcing ή το spidering, θα πρέπει να γίνει spidering._
- [ ] **Directory Brute-Forcing**: Προσπάθησε να brute force όλους τους ανακαλυφθέντες φακέλους ψάχνοντας για νέα **files** και **directories**.
- [ ] _Σημείωση ότι κάθε φορά που ανακαλύπτεται ένας νέος κατάλογος κατά το brute-forcing ή το spidering, θα πρέπει να γίνει Brute-Forced._
- [ ] **Backups checking**: Έλεγξε αν μπορείς να βρεις **backups** των **discovered files** προσθέτοντας κοινές επεκτάσεις backup.
- [ ] **Brute-Force parameters**: Προσπάθησε να **find hidden parameters**.
- [ ] Μόλις **εντοπίσεις** όλα τα πιθανά **endpoints** που δέχονται **user input**, έλεγξε για κάθε είδους **vulnerabilities** σχετιζόμενες με αυτά.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Έκδοση Server (Vulnerable?)

### Αναγνώριση

Έλεγξε αν υπάρχουν **known vulnerabilities** για την **version** του server που τρέχει.\
Τα **HTTP headers and cookies of the response** μπορούν να είναι πολύ χρήσιμα για να **identify** τις **technologies** και/ή την **version** που χρησιμοποιούνται. Το **Nmap scan** μπορεί να αναγνωρίσει την έκδοση του server, αλλά χρήσιμα μπορεί επίσης να είναι τα εργαλεία [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Αναζήτηση **για** [**ευπάθειες της web εφαρμογής** **έκδοση**](../../generic-hacking/search-exploits.md)

### **Έλεγχος αν υπάρχει WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Κόλπα για τεχνολογίες Web

Μερικά **κόλπα** για τον **εντοπισμό ευπαθειών** σε διάφορες γνωστές **τεχνολογίες** που χρησιμοποιούνται:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Custom UDP RPC Protocols**](custom-protocols.md)
- [**Dotnet SOAP WSDL client exploitation**](dotnet-soap-wsdl-client-exploitation.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Fortinet FortiWeb**](fortinet-fortiweb.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](https://github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Λάβε υπόψη ότι το **ίδιο domain** μπορεί να χρησιμοποιεί **διαφορετικές τεχνολογίες** σε διαφορετικές **θύρες**, **φακέλους** και **subdomains**._\
Αν η web εφαρμογή χρησιμοποιεί κάποια από τις γνωστές **τεχνολογίες/πλατφόρμες** που αναφέρονται παραπάνω ή **κάποια άλλη**, μην ξεχάσεις να **αναζητήσεις στο Internet** νέα κόλπα (και ενημέρωσέ με!).

### Ανασκόπηση πηγαίου κώδικα

Αν ο **πηγαίος κώδικας** της εφαρμογής είναι διαθέσιμος στο **github**, πέρα από την εκτέλεση από εσένα ενός White box test της εφαρμογής, υπάρχουν **κάποιες πληροφορίες** που θα μπορούσαν να είναι **χρήσιμες** για το τρέχον **Black-Box testing**:

- Υπάρχει ένα **Change-log ή Readme ή Version** αρχείο ή κάτι με **πληροφορίες έκδοσης προσβάσιμες** μέσω web;
- Πώς και πού αποθηκεύονται τα **credentials**; Υπάρχει κάποιο (προσβάσιμο;) **file** με credentials (usernames ή passwords)?
- Είναι τα **passwords** σε **plain text**, **encrypted** ή ποιος **hashing algorithm** χρησιμοποιείται;
- Χρησιμοποιεί κάποιο **master key** για την κρυπτογράφηση κάτι; Ποιος **algorithm** χρησιμοποιείται;
- Μπορείς να **προσπελάσεις κάποιο από αυτά τα αρχεία** εκμεταλλευόμενος κάποια ευπάθεια;
- Υπάρχει κάποια **ενδιαφέρουσα πληροφορία στο github** (solved and not solved) **issues**; Ή στο **commit history** (ίσως κάποιο **password εισαχθεί μέσα σε ένα παλιό commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Αυτόματοι σαρωτές

#### Αυτόματοι σαρωτές γενικής χρήσης
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Σαρωτές CMS

Αν χρησιμοποιείται CMS, μην ξεχάσεις να **τρέξε ένα scanner**, ίσως βρεθεί κάτι ενδιαφέρον:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** ιστότοποι για θέματα ασφάλειας. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **ή** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Σε αυτό το σημείο θα πρέπει ήδη να έχετε κάποιες πληροφορίες για τον web server που χρησιμοποιεί ο client (αν υπάρχουν δεδομένα) και κάποια κόλπα να έχετε στο μυαλό σας κατά τη διάρκεια της δοκιμής. Αν είστε τυχεροί ίσως έχετε βρει ένα CMS και έχετε τρέξει κάποιο scanner.

## Βήμα-βήμα Ανακάλυψη Web Application

> Από αυτό το σημείο θα αρχίσουμε να αλληλεπιδρούμε με την web application.

### Αρχικοί έλεγχοι

**Προεπιλεγμένες σελίδες με ενδιαφέρουσες πληροφορίες:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Ελέγξτε επίσης τα σχόλια στις κύριες και δευτερεύουσες σελίδες.

**Πρόκληση σφαλμάτων**

Οι Web servers μπορεί να **συμπεριφέρονται απρόβλεπτα** όταν τους αποστέλλονται περίεργα δεδομένα. Αυτό μπορεί να ανοίξει **vulnerabilities** ή να προκαλέσει αποκάλυψη ευαίσθητων πληροφοριών.

- Πρόσβαση σε **fake pages** όπως /whatever_fake.php (.aspx,.html,.etc)
- **Προσθέστε "[]", "]]", και "[["** σε **τιμές cookie** και **τιμές παραμέτρων** για να δημιουργήσετε σφάλματα
- Δημιουργήστε σφάλμα δίνοντας είσοδο ως **`/~randomthing/%s`** στο **τέλος** του **URL**
- Δοκιμάστε **διαφορετικά HTTP Verbs** όπως PATCH, DEBUG ή λάθος όπως FAKE

#### **Ελέγξτε αν μπορείτε να ανεβάσετε αρχεία (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Αν διαπιστώσετε ότι **WebDav** είναι **ενεργό** αλλά δεν έχετε επαρκή δικαιώματα για το ανέβασμα αρχείων στον root φάκελο, δοκιμάστε να:

- **Brute Force** credentials
- **Upload files** μέσω WebDav στους υπόλοιπους φακέλους που βρέθηκαν στην ιστοσελίδα. Μπορεί να έχετε δικαιώματα να ανεβάσετε αρχεία σε άλλους φακέλους.

### **SSL/TLS vulnerabilites**

- Αν η εφαρμογή **δεν επιβάλλει τη χρήση HTTPS** σε κανένα σημείο, τότε είναι **vulnerable to MitM**
- Αν η εφαρμογή **στέλνει ευαίσθητα δεδομένα (passwords) μέσω HTTP**. Τότε είναι υψηλό vulnerability.

Χρησιμοποιήστε [**testssl.sh**](https://github.com/drwetter/testssl.sh) για έλεγχο για **vulnerabilities** (Σε Bug Bounty προγράμματα πιθανώς αυτού του τύπου οι vulnerabilities δεν θα γίνουν αποδεκτές) και χρησιμοποιήστε [**a2sv** ](https://github.com/hahwul/a2sv) για επανέλεγχο των vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Ξεκινήστε κάποιο είδος spider μέσα στο web. Ο στόχος του spider είναι να βρει όσο το δυνατόν περισσότερα paths από την εφαρμογή που τεστάρεται. Επομένως, web crawling και εξωτερικές πηγές πρέπει να χρησιμοποιηθούν για να εντοπιστούν όσο το δυνατόν περισσότερα έγκυρα paths.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files and external sources (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, with LinkFider for JS files and Archive.org as external source.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, also indicates "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. It also searches in Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): This tool isn't a spider but it can be useful. You can just indicate a file with hosts and a file with paths and meg will fetch each path on each host and save the response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider with JS rendering capabilities. However, it looks like it's unmaintained, the precompiled version is old and the current code doesn't compile
- [**gau**](https://github.com/lc/gau) (go): HTML spider that uses external providers (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): This script will find URLs with parameter and will list them.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider with JS rendering capabilities.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, with JS beautify capabilities capable of search new paths in JS files. It could be worth it also take a look to [JSScanner](https://github.com/dark-warlord14/JSScanner), which is a wrapper of LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): To extract endpoints in both HTML source and embedded javascript files. Useful for bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests. Looks like unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Given a file (HTML) it will extract URLs from it using nifty regular expression to find and extract the relative URLs from ugly (minify) files.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Gather interesting information from JS files using several tools.
- [**subjs**](https://github.com/lc/subjs) (go): Find JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Load a page in a headless browser and print out all the urls loaded to load the page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool mixing several options of the previous tools
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): A Burp extension to find path and params in JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): A tool that given the .js.map URL will get you the beatified JS code
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): This is a tool used to discover endpoints for a given target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Discover links from the wayback machine (also downloading the responses in the wayback and looking for more links)
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (even by filling forms) and also find sensitive info using specific regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite is an advance multi-feature GUI web security Crawler/Spider designed for cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): It's a Go package and [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) for extracting URLs, paths, secrets, and other interesting data from JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge is a simple **Burp Suite extension** to **extract the paramters and endpoints** from the request to create custom wordlist for fuzzing and enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Awesome tool for this.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Print every link it's able to find.

### Brute Force directories and files

Ξεκινήστε brute-forcing από τον root φάκελο και φροντίστε να κάνετε brute-force όλα τα directories που βρέθηκαν χρησιμοποιώντας αυτή τη μέθοδο και όλα τα directories που ανακαλύφθηκαν από το Spidering (μπορείτε να κάνετε αυτό το brute-forcing αναδρομικά και να προσθέσετε στην αρχή της χρησιμοποιούμενης wordlist τα ονόματα των φακέλων που βρέθηκαν).\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Find broken links inside HTMLs that may be prone to takeovers
- **File Backups**: Μόλις βρείτε όλα τα files, ψάξτε για backups όλων των executable files ("_.php_", "_.aspx_"...). Κοινές παραλλαγές για ονόματα backup είναι: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ Μπορείτε επίσης να χρησιμοποιήσετε το εργαλείο [**bfac**](https://github.com/mazen160/bfac) **or** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **and** [**Param Miner**](https://github.com/PortSwigger/param-miner) **για να ανακαλύψετε hidden parameters. Αν μπορείτε, δοκιμάστε να ψάξετε hidden parameters σε κάθε executable web file.**
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Ελέγξτε τα comments όλων των files, μπορεί να βρείτε credentials ή hidden functionality.
- Αν παίζετε **CTF**, ένα "συνηθισμένο" κόλπο είναι να κρύψετε πληροφορία μέσα σε comments στη δεξιά πλευρά της σελίδας (χρησιμοποιώντας εκατοντάδες spaces ώστε να μην δείτε τα δεδομένα αν ανοίξετε τον source code με τον browser). Άλλη πιθανότητα είναι να χρησιμοποιήσετε πολλές new lines και να κρύψετε πληροφορία σε ένα comment στο bottom της web page.
- **API keys**: Αν βρείτε κάποιο API key υπάρχει οδηγός που δείχνει πώς να χρησιμοποιήσετε API keys από διάφορες πλατφόρμες: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](https://github.com/l4yton/RegHex)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Αν βρείτε κάποιο API key που μοιάζει με **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik μπορείτε να χρησιμοποιήσετε το project [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) για να ελέγξετε ποιες apis μπορεί να προσπελάσει το key.
- **S3 Buckets**: Κατά το spidering ελέγξτε αν κάποιο subdomain ή κάποιο link σχετίζεται με κάποιο S3 bucket. Σε αυτή την περίπτωση, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

Κατά την εκτέλεση του spidering και του brute-forcing μπορεί να βρείτε ενδιαφέροντα πράγματα που πρέπει να προσέξετε.

**Interesting files**

- Ψάξτε για links σε άλλα files μέσα στα CSS files.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Αν βρείτε ένα _**.env**_ μπορεί να βρείτε πληροφορίες όπως api keys, dbs passwords και άλλα.
- Αν βρείτε **API endpoints** θα πρέπει [να τα δοκιμάσετε επίσης](web-api-pentesting.md). Αυτά δεν είναι αρχεία, αλλά πιθανότατα "θα μοιάζουν" με αρχεία.
- **JS files**: Στην ενότητα spidering αναφέρθηκαν διάφορα εργαλεία που μπορούν να εξάγουν paths από JS files. Επίσης, είναι χρήσιμο να παρακολουθείτε κάθε JS file που βρέθηκε, καθώς σε ορισμένες περιπτώσεις μια αλλαγή μπορεί να υποδεικνύει ότι εισήχθη μια πιθανή ευπάθεια στον κώδικα. Μπορείτε να χρησιμοποιήσετε για παράδειγμα [**JSMon**](https://github.com/robre/jsmon)**.**
- Πρέπει επίσης να ελέγξετε τα discovered JS files με [**RetireJS**](https://github.com/retirejs/retire.js/) ή [**JSHole**](https://github.com/callforpapers-source/jshole) για να δείτε αν είναι vulnerable.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- Σε αρκετές περιπτώσεις, θα χρειαστεί να κατανοήσετε τις regular expressions που χρησιμοποιούνται. Αυτό θα βοηθήσει: [https://regex101.com/](https://regex101.com) ή [https://pythonium.net/regex](https://pythonium.net/regex)
- Μπορείτε επίσης να παρακολουθείτε τα files όπου ανιχνεύτηκαν φόρμες, καθώς μια αλλαγή σε ένα parameter ή η εμφάνιση μιας νέας φόρμας μπορεί να υποδεικνύει μια νέα πιθανή ευπάθεια.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Αν κάποια σελίδα ανταποκριθεί με αυτόν τον code, πιθανότατα είναι ένα badly configured proxy. **If you send a HTTP request like: `GET https://google.com HTTP/1.1`** (με το host header και άλλα κοινά headers), ο proxy θα προσπαθήσει να access _**google.com**_ και έτσι θα έχετε βρει ένα SSRF.

**NTLM Authentication - Info disclosure**

Αν ο server που ζητάει authentication είναι Windows ή βρείτε ένα login που ζητάει τα credentials σας (και ζητάει domain name), μπορείτε να προκαλέσετε information disclosure.\
Στείλτε το header: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` και λόγω του πώς δουλεύει το NTLM authentication, ο server θα απαντήσει με internal info (IIS version, Windows version...) μέσα στο header "WWW-Authenticate".\
Μπορείτε να αυτοματοποιήσετε αυτό χρησιμοποιώντας το nmap plugin "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Είναι δυνατό να βάλετε content μέσα σε μια Redirection. Αυτό το περιεχόμενο δεν θα εμφανιστεί στον user (καθώς ο browser θα εκτελέσει την redirection) αλλά κάτι μπορεί να είναι hidden εκεί.

### Web Vulnerabilities Checking

Τώρα που έγινε μια πλήρης enumeration της web εφαρμογής, είναι ώρα να ελέγξετε για πολλές πιθανές ευπάθειες. Μπορείτε να βρείτε το checklist εδώ:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Find more info about web vulns in:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Μπορείτε να χρησιμοποιήσετε εργαλεία όπως [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) για να παρακολουθείτε σελίδες για modifications που μπορεί να εισάγουν ευπάθειες.

### HackTricks Automatic Commands

<details>
<summary>HackTricks Automatic Commands</summary>
```yaml
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
</details>

{{#include ../../banners/hacktricks-training.md}}
