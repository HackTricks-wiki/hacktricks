# 80,443 - Pentesting वेब कार्यप्रणाली

{{#include ../../banners/hacktricks-training.md}}

## बुनियादी जानकारी

वेब सर्विस सबसे **आम और व्यापक सेवा** है और बहुत सारे **different types of vulnerabilities** मौजूद हैं।

**डिफ़ॉल्ट पोर्ट:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API मार्गदर्शन


{{#ref}}
web-api-pentesting.md
{{#endref}}

## कार्यप्रणाली सारांश

> इस कार्यप्रणाली में हम यह मानेंगे कि आप किसी एक domain (या subdomain) पर ही हमला करने जा रहे हैं और सिर्फ़ वही। इसलिए, आपको इस कार्यप्रणाली को स्कोप में पाए गए प्रत्येक domain, subdomain या अनिर्धारित वेब सर्वर वाले IP पर लागू करना चाहिए।

- [ ] शुरुआत करें: वेब सर्वर द्वारा उपयोग की जा रही **तकनीकें** की **पहचान** करें। यदि आप टेक की पहचान कर पाते हैं तो टेस्ट के बाकी हिस्सों में ध्यान में रखने के लिए कोई उपयोगी **tricks** देखें।
- [ ] क्या उस तकनीक के संस्करण के लिए कोई **known vulnerability** मौजूद है?
- [ ] क्या कोई **well known tech** उपयोग में है? अधिक जानकारी निकालने के लिए कोई **useful trick** है?
- [ ] क्या चलाने के लिए कोई **specialised scanner** है (जैसे wpscan)?
- [ ] **general purposes scanners** लॉन्च करें। पता नहीं वे कुछ पाएँगे या कोई रोचक जानकारी मिलेगी।
- [ ] **initial checks** से शुरू करें: **robots**, **sitemap**, **404** error और **SSL/TLS scan** (यदि **HTTPS**)।
- [ ] वेब पेज पर **spidering** शुरू करें: अब सभी संभावित **files, folders** और उपयोग हो रहे **parameters** को **find** करने का समय है। साथ ही **special findings** की जांच करें।
- [ ] _नोट: जब भी brute-forcing या spidering के दौरान कोई नया directory मिलता है, उसे spider किया जाना चाहिए._
- [ ] **Directory Brute-Forcing**: खोजे गए सभी folders को brute force करके नए **files** और **directories** खोजने का प्रयास करें।
- [ ] _नोट: जब भी brute-forcing या spidering के दौरान कोई नया directory मिलता है, उसे Brute-Forced किया जाना चाहिए._
- [ ] **Backups checking**: देखें कि क्या आप खोजे गए **files** के **backups** सामान्य backup extensions जोड़कर पा सकते हैं।
- [ ] **Brute-Force parameters**: छिपे हुए **parameters** खोजने की कोशिश करें।
- [ ] जब आपने सभी संभावित **endpoints** जो **user input** स्वीकार करते हैं **पहचान** लिए हों, तो उनसे संबंधित सभी प्रकार की **vulnerabilities** की जांच करें।
- [ ] [इस चेकलिस्ट का पालन करें](../../pentesting-web/web-vulnerabilities-methodology.md)

## सर्वर संस्करण (Vulnerable?)

### पहचान

चेक करें कि चल रहे सर्वर के उस **version** के लिए कोई **known vulnerabilities** मौजूद हैं या नहीं।\
रिस्पॉन्स के **HTTP headers** और **cookies** उस उपयोग की जा रही **technologies** और/या **version** की **identify** करने में बहुत उपयोगी हो सकते हैं। **Nmap scan** सर्वर वर्जन पहचान सकता है, लेकिन ये tools भी उपयोगी हो सकते हैं: [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
खोजें [**वेब एप्लिकेशन के संस्करण की कमजोरियाँ**](../../generic-hacking/search-exploits.md)

### **कोई WAF है या नहीं जांचें**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### वेब टेक ट्रिक्स

किसी भी उपयोग की जा रही विभिन्न प्रसिद्ध तकनीकों में कमजोरियों को खोजने के लिए कुछ ट्रिक्स:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)

_ध्यान रखें कि एक ही **domain** विभिन्न **technologies** को अलग-अलग **ports**, **folders** और **subdomains** में उपयोग कर सकता है._\
यदि वेब एप्लिकेशन किसी भी प्रसिद्ध पहले सूचीबद्ध **tech/platform** या **किसी अन्य** का उपयोग कर रहा है, तो नए ट्रिक्स के लिए इंटरनेट पर खोज करना न भूलें (और मुझे बताएं!).

### स्रोत कोड समीक्षा

यदि आवेदन का **source code** **github** पर उपलब्ध है, तो आवेदन पर अपने द्वारा एक **White box test** करने के अलावा कुछ जानकारी मौजूद हो सकती है जो वर्तमान **Black-Box testing** के लिए उपयोगी हो सकती है:

- क्या कोई **Change-log** या **Readme** या **Version** फाइल या कोई भी ऐसी चीज़ है जिसमें version info वेब के माध्यम से उपलब्ध है?
- credentials किस तरह और कहाँ saved हैं? क्या कोई (accessible?) **file** credentials (usernames या passwords) के साथ मौजूद है?
- क्या **passwords** **plain text** में हैं, **encrypted** हैं या किस **hashing algorithm** का उपयोग किया गया है?
- क्या यह किसी भी चीज़ को encrypt करने के लिए किसी **master key** का उपयोग कर रहा है? कौन सा **algorithm** उपयोग किया गया है?
- क्या आप किसी vulnerability का exploit करके इन में से किसी **file** तक पहुँच सकते हैं?
- क्या **github** में कोई रोचक जानकारी है (solved और not solved) **issues** में? या **commit history** में (शायद कोई **password** पुराने commit में जोड़ा गया हो)?


{{#ref}}
code-review-tools.md
{{#endref}}

### स्वचालित स्कैनर्स

#### सामान्य प्रयोजन के स्वचालित स्कैनर्स
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS स्कैनर

यदि किसी CMS का उपयोग किया जा रहा है तो **स्कैनर चलाना** न भूलें — हो सकता है कुछ दिलचस्प मिल जाए:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** वेबसाइटों की सुरक्षा समस्याओं के लिए। (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **या** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> इस बिंदु पर आपके पास पहले से ही क्लाइंट द्वारा उपयोग किए जा रहे web server के बारे में कुछ जानकारी होनी चाहिए (यदि कोई डेटा दिया गया है) और परीक्षण के दौरान ध्यान में रखने के लिए कुछ ट्रिक्स। अगर आप भाग्यशाली हैं तो आपने एक CMS भी पाया होगा और कुछ scanner चलाया होगा।

## चरण-दर-चरण वेब एप्लिकेशन खोज

> इस बिंदु से हम वेब एप्लिकेशन के साथ इंटरैक्ट करना शुरू करेंगे।

### प्रारंभिक जाँच

**डिफ़ॉल्ट पेज जिनमें दिलचस्प जानकारी हो:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- मुख्य और द्वितीयक पेजों में टिप्पणियाँ भी जांचें।

**त्रुटियाँ उत्पन्न करना**

Web servers जब अजीब डेटा भेजा जाता है तो अनपेक्षित तरीके से व्यवहार कर सकते हैं। इससे vulnerabilities खुल सकती हैं या संवेदनशील जानकारी का खुलासा हो सकता है।

- /whatever_fake.php (.aspx,.html,.etc) जैसे fake pages को एक्सेस करें
- त्रुटियाँ पैदा करने के लिए **cookie values** और **parameter values** में **"\[]", "]]", और "\[["** जोड़ें
- **URL** के **end** पर **`/~randomthing/%s`** जैसा इनपुट देकर त्रुटि उत्पन्न करें
- PATCH, DEBUG जैसे या FAKE जैसे गलत **HTTP Verbs** आज़माएँ

#### **जांचें कि क्या आप फाइलें अपलोड कर सकते हैं (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

यदि आप पाते हैं कि **WebDav** सक्रिय है पर root फ़ोल्डर में **uploading files** के लिए आपके पास पर्याप्त permissions नहीं हैं, तो कोशिश करें:

- **Brute Force** credentials
- WebDav के माध्यम से **Upload files** को वेब पेज के बाकी मिले हुए फ़ोल्डरों में अपलोड करने की कोशिश करें। हो सकता है कि अन्य फ़ोल्डरों में आपको फाइलें अपलोड करने की permissions मिलें।

### **SSL/TLS कमजोरियाँ**

- यदि एप्लिकेशन किसी भी हिस्से में यूजर को HTTPS उपयोग करने के लिए मजबूर नहीं कर रहा है, तो यह MitM के प्रति vulnerable है
- यदि एप्लिकेशन संवेदनशील डेटा (passwords) HTTP का उपयोग करके भेज रहा है, तो यह एक उच्च vulnerability है।

Use [**testssl.sh**](https://github.com/drwetter/testssl.sh) to checks for **vulnerabilities** (In Bug Bounty programs probably these kind of vulnerabilities won't be accepted) and use [**a2sv** ](https://github.com/hahwul/a2sv)to recheck the vulnerabilities:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
SSL/TLS कमज़ोरियों के बारे में जानकारी:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

वेब के अंदर किसी तरह का **spider** चलाएँ। spider का लक्ष्य परीक्षण किए जा रहे application से जितने संभव हो उतने **paths** **खोजना** है। इसलिए, web crawling और external sources का उपयोग करके जितने संभव हो उतने valid paths खोजे जाने चाहिए।

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files and external sources (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, with LinkFider for JS files and Archive.org as external source.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, also indicates "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. It also searches in Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): This tool isn't a spider but it can be useful. You can just indicate a file with hosts and a file with paths and meg will fetch each path on each host and save the response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider with JS rendering capabilities. However, it looks like it's unmaintained, the precompiled version is old and the current code doesn't compile
- [**gau**](https://github.com/lc/gau) (go): HTML spider that uses external providers (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): This script will find URLs with parameter and will list them.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider with JS rendering capabilities.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, with JS beautify capabilities capable of search new paths in JS files. It could be worth it also take a look to [JSScanner](https://github.com/dark-warlord14/JSScanner), which is a wrapper of LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): To extract endpoints in both HTML source and embedded javascript files. Useful for bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests. Looks like unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Given a file (HTML) it will extract URLs from it using nifty regular expression to find and extract the relative URLs from ugly (minify) files.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Gather interesting information from JS files using several tools.
- [**subjs**](https://github.com/lc/subjs) (go): Find JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Load a page in a headless browser and print out all the urls loaded to load the page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool mixing several options of the previous tools
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): A Burp extension to find path and params in JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): A tool that given the .js.map URL will get you the beatified JS code
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): This is a tool used to discover endpoints for a given target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Discover links from the wayback machine (also downloading the responses in the wayback and looking for more links
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (even by filling forms) and also find sensitive info using specific regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite is an advance multi-feature GUI web security Crawler/Spider designed for cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): It's a Go package and [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) for extracting URLs, paths, secrets, and other interesting data from JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge is a simple **Burp Suite extension** to **extract the paramters and endpoints** from the request to create custom wordlist for fuzzing and enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Awesome tool for this.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Print every link it's able to find.

### Brute Force directories and files

रूट फ़ोल्डर से **brute-forcing** शुरू करें और सुनिश्चित करें कि आप इस **method** का उपयोग करके पाए गए सभी **directories** और **Spidering** से खोजे गए सभी directories को भी brute-force करें (आप इसे **recursively** कर सकते हैं और उपयोग किए जाने वाले wordlist के शुरुआत में पाए गए directory के नाम जोड़ सकते हैं)।\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_नोट: जब भी कोई नया directory brute-forcing या spidering के दौरान मिलती है, उसे तुरंत Brute-Force किया जाना चाहिए।_

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Find broken links inside HTMLs that may be prone to takeovers
- **File Backups**: एक बार जब आपने सभी files खोज लिए, तो सभी executable files के backups खोजें ("_.php_", "_.aspx_"...). बैकअप नाम देने के सामान्य वैरिएशन हैं: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ आप [**bfac**](https://github.com/mazen160/bfac) **या** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)** का भी उपयोग कर सकते हैं। 
- **Discover new parameters**: आप hidden parameters खोजने के लिए [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **और** [**Param Miner**](https://github.com/PortSwigger/param-miner) जैसे tools का उपयोग कर सकते हैं। संभव हो तो हर executable web file पर hidden parameters खोजने की कोशिश करें।
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** सभी files की comments जाँचें; यहाँ आपको **credentials** या **hidden functionality** मिल सकती है।
- अगर आप **CTF** खेल रहे हैं तो एक सामान्य चाल यह है कि पेज के स्रोत में comments के दाईं ओर (हज़ारों spaces का उपयोग करके) जानकारी **छिपाई** जाए ताकि ब्राउज़र में सोर्स देखने पर वह दिखाई न दे। दूसरी संभावना यह है कि कई new lines का उपयोग करके पेज के bottom में comment में जानकारी छिपाई जाए।
- **API keys**: अगर आप कोई API key पाते हैं तो विभिन्न platforms की API keys कैसे उपयोग करें उस पर मार्गदर्शक हैं: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: अगर आप कोई API key पाते हैं जो **AIza** से शुरू लगती है जैसे SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik, तो आप यह जांचने के लिए [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) का उपयोग कर सकते हैं कि key किन APIs तक पहुँच सकती है।
- **S3 Buckets**: Spidering करते समय देखें कि क्या कोई **subdomain** या कोई **link** किसी **S3 bucket** से संबंधित है। ऐसी स्थिति में, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**Spidering** और **brute-forcing** करते समय आप कुछ **interesting** चीज़ें पा सकते हैं जिन पर ध्यान देना चाहिए।

**Interesting files**

- CSS फाइलों के अंदर अन्य files के **links** देखें।
- [If you find a _**.git**_ file some information can be extracted](git.md)
- अगर आपको _**.env**_ मिलता है तो उसमें api keys, dbs passwords और अन्य जानकारी मिल सकती है।
- अगर आपको **API endpoints** मिलते हैं तो आप उन्हें [should also test them](web-api-pentesting.md)। ये files नहीं हैं, पर दिखने में अक्सर उनकी तरह लगते हैं।
- **JS files**: spidering सेक्शन में कई tools का उल्लेख था जो JS files से paths निकाल सकते हैं। साथ ही, यह उपयोगी होगा कि हर पाए गए JS file की **monitoring** की जाए, क्योंकि कभी-कभी किसी JS में बदलाव यह संकेत दे सकता है कि code में संभावित vulnerability आई है। उदाहरण के लिए आप [**JSMon**](https://github.com/robre/jsmon)** का उपयोग कर सकते हैं।**
- आप पाए गए JS files को vulnerable होने के लिए [**RetireJS**](https://github.com/retirejs/retire.js/) या [**JSHole**](https://github.com/callforpapers-source/jshole) से भी चेक कर सकते हैं।
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-cy/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- कई मौकों पर, आपको उपयोग किए गए regular expressions को समझने की आवश्यकता होगी। यह उपयोगी होगा: [https://regex101.com/](https://regex101.com) या [https://pythonium.net/regex](https://pythonium.net/regex)
- आप उन files की भी monitoring कर सकते हैं जहाँ forms detect हुए थे, क्योंकि parameters में बदलाव या नए form की दिखावट किसी नई संभावित vulnerable functionality का संकेत दे सकती है।

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

यदि किसी पेज का response उस **code** के साथ आता है, तो यह संभवतः गलत configured proxy है। यदि आप ऐसा HTTP request भेजते हैं: `GET https://google.com HTTP/1.1` (host header और अन्य सामान्य headers के साथ), तो proxy _**google.com**_ तक पहुँचने की कोशिश करेगा और आप एक **SSRF** पा सकते हैं।

**NTLM Authentication - Info disclosure**

यदि running server authentication माँग रहा है और वह **Windows** है या आप कोई login पाते हैं जो आपके **credentials** माँगता है (और **domain** नाम माँगता है), तो आप **information disclosure** करवा सकते हैं।\
**Send** the **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` और NTLM authentication के काम करने के तरीके के कारण, server internal info (IIS version, Windows version...) को header "WWW-Authenticate" में return करेगा।\
आप इसे ऑटोमेट करने के लिए **nmap plugin** "_http-ntlm-info.nse_" का उपयोग कर सकते हैं।

**HTTP Redirect (CTF)**

Redirection में content रखा जा सकता है। यह content user को दिखाई नहीं देता (क्योंकि browser redirection execute कर देता है) पर वहाँ कुछ छिपाया जा सकता है।

### Web Vulnerabilities Checking

अब जब web application का व्यापक enumeration कर लिया गया है, तो कई संभावित vulnerabilities की जाँच करने का समय है। आप checklist यहाँ पाएँगे:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Web vulns के बारे में और जानकारी:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

आप ऐसे tools का उपयोग कर सकते हैं जैसे [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) ताकि pages में होने वाले modifications को monitor किया जा सके, जो vulnerabilities ला सकते हैं।

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
