# 80,443 - Metodología de Pentesting Web

{{#include ../../banners/hacktricks-training.md}}

## Información Básica

El servicio web es el servicio más **común y extenso** y existen muchos **tipos diferentes de vulnerabilidades**.

**Puerto por defecto:** 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Guía de Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Resumen de la metodología

> En esta metodología vamos a suponer que vas a atacar un dominio (o subdominio) y solo ese. Por lo tanto, debes aplicar esta metodología a cada dominio, subdominio o IP descubierto con servidor web indeterminado dentro del scope.

- [ ] Empieza por **identificar** las **technologies** usadas por el servidor web. Busca **tricks** para tener en cuenta durante el resto del test si puedes identificar la tech.
- [ ] ¿Alguna **vulnerabilidad conocida** en la versión de la tecnología?
- [ ] ¿Usando alguna **well known tech**? ¿Algún **truco útil** para extraer más información?
- [ ] ¿Algún **specialised scanner** para ejecutar (like wpscan)?
- [ ] Lanza **general purposes scanners**. Nunca sabes si van a encontrar algo o alguna información interesante.
- [ ] Empieza con las **initial checks**: **robots**, **sitemap**, **404** error and **SSL/TLS scan** (if HTTPS).
- [ ] Comienza con el **spidering** de la página web: Es hora de **encontrar** todos los posibles **archivos, carpetas** y **parámetros en uso.** Además, revisa **hallazgos especiales**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: Intenta brute force todas las carpetas descubiertas buscando nuevos **archivos** y **directorios**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **Backups checking**: Comprueba si puedes encontrar **backups** de **archivos descubiertos** añadiendo extensiones comunes de backup.
- [ ] **Brute-Force parameters**: Intenta **encontrar parámetros ocultos**.
- [ ] Una vez que hayas **identified** todos los posibles **endpoints** que aceptan **user input**, revisa todo tipo de **vulnerabilidades** relacionadas.
- [ ] [Sigue esta checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identificar

Comprueba si existen **vulnerabilidades conocidas** para la **version** del servidor que se está ejecutando.\
Las **HTTP headers and cookies of the response** pueden ser muy útiles para **identify** las **technologies** y/o la **version** en uso. **Nmap scan** puede identificar la version del servidor, pero también pueden ser útiles las herramientas [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech**](https://github.com/ShielderSec/webtech) o [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Buscar [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Comprobar si hay algún WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Trucos de tecnología web

Algunos **trucos** para **encontrar vulnerabilidades** en distintas **tecnologías** bien conocidas que se estén usando:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)

_Ten en cuenta que el **mismo dominio** puede usar **diferentes tecnologías** en distintos **puertos**, **carpetas** y **subdominios**._\
Si la aplicación web está usando alguna **tecnología/plataforma** conocida listada anteriormente o cualquier otra, no olvides **buscar en Internet** nuevos trucos (¡y házmelo saber!).

### Revisión de código fuente

Si el **source code** de la aplicación está disponible en **github**, además de realizar por tu cuenta una prueba White box de la aplicación, hay **alguna información** que podría ser **útil** para la actual prueba Black-Box:

- ¿Existe un **Change-log o Readme o Version** o algo con **info de versión accesible** vía web?
- ¿Cómo y dónde se guardan las **credenciales**? ¿Hay algún (¿accesible?) **archivo** con credenciales (nombres de usuario o contraseñas)?
- ¿Las **contraseñas** están en **texto plano**, **encriptadas** o qué **algoritmo de hashing** se usa?
- ¿Se usa alguna **master key** para encriptar algo? ¿Qué **algoritmo** se utiliza?
- ¿Puedes **acceder a alguno de estos archivos** explotando alguna vulnerabilidad?
- ¿Hay alguna **información interesante en github** (issues resueltas y no resueltas)? ¿O en el **historial de commits** (quizá alguna **contraseña** introducida en un commit antiguo)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Escáneres automáticos

#### Escáneres automáticos de propósito general
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Escáneres de CMS

Si se usa un CMS no olvides **ejecutar un scanner**, puede que se encuentre algo jugoso:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** sitios web en busca de problemas de seguridad. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **o** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> En este punto ya deberías tener algo de información sobre el servidor web que usa el cliente (si se ha proporcionado algún dato) y algunos trucos para tener en cuenta durante la prueba. Si tienes suerte, incluso habrás encontrado un CMS y ejecutado algún escáner.

## Descubrimiento paso a paso de la aplicación web

> A partir de este punto vamos a empezar a interactuar con la aplicación web.

### Comprobaciones iniciales

**Páginas por defecto con información interesante:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Revisa también los comentarios en las páginas principales y secundarias.

**Provocar errores**

Los servidores web pueden **comportarse de forma inesperada** cuando se les envían datos extraños. Esto puede abrir **vulnerabilidades** o **filtrar información sensible**.

- Accede a **páginas falsas** como /whatever_fake.php (.aspx,.html,.etc)
- **Agrega "\[]", "]]", and "\[\["** en **valores de cookie** y **valores de parámetros** para crear errores
- Genera un error dando la entrada como **`/~randomthing/%s`** al **final** de la **URL**
- Prueba **diferentes HTTP Verbs** como PATCH, DEBUG o incorrectos como FAKE

#### **Comprueba si puedes subir archivos (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Si encuentras que **WebDav** está **habilitado** pero no tienes suficientes permisos para **subir archivos** en la carpeta raíz intenta:

- **Brute Force** credentials
- **Sube archivos** vía WebDav al **resto** de **carpetas encontradas** dentro de la página web. Puede que tengas permisos para subir archivos en otras carpetas.

### **SSL/TLS vulnerabilidades**

- Si la aplicación **no obliga al uso de HTTPS** en ninguna parte, entonces es **vulnerable a MitM**
- Si la aplicación está **enviando datos sensibles (contraseñas) usando HTTP**. Entonces es una vulnerabilidad grave.

Usa [**testssl.sh**](https://github.com/drwetter/testssl.sh) para comprobar **vulnerabilidades** (En Bug Bounty programs probablemente este tipo de vulnerabilidades no serán aceptadas) y usa [**a2sv** ](https://github.com/hahwul/a2sv) para volver a comprobar las vulnerabilidades:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Lanza algún tipo de **spider** dentro del sitio. El objetivo del spider es **encontrar la mayor cantidad de rutas posible** de la aplicación probada. Por lo tanto, se debe usar web crawling y fuentes externas para encontrar la mayor cantidad de rutas válidas posible.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder en archivos JS y fuentes externas (Archive.org, CommonCrawl.org, VirusTotal.com, AlienVault.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, con LinkFider para archivos JS y Archive.org como fuente externa.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, también indica "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): CLI interactivo HTML spider. También busca en Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): Esta herramienta no es un spider pero puede ser útil. Puedes indicar un archivo con hosts y un archivo con paths y meg hará fetch de cada path en cada host y guardará la respuesta.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider con capacidades de renderizado JS. Sin embargo, parece no estar mantenida, la versión precompilada es antigua y el código actual no compila.
- [**gau**](https://github.com/lc/gau) (go): HTML spider que usa proveedores externos (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Este script encontrará URLs con parámetros y las listará.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider con capacidades de renderizado JS.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, con capacidades de JS beautify capaz de buscar nuevas rutas en archivos JS. También puede valer la pena echar un vistazo a [JSScanner](https://github.com/dark-warlord14/JSScanner), que es un wrapper de LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Para extraer endpoints tanto del source HTML como de archivos javascript embebidos. Útil para bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Un script en python 2.7 usando Tornado y JSBeautifier para parsear URLs relativas desde archivos JavaScript. Útil para descubrir fácilmente peticiones AJAX. Parece no estar mantenido.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Dado un archivo (HTML) extraerá URLs usando una expresión regular ingeniosa para encontrar y extraer URLs relativas de archivos feos (minificados).
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, varias herramientas): Recolecta información interesante de archivos JS usando varias herramientas.
- [**subjs**](https://github.com/lc/subjs) (go): Encuentra archivos JS.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Carga una página en un navegador headless e imprime todas las urls cargadas para renderizar la página.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Herramienta de discovery de contenido que mezcla varias opciones de las herramientas anteriores
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Una extensión de Burp para encontrar paths y params en archivos JS.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Una herramienta que dado el URL de .js.map te conseguirá el código JS beautified
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Herramienta usada para descubrir endpoints para un target dado.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Descubre links desde the wayback machine (también descarga las respuestas en el wayback y busca más links)
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (incluso rellenando formularios) y también busca info sensible usando regex específicas.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite es un avanzado crawler/spider GUI multi-feature diseñado para profesionales de ciberseguridad.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): Es un package en Go y [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) para extraer URLs, paths, secretos y otros datos interesantes del código fuente JavaScript.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge es una simple **Burp Suite extension** para **extraer los parámetros y endpoints** de las requests y crear wordlists personalizadas para fuzzing y enumeración.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Excelente herramienta para esto.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Imprime cada link que pueda encontrar.

### Brute Force directories and files

Start **brute-forcing** from the root folder and be sure to brute-force **all** the **directories found** using **this method** and all the directories **discovered** by the **Spidering** (you can do this brute-forcing **recursively** and appending at the beginning of the used wordlist the names of the found directories).\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Encuentra enlaces rotos dentro de HTMLs que pueden ser susceptibles a takeover.
- **File Backups**: Una vez que hayas encontrado todos los archivos, busca backups de todos los ficheros ejecutables ("_.php_", "_.aspx_"...). Variaciones comunes para nombrar backups son: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ También puedes usar la herramienta [**bfac**](https://github.com/mazen160/bfac) **o** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Puedes usar herramientas como [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **y** [**Param Miner**](https://github.com/PortSwigger/param-miner) **para descubrir parámetros ocultos. Si puedes, intenta buscar** parámetros ocultos en cada archivo web ejecutable.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Revisa los comentarios de todos los archivos; puedes encontrar **credentials** o **funcionalidad oculta**.
- Si estás jugando en **CTF**, un truco "común" es **ocultar** **información** dentro de comentarios a la **derecha** de la **página** (usando **centenares** de **espacios** para que no veas los datos si abres el código fuente con el navegador). Otra posibilidad es usar **varias líneas nuevas** y **ocultar información** en un comentario al **final** de la página web.
- **API keys**: Si **encuentras alguna API key** hay proyectos que indican cómo usar API keys de diferentes plataformas: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Si encuentras una API key que empiece por **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik puedes usar el proyecto [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) para comprobar qué APIs puede consumir la key.
- **S3 Buckets**: Mientras haces spidering busca si algún **subdomain** o algún **link** está relacionado con algún **S3 bucket**. En ese caso, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**Mientras** realizas el **spidering** y el **brute-forcing** podrías encontrar **cosas interesantes** que debes **tener en cuenta**.

**Archivos interesantes**

- Busca **links** a otros ficheros dentro de los archivos **CSS**.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- Si encuentras un _**.env**_ se pueden encontrar información como api keys, passwords de bases de datos y otra información.
- Si encuentras **API endpoints** deberías [also test them](web-api-pentesting.md). Estos no son archivos, pero probablemente "se verán" como tales.
- **JS files**: En la sección de spidering se mencionaron varias herramientas que pueden extraer paths de archivos JS. También sería interesante **monitorizar cada archivo JS encontrado**, ya que en algunas ocasiones un cambio puede indicar que se ha introducido una vulnerabilidad potencial en el código. Puedes usar por ejemplo [**JSMon**](https://github.com/robre/jsmon)**.**
- También deberías comprobar los JS descubiertos con [**RetireJS**](https://github.com/retirejs/retire.js/) o [**JSHole**](https://github.com/callforpapers-source/jshole) para ver si son vulnerables.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- En varias ocasiones necesitarás **entender las expresiones regulares** usadas. Esto te será útil: [https://regex101.com/](https://regex101.com) o [https://pythonium.net/regex](https://pythonium.net/regex)
- También podrías **monitorizar los archivos donde se detectaron formularios**, ya que un cambio en los parámetros o la aparición de un nuevo formulario puede indicar una funcionalidad potencialmente vulnerable.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Si alguna página **responde** con ese **código**, probablemente sea un **proxy mal configurado**. **Si envías una petición HTTP como: `GET https://google.com HTTP/1.1`** (con el header Host y otros headers comunes), el **proxy** intentará **acceder** a _**google.com**_ **y habrás encontrado un** SSRF.

**NTLM Authentication - Info disclosure**

Si el servidor que solicita autenticación es **Windows** o encuentras un login que pide tus **credenciales** (y pide **nombre** de **dominio**), puedes provocar una **divulgación de información**.\
**Envía** el **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` y debido a cómo funciona la **autenticación NTLM**, el servidor responderá con información interna (versión de IIS, versión de Windows...) dentro del header "WWW-Authenticate".\
Puedes **automatizar** esto usando el **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Es posible **poner contenido** dentro de una **Redirección**. Este contenido **no se mostrará al usuario** (ya que el navegador ejecutará la redirección) pero algo podría estar **oculto** allí.

### Web Vulnerabilities Checking

Now that a comprehensive enumeration of the web application has been performed it's time to check for a lot of possible vulnerabilities. You can find the checklist here:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Find more info about web vulns in:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Puedes usar herramientas como [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) para monitorizar páginas y detectar modificaciones que pudieran introducir vulnerabilidades.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
