# 80,443 - Pentesting Web-metodologie

{{#include ../../banners/hacktricks-training.md}}

## Basiese Inligting

Die webdiens is die mees **algemene en omvattende diens** en daar bestaan baie **verskillende tipes kwesbaarhede**.

**Standaardpoort:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API Riglyne


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Opsomming van metodologie

> In hierdie metodologie veronderstel ons dat jy 'n domein (of subdomein) en slegs daardie gaan aanval. Dus behoort jy hierdie metodologie toe te pas op elke ontdekte domein, subdomein of IP met 'n onbepaalde webbediener binne die scope.

- [ ] Begin deur die **tegnologieë** te identifiseer wat deur die webbediener gebruik word. Soek na **truuks** om in gedagte te hou tydens die res van die toets as jy die tegnologie suksesvol kan identifiseer.
- [ ] Enige **bekende kwetsbaarheid** in die weergawe van die tegnologie?
- [ ] Gebruik jy enige **bekende tegnologie**? Enige **nuttige truuk** om meer inligting te onttrek?
- [ ] Enige **gespesialiseerde skandeerder** om te hardloop (soos wpscan)?
- [ ] Begin met **generiese skandeerders**. Jy weet nooit of hulle iets gaan vind of interessante inligting nie.
- [ ] Begin met die **aanvanklike kontroles**: **robots**, **sitemap**, **404** fout en **SSL/TLS scan** (indien HTTPS).
- [ ] Begin met **spidering** van die webblad: dit is tyd om al die moontlike **lêers, gidse** en **parameters** wat gebruik word te vind. Kyk ook na **spesiale bevindings**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: Probeer om al die ontdekte folders te brute-force om na nuwe **files** en **directories** te soek.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **Backups checking**: Toets of jy **backups** van **ontdekte files** kan vind deur algemene backup-uitbreidings by te voeg.
- [ ] **Brute-Force parameters**: Probeer om **hidden parameters** te vind.
- [ ] Sodra jy al die moontlike **endpoints** wat **user input** aanvaar geïdentifiseer het, toets vir alle soorte **vulnerabilities** wat daarmee verband hou.
- [ ] [Volg hierdie checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Bedienerweergawe (Kwetsbaar?)

### Identifiseer

Kontroleer of daar **bekende kwetsbaarhede** is vir die server **weergawe** wat aan die loop is.\
Die **HTTP headers** en **cookies** van die response kan baie nuttig wees om die **technologies** en/of **weergawe** wat gebruik word te identifiseer. **Nmap scan** kan die serverweergawe identifiseer, maar dit kan ook nuttig wees om die tools [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech) of [**https://builtwith.com/**](https://builtwith.com)** te gebruik:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Soek **for** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **Kyk of daar enige WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Web tech tricks

Sommige **tricks** vir **finding vulnerabilities** in verskillende bekende **technologies** wat gebruik word:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Neem in ag dat die **same domain** kan gebruik **different technologies** in verskillende **ports**, **folders** en **subdomains**._\
Indien die web application enige well known **tech/platform listed before** of **any other** gebruik, moenie vergeet om op die Internet na nuwe tricks te soek nie (en laat weet my!).

### Source Code Review

As die **source code** van die application in **github** beskikbaar is, behalwe om self 'n **White box test** van die application uit te voer, is daar **sommige inligting** wat **nuttig** kan wees vir die huidige **Black-Box testing**:

- Is daar 'n **Change-log or Readme or Version** file of enigiets met **version info accessible** via web?
- Hoe en waar word die **credentials** gestoor? Is daar enige (accessible?) **file** met credentials (usernames or passwords)?
- Is die **passwords** in **plain text**, **encrypted** of watter **hashing algorithm** word gebruik?
- Gebruik dit 'n **master key** om iets te enkripteer? Watter **algorithm** word gebruik?
- Kan jy **access any of these files** deur 'n kwetsbaarheid uit te buit?
- Is daar enige **interesting information in the github** (solved and not solved) **issues**? Of in **commit history** (miskien 'n **password introduced inside an old commit**)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### Algemene outomatiese skandeerders
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS scanners

As 'n CMS gebruik word, moenie vergeet om **run a scanner** nie, dalk word iets sappigs gevind:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** webwerwe vir Security issues. (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **of** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Op hierdie stadium behoort jy alreeds sekere inligting te hê oor die webbediener wat deur die kliënt gebruik word (indien enige data gegee is) en 'n paar truuks om in gedagte te hou tydens die toets. As jy gelukkig is het jy selfs 'n CMS gevind en 'n scanner laat loop.

## Stap-vir-stap Webtoepassing-ontdekking

> Vanaf hierdie punt gaan ons begin om met die webtoepassing te werk.

### Aanvanklike kontroles

**Standaard bladsye met interessante inligting:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Kyk ook na kommentaar op die hoof- en sekondêre bladsye.

**Foute afdwing**

Webbedieners kan **onverwag optree** wanneer vreemde data aan hulle gestuur word. Dit kan **vulnerabilities** oopmaak of die **onthulling van sensitiewe inligting** tot gevolg hê.

- Gaan na **fake pages** soos /whatever_fake.php (.aspx,.html,.etc)
- **Voeg "[]", "]]", en "[["** in **cookie values** en **parameter** waardes om foute te veroorsaak
- Genereer 'n fout deur invoer as **`/~randomthing/%s`** te gee aan die **einde** van die **URL**
- Probeer **verskillende HTTP Verbs** soos PATCH, DEBUG of verkeerde soos FAKE

#### **Check if you can upload files (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

As jy ontdek dat **WebDav** **enabled** is maar jy nie genoeg permissies het om lêers in die root-lêergids op te laai nie, probeer om:

- **Brute Force** credentials
- Laai lêers op via WebDav na die res van die gevonde vouers binne die webblad. Jy mag permissies hê om lêers in ander vouers op te laai.

### **SSL/TLS kwesbaarhede**

- As die toepassing **nie gebruikers dwing om HTTPS te gebruik** in enige deel nie, is dit **vatbaar vir MitM**
- As die toepassing **sensitiewe data (passwords) via HTTP stuur**, is dit 'n hoë kwesbaarheid.

Gebruik [**testssl.sh**](https://github.com/drwetter/testssl.sh) om te kyk vir **vulnerabilities** (In Bug Bounty programme sal hierdie soort vulnerabilities waarskynlik nie aanvaar word nie) en gebruik [**a2sv**](https://github.com/hahwul/a2sv) om die vulnerabilities weer te kontroleer:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Inligting oor SSL/TLS kwesbaarhede:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Start 'n soort **spider** in die web. Die doel van die **spider** is om soveel paaie as moontlik van die getoetste toepassing te vind. Daarom moet web crawling en eksterne bronne gebruik word om soveel geldige paaie as moontlik te ontdek.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder in JS files and external sources (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, with LinkFider for JS files and Archive.org as external source.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, also indicates "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider. It also searches in Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): This tool isn't a spider but it can be useful. You can just indicate a file with hosts and a file with paths and meg will fetch each path on each host and save the response.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider with JS rendering capabilities. However, it looks like it's unmaintained, the precompiled version is old and the current code doesn't compile
- [**gau**](https://github.com/lc/gau) (go): HTML spider that uses external providers (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): This script will find URLs with parameter and will list them.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider with JS rendering capabilities.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, with JS beautify capabilities capable of search new paths in JS files. It could be worth it also take a look to [JSScanner](https://github.com/dark-warlord14/JSScanner), which is a wrapper of LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): To extract endpoints in both HTML source and embedded javascript files. Useful for bug hunters, red teamers, infosec ninjas.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files. Useful for easily discovering AJAX requests. Looks like unmaintained.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Given a file (HTML) it will extract URLs from it using nifty regular expression to find and extract the relative URLs from ugly (minify) files.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): Gather interesting information from JS files using several tools.
- [**subjs**](https://github.com/lc/subjs) (go): Find JS files.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Load a page in a headless browser and print out all the urls loaded to load the page.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool mixing several options of the previous tools
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): A Burp extension to find path and params in JS files.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): A tool that given the .js.map URL will get you the beatified JS code
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): This is a tool used to discover endpoints for a given target.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Discover links from the wayback machine (also downloading the responses in the wayback and looking for more links
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (even by filling forms) and also find sensitive info using specific regexes.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite is an advance multi-feature GUI web security Crawler/Spider designed for cyber security professionals.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): It's a Go package and [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) for extracting URLs, paths, secrets, and other interesting data from JavaScript source code.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge is a simple **Burp Suite extension** to **extract the paramters and endpoints** from the request to create custom wordlist for fuzzing and enumeration.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Awesome tool for this.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Print every link it's able to find.

### Brute Force directories and files

Begin met **brute-forcing** vanaf die root-gids en maak seker om **al** die **directories** wat gevind is met hierdie metode en al die directories **ontdek** deur die **Spidering** te brute-force (jy kan dit brute-forcing **rekursief** doen en die name van die gevonde directories aan die begin van die gebruikte wordlist toevoeg).\
Tools:

- **Dirb** / **Dirbuster** - Included in Kali, **old** (and **slow**) but functional. Allow auto-signed certificates and recursive search. Too slow compared with th other options.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: It doesn't allow auto-signed certificates but** allows recursive search.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): It allows auto-signed certificates, it **doesn't** have **recursive** search.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): This isn't a spider but a tool that given the list of found URLs will to delete "duplicated" URLs.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension to create a list of directories from the burp history of different pages
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Remove URLs with duplicated functionalities (based on js imports)
- [**Chamaleon**](https://github.com/iustin24/chameleon): It uses wapalyzer to detect used technologies and select the wordlists to use.

**Aanbevole woordlyste:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._

### Wat om te kontroleer op elke gevonde lêer

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Vind verbroke skakels binne HTML's wat vatbaar mag wees vir takeovers
- **File Backups**: Sodra jy al die lêers gevind het, soek na rugsteun kopieë van uitvoerbare lêers ("_.php_", "_.aspx_"...). Algemene variasies vir die naam van 'n backup is: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp and file.old._ Jy kan ook die tool [**bfac**](https://github.com/mazen160/bfac) **of** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)** gebruik.**
- **Discover new parameters**: Jy kan tools soos [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **en** [**Param Miner**](https://github.com/PortSwigger/param-miner) **gebruik om verborge parameters te ontdek. Indien moontlik, probeer om verborge parameters op elke uitvoerbare web-lêer te soek.**
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Kontroleer die comments in al die lêers; jy kan **credentials** of **hidden functionality** daar vind.
- If you are playing **CTF**, 'n "common" truuk is om **inligting** in kommentaar te **hide** aan die **regterkant** van die **bladsy** (deur honderde spasies te gebruik sodat jy die data nie in die blaaier se view sou sien nie). 'n Ander moontlikheid is om verskeie new lines te gebruik en inligting in 'n kommentaar aan die onderkant van die webblad te verberg.
- **API keys**: As jy enige API key vind, daar is gidse wat aandui hoe om API keys van verskeie platforms te gebruik: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: If you find any API key looking like **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik you can use the project [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) to check which apis the key can access.
- **S3 Buckets**: Terwyl jy spidering doen, kyk of enige **subdomain** of skakel verwant is aan 'n **S3 bucket**. In daardie geval, [**check** the **permissions** of the bucket](buckets/index.html).

### Spesiale bevindinge

**Terwyl** jy die **spidering** en **brute-forcing** uitvoer, kan jy **interessante** dinge aantref wat jy moet merk.

Interessante lêers

- Kyk vir **links** na ander lêers binne **CSS** lêers.
- [If you find a _**.git**_ file some information can be extracted](git.md)
- As jy 'n _**.env**_ vind, kan inligting soos api keys, db-wagwoorde en ander sensitiewe data daar gevind word.
- As jy **API endpoints** vind, jy [should also test them](web-api-pentesting.md). Dit is nie lêers nie, maar kan soos lêers voorkom.
- **JS files**: In die spidering afdeling is verskeie tools genoem wat paaie uit JS files kan ekstraheer. Dit sal ook sinvol wees om elke gevonde JS file te **monitor**, want in sommige gevalle kan 'n verandering aandui dat 'n potensiële kwesbaarheid in die kode ingevoeg is. Jy kan byvoorbeeld [**JSMon**](https://github.com/robre/jsmon)** gebruik.**
- Jy moet ook ontdekde JS files kontroleer met [**RetireJS**](https://github.com/retirejs/retire.js/) of [**JSHole**](https://github.com/callforpapers-source/jshole) om te sien of dit kwesbaar is.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-cy/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- In baie gevalle sal jy die gebruikte regular expressions moet verstaan. Dit sal nuttig wees: [https://regex101.com/](https://regex101.com) of [https://pythonium.net/regex](https://pythonium.net/regex)
- Jy kan ook die lêers monitor waar forms gedetecteer is, aangesien 'n verandering in 'n parameter of die verskyning van 'n nuwe form 'n aanduiding van 'n potensiële nuwe kwesbare funksionaliteit kan wees.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

As enige bladsy met daardie kode **antwoord**, is dit waarskynlik 'n sleg geconfigureerde proxy. **As jy 'n HTTP versoek stuur soos: `GET https://google.com HTTP/1.1`** (met die host header en ander algemene headers), sal die **proxy** probeer om na _**google.com**_ te gaan **en jy het 'n** SSRF gevind.

**NTLM Authentication - Info disclosure**

As die bediener wat authentication versoek 'n **Windows** bediener is of jy vind 'n login wat vir jou **credentials** vra (en vir die **domain** **name** vra), kan jy 'n **information disclosure** veroorsaak.\
**Stuur** die **header**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` en as gevolg van hoe **NTLM authentication** werk, sal die bediener met interne inligting (IIS version, Windows version...) in die header "WWW-Authenticate" reageer.\
Jy kan dit **automate** met die **nmap plugin** "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Dit is moontlik om **content** binne 'n **Redirection** te sit. Hierdie content **sal nie aan die gebruiker gewys word nie** (aangesien die blaaier die redirect uitvoer) maar iets kan daarin **wegsteek**.

### Web Vulnerabilities Checking

Nou dat 'n omvattende enumerasie van die web toepassing uitgevoer is, is dit tyd om 'n groot aantal moontlike kwesbaarhede te toets. Jy kan die checklist hier vind:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Vind meer inligting oor web kwesbaarhede in:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Jy kan tools soos [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) gebruik om bladsye te monitor vir wysigings wat kwesbaarhede kan inbring.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
