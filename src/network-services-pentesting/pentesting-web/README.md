# 80,443 - Pentesting वेब पद्धति

{{#include ../../banners/hacktricks-training.md}}

## बुनियादी जानकारी

वेब सेवा सबसे **सामान्य और व्यापक सेवा** है और कई अलग-अलग प्रकार की **vulnerabilities** मौजूद हैं।

**Default port:** 80 (HTTP), 443 (HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Web API मार्गदर्शन


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Methodology summary

> इस methodology में हम मानकर चलेंगे कि आप केवल एक domain (or subdomain) पर हमला करने जा रहे हैं। इसलिए, आपको यह methodology हर खोजे गए domain, subdomain या scope के अंदर किसी भी undetermined web server वाले IP पर लागू करनी चाहिए।

- [ ] शुरुआत करें **पहचानने** से कि web server द्वारा कौन‑सी **technologies** उपयोग की जा रही हैं। टेस्ट के बाकी हिस्सों में ध्यान में रखने के लिए कोई **tricks** ढूँढें यदि आप tech की सफलतापूर्वक पहचान कर पाते हैं।
- [ ] क्या उस technology के version में कोई **known vulnerability** है?
- [ ] कोई **well known tech** उपयोग हो रही है? कोई **useful trick** जिससे और जानकारी निकाली जा सके?
- [ ] क्या चलाने के लिए कोई **specialised scanner** है (जैसे wpscan)?
- [ ] **general purposes scanners** चलाएँ। आप कभी नहीं जानते वे कुछ खोज लेंगे या कुछ रोचक जानकारी दे देंगे।
- [ ] **initial checks** से शुरुआत करें: **robots**, **sitemap**, **404** error और **SSL/TLS scan** (यदि HTTPS)।
- [ ] वेब पेज की **spidering** शुरू करें: यह समय है सभी संभावित **files, folders** और उपयोग हो रहे **parameters** को **find** करने का। साथ ही **special findings** की भी जाँच करें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory खोजा जाए, उसे spider किया जाना चाहिए._
- [ ] **Directory Brute-Forcing**: खोजे गए सभी folders पर brute force करके नए **files** और **directories** खोजने की कोशिश करें।
- [ ] _ध्यान दें कि जब भी brute-forcing या spidering के दौरान कोई नया directory खोजा जाए, उसे Brute-Forced किया जाना चाहिए._
- [ ] **Backups checking**: सामान्य backup extensions जोड़कर खोजे गए **files** के **backups** मिलते हैं या नहीं टैस्ट करें।
- [ ] **Brute-Force parameters**: छिपे हुए parameters **find** करने की कोशिश करें।
- [ ] एक बार जब आप सभी संभावित **endpoints** जो **user input** स्वीकार करते हैं, की **पहचान** कर लें, तो उनसे जुड़ी सभी तरह की **vulnerabilities** की जाँच करें।
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

जाँच करें कि चल रहे server के version के लिए कोई known vulnerabilities मौजूद हैं या नहीं।\
response के **HTTP headers और cookies** technologies और/या उपयोग हो रहे version की **identify** करने में बहुत उपयोगी हो सकते हैं। **Nmap scan** server version को identify कर सकता है, लेकिन निम्न tools भी उपयोगी हो सकते हैं: [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech) या [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
खोजें **के लिए** [**vulnerabilities of the web application** **version**](../../generic-hacking/search-exploits.md)

### **जाँचें कि कोई WAF मौजूद है या नहीं**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### वेब टेक ट्रिक्स

कई प्रचलित तकनीकों में उपयोग हो रही संभावित कमजोरियों (vulnerabilities) को ढूँढने के लिए कुछ **ट्रिक्स**:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Fortinet FortiWeb**](fortinet-fortiweb.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](https://github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Roundcube**](roundcube.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_ध्यान रखें कि **same domain** विभिन्न **technologies** को अलग-अलग **ports**, **folders** और **subdomains** में उपयोग कर सकता है._\
यदि web application किसी पहले सूचीबद्ध प्रचलित **tech/platform** या किसी अन्य का उपयोग कर रहा है, तो इंटरनेट पर नए ट्रिक्स खोजना न भूलें (और मुझे बताएं!).

### स्रोत कोड समीक्षा

यदि application का **source code** **github** पर उपलब्ध है, तो application पर अपना **White box test** करने के अलावा कुछ ऐसी जानकारी हो सकती है जो वर्तमान **Black-Box testing** के लिए उपयोगी हो सकती है:

- क्या कोई **Change-log or Readme or Version** फाइल है या कुछ भी जिसमें **version info accessible** वेब के माध्यम से मिल सके?
- credentials कहाँ और कैसे सेव होते हैं? क्या कोई (accessible?) **file** है जिसमें credentials (usernames या passwords) हैं?
- क्या **passwords** **plain text** में हैं, **encrypted** हैं, या कौन सा **hashing algorithm** उपयोग किया गया है?
- क्या यह किसी **master key** का उपयोग कुछ encrypt करने के लिए करता है? कौन सा **algorithm** उपयोग किया गया है?
- क्या आप किसी vulnerability का exploit करके इन फाइलों में से किसी तक पहुँच सकते हैं?
- क्या github में कोई रोचक जानकारी है (solved और not solved) **issues** में? या **commit history** में (शायद कोई **password introduced inside an old commit**)?

{{#ref}}
code-review-tools.md
{{#endref}}

### Automatic scanners

#### General purpose automatic scanners
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### CMS scanners

यदि कोई CMS इस्तेमाल हो रहा है तो **run a scanner** चलाना न भूलें — शायद कुछ दिलचस्प मिल जाए:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** वेबसाइट्स में सुरक्षा समस्याओं के लिए। (GUI)\
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **या** [**(M)oodle**](moodle.md)\
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> इस बिंदु पर आपके पास क्लाइент द्वारा उपयोग किए जा रहे वेब सर्वर की कुछ जानकारी पहले से होनी चाहिए (यदि कोई डेटा दिया गया हो) और परीक्षण के दौरान ध्यान में रखने के लिए कुछ तरकीबें। यदि आप भाग्यशाली हैं तो आपने किसी CMS को भी ढूँढ लिया होगा और कुछ स्कैनर चला लिया होगा।

## चरण-दर-चरण वेब एप्लिकेशन डिस्कवरी

> इस बिंदु से हम वेब एप्लिकेशन के साथ इंटरैक्ट करना शुरू करने वाले हैं।

### प्रारंभिक जाँच

**डिफ़ॉल्ट पेज जिनमें रोचक जानकारी हो:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- मुख्य और सहायक पेजों में टिप्पणियाँ भी जाँचें।

**त्रुटियाँ उत्पन्न करना**

वेब सर्वर तब **अनपेक्षित व्यवहार** कर सकते हैं जब उन्हें अजीब डेटा भेजा जाता है। इससे **कमजोरियाँ** खुल सकती हैं या **संवेदनशील जानकारी का खुलासा** हो सकता है।

- Access **fake pages** like /whatever_fake.php (.aspx,.html,.etc)
- त्रुटियाँ उत्पन्न करने के लिए **cookie values** और **parameter values** में **"[]", "]]", और "[["** जोड़ें
- **`/~randomthing/%s`** जैसा इनपुट देकर **URL** के **अंत** में त्रुटि उत्पन्न करें
- अलग-अलग **HTTP Verbs** आज़माएँ जैसे PATCH, DEBUG या गलत जैसे FAKE

#### **जाँचें कि क्या आप फ़ाइलें अपलोड कर सकते हैं (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

यदि आप पाते हैं कि **WebDav** **enabled** है लेकिन root फ़ोल्डर में **uploading files** के लिए आपके पास पर्याप्त permissions नहीं हैं तो कोशिश करें:

- **Brute Force** credentials
- वेब पेज के भीतर पाए गए **found folders** के **rest** में WebDav के माध्यम से **Upload files** करें। हो सकता है आपके पास अन्य फ़ोल्डरों में फ़ाइलें अपलोड करने की अनुमति हो।

### **SSL/TLS कमजोरियाँ**

- यदि एप्लिकेशन किसी भी हिस्से में **HTTPS के उपयोग को मजबूर नहीं कर रहा है**, तो यह **MitM** के प्रति कमजोर है
- यदि एप्लिकेशन **संवेदनशील डेटा (passwords) HTTP का उपयोग करके भेज रहा है** तो यह एक उच्च गंभीरता की कमजोरी है।

इन कमजोरियों की जाँच करने के लिए [**testssl.sh**](https://github.com/drwetter/testssl.sh) का उपयोग करें (Bug Bounty programs में शायद इस तरह की कमजोरियाँ स्वीकार नहीं की जाएँगी) और कमजोरियों को पुनः जाँचने के लिए [**a2sv** ](https://github.com/hahwul/a2sv) का उपयोग करें:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Information about SSL/TLS vulnerabilities:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

वेब के अंदर किसी तरह का **spider** लॉन्च करें। spider का उद्देश्य टेस्ट किए जा रहे एप्लिकेशन से जितने संभव हो उतने पाथ्स **ढूँढना** है। इसलिए, वेब crawling और external sources का उपयोग करके जितने भी valid paths मिल सकें उन्हें ढूँढा जाना चाहिए।

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, JS फ़ाइलों में LinkFinder और external sources (Archive.org, CommonCrawl.org, VirusTotal.com)।
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, JS फ़ाइलों के लिए LinkFinder और Archive.org को external source के रूप में उपयोग करता है।
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, जो "juicy files" भी बताता है।
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interactive CLI HTML spider। यह Archive.org में भी खोज करता है।
- [**meg**](https://github.com/tomnomnom/meg) (go): यह tool स्पाइडर नहीं है पर उपयोगी हो सकता है। आप hosts की एक file और paths की एक file दे सकते हैं और meg हर host पर हर path को fetch करेगा और response save करेगा।
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): JS rendering क्षमताओं वाला HTML spider। हालाँकि, ऐसा लगता है कि यह unmaintained है, precompiled version पुराना है और वर्तमान code compile नहीं होता।
- [**gau**](https://github.com/lc/gau) (go): external providers (wayback, otx, commoncrawl) का उपयोग करने वाला HTML spider।
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): यह script URLs जिनमें parameter होते हैं ढूँढेगा और उन्हें सूचीबद्ध करेगा।
- [**galer**](https://github.com/dwisiswant0/galer) (go): JS rendering क्षमताओं वाला HTML spider।
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider, JS beautify क्षमताओं के साथ जो JS फ़ाइलों में नए पाथ खोजने में सक्षम है। यह देखने लायक हो सकता है [JSScanner](https://github.com/dark-warlord14/JSScanner) भी, जो LinkFinder का wrapper है।
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): HTML source और embedded javascript फ़ाइलों दोनों में endpoints निकालने के लिए। bug hunters, red teamers, infosec ninjas के लिए उपयोगी।
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Tornado और JSBeautifier का उपयोग करके JavaScript फ़ाइलों से relative URLs parse करने वाला python 2.7 script। AJAX requests आसानी से खोजने में उपयोगी। ऐसा लगता है कि यह unmaintained है।
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): किसी फ़ाइल (HTML) में से उपयोगी regular expression का उपयोग करके relative URLs निकालता है, खासकर minified files से।
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, several tools): कई tools का उपयोग करके JS फ़ाइलों से interesting जानकारी इकट्ठा करता है।
- [**subjs**](https://github.com/lc/subjs) (go): JS फ़ाइलें खोजता है।
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): headless browser में एक पेज लोड करता है और पेज लोड करने के लिए लोड होने वाले सभी urls print करता है।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Content discovery tool जो पिछले कई विकल्पों को मिलाता है।
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): JS फ़ाइलों में path और params खोजने के लिए एक Burp extension।
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): एक tool जो .js.map URL दिए जाने पर beautified JS code देता है।
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): दिए गए target के लिए endpoints खोजने के लिए उपयोग होने वाला tool।
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** wayback machine से links खोजें (wayback में responses डाउनलोड करते हुए और और links खोजते हुए)।
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (यहाँ तक कि forms भरकर भी) और specific regexes का उपयोग करके sensitive info खोजता है।
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite एक advance multi-feature GUI web security Crawler/Spider है जो cyber security professionals के लिए डिज़ाइन किया गया है।
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): यह एक Go package और [command-line tool](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) है जो JavaScript source code से URLs, paths, secrets, और अन्य interesting data निकालने के लिए है।
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge एक simple **Burp Suite extension** है जो request से **parameters और endpoints** extract करके fuzzing और enumeration के लिए custom wordlist बनाता है।
- [**katana**](https://github.com/projectdiscovery/katana) (go): इस काम के लिए एक बढ़िया tool।
- [**Crawley**](https://github.com/s0rg/crawley) (go): यह जितनी links ढूँढ सकता है उन्हें print करता है।

### Brute Force directories and files

रूट फ़ोल्डर से **brute-forcing** शुरू करें और सुनिश्चित करें कि **इस method** से मिले सभी **directories** और **Spidering** द्वारा खोजे गए सभी directories को brute-force किया जाए (आप इसे **recursive** तरीके से कर सकते हैं और उपयोग की जाने वाली wordlist के शुरुआत में मिले हुए directory के नाम जोड़ सकते हैं)।\
Tools:

- **Dirb** / **Dirbuster** - Kali में शामिल, **पुराना** (और **slow**) पर functional। auto-signed certificates और recursive search allow करता है। अन्य विकल्पों की तुलना में बहुत slow।
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: यह auto-signed certificates allow नहीं करता पर recursive search allow करता है।
- [**Gobuster**](https://github.com/OJ/gobuster) (go): यह auto-signed certificates allow करता है, इसमें **recursive** search नहीं है।
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Fast, supports recursive search.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Fast: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): यह spider नहीं है पर यह दिए गए URLs की list लेकर "duplicated" URLs हटाने का काम करता है।
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension जो burp history से directories की list बनाता है।
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): js imports के आधार पर duplicated functionalities वाले URLs हटाता है।
- [**Chamaleon**](https://github.com/iustin24/chameleon): यह wapalyzer का उपयोग करके technologies detect करता है और उपयोग करने के लिए wordlists चुनता है।

**Recommended dictionaries:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_ध्यान दें कि जब भी कोई नया directory brute-forcing या spidering के दौरान खोजा जाए, उसे Brute-Force किया जाना चाहिए।_

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): HTMLs के अंदर broken links ढूँढें जो takeover के लिए प्रवण हो सकते हैं।
- **File Backups**: एक बार जब आपने सभी files ढूँढ लिए तो सभी executable files के backups खोजें ("_.php_", "_.aspx_"...)। backup नामकरण के सामान्य स्वरूप होते हैं: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp और file.old._ आप tool [**bfac**](https://github.com/mazen160/bfac) **या** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)** का उपयोग भी कर सकते हैं। 
- **Discover new parameters**: आप hidden parameters खोजने के लिए [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **और** [**Param Miner**](https://github.com/PortSwigger/param-miner) जैसे tools का उपयोग कर सकते हैं। अगर संभव हो तो प्रत्येक executable web file पर hidden parameters खोजने की कोशिश करें।
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** सभी files के comments चेक करें, आप वहाँ **credentials** या **hidden functionality** पा सकते हैं।
- अगर आप **CTF** खेल रहे हैं, तो एक "common" trick यह है कि page के source में comments के दाहिनी ओर (कई सैकड़ों spaces का उपयोग करके) information छुपा दी जाती है ताकि browser में source खोलने पर आप सीधे न देखें। दूसरी संभावना यह है कि कई new lines का उपयोग करके page के bottom में एक comment में जानकारी छुपाई जाए।
- **API keys**: अगर आपको कोई API key मिलती है तो विभिन्न प्लेटफार्मों की API keys को उपयोग करने का तरीका बताने वाले प्रोजेक्ट हैं: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](https://github.com/l4yton/RegHex)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: अगर आप कोई API key पाते हैं जो **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik जैसी दिखती है तो आप यह जांचने के लिए [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) का उपयोग कर सकते हैं कि key किन APIs को access कर सकती है।
- **S3 Buckets**: Spidering के दौरान देखें कि क्या कोई **subdomain** या कोई **link** किसी **S3 bucket** से जुड़ा है। ऐसी स्थिति में, [**check** the **permissions** of the bucket](buckets/index.html).

### Special findings

**Spidering** और **brute-forcing** करते समय आप कुछ **interesting** चीजें पा सकते हैं जिन पर ध्यान देना ज़रूरी है।

**Interesting files**

- CSS फ़ाइलों के अंदर अन्य files के **links** देखें।
- [If you find a _**.git**_ file some information can be extracted](git.md)
- अगर आपको _**.env**_ मिले तो वहाँ api keys, dbs passwords और अन्य जानकारी मिल सकती है।
- अगर आपको **API endpoints** मिलते हैं तो आप [उन्हें भी टेस्ट करना चाहिए](web-api-pentesting.md)। ये files नहीं हैं, पर अक्सर "उन जैसी" दिखती हैं।
- **JS files**: spidering सेक्शन में कई tools का ज़िक्र जो JS फ़ाइलों से paths निकाल सकते हैं। इसके अलावा, यह उपयोगी होगा कि प्रत्येक JS फ़ाइल की निगरानी की जाए, क्योंकि कुछ मामलों में किसी फ़ाइल में बदलाव बताता है कि code में संभावित vulnerability आ गई है। उदाहरण के लिए आप [**JSMon**](https://github.com/robre/jsmon)** का उपयोग कर सकते हैं।**
- आपको खोजी गई JS फ़ाइलों को [**RetireJS**](https://github.com/retirejs/retire.js/) या [**JSHole**](https://github.com/callforpapers-source/jshole) के साथ भी चेक करना चाहिए ताकि पता चले कि क्या वे vulnerable हैं।
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript with chars:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- [**TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- कई मौकों पर, आपको उपयोग किए गए regular expressions को समझना होगा। यह उपयोगी होगा: [https://regex101.com/](https://regex101.com) या [https://pythonium.net/regex](https://pythonium.net/regex)
- आप उन files की भी monitoring कर सकते हैं जहाँ forms detect हुए थे, क्योंकि किसी parameter में बदलाव या नए form की उपस्थिति संभावित नई vulnerable functionality का संकेत दे सकती है।

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

अगर किसी पेज का response उस code के साथ आता है, तो संभवतः proxy गलत तरीके से configured है। **अगर आप एक HTTP request भेजते हैं जैसे: `GET https://google.com HTTP/1.1`** (host header और अन्य सामान्य headers के साथ), तो **proxy** _**google.com**_ तक पहुँचने की कोशिश करेगा और आप एक SSRF पा सकते हैं।

**NTLM Authentication - Info disclosure**

अगर चल रहा server authentication मांग रहा है और वह **Windows** है या आपको ऐसा login मिलता है जो आपके **credentials** माँगता है (और **domain** नाम पूछता है), तो आप **information disclosure** करवा सकते हैं।\
**इस header को भेजें**: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` और जिस तरह से **NTLM authentication** काम करता है, server header "WWW-Authenticate" में internal info (IIS version, Windows version...) के साथ respond करेगा।\
आप इसे automate करने के लिए **nmap plugin** "_http-ntlm-info.nse_" का उपयोग कर सकते हैं।

**HTTP Redirect (CTF)**

Redirection के अंदर content रखना संभव है। यह content **user को दिखाई नहीं देगा** (क्योंकि browser redirection execute कर देगा) लेकिन वहाँ कुछ छुपा हुआ हो सकता है।

### Web Vulnerabilities Checking

अब जब web application की comprehensive enumeration हो चुकी है तो अब कई संभावित vulnerabilities की जाँच करने का समय है। आप checklist यहाँ पा सकते हैं:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

वेब vulnerabilities के बारे में अधिक जानकारी:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

आप pages में modifications की निगरानी करने के लिए [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) जैसे tools का उपयोग कर सकते हैं ताकि संभावित vulnerabilities के लिए परिवर्तन को पकड़ा जा सके।

### HackTricks Automatic Commands

<details>
<summary>HackTricks Automatic Commands</summary>
```yaml
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
</details>

{{#include ../../banners/hacktricks-training.md}}
