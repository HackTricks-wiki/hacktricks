# 80,443 - Pentesting Web Methodology

{{#include ../../banners/hacktricks-training.md}}

## Podstawowe informacje

Serwis webowy to najbardziej **powszechna i rozległa usługa** i istnieje wiele **różnych typów podatności**.

**Port domyślny:** 80 (HTTP), 443(HTTPS)
```bash
PORT    STATE SERVICE
80/tcp  open  http
443/tcp open  ssl/https
```

```bash
nc -v domain.com 80 # GET / HTTP/1.0
openssl s_client -connect domain.com:443 # GET / HTTP/1.0
```
### Wytyczne Web API


{{#ref}}
web-api-pentesting.md
{{#endref}}

## Podsumowanie metodologii

> W tej metodologii założymy, że będziesz atakować jedną domenę (lub subdomenę) i tylko ją. Zastosuj tę metodologię do każdej odkrytej domeny, subdomeny lub adresu IP ze stroną WWW o nieokreślonym serwerze w zakresie.

- [ ] Zacznij od **identyfikacji** **technologii** używanych przez serwer WWW. Szukaj **trików**, które warto mieć na uwadze podczas reszty testu, jeśli uda Ci się poprawnie zidentyfikować technologię.
- [ ] Czy istnieje jakaś **znana podatność** w wersji danej technologii?
- [ ] Czy używana jest jakaś **powszechnie znana technologia**? Jakiś **użyteczny trik** pozwalający wydobyć więcej informacji?
- [ ] Czy warto uruchomić jakiś **specjalistyczny skaner** (np. wpscan)?
- [ ] Uruchom **skanery ogólnego przeznaczenia**. Nigdy nie wiadomo, czy coś znajdą lub czy wyciągną jakieś interesujące informacje.
- [ ] Zacznij od **wstępnych sprawdzeń**: **robots**, **sitemap**, błąd **404** oraz **SSL/TLS scan** (jeśli HTTPS).
- [ ] Rozpocznij **spidering** strony: czas **znaleźć** wszystkie możliwe **pliki, foldery** i **używane parametry**. Sprawdź też **szczególne znaleziska**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be spidered._
- [ ] **Directory Brute-Forcing**: Spróbuj przeprowadzić brute force wszystkich odkrytych folderów, szukając nowych **plików** i **katalogów**.
- [ ] _Note that anytime a new directory is discovered during brute-forcing or spidering, it should be Brute-Forced._
- [ ] **Backups checking**: Sprawdź, czy możesz znaleźć **backups** odkrytych **plików**, dopisując typowe rozszerzenia kopii zapasowych.
- [ ] **Brute-Force parameters**: Spróbuj **znaleźć ukryte parametry**.
- [ ] Gdy **zidentyfikujesz** wszystkie możliwe **endpoints** akceptujące **user input**, sprawdź wszystkie rodzaje **vulnerabilities** z nimi związane.
- [ ] [Follow this checklist](../../pentesting-web/web-vulnerabilities-methodology.md)

## Server Version (Vulnerable?)

### Identify

Sprawdź, czy istnieją **znane podatności** dla wersji serwera, która jest uruchomiona.\
**HTTP headers** i **cookies** odpowiedzi mogą być bardzo pomocne w **identyfikacji** używanych **technologii** i/lub **wersji**. **Nmap scan** może zidentyfikować wersję serwera, ale przydatne mogą być też narzędzia [**whatweb**](https://github.com/urbanadventurer/WhatWeb)**,** [**webtech** ](https://github.com/ShielderSec/webtech)or [**https://builtwith.com/**](https://builtwith.com)**:**
```bash
whatweb -a 1 <URL> #Stealthy
whatweb -a 3 <URL> #Aggresive
webtech -u <URL>
webanalyze -host https://google.com -crawl 2
```
Wyszukaj **dla** [**luki w aplikacji webowej** **wersji**](../../generic-hacking/search-exploits.md)

### **Sprawdź, czy istnieje WAF**

- [**https://github.com/EnableSecurity/wafw00f**](https://github.com/EnableSecurity/wafw00f)
- [**https://github.com/Ekultek/WhatWaf.git**](https://github.com/Ekultek/WhatWaf.git)
- [**https://nmap.org/nsedoc/scripts/http-waf-detect.html**](https://nmap.org/nsedoc/scripts/http-waf-detect.html)

### Triki technologii webowych

Kilka **trików** do **znajdowania podatności** w różnych dobrze znanych **technologiach** używanych:

- [**AEM - Adobe Experience Cloud**](aem-adobe-experience-cloud.md)
- [**Apache**](apache.md)
- [**Artifactory**](artifactory-hacking-guide.md)
- [**Buckets**](buckets/index.html)
- [**CGI**](cgi.md)
- [**Drupal**](drupal/index.html)
- [**Flask**](flask.md)
- [**Git**](git.md)
- [**Golang**](golang.md)
- [**GraphQL**](graphql.md)
- [**H2 - Java SQL database**](h2-java-sql-database.md)
- [**ISPConfig**](ispconfig.md)
- [**IIS tricks**](iis-internet-information-services.md)
- [**Microsoft SharePoint**](microsoft-sharepoint.md)
- [**JBOSS**](jboss.md)
- [**Jenkins**](<[https:/github.com/carlospolop/hacktricks/blob/master/network-services-pentesting/pentesting-web/broken-reference/README.md](https:/github.com/HackTricks-wiki/hacktricks-cloud/tree/master/pentesting-ci-cd/jenkins-security)/>)
- [**Jira**](jira.md)
- [**Joomla**](joomla.md)
- [**JSP**](jsp.md)
- [**Laravel**](laravel.md)
- [**Moodle**](moodle.md)
- [**Nginx**](nginx.md)
- [**PHP (php has a lot of interesting tricks that could be exploited)**](php-tricks-esp/index.html)
- [**Python**](python.md)
- [**Spring Actuators**](spring-actuators.md)
- [**Symphony**](symphony.md)
- [**Tomcat**](tomcat/index.html)
- [**VMWare**](vmware-esx-vcenter....md)
- [**Web API Pentesting**](web-api-pentesting.md)
- [**WebDav**](put-method-webdav.md)
- [**Werkzeug**](werkzeug.md)
- [**Wordpress**](wordpress.md)
- [**Electron Desktop (XSS to RCE)**](electron-desktop-apps/index.html)
- [**Sitecore**](sitecore/index.html)
- [**Zabbix**](zabbix.md)

_Weź pod uwagę, że ta **sama domena** może używać **różnych technologii** w różnych **portach**, **folderach** i **subdomenach**._\
Jeśli aplikacja webowa używa którejkolwiek z dobrze znanych **tech/platform listed before** lub **any other**, nie zapomnij **wyszukać w Internecie** nowych trików (i daj mi znać!).

### Przegląd kodu źródłowego

Jeśli **source code** aplikacji jest dostępny na **github**, oprócz przeprowadzenia przez **Ciebie White box testu** aplikacji istnieją **pewne informacje**, które mogą być **użyteczne** dla bieżącego **Black-Box testing**:

- Czy istnieje **Change-log or Readme or Version** file lub cokolwiek z **version info accessible** przez web?
- Jak i gdzie są przechowywane **credentials**? Czy istnieje jakiś (dostępny?) **file** z credentials (usernames or passwords)?
- Czy **passwords** są w **plain text**, **encrypted** czy jaki **hashing algorithm** jest używany?
- Czy używa jakiegokolwiek **master key** do szyfrowania czegoś? Jaki **algorithm** jest używany?
- Czy możesz uzyskać dostęp do któregokolwiek z tych plików, exploitując jakąś **vulnerability**?
- Czy w **github** są jakieś interesujące informacje w issues (rozwiązane i nierozwiązane)? Albo w commit history (może jakieś hasło wprowadzone w starym commicie)?


{{#ref}}
code-review-tools.md
{{#endref}}

### Automatyczne skanery

#### Automatyczne skanery ogólnego przeznaczenia
```bash
nikto -h <URL>
whatweb -a 4 <URL>
wapiti -u <URL>
W3af
zaproxy #You can use an API
nuclei -ut && nuclei -target <URL>

# https://github.com/ignis-sec/puff (client side vulns fuzzer)
node puff.js -w ./wordlist-examples/xss.txt -u "http://www.xssgame.com/f/m4KKGHi2rVUN/?query=FUZZ"
```
#### Skanery CMS

Jeśli używany jest CMS, nie zapomnij **uruchomić skanera**, możesz znaleźć coś ciekawego:

[**Clusterd**](https://github.com/hatRiot/clusterd)**:** [**JBoss**](jboss.md)**, ColdFusion, WebLogic,** [**Tomcat**](tomcat/index.html)**, Railo, Axis2, Glassfish**\
[**CMSScan**](https://github.com/ajinabraham/CMSScan): [**WordPress**](wordpress.md), [**Drupal**](drupal/index.html), **Joomla**, **vBulletin** — skanuje strony pod kątem problemów bezpieczeństwa. (GUI)\  
[**VulnX**](https://github.com/anouarbensaad/vulnx)**:** [**Joomla**](joomla.md)**,** [**Wordpress**](wordpress.md)**,** [**Drupal**](drupal/index.html)**, PrestaShop, Opencart**\
**CMSMap**: [**(W)ordpress**](wordpress.md)**,** [**(J)oomla**](joomla.md)**,** [**(D)rupal**](drupal/index.html) **lub** [**(M)oodle**](moodle.md)\  
[**droopscan**](https://github.com/droope/droopescan)**:** [**Drupal**](drupal/index.html)**,** [**Joomla**](joomla.md)**,** [**Moodle**](moodle.md)**, Silverstripe,** [**Wordpress**](wordpress.md)
```bash
cmsmap [-f W] -F -d <URL>
wpscan --force update -e --url <URL>
joomscan --ec -u <URL>
joomlavs.rb #https://github.com/rastating/joomlavs
```
> Na tym etapie powinieneś mieć już pewne informacje o serwerze webowym używanym przez klienta (jeśli podano jakiekolwiek dane) oraz kilka trików do zapamiętania podczas testu. Jeśli masz szczęście, znalazłeś nawet CMS i uruchomiłeś jakiś scanner.

## Krok po kroku: odkrywanie aplikacji webowej

> Od tego momentu zaczniemy wchodzić w interakcję z aplikacją webową.

### Wstępne sprawdzenia

**Domyślne strony z interesującymi informacjami:**

- /robots.txt
- /sitemap.xml
- /crossdomain.xml
- /clientaccesspolicy.xml
- /.well-known/
- Sprawdź też komentarze na stronach głównych i pomocniczych.

**Wymuszanie błędów**

Serwery webowe mogą **zachowywać się nieoczekiwanie**, gdy wysyłane są do nich dziwne dane. Może to ujawnić **vulnerabilities** lub spowodować **disclosure sensitive information**.

- Uzyskaj dostęp do **fake pages** takich jak /whatever_fake.php (.aspx,.html,.etc)
- **Dodaj "[]", "]]" i "[["** w **cookie values** oraz wartościach **parameter**, aby wywołać błędy
- Wygeneruj błąd, podając wejście jako **`/~randomthing/%s`** na **końcu** **URL**
- Wypróbuj **different HTTP Verbs** takie jak PATCH, DEBUG lub błędne jak FAKE

#### **Sprawdź, czy możesz przesłać pliki (**[**PUT verb, WebDav**](put-method-webdav.md)**)**

Jeśli odkryjesz, że **WebDav** jest **włączony**, ale nie masz wystarczających uprawnień do przesyłania plików w katalogu root, spróbuj:

- **Brute Force** credentials
- **Upload files** przez WebDav do pozostałych znalezionych folderów na stronie. Możesz mieć uprawnienia do przesyłania plików w innych folderach.

### **SSL/TLS podatności**

- Jeśli aplikacja **nie wymusza użycia HTTPS** w żadnej części, wtedy jest **podatna na MitM**
- Jeśli aplikacja **wysyła dane wrażliwe (passwords) przez HTTP**, jest to poważna podatność.

Użyj [**testssl.sh**](https://github.com/drwetter/testssl.sh) do sprawdzenia **podatności** (w programach Bug Bounty prawdopodobnie tego typu podatności nie będą akceptowane) i użyj [**a2sv**](https://github.com/hahwul/a2sv) do ponownego sprawdzenia podatności:
```bash
./testssl.sh [--htmlfile] 10.10.10.10:443
#Use the --htmlfile to save the output inside an htmlfile also

# You can also use other tools, by testssl.sh at this momment is the best one (I think)
sslscan <host:port>
sslyze --regular <ip:port>
```
Informacje o podatnościach SSL/TLS:

- [https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/](https://www.gracefulsecurity.com/tls-ssl-vulnerabilities/)
- [https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/](https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/)

### Spidering

Uruchom jakiś rodzaj **spider** w obrębie serwisu. Celem spidera jest **znalezienie jak największej liczby ścieżek** w testowanej aplikacji. Dlatego należy używać crawlowania stron oraz źródeł zewnętrznych, aby odnaleźć jak najwięcej prawidłowych ścieżek.

- [**gospider**](https://github.com/jaeles-project/gospider) (go): HTML spider, LinkFinder w plikach JS i zewnętrzne źródła (Archive.org, CommonCrawl.org, VirusTotal.com).
- [**hakrawler**](https://github.com/hakluke/hakrawler) (go): HML spider, z LinkFinder dla plików JS i Archive.org jako źródło zewnętrzne.
- [**dirhunt**](https://github.com/Nekmo/dirhunt) (python): HTML spider, dodatkowo wskazuje "juicy files".
- [**evine** ](https://github.com/saeeddhqan/evine)(go): Interaktywny CLI HTML spider. Szuka też w Archive.org
- [**meg**](https://github.com/tomnomnom/meg) (go): To narzędzie nie jest spiderem, ale może być przydatne. Możesz podać plik z hostami i plik ze ścieżkami, a meg pobierze każdą ścieżkę dla każdego hosta i zapisze odpowiedź.
- [**urlgrab**](https://github.com/IAmStoxe/urlgrab) (go): HTML spider z możliwością renderowania JS. Wygląda jednak na nieutrzymywany, skompilowana wersja jest stara, a aktualny kod się nie kompiluje.
- [**gau**](https://github.com/lc/gau) (go): HTML spider używający zewnętrznych providerów (wayback, otx, commoncrawl)
- [**ParamSpider**](https://github.com/devanshbatham/ParamSpider): Skrypt znajdzie URL-e z parametrami i je wypisze.
- [**galer**](https://github.com/dwisiswant0/galer) (go): HTML spider z możliwością renderowania JS.
- [**LinkFinder**](https://github.com/GerbenJavado/LinkFinder) (python): HTML spider z możliwością beautify JS, potrafi szukać nowych ścieżek w plikach JS. Warto też zerknąć na [JSScanner](https://github.com/dark-warlord14/JSScanner), który jest wrapperem LinkFinder.
- [**goLinkFinder**](https://github.com/0xsha/GoLinkFinder) (go): Do wyciągania endpointów zarówno z HTML, jak i osadzonego JavaScriptu. Przydatne dla bug hunterów, red teamów, infosec ninja.
- [**JSParser**](https://github.com/nahamsec/JSParser) (python2.7): Skrypt Python 2.7 używający Tornado i JSBeautifier do parsowania relatywnych URL-i z plików JavaScript. Przydatny do łatwego odkrywania żądań AJAX. Wygląda na nieutrzymywany.
- [**relative-url-extractor**](https://github.com/jobertabma/relative-url-extractor) (ruby): Dla danego pliku (HTML) wyciąga URL-e używając niezłych wyrażeń regularnych do znalezienia i wyciągnięcia relatywnych URL-i z "brzydkich" (zminifikowanych) plików.
- [**JSFScan**](https://github.com/KathanP19/JSFScan.sh) (bash, kilka narzędzi): Zbiera interesujące informacje z plików JS używając kilku narzędzi.
- [**subjs**](https://github.com/lc/subjs) (go): Znajduje pliki JS.
- [**page-fetch**](https://github.com/detectify/page-fetch) (go): Ładuje stronę w headless browser i wypisuje wszystkie URL-e załadowane przy wczytywaniu strony.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) (rust): Narzędzie do odkrywania zawartości łączące różne opcje poprzednich narzędzi.
- [**Javascript Parsing**](https://github.com/xnl-h4ck3r/burp-extensions): Rozszerzenie Burp do znajdowania ścieżek i parametrów w plikach JS.
- [**Sourcemapper**](https://github.com/denandz/sourcemapper): Narzędzie, które dla podanego .js.map URL pobierze dla Ciebie "beautified" kod JS.
- [**xnLinkFinder**](https://github.com/xnl-h4ck3r/xnLinkFinder): Narzędzie używane do odkrywania endpointów dla danego targetu.
- [**waymore**](https://github.com/xnl-h4ck3r/waymore)**:** Odkrywa linki z wayback machine (również pobierając odpowiedzi z wayback i szukając w nich kolejnych linków).
- [**HTTPLoot**](https://github.com/redhuntlabs/HTTPLoot) (go): Crawl (nawet poprzez wypełnianie formularzy) i również znajduje wrażliwe dane używając specyficznych regexów.
- [**SpiderSuite**](https://github.com/3nock/SpiderSuite): Spider Suite to zaawansowany, wielofunkcyjny GUI web security Crawler/Spider zaprojektowany dla specjalistów ds. cyberbezpieczeństwa.
- [**jsluice**](https://github.com/BishopFox/jsluice) (go): Pakiet Go i [narzędzie wiersza poleceń](https://github.com/BishopFox/jsluice/blob/main/cmd/jsluice) do ekstrakcji URL-i, ścieżek, sekretów i innych ciekawych danych z kodu JavaScript.
- [**ParaForge**](https://github.com/Anof-cyber/ParaForge): ParaForge to proste **Burp Suite extension** do **ekstrakcji parametrów i endpointów** z requestów w celu tworzenia custom wordlist do fuzzingu i enumeracji.
- [**katana**](https://github.com/projectdiscovery/katana) (go): Świetne narzędzie do tego.
- [**Crawley**](https://github.com/s0rg/crawley) (go): Wypisuje każdy link, który jest w stanie znaleźć.

### Brute Force directories and files

Zacznij **brute-forcing** od katalogu root i upewnij się, że wykonujesz brute-force we **wszystkich** **katalogach znalezionych** używając **tej metody** oraz we wszystkich katalogach **odkrytych** przez **Spidering** (możesz robić to brute-forcing **rekurencyjnie**, dopisując na początek użytej wordlisty nazwy znalezionych katalogów).\
Narzędzia:

- **Dirb** / **Dirbuster** - W zestawie Kali, **stare** (i **wolne**) ale funkcjonalne. Pozwalają na auto-signed certyfikaty i wyszukiwanie rekurencyjne. Zbyt wolne w porównaniu do innych opcji.
- [**Dirsearch**](https://github.com/maurosoria/dirsearch) (python)**: Nie pozwala na auto-signed certyfikaty, ale** wspiera wyszukiwanie rekurencyjne.
- [**Gobuster**](https://github.com/OJ/gobuster) (go): Pozwala na auto-signed certyfikaty, **nie** ma natywnego wyszukiwania **rekurencyjnego**.
- [**Feroxbuster**](https://github.com/epi052/feroxbuster) **- Szybki, wspiera wyszukiwanie rekurencyjne.**
- [**wfuzz**](https://github.com/xmendez/wfuzz) `wfuzz -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt https://domain.com/api/FUZZ`
- [**ffuf** ](https://github.com/ffuf/ffuf)- Szybki: `ffuf -c -w /usr/share/wordlists/dirb/big.txt -u http://10.10.10.10/FUZZ`
- [**uro**](https://github.com/s0md3v/uro) (python): To nie jest spider, ale narzędzie, które biorąc listę znalezionych URL-i skasuje "zduplikowane" URL-e.
- [**Scavenger**](https://github.com/0xDexter0us/Scavenger): Burp Extension do tworzenia listy katalogów z historii Burpa z różnych stron.
- [**TrashCompactor**](https://github.com/michael1026/trashcompactor): Usuwa URL-e o zduplikowanej funkcjonalności (na podstawie importów js).
- [**Chamaleon**](https://github.com/iustin24/chameleon): Używa wapalyzer do wykrycia użytych technologii i dobiera słowniki do użycia.

**Zalecane słowniki:**

- [https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt](https://github.com/carlospolop/Auto_Wordlists/blob/main/wordlists/bf_directories.txt)
- [**Dirsearch** included dictionary](https://github.com/maurosoria/dirsearch/blob/master/db/dicc.txt)
- [http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10](http://gist.github.com/jhaddix/b80ea67d85c13206125806f0828f4d10)
- [Assetnote wordlists](https://wordlists.assetnote.io)
- [https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content](https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content)
- raft-large-directories-lowercase.txt
- directory-list-2.3-medium.txt
- RobotsDisallowed/top10000.txt
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/google/fuzzing/tree/master/dictionaries](https://github.com/google/fuzzing/tree/master/dictionaries)
- [https://github.com/six2dez/OneListForAll](https://github.com/six2dez/OneListForAll)
- [https://github.com/random-robbie/bruteforce-lists](https://github.com/random-robbie/bruteforce-lists)
- [https://github.com/ayoubfathi/leaky-paths](https://github.com/ayoubfathi/leaky-paths)
- _/usr/share/wordlists/dirb/common.txt_
- _/usr/share/wordlists/dirb/big.txt_
- _/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt_

_Zauważ, że za każdym razem, gdy nowy katalog zostanie odkryty podczas brute-forcingu lub spideringu, powinien być on poddany Brute-Forcingowi._

### What to check on each file found

- [**Broken link checker**](https://github.com/stevenvachon/broken-link-checker): Znajduje broken linki w HTML-ach, które mogą być podatne na takeovery
- **File Backups**: Gdy znajdziesz wszystkie pliki, szukaj backupów wszystkich plików wykonywalnych ("_.php_", "_.aspx_"...). Typowe warianty nazw backupów to: _file.ext\~, #file.ext#, \~file.ext, file.ext.bak, file.ext.tmp, file.ext.old, file.bak, file.tmp oraz file.old._ Możesz też użyć narzędzia [**bfac**](https://github.com/mazen160/bfac) **lub** [**backup-gen**](https://github.com/Nishantbhagat57/backup-gen)**.**
- **Discover new parameters**: Możesz użyć narzędzi takich jak [**Arjun**](https://github.com/s0md3v/Arjun)**,** [**parameth**](https://github.com/maK-/parameth)**,** [**x8**](https://github.com/sh1yo/x8) **i** [**Param Miner**](https://github.com/PortSwigger/param-miner) **do odkrywania ukrytych parametrów. Jeśli możesz, spróbuj szukać** ukrytych parametrów w każdym wykonywalnym pliku webowym.
- _Arjun all default wordlists:_ [https://github.com/s0md3v/Arjun/tree/master/arjun/db](https://github.com/s0md3v/Arjun/tree/master/arjun/db)
- _Param-miner “params” :_ [https://github.com/PortSwigger/param-miner/blob/master/resources/params](https://github.com/PortSwigger/param-miner/blob/master/resources/params)
- _Assetnote “parameters_top_1m”:_ [https://wordlists.assetnote.io/](https://wordlists.assetnote.io)
- _nullenc0de “params.txt”:_ [https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773](https://gist.github.com/nullenc0de/9cb36260207924f8e1787279a05eb773)
- **Comments:** Sprawdź komentarze we wszystkich plikach — możesz znaleźć **credentials** lub **ukrytą funkcjonalność**.
- Jeśli grasz w **CTF**, "powszechny" trik to **ukrycie** **informacji** w komentarzach po **prawej** stronie **strony** (używając **setek** **spacji**, żeby nie widać było danych przy otwarciu źródła w przeglądarce). Inną możliwością jest użycie **wielu nowych linii** i **ukrycie informacji** w komentarzu na **dole** strony.
- **API keys**: Jeśli **znajdziesz jakikolwiek API key** istnieje przewodnik, który pokazuje jak używać kluczy API z różnych platform: [**keyhacks**](https://github.com/streaak/keyhacks)**,** [**zile**](https://github.com/xyele/zile.git)**,** [**truffleHog**](https://github.com/trufflesecurity/truffleHog)**,** [**SecretFinder**](https://github.com/m4ll0k/SecretFinder)**,** [**RegHex**](<https://github.com/l4yton/RegHex)/>)**,** [**DumpsterDive**](https://github.com/securing/DumpsterDiver)**,** [**EarlyBird**](https://github.com/americanexpress/earlybird)
- Google API keys: Jeśli znajdziesz klucz API wyglądający jak **AIza**SyA-qLheq6xjDiEIRisP_ujUseYLQCHUjik możesz użyć projektu [**gmapapiscanner**](https://github.com/ozguralp/gmapsapiscanner) aby sprawdzić, do jakich api klucz ma dostęp.
- **S3 Buckets**: Podczas spideringu sprawdź, czy jakiś **subdomain** lub jakiś **link** jest związany z S3 bucketem. W takim przypadku [**sprawdź** **uprawnienia** bucketu](buckets/index.html).

### Special findings

**Podczas** wykonywania **spideringu** i **brute-forcingu** możesz znaleźć **interesujące** **rzeczy**, na które musisz **zwrócić uwagę**.

**Interesujące pliki**

- Szukaj **linków** do innych plików w plikach **CSS**.
- [Jeśli znajdziesz _**.git**_ można wydobyć pewne informacje](git.md)
- Jeśli znajdziesz _**.env**_ można znaleźć informacje takie jak api keys, hasła do db i inne poufne dane.
- Jeśli znajdziesz **API endpoints** powinieneś je [też przetestować](web-api-pentesting.md). To nie są pliki, ale prawdopodobnie będą "wyglądać" jak pliki.
- **JS files**: W sekcji spideringu wymieniono kilka narzędzi, które potrafią wyciągać ścieżki z plików JS. Dobrze byłoby też **monitorować każdy znaleziony plik JS**, ponieważ w niektórych przypadkach zmiana może wskazywać, że do kodu została wprowadzona potencjalna podatność. Możesz na przykład użyć [**JSMon**](https://github.com/robre/jsmon)**.**
- Powinieneś także sprawdzić odkryte pliki JS za pomocą [**RetireJS**](https://github.com/retirejs/retire.js/) lub [**JSHole**](https://github.com/callforpapers-source/jshole) w celu wykrycia znanych podatności.
- **Javascript Deobfuscator and Unpacker:** [https://lelinhtinh.github.io/de4js/](https://lelinhtinh.github.io/de4js/), [https://www.dcode.fr/javascript-unobfuscator](https://www.dcode.fr/javascript-unobfuscator)
- **Javascript Beautifier:** [http://jsbeautifier.org/](https://beautifier.io), [http://jsnice.org/](http://jsnice.org)
- **JsFuck deobfuscation** (javascript z znakami:"\[]!+" [https://enkhee-osiris.github.io/Decoder-JSFuck/](https://enkhee-osiris.github.io/Decoder-JSFuck/))
- **TrainFuck**](https://github.com/taco-c/trainfuck)**:** `+72.+29.+7..+3.-67.-12.+55.+24.+3.-6.-8.-67.-23.`
- W wielu przypadkach będziesz musiał **zrozumieć wyrażenia regularne** używane w kodzie. Przydatne będą: [https://regex101.com/](https://regex101.com) lub [https://pythonium.net/regex](https://pythonium.net/regex)
- Możesz również **monitorować pliki, w których wykryto formularze**, ponieważ zmiana parametru lub pojawienie się nowego formularza może wskazywać na potencjalnie nową, podatną funkcjonalność.

**403 Forbidden/Basic Authentication/401 Unauthorized (bypass)**


{{#ref}}
403-and-401-bypasses.md
{{#endref}}

**502 Proxy Error**

Jeśli jakaś strona **odpowiada** tym **kodem**, prawdopodobnie jest to **źle skonfigurowany proxy**. **Jeśli wyślesz żądanie HTTP takie jak: `GET https://google.com HTTP/1.1`** (z nagłówkiem host i innymi standardowymi nagłówkami), **proxy** spróbuje **dostępować się** do _**google.com**_ **i znalazłeś** w ten sposób SSRF.

**NTLM Authentication - Info disclosure**

Jeśli serwer proszący o uwierzytelnienie jest **Windows** lub znajdziesz login proszący o Twoje **credentials** (i wymagający **nazwy domeny**), możesz spowodować **wyciek informacji**.\
**Wyślij** nagłówek: `“Authorization: NTLM TlRMTVNTUAABAAAAB4IIAAAAAAAAAAAAAAAAAAAAAAA=”` i ze względu na sposób działania **NTLM authentication**, serwer odpowie wewnętrznymi informacjami (wersja IIS, wersja Windows...) w nagłówku "WWW-Authenticate".\
Możesz to **zautomatyzować** używając nmap pluginu "_http-ntlm-info.nse_".

**HTTP Redirect (CTF)**

Możliwe jest **umieszczenie treści** wewnątrz **Redirection**. Ta treść **nie będzie widoczna dla użytkownika** (ponieważ przeglądarka wykona przekierowanie), ale coś może być **ukryte** w środku.

### Web Vulnerabilities Checking

Teraz, gdy przeprowadzono kompleksową enumerację aplikacji webowej, czas na sprawdzenie wielu możliwych podatności. Checklistę znajdziesz tutaj:


{{#ref}}
../../pentesting-web/web-vulnerabilities-methodology.md
{{#endref}}

Więcej informacji o web vulns:

- [https://six2dez.gitbook.io/pentest-book/others/web-checklist](https://six2dez.gitbook.io/pentest-book/others/web-checklist)
- [https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html](https://kennel209.gitbooks.io/owasp-testing-guide-v4/content/en/web_application_security_testing/configuration_and_deployment_management_testing.html)
- [https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection](https://owasp-skf.gitbook.io/asvs-write-ups/kbid-111-client-side-template-injection)

### Monitor Pages for changes

Możesz użyć narzędzi takich jak [https://github.com/dgtlmoon/changedetection.io](https://github.com/dgtlmoon/changedetection.io) do monitorowania stron pod kątem zmian, które mogą wprowadzić podatności.

### HackTricks Automatic Commands
```
Protocol_Name: Web    #Protocol Abbreviation if there is one.
Port_Number:  80,443     #Comma separated if there is more than one.
Protocol_Description: Web         #Protocol Abbreviation Spelled out

Entry_1:
Name: Notes
Description: Notes for Web
Note: |
https://book.hacktricks.wiki/en/network-services-pentesting/pentesting-web/index.html

Entry_2:
Name: Quick Web Scan
Description: Nikto and GoBuster
Command: nikto -host {Web_Proto}://{IP}:{Web_Port} &&&& gobuster dir -w {Small_Dirlist} -u {Web_Proto}://{IP}:{Web_Port} && gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_3:
Name: Nikto
Description: Basic Site Info via Nikto
Command: nikto -host {Web_Proto}://{IP}:{Web_Port}

Entry_4:
Name: WhatWeb
Description: General purpose auto scanner
Command: whatweb -a 4 {IP}

Entry_5:
Name: Directory Brute Force Non-Recursive
Description:  Non-Recursive Directory Brute Force
Command: gobuster dir -w {Big_Dirlist} -u {Web_Proto}://{IP}:{Web_Port}

Entry_6:
Name: Directory Brute Force Recursive
Description: Recursive Directory Brute Force
Command: python3 {Tool_Dir}dirsearch/dirsearch.py -w {Small_Dirlist} -e php,exe,sh,py,html,pl -f -t 20 -u {Web_Proto}://{IP}:{Web_Port} -r 10

Entry_7:
Name: Directory Brute Force CGI
Description: Common Gateway Interface Brute Force
Command: gobuster dir -u {Web_Proto}://{IP}:{Web_Port}/ -w /usr/share/seclists/Discovery/Web-Content/CGIs.txt -s 200

Entry_8:
Name: Nmap Web Vuln Scan
Description: Tailored Nmap Scan for web Vulnerabilities
Command: nmap -vv --reason -Pn -sV -p {Web_Port} --script=`banner,(http* or ssl*) and not (brute or broadcast or dos or external or http-slowloris* or fuzzer)` {IP}

Entry_9:
Name: Drupal
Description: Drupal Enumeration Notes
Note: |
git clone https://github.com/immunIT/drupwn.git for low hanging fruit and git clone https://github.com/droope/droopescan.git for deeper enumeration

Entry_10:
Name: WordPress
Description: WordPress Enumeration with WPScan
Command: |
?What is the location of the wp-login.php? Example: /Yeet/cannon/wp-login.php
wpscan --url {Web_Proto}://{IP}{1} --enumerate ap,at,cb,dbe && wpscan --url {Web_Proto}://{IP}{1} --enumerate u,tt,t,vp --passwords {Big_Passwordlist} -e

Entry_11:
Name: WordPress Hydra Brute Force
Description: Need User (admin is default)
Command: hydra -l admin -P {Big_Passwordlist} {IP} -V http-form-post '/wp-login.php:log=^USER^&pwd=^PASS^&wp-submit=Log In&testcookie=1:S=Location'

Entry_12:
Name: Ffuf Vhost
Description: Simple Scan with Ffuf for discovering additional vhosts
Command: ffuf -w {Subdomain_List}:FUZZ -u {Web_Proto}://{Domain_Name} -H "Host:FUZZ.{Domain_Name}" -c -mc all {Ffuf_Filters}
```
{{#include ../../banners/hacktricks-training.md}}
