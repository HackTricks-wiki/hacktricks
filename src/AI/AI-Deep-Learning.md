# Derin Ã–ÄŸrenme

{{#include ../banners/hacktricks-training.md}}

## Derin Ã–ÄŸrenme

Derin Ã¶ÄŸrenme, verilerdeki karmaÅŸÄ±k kalÄ±plarÄ± modellemek iÃ§in birden fazla katmana (derin sinir aÄŸlarÄ±) sahip sinir aÄŸlarÄ± kullanan makine Ã¶ÄŸreniminin bir alt kÃ¼mesidir. Bilgisayarla gÃ¶rme, doÄŸal dil iÅŸleme ve konuÅŸma tanÄ±ma gibi Ã§eÅŸitli alanlarda dikkate deÄŸer baÅŸarÄ±lar elde etmiÅŸtir.

### Sinir AÄŸlarÄ±

Sinir aÄŸlarÄ±, derin Ã¶ÄŸrenmenin yapÄ± taÅŸlarÄ±dÄ±r. Katmanlar halinde dÃ¼zenlenmiÅŸ birbirine baÄŸlÄ± dÃ¼ÄŸÃ¼mlerden (nÃ¶ronlar) oluÅŸurlar. Her nÃ¶ron, girdileri alÄ±r, aÄŸÄ±rlÄ±klÄ± toplam uygular ve bir Ã§Ä±kÄ±ÅŸ Ã¼retmek iÃ§in sonucu bir aktivasyon fonksiyonundan geÃ§irir. Katmanlar ÅŸu ÅŸekilde kategorize edilebilir:
- **Girdi KatmanÄ±**: Girdi verilerini alan ilk katman.
- **Gizli Katmanlar**: Girdi verileri Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼mler gerÃ§ekleÅŸtiren ara katmanlar. Gizli katmanlarÄ±n ve her katmandaki nÃ¶ron sayÄ±sÄ±nÄ±n deÄŸiÅŸkenlik gÃ¶stermesi, farklÄ± mimarilere yol aÃ§abilir.
- **Ã‡Ä±kÄ±ÅŸ KatmanÄ±**: AÄŸÄ±n Ã§Ä±ktÄ±sÄ±nÄ± Ã¼reten son katman, Ã¶rneÄŸin sÄ±nÄ±flandÄ±rma gÃ¶revlerinde sÄ±nÄ±f olasÄ±lÄ±klarÄ±.

### Aktivasyon FonksiyonlarÄ±

Bir nÃ¶ron katmanÄ± girdi verilerini iÅŸlerken, her nÃ¶ron girdiye bir aÄŸÄ±rlÄ±k ve bir bias uygular (`z = w * x + b`), burada `w` aÄŸÄ±rlÄ±k, `x` girdi ve `b` bias'tÄ±r. NÃ¶ronun Ã§Ä±ktÄ±sÄ± daha sonra modele doÄŸrusal olmayanlÄ±k eklemek iÃ§in bir **aktivasyon fonksiyonundan geÃ§irilir**. Bu aktivasyon fonksiyonu, bir sonraki nÃ¶ronun "aktif hale gelip gelmeyeceÄŸini ve ne kadar aktif olacaÄŸÄ±nÄ±" belirtir. Bu, aÄŸÄ±n verilerdeki karmaÅŸÄ±k kalÄ±plarÄ± ve iliÅŸkileri Ã¶ÄŸrenmesini saÄŸlar, bÃ¶ylece herhangi bir sÃ¼rekli fonksiyonu yaklaÅŸÄ±k olarak modelleyebilir.

Bu nedenle, aktivasyon fonksiyonlarÄ± sinir aÄŸÄ±na doÄŸrusal olmayanlÄ±k katarak verilerdeki karmaÅŸÄ±k iliÅŸkileri Ã¶ÄŸrenmesine olanak tanÄ±r. YaygÄ±n aktivasyon fonksiyonlarÄ± ÅŸunlardÄ±r:
- **Sigmoid**: Girdi deÄŸerlerini 0 ile 1 arasÄ±nda bir aralÄ±ÄŸa haritalar, genellikle ikili sÄ±nÄ±flandÄ±rmada kullanÄ±lÄ±r.
- **ReLU (DÃ¼zeltilmiÅŸ DoÄŸrusal Birim)**: Girdi pozitifse doÄŸrudan Ã§Ä±ktÄ±yÄ± verir; aksi takdirde sÄ±fÄ±r verir. Derin aÄŸlarÄ±n eÄŸitiminde basitliÄŸi ve etkinliÄŸi nedeniyle yaygÄ±n olarak kullanÄ±lÄ±r.
- **Tanh**: Girdi deÄŸerlerini -1 ile 1 arasÄ±nda bir aralÄ±ÄŸa haritalar, genellikle gizli katmanlarda kullanÄ±lÄ±r.
- **Softmax**: Ham puanlarÄ± olasÄ±lÄ±klara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, genellikle Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma iÃ§in Ã§Ä±kÄ±ÅŸ katmanÄ±nda kullanÄ±lÄ±r.

### Geri YayÄ±lÄ±m

Geri yayÄ±lÄ±m, sinir aÄŸlarÄ±nÄ± nÃ¶ronlar arasÄ±ndaki baÄŸlantÄ±larÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± ayarlayarak eÄŸitmek iÃ§in kullanÄ±lan algoritmadÄ±r. KayÄ±p fonksiyonunun her bir aÄŸÄ±rlÄ±kla ilgili gradyanÄ±nÄ± hesaplayarak ve aÄŸÄ±rlÄ±klarÄ± gradyanÄ±n ters yÃ¶nÃ¼nde gÃ¼ncelleyerek kaybÄ± minimize eder. Geri yayÄ±lÄ±mda yer alan adÄ±mlar ÅŸunlardÄ±r:

1. **Ä°leri GeÃ§iÅŸ**: Girdiyi katmanlardan geÃ§irerek ve aktivasyon fonksiyonlarÄ±nÄ± uygulayarak aÄŸÄ±n Ã§Ä±ktÄ±sÄ±nÄ± hesaplayÄ±n.
2. **KayÄ±p Hesaplama**: Tahmin edilen Ã§Ä±ktÄ± ile gerÃ§ek hedef arasÄ±ndaki kaybÄ± (hata) bir kayÄ±p fonksiyonu kullanarak hesaplayÄ±n (Ã¶rneÄŸin, regresyon iÃ§in ortalama kare hatasÄ±, sÄ±nÄ±flandÄ±rma iÃ§in Ã§apraz entropi).
3. **Geri GeÃ§iÅŸ**: KayÄ±p ile her bir aÄŸÄ±rlÄ±k arasÄ±ndaki gradyanlarÄ± hesaplayÄ±n, kalkÃ¼lÃ¼sÃ¼n zincir kuralÄ±nÄ± kullanarak.
4. **AÄŸÄ±rlÄ±k GÃ¼ncelleme**: KayÄ±bÄ± minimize etmek iÃ§in bir optimizasyon algoritmasÄ± (Ã¶rneÄŸin, stokastik gradyan iniÅŸi, Adam) kullanarak aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelleyin.

## KonvolÃ¼syonel Sinir AÄŸlarÄ± (CNN'ler)

KonvolÃ¼syonel Sinir AÄŸlarÄ± (CNN'ler), Ä±zgara benzeri verileri, Ã¶rneÄŸin gÃ¶rÃ¼ntÃ¼leri iÅŸlemek iÃ§in tasarlanmÄ±ÅŸ Ã¶zel bir sinir aÄŸÄ± tÃ¼rÃ¼dÃ¼r. Ã–zellikle, Ã¶zelliklerin mekansal hiyerarÅŸilerini otomatik olarak Ã¶ÄŸrenme yetenekleri nedeniyle bilgisayarla gÃ¶rme gÃ¶revlerinde oldukÃ§a etkilidirler.

CNN'lerin ana bileÅŸenleri ÅŸunlardÄ±r:
- **KonvolÃ¼syonel Katmanlar**: Girdi verilerine Ã¶ÄŸrenilebilir filtreler (Ã§ekirdekler) kullanarak konvolÃ¼syon iÅŸlemleri uygular ve yerel Ã¶zellikleri Ã§Ä±karÄ±r. Her filtre, girdinin Ã¼zerinde kayar ve bir nokta Ã§arpÄ±mÄ± hesaplayarak bir Ã¶zellik haritasÄ± Ã¼retir.
- **Havuzlama KatmanlarÄ±**: Ã–nemli Ã¶zellikleri korurken Ã¶zellik haritalarÄ±nÄ±n mekansal boyutlarÄ±nÄ± azaltmak iÃ§in Ã¶rnekleme yapar. YaygÄ±n havuzlama iÅŸlemleri arasÄ±nda maksimum havuzlama ve ortalama havuzlama bulunur.
- **Tam BaÄŸlantÄ±lÄ± Katmanlar**: Bir katmandaki her nÃ¶ronu bir sonraki katmandaki her nÃ¶rona baÄŸlar, geleneksel sinir aÄŸlarÄ±na benzer. Bu katmanlar genellikle sÄ±nÄ±flandÄ±rma gÃ¶revleri iÃ§in aÄŸÄ±n sonunda kullanÄ±lÄ±r.

Bir CNN iÃ§indeki **`KonvolÃ¼syonel Katmanlar`** arasÄ±nda ayrÄ±ca ÅŸunlarÄ± ayÄ±rt edebiliriz:
- **Ä°lk KonvolÃ¼syonel Katman**: Ham girdi verilerini (Ã¶rneÄŸin, bir gÃ¶rÃ¼ntÃ¼) iÅŸleyen ilk konvolÃ¼syonel katman ve kenarlar ve dokular gibi temel Ã¶zellikleri tanÄ±mlamak iÃ§in faydalÄ±dÄ±r.
- **Ara KonvolÃ¼syonel Katmanlar**: Ä°lk katmanÄ±n Ã¶ÄŸrendiÄŸi Ã¶zellikler Ã¼zerine inÅŸa eden sonraki konvolÃ¼syonel katmanlar, aÄŸÄ±n daha karmaÅŸÄ±k kalÄ±plarÄ± ve temsilleri Ã¶ÄŸrenmesine olanak tanÄ±r.
- **Son KonvolÃ¼syonel Katman**: Tam baÄŸlantÄ±lÄ± katmanlardan Ã¶nceki son konvolÃ¼syonel katmanlar, yÃ¼ksek seviyeli Ã¶zellikleri yakalar ve verileri sÄ±nÄ±flandÄ±rma iÃ§in hazÄ±rlar.

> [!TIP]
> CNN'ler, Ä±zgara benzeri verilerdeki Ã¶zelliklerin mekansal hiyerarÅŸilerini Ã¶ÄŸrenme yetenekleri ve aÄŸÄ±rlÄ±k paylaÅŸÄ±mÄ± yoluyla parametre sayÄ±sÄ±nÄ± azaltma Ã¶zellikleri nedeniyle gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, nesne tespiti ve gÃ¶rÃ¼ntÃ¼ segmentasyonu gÃ¶revlerinde Ã¶zellikle etkilidir.
> AyrÄ±ca, komÅŸu verilerin (piksel) uzak pikselere gÃ¶re daha fazla iliÅŸkili olma olasÄ±lÄ±ÄŸÄ±nÄ±n yÃ¼ksek olduÄŸu Ã¶zellik yerelliÄŸi ilkesini destekleyen verilerle daha iyi Ã§alÄ±ÅŸtÄ±klarÄ±nÄ± unutmayÄ±n; bu, metin gibi diÄŸer veri tÃ¼rleri iÃ§in geÃ§erli olmayabilir.
> DahasÄ±, CNN'lerin karmaÅŸÄ±k Ã¶zellikleri tanÄ±mlayabileceÄŸini ancak herhangi bir mekansal baÄŸlam uygulayamayacaÄŸÄ±nÄ±, yani gÃ¶rÃ¼ntÃ¼nÃ¼n farklÄ± bÃ¶lgelerinde bulunan aynÄ± Ã¶zelliÄŸin aynÄ± olacaÄŸÄ±nÄ± unutmayÄ±n.

### CNN TanÄ±mlama Ã–rneÄŸi

*Burada, 48x48 boyutunda bir RGB gÃ¶rÃ¼ntÃ¼ kÃ¼mesi ile baÅŸlayan bir KonvolÃ¼syonel Sinir AÄŸÄ± (CNN) tanÄ±mlamanÄ±n nasÄ±l yapÄ±lacaÄŸÄ±na dair bir aÃ§Ä±klama bulacaksÄ±nÄ±z ve Ã¶zellikleri Ã§Ä±karmak iÃ§in konvolÃ¼syonel katmanlar ve maksimum havuzlama kullanÄ±lÄ±r, ardÄ±ndan sÄ±nÄ±flandÄ±rma iÃ§in tam baÄŸlantÄ±lÄ± katmanlar gelir.*

PyTorch'ta 1 konvolÃ¼syonel katmanÄ± ÅŸu ÅŸekilde tanÄ±mlayabilirsiniz: `self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)`.

- `in_channels`: Girdi kanallarÄ±nÄ±n sayÄ±sÄ±. RGB gÃ¶rÃ¼ntÃ¼leri durumunda bu 3'tÃ¼r (her renk kanalÄ± iÃ§in bir tane). EÄŸer gri tonlamalÄ± gÃ¶rÃ¼ntÃ¼lerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, bu 1 olacaktÄ±r.

- `out_channels`: KonvolÃ¼syonel katmanÄ±n Ã¶ÄŸreneceÄŸi Ã§Ä±ktÄ± kanallarÄ±nÄ±n (filtrelerin) sayÄ±sÄ±dÄ±r. Bu, model mimarinize gÃ¶re ayarlayabileceÄŸiniz bir hiperparametredir.

- `kernel_size`: KonvolÃ¼syonel filtrenin boyutu. YaygÄ±n bir seÃ§im 3x3'tÃ¼r, bu da filtrenin girdi gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼n 3x3 alanÄ±nÄ± kapsayacaÄŸÄ± anlamÄ±na gelir. Bu, in_channels'tan out_channels'Ä± Ã¼retmek iÃ§in kullanÄ±lan 3Ã—3Ã—3 renk damgasÄ± gibidir:
1. O 3Ã—3Ã—3 damgayÄ± gÃ¶rÃ¼ntÃ¼ kÃ¼pÃ¼nÃ¼n sol Ã¼st kÃ¶ÅŸesine yerleÅŸtirin.
2. Her aÄŸÄ±rlÄ±ÄŸÄ± altÄ±ndaki piksel ile Ã§arpÄ±n, hepsini toplayÄ±n, bias ekleyin â†’ bir sayÄ± elde edersiniz.
3. O sayÄ±yÄ± boÅŸ bir haritada (0, 0) konumuna yazÄ±n.
4. DamgayÄ± bir piksel saÄŸa kaydÄ±rÄ±n (stride = 1) ve 48Ã—48 Ä±zgarayÄ± doldurana kadar tekrarlayÄ±n.

- `padding`: GirdiÄŸin her tarafÄ±na eklenen piksel sayÄ±sÄ±. Padding, Ã§Ä±ktÄ±nÄ±n boyutunu daha iyi kontrol edebilmek iÃ§in girdiÄŸin mekansal boyutlarÄ±nÄ± korumaya yardÄ±mcÄ± olur. Ã–rneÄŸin, 3x3 Ã§ekirdek ile 48x48 piksel girdi iÃ§in, 1'lik bir padding, konvolÃ¼syon iÅŸlemi sonrasÄ±nda Ã§Ä±ktÄ± boyutunu aynÄ± (48x48) tutar. Bunun nedeni, padding'in girdi gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼n etrafÄ±na 1 piksel geniÅŸliÄŸinde bir kenar eklemesi ve Ã§ekirdeÄŸin kenarlarÄ±n Ã¼zerinden kaymasÄ±na olanak tanÄ±masÄ±dÄ±r.

Bu katmandaki eÄŸitilebilir parametrelerin sayÄ±sÄ±:
- (3x3x3 (Ã§ekirdek boyutu) + 1 (bias)) x 32 (out_channels) = 896 eÄŸitilebilir parametre.

Her Ã§ekirdek iÃ§in bir Bias (+1) eklenir Ã§Ã¼nkÃ¼ her konvolÃ¼syonel katmanÄ±n iÅŸlevi, girdinin doÄŸrusal bir dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ Ã¶ÄŸrenmektir ve bu, ÅŸu denklemi temsil eder:
```plaintext
Y = f(W * X + b)
```
`W` aÄŸÄ±rlÄ±k matrisidir (Ã¶ÄŸrenilen filtreler, 3x3x3 = 27 parametre), `b` ise her Ã§Ä±kÄ±ÅŸ kanalÄ± iÃ§in +1 olan bias vektÃ¶rÃ¼dÃ¼r.

`self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)` ifadesinin Ã§Ä±ktÄ±sÄ±nÄ±n `(batch_size, 32, 48, 48)` ÅŸeklinde bir tensÃ¶r olacaÄŸÄ±nÄ± unutmayÄ±n, Ã§Ã¼nkÃ¼ 32, 48x48 piksel boyutunda Ã¼retilen yeni kanal sayÄ±sÄ±dÄ±r.

Sonra, bu konvolÃ¼syon katmanÄ±nÄ± baÅŸka bir konvolÃ¼syon katmanÄ±na baÄŸlayabiliriz: `self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)`.

Bu, ÅŸunlarÄ± ekleyecektir: (32x3x3 (kernel boyutu) + 1 (bias)) x 64 (out_channels) = 18,496 eÄŸitilebilir parametre ve `(batch_size, 64, 48, 48)` ÅŸeklinde bir Ã§Ä±ktÄ±.

GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, **parametre sayÄ±sÄ± her ek konvolÃ¼syon katmanÄ±yla hÄ±zla artar**, Ã¶zellikle Ã§Ä±kÄ±ÅŸ kanallarÄ±nÄ±n sayÄ±sÄ± arttÄ±kÃ§a.

KullanÄ±lan veri miktarÄ±nÄ± kontrol etmenin bir yolu, her konvolÃ¼syon katmanÄ±ndan sonra **max pooling** kullanmaktÄ±r. Max pooling, Ã¶zellik haritalarÄ±nÄ±n mekansal boyutlarÄ±nÄ± azaltÄ±r, bu da parametre sayÄ±sÄ±nÄ± ve hesaplama karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltmaya yardÄ±mcÄ± olurken Ã¶nemli Ã¶zelliklerin korunmasÄ±na yardÄ±mcÄ± olur.

Åu ÅŸekilde tanÄ±mlanabilir: `self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)`. Bu, temel olarak 2x2 piksel Ä±zgarasÄ± kullanmayÄ± ve her Ä±zgaradan maksimum deÄŸeri alarak Ã¶zellik haritasÄ±nÄ±n boyutunu yarÄ±ya indirmeyi belirtir. AyrÄ±ca, `stride=2` demek, pooling iÅŸleminin her seferinde 2 piksel hareket edeceÄŸi anlamÄ±na gelir; bu durumda, pooling bÃ¶lgeleri arasÄ±nda herhangi bir Ã¶rtÃ¼ÅŸmeyi Ã¶nler.

Bu pooling katmanÄ±yla, ilk konvolÃ¼syon katmanÄ±ndan sonra Ã§Ä±ktÄ± ÅŸekli, `self.conv2` Ã§Ä±ktÄ±sÄ±na `self.pool1` uygulandÄ±ktan sonra `(batch_size, 64, 24, 24)` olacaktÄ±r ve boyutu Ã¶nceki katmanÄ±n 1/4'Ã¼ne dÃ¼ÅŸecektir.

> [!TIP]
> KonvolÃ¼syon katmanlarÄ±ndan sonra pooling yapmak, Ã¶zellik haritalarÄ±nÄ±n mekansal boyutlarÄ±nÄ± azaltmak iÃ§in Ã¶nemlidir; bu, parametre sayÄ±sÄ±nÄ± ve hesaplama karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± kontrol etmeye yardÄ±mcÄ± olurken, baÅŸlangÄ±Ã§ parametrelerinin Ã¶nemli Ã¶zellikleri Ã¶ÄŸrenmesini saÄŸlar.
> Pooling katmanÄ±ndan Ã¶nceki konvolÃ¼syonlarÄ±, giriÅŸ verilerinden Ã¶zellikleri Ã§Ä±karmanÄ±n bir yolu olarak gÃ¶rebilirsiniz (Ã§izgiler, kenarlar gibi), bu bilgi hala havuzlanmÄ±ÅŸ Ã§Ä±ktÄ±da mevcut olacaktÄ±r, ancak bir sonraki konvolÃ¼syon katmanÄ± orijinal giriÅŸ verilerini gÃ¶remeyecek, yalnÄ±zca bu bilginin azaltÄ±lmÄ±ÅŸ versiyonu olan havuzlanmÄ±ÅŸ Ã§Ä±ktÄ±yÄ± gÃ¶recektir.
> Genellikle ÅŸu sÄ±rayla: `Conv â†’ ReLU â†’ Pool`, her 2Ã—2 havuzlama penceresi artÄ±k Ã¶zellik aktivasyonlarÄ±yla (â€œkenar mevcut / yokâ€) rekabet eder, ham piksel yoÄŸunluklarÄ±yla deÄŸil. En gÃ¼Ã§lÃ¼ aktivasyonu korumak, gerÃ§ekten de en belirgin kanÄ±tÄ± korur.

Sonra, ihtiyaÃ§ duyulan kadar konvolÃ¼syon ve pooling katmanÄ± ekledikten sonra, Ã§Ä±ktÄ±yÄ± tamamen baÄŸlÄ± katmanlara beslemek iÃ§in dÃ¼zleÅŸtirebiliriz. Bu, tensÃ¶rÃ¼ her Ã¶rnek iÃ§in 1D vektÃ¶r haline getirerek yapÄ±lÄ±r:
```python
x = x.view(-1, 64*24*24)
```
Ve Ã¶nceki konvolÃ¼syonel ve havuzlama katmanlarÄ± tarafÄ±ndan Ã¼retilen tÃ¼m eÄŸitim parametreleriyle bu 1D vektÃ¶rle, tam baÄŸlantÄ±lÄ± bir katmanÄ± ÅŸu ÅŸekilde tanÄ±mlayabiliriz:
```python
self.fc1 = nn.Linear(64 * 24 * 24, 512)
```
Ã–nceki katmanÄ±n dÃ¼zleÅŸtirilmiÅŸ Ã§Ä±ktÄ±sÄ±nÄ± alacak ve bunu 512 gizli birime haritalayacaktÄ±r.

Bu katmanÄ±n `(64 * 24 * 24 + 1 (bias)) * 512 = 3,221,504` eÄŸitilebilir parametre eklediÄŸine dikkat edin; bu, konvolÃ¼syonel katmanlara kÄ±yasla Ã¶nemli bir artÄ±ÅŸtÄ±r. Bunun nedeni, tam baÄŸlantÄ±lÄ± katmanlarÄ±n bir katmandaki her nÃ¶ronu bir sonraki katmandaki her nÃ¶rona baÄŸlamasÄ±dÄ±r, bu da bÃ¼yÃ¼k bir parametre sayÄ±sÄ±na yol aÃ§ar.

Son olarak, nihai sÄ±nÄ±f logitlerini Ã¼retmek iÃ§in bir Ã§Ä±kÄ±ÅŸ katmanÄ± ekleyebiliriz:
```python
self.fc2 = nn.Linear(512, num_classes)
```
Bu, `(512 + 1 (bias)) * num_classes` eÄŸitilebilir parametre ekleyecektir; burada `num_classes`, sÄ±nÄ±flandÄ±rma gÃ¶revindeki sÄ±nÄ±f sayÄ±sÄ±nÄ± ifade eder (Ã¶rneÄŸin, GTSRB veri seti iÃ§in 43).

Son yaygÄ±n uygulamalardan biri, aÅŸÄ±rÄ± uyumu Ã¶nlemek iÃ§in tam baÄŸlantÄ±lÄ± katmanlardan Ã¶nce bir dropout katmanÄ± eklemektir. Bu, ÅŸu ÅŸekilde yapÄ±labilir:
```python
self.dropout = nn.Dropout(0.5)
```
Bu katman, eÄŸitim sÄ±rasÄ±nda giriÅŸ birimlerinin bir kÄ±smÄ±nÄ± rastgele sÄ±fÄ±ra ayarlar; bu, belirli nÃ¶ronlara olan baÄŸÄ±mlÄ±lÄ±ÄŸÄ± azaltarak aÅŸÄ±rÄ± uyumu Ã¶nlemeye yardÄ±mcÄ± olur.

### CNN Kod Ã¶rneÄŸi
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MY_NET(nn.Module):
def __init__(self, num_classes=32):
super(MY_NET, self).__init__()
# Initial conv layer: 3 input channels (RGB), 32 output channels, 3x3 kernel, padding 1
# This layer will learn basic features like edges and textures
self.conv1 = nn.Conv2d(
in_channels=3, out_channels=32, kernel_size=3, padding=1
)
# Output: (Batch Size, 32, 48, 48)

# Conv Layer 2: 32 input channels, 64 output channels, 3x3 kernel, padding 1
# This layer will learn more complex features based on the output of conv1
self.conv2 = nn.Conv2d(
in_channels=32, out_channels=64, kernel_size=3, padding=1
)
# Output: (Batch Size, 64, 48, 48)

# Max Pooling 1: Kernel 2x2, Stride 2. Reduces spatial dimensions by half (1/4th of the previous layer).
self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
# Output: (Batch Size, 64, 24, 24)

# Conv Layer 3: 64 input channels, 128 output channels, 3x3 kernel, padding 1
# This layer will learn even more complex features based on the output of conv2
# Note that the number of output channels can be adjusted based on the complexity of the task
self.conv3 = nn.Conv2d(
in_channels=64, out_channels=128, kernel_size=3, padding=1
)
# Output: (Batch Size, 128, 24, 24)

# Max Pooling 2: Kernel 2x2, Stride 2. Reduces spatial dimensions by half again.
# Reducing the dimensions further helps to control the number of parameters and computational complexity.
self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
# Output: (Batch Size, 128, 12, 12)

# From the second pooling layer, we will flatten the output to feed it into fully connected layers.
# The feature size is calculated as follows:
# Feature size = Number of output channels * Height * Width
self._feature_size = 128 * 12 * 12

# Fully Connected Layer 1 (Hidden): Maps flattened features to hidden units.
# This layer will learn to combine the features extracted by the convolutional layers.
self.fc1 = nn.Linear(self._feature_size, 512)

# Fully Connected Layer 2 (Output): Maps hidden units to class logits.
# Output size MUST match num_classes
self.fc2 = nn.Linear(512, num_classes)

# Dropout layer configuration with a dropout rate of 0.5.
# This layer is used to prevent overfitting by randomly setting a fraction of the input units to zero during training.
self.dropout = nn.Dropout(0.5)

def forward(self, x):
"""
The forward method defines the forward pass of the network.
It takes an input tensor `x` and applies the convolutional layers, pooling layers, and fully connected layers in sequence.
The input tensor `x` is expected to have the shape (Batch Size, Channels, Height, Width), where:
- Batch Size: Number of samples in the batch
- Channels: Number of input channels (e.g., 3 for RGB images)
- Height: Height of the input image (e.g., 48 for 48x48 images)
- Width: Width of the input image (e.g., 48 for 48x48 images)
The output of the forward method is the logits for each class, which can be used for classification tasks.
Args:
x (torch.Tensor): Input tensor of shape (Batch Size, Channels, Height, Width)
Returns:
torch.Tensor: Output tensor of shape (Batch Size, num_classes) containing the class logits.
"""

# Conv1 -> ReLU -> Conv2 -> ReLU -> Pool1 -> Conv3 -> ReLU -> Pool2
x = self.conv1(x)
x = F.relu(x)
x = self.conv2(x)
x = F.relu(x)
x = self.pool1(x)
x = self.conv3(x)
x = F.relu(x)
x = self.pool2(x)
# At this point, x has shape (Batch Size, 128, 12, 12)

# Flatten the output to feed it into fully connected layers
x = torch.flatten(x, 1)

# Apply dropout to prevent overfitting
x = self.dropout(x)

# First FC layer with ReLU activation
x = F.relu(self.fc1(x))

# Apply Dropout again
x = self.dropout(x)
# Final FC layer to get logits
x = self.fc2(x)
# Output shape will be (Batch Size, num_classes)
# Note that the output is not passed through a softmax activation here, as it is typically done in the loss function (e.g., CrossEntropyLoss)
return x
```
### CNN Kod eÄŸitim Ã¶rneÄŸi

AÅŸaÄŸÄ±daki kod, bazÄ± eÄŸitim verileri oluÅŸturacak ve yukarÄ±da tanÄ±mlanan `MY_NET` modelini eÄŸitecektir. Dikkate deÄŸer bazÄ± ilginÃ§ deÄŸerler:

- `EPOCHS`, modelin eÄŸitim sÄ±rasÄ±nda tÃ¼m veri kÃ¼mesini gÃ¶receÄŸi kezdir. EPOCH Ã§ok kÃ¼Ã§Ã¼kse, model yeterince Ã¶ÄŸrenemeyebilir; Ã§ok bÃ¼yÃ¼kse, aÅŸÄ±rÄ± uyum saÄŸlayabilir.
- `LEARNING_RATE`, optimizasyon iÃ§in adÄ±m boyutudur. KÃ¼Ã§Ã¼k bir Ã¶ÄŸrenme oranÄ± yavaÅŸ yakÄ±nsama ile sonuÃ§lanabilirken, bÃ¼yÃ¼k bir oran optimal Ã§Ã¶zÃ¼mÃ¼ aÅŸabilir ve yakÄ±nsamayÄ± engelleyebilir.
- `WEIGHT_DECAY`, bÃ¼yÃ¼k aÄŸÄ±rlÄ±klarÄ± cezalandÄ±rarak aÅŸÄ±rÄ± uyumu Ã¶nlemeye yardÄ±mcÄ± olan bir dÃ¼zenleme terimidir.

EÄŸitim dÃ¶ngÃ¼sÃ¼ ile ilgili bilmeniz gereken bazÄ± ilginÃ§ bilgiler:
- `criterion = nn.CrossEntropyLoss()` Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma gÃ¶revleri iÃ§in kullanÄ±lan kayÄ±p fonksiyonudur. Softmax aktivasyonu ve Ã§apraz entropi kaybÄ±nÄ± tek bir fonksiyonda birleÅŸtirerek, sÄ±nÄ±f logitleri Ã¼reten modellerin eÄŸitimi iÃ§in uygun hale getirir.
- Modelin ikili sÄ±nÄ±flandÄ±rma veya regresyon gibi diÄŸer tÃ¼rde Ã§Ä±ktÄ±lar Ã¼retmesi bekleniyorsa, ikili sÄ±nÄ±flandÄ±rma iÃ§in `nn.BCEWithLogitsLoss()` veya regresyon iÃ§in `nn.MSELoss()` gibi farklÄ± kayÄ±p fonksiyonlarÄ± kullanÄ±rdÄ±k.
- `optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)` Adam optimizasyonunu baÅŸlatÄ±r; bu, derin Ã¶ÄŸrenme modellerini eÄŸitmek iÃ§in popÃ¼ler bir tercihtir. Ã–ÄŸrenme oranÄ±nÄ±, gradyanlarÄ±n birinci ve ikinci momentlerine gÃ¶re her parametre iÃ§in uyarlamaktadÄ±r.
- `optim.SGD` (Stokastik Gradyan Ä°niÅŸi) veya `optim.RMSprop` gibi diÄŸer optimizatÃ¶rler de, eÄŸitim gÃ¶revlerinin Ã¶zel gereksinimlerine baÄŸlÄ± olarak kullanÄ±labilir.
- `model.train()` metodu, modeli eÄŸitim moduna ayarlar ve dropout ve batch normalization gibi katmanlarÄ±n eÄŸitim sÄ±rasÄ±nda deÄŸerlendirmeden farklÄ± davranmasÄ±nÄ± saÄŸlar.
- `optimizer.zero_grad()` geri yayÄ±lmadan Ã¶nce tÃ¼m optimize edilen tensÃ¶rlerin gradyanlarÄ±nÄ± temizler; bu, PyTorch'ta gradyanlarÄ±n varsayÄ±lan olarak biriktiÄŸi iÃ§in gereklidir. Temizlenmezse, Ã¶nceki iterasyonlardan gelen gradyanlar mevcut gradyanlara eklenir ve yanlÄ±ÅŸ gÃ¼ncellemelerle sonuÃ§lanÄ±r.
- `loss.backward()` kaybÄ±n model parametrelerine gÃ¶re gradyanlarÄ±nÄ± hesaplar; bu gradyanlar daha sonra optimizatÃ¶r tarafÄ±ndan aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellemek iÃ§in kullanÄ±lÄ±r.
- `optimizer.step()` hesaplanan gradyanlar ve Ã¶ÄŸrenme oranÄ±na dayanarak model parametrelerini gÃ¼nceller.
```python
import torch, torch.nn.functional as F
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# ---------------------------------------------------------------------------
# 1. Globals
# ---------------------------------------------------------------------------
IMG_SIZE      = 48               # model expects 48Ã—48
NUM_CLASSES   = 10               # MNIST has 10 digits
BATCH_SIZE    = 64               # batch size for training and validation
EPOCHS        = 5                # number of training epochs
LEARNING_RATE = 1e-3             # initial learning rate for Adam optimiser
WEIGHT_DECAY  = 1e-4             # L2 regularisation to prevent overfitting

# Channel-wise mean / std for MNIST (grayscale â‡’ repeat for 3-channel input)
MNIST_MEAN = (0.1307, 0.1307, 0.1307)
MNIST_STD  = (0.3081, 0.3081, 0.3081)

# ---------------------------------------------------------------------------
# 2. Transforms
# ---------------------------------------------------------------------------
# 1) Baseline transform: resize + tensor (no colour/aug/no normalise)
transform_base = transforms.Compose([
transforms.Resize((IMG_SIZE, IMG_SIZE)),      # ğŸ”¹ Resize â€“ force all images to 48 Ã— 48 so the CNN sees a fixed geometry
transforms.Grayscale(num_output_channels=3),  # ğŸ”¹ Grayscaleâ†’RGB â€“ MNIST is 1-channel; duplicate into 3 channels for convnet
transforms.ToTensor(),                        # ğŸ”¹ ToTensor â€“ convert PIL image [0â€’255] â†’ float tensor [0.0â€’1.0]
])

# 2) Training transform: augment  + normalise
transform_norm = transforms.Compose([
transforms.Resize((IMG_SIZE, IMG_SIZE)),      # keep 48 Ã— 48 input size
transforms.Grayscale(num_output_channels=3),  # still need 3 channels
transforms.RandomRotation(10),                # ğŸ”¹ RandomRotation(Â±10Â°) â€“ small tilt â‡¢ rotation-invariance, combats overfitting
transforms.ColorJitter(brightness=0.2,
contrast=0.2),         # ğŸ”¹ ColorJitter â€“ pseudo-RGB brightness/contrast noise; extra variety
transforms.ToTensor(),                        # convert to tensor before numeric ops
transforms.Normalize(mean=MNIST_MEAN,
std=MNIST_STD),          # ğŸ”¹ Normalize â€“ zero-centre & scale so every channel â‰ˆ N(0,1)
])

# 3) Test/validation transform: only resize + normalise (no aug)
transform_test = transforms.Compose([
transforms.Resize((IMG_SIZE, IMG_SIZE)),      # same spatial size as train
transforms.Grayscale(num_output_channels=3),  # match channel count
transforms.ToTensor(),                        # tensor conversion
transforms.Normalize(mean=MNIST_MEAN,
std=MNIST_STD),          # ğŸ”¹ keep test data on same scale as training data
])

# ---------------------------------------------------------------------------
# 3. Datasets & loaders
# ---------------------------------------------------------------------------
train_set = datasets.MNIST("data",   train=True,  download=True, transform=transform_norm)
test_set  = datasets.MNIST("data",   train=False, download=True, transform=transform_test)

train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
test_loader  = DataLoader(test_set,  batch_size=256,          shuffle=False)

print(f"Training on {len(train_set)} samples, validating on {len(test_set)} samples.")

# ---------------------------------------------------------------------------
# 4. Model / loss / optimiser
# ---------------------------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model  = MY_NET(num_classes=NUM_CLASSES).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

# ---------------------------------------------------------------------------
# 5. Training loop
# ---------------------------------------------------------------------------
for epoch in range(1, EPOCHS + 1):
model.train()                          # Set model to training mode enabling dropout and batch norm

running_loss = 0.0                     # sums batch losses to compute epoch average
correct      = 0                       # number of correct predictions
total        = 0                       # number of samples seen

# tqdm wraps the loader to show a live progress-bar per epoch
for X_batch, y_batch in tqdm(train_loader, desc=f"Epoch {epoch}", leave=False):
# 3-a) Move data to GPU (if available) ----------------------------------
X_batch, y_batch = X_batch.to(device), y_batch.to(device)

# 3-b) Forward pass -----------------------------------------------------
logits = model(X_batch)            # raw class scores (shape: [B, NUM_CLASSES])
loss   = criterion(logits, y_batch)

# 3-c) Backward pass & parameter update --------------------------------
optimizer.zero_grad()              # clear old gradients
loss.backward()                    # compute new gradients
optimizer.step()                   # gradient â†’ weight update

# 3-d) Statistics -------------------------------------------------------
running_loss += loss.item() * X_batch.size(0)     # sum of (batch loss Ã— batch size)
preds   = logits.argmax(dim=1)                    # predicted class labels
correct += (preds == y_batch).sum().item()        # correct predictions in this batch
total   += y_batch.size(0)                        # samples processed so far

# 3-e) Epoch-level metrics --------------------------------------------------
epoch_loss = running_loss / total
epoch_acc  = 100.0 * correct / total
print(f"[Epoch {epoch}] loss = {epoch_loss:.4f} | accuracy = {epoch_acc:.2f}%")

print("\nâœ… Training finished.\n")

# ---------------------------------------------------------------------------
# 6. Evaluation on test set
# ---------------------------------------------------------------------------
model.eval() # Set model to evaluation mode (disables dropout and batch norm)
with torch.no_grad():
logits_all, labels_all = [], []
for X, y in test_loader:
logits_all.append(model(X.to(device)).cpu())
labels_all.append(y)
logits_all = torch.cat(logits_all)
labels_all = torch.cat(labels_all)
preds_all  = logits_all.argmax(1)

test_loss = criterion(logits_all, labels_all).item()
test_acc  = (preds_all == labels_all).float().mean().item() * 100

print(f"Test loss: {test_loss:.4f}")
print(f"Test accuracy: {test_acc:.2f}%\n")

print("Classification report (precision / recall / F1):")
print(classification_report(labels_all, preds_all, zero_division=0))

print("Confusion matrix (rows = true, cols = pred):")
print(confusion_matrix(labels_all, preds_all))
```
## Tekrarlayan Sinir AÄŸlarÄ± (RNN'ler)

Tekrarlayan Sinir AÄŸlarÄ± (RNN'ler), zaman serileri veya doÄŸal dil gibi sÄ±ralÄ± verileri iÅŸlemek iÃ§in tasarlanmÄ±ÅŸ bir sinir aÄŸÄ± sÄ±nÄ±fÄ±dÄ±r. Geleneksel ileri beslemeli sinir aÄŸlarÄ±nÄ±n aksine, RNN'ler kendilerine geri dÃ¶nen baÄŸlantÄ±lara sahiptir, bu da onlara dizideki Ã¶nceki girdiler hakkÄ±nda bilgi tutan gizli bir durum sÃ¼rdÃ¼rme imkanÄ± tanÄ±r.

RNN'lerin ana bileÅŸenleri ÅŸunlardÄ±r:
- **Tekrarlayan Katmanlar**: Bu katmanlar, giriÅŸ dizilerini bir zaman adÄ±mÄ±nda bir kez iÅŸleyerek, mevcut girdi ve Ã¶nceki gizli duruma dayanarak gizli durumlarÄ±nÄ± gÃ¼nceller. Bu, RNN'lerin verideki zamansal baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenmesine olanak tanÄ±r.
- **Gizli Durum**: Gizli durum, Ã¶nceki zaman adÄ±mlarÄ±ndan gelen bilgileri Ã¶zetleyen bir vektÃ¶rdÃ¼r. Her zaman adÄ±mÄ±nda gÃ¼ncellenir ve mevcut girdi iÃ§in tahminler yapmakta kullanÄ±lÄ±r.
- **Ã‡Ä±ktÄ± KatmanÄ±**: Ã‡Ä±ktÄ± katmanÄ±, gizli duruma dayanarak nihai tahminleri Ã¼retir. BirÃ§ok durumda, RNN'ler Ã§Ä±ktÄ±nÄ±n bir dizideki bir sonraki kelime Ã¼zerindeki olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± olduÄŸu dil modelleme gibi gÃ¶revler iÃ§in kullanÄ±lÄ±r.

Ã–rneÄŸin, bir dil modelinde, RNN bir kelime dizisini iÅŸler, Ã¶rneÄŸin, "Kedi" ve Ã¶nceki kelimelerin saÄŸladÄ±ÄŸÄ± baÄŸlama dayanarak bir sonraki kelimeyi tahmin eder, bu durumda "halÄ±".

### Uzun KÄ±sa SÃ¼reli Bellek (LSTM) ve KapÄ±lÄ± Tekrarlayan Birim (GRU)

RNN'ler, dil modelleme, makine Ã§evirisi ve konuÅŸma tanÄ±ma gibi sÄ±ralÄ± verilerle ilgili gÃ¶revler iÃ§in Ã¶zellikle etkilidir. Ancak, **uzun menzilli baÄŸÄ±mlÄ±lÄ±klar ile ilgili sorunlar nedeniyle zayÄ±flayabilmektedirler**.

Bunu ele almak iÃ§in, Uzun KÄ±sa SÃ¼reli Bellek (LSTM) ve KapÄ±lÄ± Tekrarlayan Birim (GRU) gibi Ã¶zel mimariler geliÅŸtirilmiÅŸtir. Bu mimariler, bilgiyi kontrol eden kapama mekanizmalarÄ± tanÄ±tarak uzun menzilli baÄŸÄ±mlÄ±lÄ±klarÄ± daha etkili bir ÅŸekilde yakalamalarÄ±na olanak tanÄ±r.

- **LSTM**: LSTM aÄŸlarÄ±, hÃ¼cre durumuna bilgi akÄ±ÅŸÄ±nÄ± dÃ¼zenlemek iÃ§in Ã¼Ã§ kapÄ± (giriÅŸ kapÄ±sÄ±, unutma kapÄ±sÄ± ve Ã§Ä±kÄ±ÅŸ kapÄ±sÄ±) kullanÄ±r ve uzun diziler boyunca bilgiyi hatÄ±rlama veya unutma yeteneÄŸi saÄŸlar. GiriÅŸ kapÄ±sÄ±, mevcut girdi ve Ã¶nceki gizli duruma dayanarak ne kadar yeni bilgi ekleyeceÄŸini kontrol eder, unutma kapÄ±sÄ± ise ne kadar bilgiyi atacaÄŸÄ±nÄ± kontrol eder. GiriÅŸ kapÄ±sÄ± ve unutma kapÄ±sÄ±nÄ± birleÅŸtirerek yeni durumu elde ederiz. Son olarak, yeni hÃ¼cre durumunu, giriÅŸ ve Ã¶nceki gizli durum ile birleÅŸtirerek yeni gizli durumu elde ederiz.
- **GRU**: GRU aÄŸlarÄ±, LSTM mimarisini giriÅŸ ve unutma kapÄ±larÄ±nÄ± tek bir gÃ¼ncelleme kapÄ±sÄ±nda birleÅŸtirerek basitleÅŸtirir, bu da onlarÄ± hesaplama aÃ§Ä±sÄ±ndan daha verimli hale getirirken uzun menzilli baÄŸÄ±mlÄ±lÄ±klarÄ± yakalamaya devam eder.

## LLM'ler (BÃ¼yÃ¼k Dil Modelleri)

BÃ¼yÃ¼k Dil Modelleri (LLM'ler), doÄŸal dil iÅŸleme gÃ¶revleri iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ bir derin Ã¶ÄŸrenme modeli tÃ¼rÃ¼dÃ¼r. BÃ¼yÃ¼k miktarda metin verisi Ã¼zerinde eÄŸitilirler ve insan benzeri metinler Ã¼retebilir, sorularÄ± yanÄ±tlayabilir, dilleri Ã§evirebilir ve Ã§eÅŸitli diÄŸer dil ile ilgili gÃ¶revleri yerine getirebilirler. LLM'ler genellikle, bir dizideki kelimeler arasÄ±ndaki iliÅŸkileri yakalamak iÃ§in kendine dikkat mekanizmalarÄ± kullanan dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ mimarilere dayanÄ±r, bu da baÄŸlamÄ± anlamalarÄ±na ve tutarlÄ± metinler Ã¼retmelerine olanak tanÄ±r.

### DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ Mimarisi
DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ mimarisi, birÃ§ok LLM'nin temelini oluÅŸturur. GiriÅŸ dizisini iÅŸleyen bir kodlayÄ±cÄ±-Ã§Ã¶zÃ¼cÃ¼ yapÄ±sÄ±ndan oluÅŸur ve Ã§Ã¶zÃ¼cÃ¼ Ã§Ä±ktÄ± dizisini Ã¼retir. DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ mimarisinin ana bileÅŸenleri ÅŸunlardÄ±r:
- **Kendine Dikkat MekanizmasÄ±**: Bu mekanizma, modelin temsil oluÅŸtururken bir dizideki farklÄ± kelimelerin Ã¶nemini tartmasÄ±na olanak tanÄ±r. Kelimeler arasÄ±ndaki iliÅŸkilere dayanarak dikkat puanlarÄ± hesaplar, bu da modelin ilgili baÄŸlama odaklanmasÄ±nÄ± saÄŸlar.
- **Ã‡oklu BaÅŸlÄ± Dikkat**: Bu bileÅŸen, modelin birden fazla dikkat baÅŸlÄ±ÄŸÄ± kullanarak kelimeler arasÄ±ndaki birden fazla iliÅŸkiyi yakalamasÄ±na olanak tanÄ±r; her baÅŸlÄ±k, giriÅŸin farklÄ± yÃ¶nlerine odaklanÄ±r.
- **Pozisyonel Kodlama**: DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ler, kelime sÄ±rasÄ± hakkÄ±nda yerleÅŸik bir kavrama sahip olmadÄ±ÄŸÄ±ndan, dizideki kelimelerin konumuna dair bilgi saÄŸlamak iÃ§in giriÅŸ gÃ¶mme katmanlarÄ±na pozisyonel kodlama eklenir.

## DifÃ¼zyon Modelleri
DifÃ¼zyon modelleri, bir difÃ¼zyon sÃ¼recini simÃ¼le ederek veri Ã¼retmeyi Ã¶ÄŸrenen bir Ã¼retken model sÄ±nÄ±fÄ±dÄ±r. GÃ¶rÃ¼ntÃ¼ Ã¼retimi gibi gÃ¶revler iÃ§in Ã¶zellikle etkilidirler ve son yÄ±llarda popÃ¼lerlik kazanmÄ±ÅŸlardÄ±r. DifÃ¼zyon modelleri, basit bir gÃ¼rÃ¼ltÃ¼ daÄŸÄ±lÄ±mÄ±nÄ± karmaÅŸÄ±k bir veri daÄŸÄ±lÄ±mÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in bir dizi difÃ¼zyon adÄ±mÄ± aracÄ±lÄ±ÄŸÄ±yla Ã§alÄ±ÅŸÄ±r. DifÃ¼zyon modellerinin ana bileÅŸenleri ÅŸunlardÄ±r:
- **Ä°leri DifÃ¼zyon SÃ¼reci**: Bu sÃ¼reÃ§, veriye gÃ¼rÃ¼ltÃ¼ ekleyerek onu basit bir gÃ¼rÃ¼ltÃ¼ daÄŸÄ±lÄ±mÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Ä°leri difÃ¼zyon sÃ¼reci genellikle, her seviye belirli bir miktarda gÃ¼rÃ¼ltÃ¼ eklenmesini temsil eden bir dizi gÃ¼rÃ¼ltÃ¼ seviyesi ile tanÄ±mlanÄ±r.
- **Ters DifÃ¼zyon SÃ¼reci**: Bu sÃ¼reÃ§, ileri difÃ¼zyon sÃ¼recini tersine Ã§evirmeyi Ã¶ÄŸrenir, veriyi yavaÅŸ yavaÅŸ gÃ¼rÃ¼ltÃ¼den arÄ±ndÄ±rarak hedef daÄŸÄ±lÄ±mdan Ã¶rnekler Ã¼retir. Ters difÃ¼zyon sÃ¼reci, modelin gÃ¼rÃ¼ltÃ¼lÃ¼ Ã¶rneklerden orijinal veriyi yeniden oluÅŸturmasÄ±nÄ± teÅŸvik eden bir kayÄ±p fonksiyonu kullanÄ±larak eÄŸitilir.

AyrÄ±ca, bir metin isteminden bir gÃ¶rÃ¼ntÃ¼ Ã¼retmek iÃ§in, difÃ¼zyon modelleri genellikle ÅŸu adÄ±mlarÄ± izler:
1. **Metin Kodlama**: Metin istemi, bir metin kodlayÄ±cÄ± (Ã¶rneÄŸin, bir dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ tabanlÄ± model) kullanÄ±larak gizli bir temsile kodlanÄ±r. Bu temsil, metnin anlamsal anlamÄ±nÄ± yakalar.
2. **GÃ¼rÃ¼ltÃ¼ Ã–rnekleme**: Bir Gauss daÄŸÄ±lÄ±mÄ±ndan rastgele bir gÃ¼rÃ¼ltÃ¼ vektÃ¶rÃ¼ Ã¶rneklenir.
3. **DifÃ¼zyon AdÄ±mlarÄ±**: Model, gÃ¼rÃ¼ltÃ¼ vektÃ¶rÃ¼nÃ¼ metin istemine karÅŸÄ±lÄ±k gelen bir gÃ¶rÃ¼ntÃ¼ye dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in bir dizi difÃ¼zyon adÄ±mÄ± uygular. Her adÄ±m, gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¼rÃ¼ltÃ¼den arÄ±ndÄ±rmak iÃ§in Ã¶ÄŸrenilen dÃ¶nÃ¼ÅŸÃ¼mleri uygulamayÄ± iÃ§erir.

{{#include ../banners/hacktricks-training.md}}
