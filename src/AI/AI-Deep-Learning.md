# æ·±åº¦å­¦ä¹ 

{{#include ../banners/hacktricks-training.md}}

## æ·±åº¦å­¦ä¹ 

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨å…·æœ‰å¤šä¸ªå±‚ï¼ˆæ·±åº¦ç¥ç»ç½‘ç»œï¼‰çš„ç¥ç»ç½‘ç»œæ¥å»ºæ¨¡æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚å®ƒåœ¨å¤šä¸ªé¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼ŒåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ã€‚

### ç¥ç»ç½‘ç»œ

ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„æ„å»ºå—ã€‚å®ƒä»¬ç”±äº’è”çš„èŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰ç»„æˆï¼Œç»„ç»‡æˆå±‚ã€‚æ¯ä¸ªç¥ç»å…ƒæ¥æ”¶è¾“å…¥ï¼Œåº”ç”¨åŠ æƒå’Œï¼Œå¹¶é€šè¿‡æ¿€æ´»å‡½æ•°ä¼ é€’ç»“æœä»¥äº§ç”Ÿè¾“å‡ºã€‚å±‚å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š
- **è¾“å…¥å±‚**ï¼šæ¥æ”¶è¾“å…¥æ•°æ®çš„ç¬¬ä¸€å±‚ã€‚
- **éšè—å±‚**ï¼šå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå˜æ¢çš„ä¸­é—´å±‚ã€‚éšè—å±‚å’Œæ¯å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡å¯ä»¥å˜åŒ–ï¼Œä»è€Œå¯¼è‡´ä¸åŒçš„æ¶æ„ã€‚
- **è¾“å‡ºå±‚**ï¼šäº§ç”Ÿç½‘ç»œè¾“å‡ºçš„æœ€åä¸€å±‚ï¼Œä¾‹å¦‚åˆ†ç±»ä»»åŠ¡ä¸­çš„ç±»åˆ«æ¦‚ç‡ã€‚

### æ¿€æ´»å‡½æ•°

å½“ä¸€å±‚ç¥ç»å…ƒå¤„ç†è¾“å…¥æ•°æ®æ—¶ï¼Œæ¯ä¸ªç¥ç»å…ƒå¯¹è¾“å…¥åº”ç”¨æƒé‡å’Œåç½®ï¼ˆ`z = w * x + b`ï¼‰ï¼Œå…¶ä¸­ `w` æ˜¯æƒé‡ï¼Œ`x` æ˜¯è¾“å…¥ï¼Œ`b` æ˜¯åç½®ã€‚ç„¶åï¼Œç¥ç»å…ƒçš„è¾“å‡ºé€šè¿‡**æ¿€æ´»å‡½æ•°å¼•å…¥éçº¿æ€§**åˆ°æ¨¡å‹ä¸­ã€‚è¿™ä¸ªæ¿€æ´»å‡½æ•°åŸºæœ¬ä¸ŠæŒ‡ç¤ºä¸‹ä¸€ä¸ªç¥ç»å…ƒâ€œæ˜¯å¦åº”è¯¥è¢«æ¿€æ´»ä»¥åŠæ¿€æ´»çš„ç¨‹åº¦â€ã€‚è¿™ä½¿å¾—ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼å’Œå…³ç³»ï¼Œä»è€Œèƒ½å¤Ÿè¿‘ä¼¼ä»»ä½•è¿ç»­å‡½æ•°ã€‚

å› æ­¤ï¼Œæ¿€æ´»å‡½æ•°å°†éçº¿æ€§å¼•å…¥ç¥ç»ç½‘ç»œï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ã€‚å¸¸è§çš„æ¿€æ´»å‡½æ•°åŒ…æ‹¬ï¼š
- **Sigmoid**ï¼šå°†è¾“å…¥å€¼æ˜ å°„åˆ°0å’Œ1ä¹‹é—´çš„èŒƒå›´ï¼Œé€šå¸¸ç”¨äºäºŒåˆ†ç±»ã€‚
- **ReLUï¼ˆä¿®æ­£çº¿æ€§å•å…ƒï¼‰**ï¼šå¦‚æœè¾“å…¥ä¸ºæ­£ï¼Œåˆ™ç›´æ¥è¾“å‡ºè¾“å…¥ï¼›å¦åˆ™ï¼Œè¾“å‡ºé›¶ã€‚ç”±äºå…¶ç®€å•æ€§å’Œåœ¨è®­ç»ƒæ·±åº¦ç½‘ç»œä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¿æ³›ä½¿ç”¨ã€‚
- **Tanh**ï¼šå°†è¾“å…¥å€¼æ˜ å°„åˆ°-1å’Œ1ä¹‹é—´çš„èŒƒå›´ï¼Œé€šå¸¸ç”¨äºéšè—å±‚ã€‚
- **Softmax**ï¼šå°†åŸå§‹åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œé€šå¸¸ç”¨äºå¤šç±»åˆ†ç±»çš„è¾“å‡ºå±‚ã€‚

### åå‘ä¼ æ’­

åå‘ä¼ æ’­æ˜¯ç”¨äºé€šè¿‡è°ƒæ•´ç¥ç»å…ƒä¹‹é—´è¿æ¥çš„æƒé‡æ¥è®­ç»ƒç¥ç»ç½‘ç»œçš„ç®—æ³•ã€‚å®ƒé€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¯ä¸ªæƒé‡çš„æ¢¯åº¦ï¼Œå¹¶åœ¨æ¢¯åº¦çš„ç›¸åæ–¹å‘æ›´æ–°æƒé‡ä»¥æœ€å°åŒ–æŸå¤±ã€‚åå‘ä¼ æ’­æ¶‰åŠçš„æ­¥éª¤åŒ…æ‹¬ï¼š

1. **å‰å‘ä¼ æ’­**ï¼šé€šè¿‡å°†è¾“å…¥ä¼ é€’é€šè¿‡å±‚å¹¶åº”ç”¨æ¿€æ´»å‡½æ•°æ¥è®¡ç®—ç½‘ç»œçš„è¾“å‡ºã€‚
2. **æŸå¤±è®¡ç®—**ï¼šä½¿ç”¨æŸå¤±å‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œå›å½’çš„å‡æ–¹è¯¯å·®ï¼Œåˆ†ç±»çš„äº¤å‰ç†µï¼‰è®¡ç®—é¢„æµ‹è¾“å‡ºä¸çœŸå®ç›®æ ‡ä¹‹é—´çš„æŸå¤±ï¼ˆè¯¯å·®ï¼‰ã€‚
3. **åå‘ä¼ æ’­**ï¼šä½¿ç”¨å¾®ç§¯åˆ†çš„é“¾å¼æ³•åˆ™è®¡ç®—æŸå¤±ç›¸å¯¹äºæ¯ä¸ªæƒé‡çš„æ¢¯åº¦ã€‚
4. **æƒé‡æ›´æ–°**ï¼šä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆä¾‹å¦‚ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ï¼ŒAdamï¼‰æ›´æ–°æƒé‡ä»¥æœ€å°åŒ–æŸå¤±ã€‚

## å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰

å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰æ˜¯ä¸€ç§ä¸“é—¨è®¾è®¡ç”¨äºå¤„ç†ç½‘æ ¼çŠ¶æ•°æ®ï¼ˆå¦‚å›¾åƒï¼‰çš„ç¥ç»ç½‘ç»œã€‚ç”±äºå…¶èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ ç‰¹å¾çš„ç©ºé—´å±‚æ¬¡ç»“æ„ï¼Œå› æ­¤åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­ç‰¹åˆ«æœ‰æ•ˆã€‚

CNNçš„ä¸»è¦ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š
- **å·ç§¯å±‚**ï¼šä½¿ç”¨å¯å­¦ä¹ çš„æ»¤æ³¢å™¨ï¼ˆå†…æ ¸ï¼‰å¯¹è¾“å…¥æ•°æ®åº”ç”¨å·ç§¯æ“ä½œï¼Œä»¥æå–å±€éƒ¨ç‰¹å¾ã€‚æ¯ä¸ªæ»¤æ³¢å™¨åœ¨è¾“å…¥ä¸Šæ»‘åŠ¨å¹¶è®¡ç®—ç‚¹ç§¯ï¼Œç”Ÿæˆç‰¹å¾å›¾ã€‚
- **æ± åŒ–å±‚**ï¼šå¯¹ç‰¹å¾å›¾è¿›è¡Œä¸‹é‡‡æ ·ï¼Œä»¥å‡å°‘å…¶ç©ºé—´ç»´åº¦ï¼ŒåŒæ—¶ä¿ç•™é‡è¦ç‰¹å¾ã€‚å¸¸è§çš„æ± åŒ–æ“ä½œåŒ…æ‹¬æœ€å¤§æ± åŒ–å’Œå¹³å‡æ± åŒ–ã€‚
- **å…¨è¿æ¥å±‚**ï¼šå°†ä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒä¸ä¸‹ä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒè¿æ¥ï¼Œç±»ä¼¼äºä¼ ç»Ÿç¥ç»ç½‘ç»œã€‚è¿™äº›å±‚é€šå¸¸åœ¨ç½‘ç»œçš„æœ«å°¾ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚

åœ¨CNNçš„**å·ç§¯å±‚**ä¸­ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åŒºåˆ†ï¼š
- **åˆå§‹å·ç§¯å±‚**ï¼šå¤„ç†åŸå§‹è¾“å…¥æ•°æ®ï¼ˆä¾‹å¦‚å›¾åƒï¼‰çš„ç¬¬ä¸€å·ç§¯å±‚ï¼Œæœ‰åŠ©äºè¯†åˆ«åŸºæœ¬ç‰¹å¾ï¼Œå¦‚è¾¹ç¼˜å’Œçº¹ç†ã€‚
- **ä¸­é—´å·ç§¯å±‚**ï¼šåç»­å·ç§¯å±‚ï¼ŒåŸºäºåˆå§‹å±‚å­¦ä¹ çš„ç‰¹å¾ï¼Œå…è®¸ç½‘ç»œå­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼å’Œè¡¨ç¤ºã€‚
- **æœ€ç»ˆå·ç§¯å±‚**ï¼šåœ¨å…¨è¿æ¥å±‚ä¹‹å‰çš„æœ€åå·ç§¯å±‚ï¼Œæ•è·é«˜çº§ç‰¹å¾å¹¶ä¸ºåˆ†ç±»å‡†å¤‡æ•°æ®ã€‚

> [!TIP]
> CNNåœ¨å›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹å’Œå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿå­¦ä¹ ç½‘æ ¼çŠ¶æ•°æ®ä¸­ç‰¹å¾çš„ç©ºé—´å±‚æ¬¡ç»“æ„ï¼Œå¹¶é€šè¿‡æƒé‡å…±äº«å‡å°‘å‚æ•°æ•°é‡ã€‚
> æ­¤å¤–ï¼Œå®ƒä»¬åœ¨æ”¯æŒç‰¹å¾å±€éƒ¨æ€§åŸåˆ™çš„æ•°æ®ä¸Šè¡¨ç°æ›´å¥½ï¼Œå…¶ä¸­ç›¸é‚»æ•°æ®ï¼ˆåƒç´ ï¼‰æ›´å¯èƒ½ç›¸å…³ï¼Œè€Œè¿œç¦»çš„åƒç´ å¯èƒ½ä¸æ˜¯å…¶ä»–ç±»å‹æ•°æ®ï¼ˆå¦‚æ–‡æœ¬ï¼‰çš„æƒ…å†µã€‚
> æ­¤å¤–ï¼Œè¯·æ³¨æ„ï¼ŒCNNèƒ½å¤Ÿè¯†åˆ«ç”šè‡³å¤æ‚çš„ç‰¹å¾ï¼Œä½†æ— æ³•åº”ç”¨ä»»ä½•ç©ºé—´ä¸Šä¸‹æ–‡ï¼Œè¿™æ„å‘³ç€åœ¨å›¾åƒä¸åŒéƒ¨åˆ†å‘ç°çš„ç›¸åŒç‰¹å¾å°†æ˜¯ç›¸åŒçš„ã€‚

### å®šä¹‰CNNçš„ç¤ºä¾‹

*åœ¨è¿™é‡Œï¼Œæ‚¨å°†æ‰¾åˆ°å¦‚ä½•åœ¨PyTorchä¸­å®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„æè¿°ï¼Œè¯¥ç½‘ç»œä»¥å¤§å°ä¸º48x48çš„RGBå›¾åƒæ‰¹æ¬¡ä½œä¸ºæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨å·ç§¯å±‚å’Œæœ€å¤§æ± åŒ–æå–ç‰¹å¾ï¼Œéšåæ˜¯å…¨è¿æ¥å±‚è¿›è¡Œåˆ†ç±»ã€‚*

è¿™å°±æ˜¯æ‚¨å¦‚ä½•åœ¨PyTorchä¸­å®šä¹‰1ä¸ªå·ç§¯å±‚ï¼š`self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)`ã€‚

- `in_channels`ï¼šè¾“å…¥é€šé“çš„æ•°é‡ã€‚åœ¨RGBå›¾åƒçš„æƒ…å†µä¸‹ï¼Œè¿™æ˜¯3ï¼ˆæ¯ä¸ªé¢œè‰²é€šé“ä¸€ä¸ªï¼‰ã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ç°åº¦å›¾åƒï¼Œåˆ™ä¸º1ã€‚

- `out_channels`ï¼šå·ç§¯å±‚å°†å­¦ä¹ çš„è¾“å‡ºé€šé“ï¼ˆæ»¤æ³¢å™¨ï¼‰æ•°é‡ã€‚è¿™æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œæ‚¨å¯ä»¥æ ¹æ®æ¨¡å‹æ¶æ„è¿›è¡Œè°ƒæ•´ã€‚

- `kernel_size`ï¼šå·ç§¯æ»¤æ³¢å™¨çš„å¤§å°ã€‚å¸¸è§é€‰æ‹©æ˜¯3x3ï¼Œè¿™æ„å‘³ç€æ»¤æ³¢å™¨å°†è¦†ç›–è¾“å…¥å›¾åƒçš„3x3åŒºåŸŸã€‚è¿™å°±åƒä¸€ä¸ª3Ã—3Ã—3çš„é¢œè‰²å°ç« ï¼Œç”¨äºä»è¾“å…¥é€šé“ç”Ÿæˆè¾“å‡ºé€šé“ï¼š
1. å°†è¯¥3Ã—3Ã—3çš„å°ç« æ”¾åœ¨å›¾åƒç«‹æ–¹ä½“çš„å·¦ä¸Šè§’ã€‚
2. å°†æ¯ä¸ªæƒé‡ä¹˜ä»¥å…¶ä¸‹æ–¹çš„åƒç´ ï¼Œå°†å®ƒä»¬ç›¸åŠ ï¼Œæ·»åŠ åç½®â†’æ‚¨å¾—åˆ°ä¸€ä¸ªæ•°å­—ã€‚
3. å°†è¯¥æ•°å­—å†™å…¥ä½ç½®ï¼ˆ0, 0ï¼‰çš„ç©ºç™½å›¾ä¸­ã€‚
4. å°†å°ç« å‘å³æ»‘åŠ¨ä¸€ä¸ªåƒç´ ï¼ˆæ­¥å¹…=1ï¼‰ï¼Œé‡å¤ç›´åˆ°å¡«æ»¡æ•´ä¸ª48Ã—48çš„ç½‘æ ¼ã€‚

- `padding`ï¼šæ·»åŠ åˆ°è¾“å…¥æ¯ä¸€ä¾§çš„åƒç´ æ•°é‡ã€‚å¡«å……æœ‰åŠ©äºä¿æŒè¾“å…¥çš„ç©ºé—´ç»´åº¦ï¼Œä»è€Œæ›´å¥½åœ°æ§åˆ¶è¾“å‡ºå¤§å°ã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ª3x3çš„å†…æ ¸å’Œ48x48åƒç´ çš„è¾“å…¥ï¼Œå¡«å……1å°†ä½¿å·ç§¯æ“ä½œåçš„è¾“å‡ºå¤§å°ä¿æŒä¸å˜ï¼ˆ48x48ï¼‰ã€‚è¿™æ˜¯å› ä¸ºå¡«å……åœ¨è¾“å…¥å›¾åƒå‘¨å›´æ·»åŠ äº†1åƒç´ çš„è¾¹æ¡†ï¼Œä½¿å†…æ ¸èƒ½å¤Ÿåœ¨è¾¹ç¼˜æ»‘åŠ¨è€Œä¸å‡å°‘ç©ºé—´ç»´åº¦ã€‚

ç„¶åï¼Œè¿™ä¸€å±‚ä¸­çš„å¯è®­ç»ƒå‚æ•°æ•°é‡ä¸ºï¼š
- (3x3x3ï¼ˆå†…æ ¸å¤§å°ï¼‰ + 1ï¼ˆåç½®ï¼‰) x 32ï¼ˆout_channelsï¼‰ = 896ä¸ªå¯è®­ç»ƒå‚æ•°ã€‚

è¯·æ³¨æ„ï¼Œæ¯ä¸ªä½¿ç”¨çš„å†…æ ¸æ·»åŠ äº†ä¸€ä¸ªåç½®ï¼ˆ+1ï¼‰ï¼Œå› ä¸ºæ¯ä¸ªå·ç§¯å±‚çš„åŠŸèƒ½æ˜¯å­¦ä¹ è¾“å…¥çš„çº¿æ€§å˜æ¢ï¼Œè¿™ç”±ä»¥ä¸‹æ–¹ç¨‹è¡¨ç¤ºï¼š
```plaintext
Y = f(W * X + b)
```
`W` æ˜¯æƒé‡çŸ©é˜µï¼ˆå­¦ä¹ åˆ°çš„æ»¤æ³¢å™¨ï¼Œ3x3x3 = 27 ä¸ªå‚æ•°ï¼‰ï¼Œ`b` æ˜¯åç½®å‘é‡ï¼Œå¯¹äºæ¯ä¸ªè¾“å‡ºé€šé“ä¸º +1ã€‚

è¯·æ³¨æ„ï¼Œ`self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)` çš„è¾“å‡ºå°†æ˜¯å½¢çŠ¶ä¸º `(batch_size, 32, 48, 48)` çš„å¼ é‡ï¼Œå› ä¸º 32 æ˜¯ç”Ÿæˆçš„æ–°çš„ 48x48 åƒç´ å¤§å°çš„é€šé“æ•°é‡ã€‚

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªå·ç§¯å±‚è¿æ¥åˆ°å¦ä¸€ä¸ªå·ç§¯å±‚ï¼Œå¦‚ï¼š`self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)`ã€‚

è¿™å°†å¢åŠ ï¼š(32x3x3ï¼ˆå·ç§¯æ ¸å¤§å°ï¼‰ + 1ï¼ˆåç½®ï¼‰) x 64ï¼ˆè¾“å‡ºé€šé“ï¼‰ = 18,496 ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º `(batch_size, 64, 48, 48)`ã€‚

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œ**æ¯å¢åŠ ä¸€ä¸ªå·ç§¯å±‚ï¼Œå‚æ•°çš„æ•°é‡è¿…é€Ÿå¢é•¿**ï¼Œå°¤å…¶æ˜¯å½“è¾“å‡ºé€šé“çš„æ•°é‡å¢åŠ æ—¶ã€‚

æ§åˆ¶ä½¿ç”¨æ•°æ®é‡çš„ä¸€ä¸ªé€‰é¡¹æ˜¯åœ¨æ¯ä¸ªå·ç§¯å±‚åä½¿ç”¨ **æœ€å¤§æ± åŒ–**ã€‚æœ€å¤§æ± åŒ–å‡å°‘ç‰¹å¾å›¾çš„ç©ºé—´ç»´åº¦ï¼Œè¿™æœ‰åŠ©äºå‡å°‘å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚æ€§ï¼ŒåŒæ—¶ä¿ç•™é‡è¦ç‰¹å¾ã€‚

å¯ä»¥å£°æ˜ä¸ºï¼š`self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)`ã€‚è¿™åŸºæœ¬ä¸Šè¡¨ç¤ºä½¿ç”¨ 2x2 åƒç´ çš„ç½‘æ ¼ï¼Œå¹¶ä»æ¯ä¸ªç½‘æ ¼ä¸­å–æœ€å¤§å€¼ï¼Œä»¥å°†ç‰¹å¾å›¾çš„å¤§å°å‡å°‘ä¸€åŠã€‚æ­¤å¤–ï¼Œ`stride=2` æ„å‘³ç€æ± åŒ–æ“ä½œæ¯æ¬¡ç§»åŠ¨ 2 ä¸ªåƒç´ ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé˜²æ­¢æ± åŒ–åŒºåŸŸä¹‹é—´çš„é‡å ã€‚

ä½¿ç”¨è¿™ä¸ªæ± åŒ–å±‚ï¼Œç»è¿‡ç¬¬ä¸€ä¸ªå·ç§¯å±‚åçš„è¾“å‡ºå½¢çŠ¶å°†æ˜¯ `(batch_size, 64, 24, 24)`ï¼Œåœ¨å°† `self.pool1` åº”ç”¨åˆ° `self.conv2` çš„è¾“å‡ºåï¼Œå¤§å°å‡å°‘åˆ°å‰ä¸€å±‚çš„ 1/4ã€‚

> [!TIP]
> åœ¨å·ç§¯å±‚åè¿›è¡Œæ± åŒ–æ˜¯å¾ˆé‡è¦çš„ï¼Œä»¥å‡å°‘ç‰¹å¾å›¾çš„ç©ºé—´ç»´åº¦ï¼Œè¿™æœ‰åŠ©äºæ§åˆ¶å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚æ€§ï¼ŒåŒæ—¶ä½¿åˆå§‹å‚æ•°å­¦ä¹ é‡è¦ç‰¹å¾ã€‚
> ä½ å¯ä»¥å°†æ± åŒ–å±‚å‰çš„å·ç§¯è§†ä¸ºä»è¾“å…¥æ•°æ®ä¸­æå–ç‰¹å¾ï¼ˆå¦‚çº¿æ¡ã€è¾¹ç¼˜ï¼‰ï¼Œè¿™äº›ä¿¡æ¯ä»ç„¶ä¼šå­˜åœ¨äºæ± åŒ–è¾“å‡ºä¸­ï¼Œä½†ä¸‹ä¸€ä¸ªå·ç§¯å±‚å°†æ— æ³•çœ‹åˆ°åŸå§‹è¾“å…¥æ•°æ®ï¼Œåªèƒ½çœ‹åˆ°æ± åŒ–è¾“å‡ºï¼Œè¿™æ˜¯å‰ä¸€å±‚çš„ç®€åŒ–ç‰ˆæœ¬ï¼ŒåŒ…å«äº†è¿™äº›ä¿¡æ¯ã€‚
> æŒ‰ç…§é€šå¸¸çš„é¡ºåºï¼š`Conv â†’ ReLU â†’ Pool`ï¼Œæ¯ä¸ª 2Ã—2 çš„æ± åŒ–çª—å£ç°åœ¨å¤„ç†ç‰¹å¾æ¿€æ´»ï¼ˆâ€œè¾¹ç¼˜å­˜åœ¨/ä¸å­˜åœ¨â€ï¼‰ï¼Œè€Œä¸æ˜¯åŸå§‹åƒç´ å¼ºåº¦ã€‚ä¿ç•™æœ€å¼ºçš„æ¿€æ´»ç¡®å®ä¿ç•™äº†æœ€æ˜¾è‘—çš„è¯æ®ã€‚

ç„¶åï¼Œåœ¨æ·»åŠ æ‰€éœ€çš„å·ç§¯å±‚å’Œæ± åŒ–å±‚åï¼Œæˆ‘ä»¬å¯ä»¥å°†è¾“å‡ºå±•å¹³ï¼Œä»¥ä¾¿å°†å…¶è¾“å…¥åˆ°å…¨è¿æ¥å±‚ã€‚è¿™æ˜¯é€šè¿‡å°†å¼ é‡é‡å¡‘ä¸ºæ¯ä¸ªæ‰¹æ¬¡æ ·æœ¬çš„ 1D å‘é‡æ¥å®Œæˆçš„ï¼š
```python
x = x.view(-1, 64*24*24)
```
é€šè¿‡è¿™ä¸ªåŒ…å«æ‰€æœ‰ç”±å‰é¢çš„å·ç§¯å±‚å’Œæ± åŒ–å±‚ç”Ÿæˆçš„è®­ç»ƒå‚æ•°çš„1Då‘é‡ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
```python
self.fc1 = nn.Linear(64 * 24 * 24, 512)
```
å°†å‰ä¸€å±‚çš„æ‰å¹³è¾“å‡ºæ˜ å°„åˆ°512ä¸ªéšè—å•å…ƒã€‚

æ³¨æ„ï¼Œè¿™ä¸€å±‚å¢åŠ äº†`(64 * 24 * 24 + 1 (bias)) * 512 = 3,221,504`ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œè¿™ä¸å·ç§¯å±‚ç›¸æ¯”æ˜¯ä¸€ä¸ªæ˜¾è‘—çš„å¢åŠ ã€‚è¿™æ˜¯å› ä¸ºå…¨è¿æ¥å±‚å°†ä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒä¸ä¸‹ä¸€å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒè¿æ¥ï¼Œä»è€Œå¯¼è‡´å‚æ•°æ•°é‡åºå¤§ã€‚

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªè¾“å‡ºå±‚ä»¥ç”Ÿæˆæœ€ç»ˆçš„ç±»åˆ«logitsï¼š
```python
self.fc2 = nn.Linear(512, num_classes)
```
è¿™å°†æ·»åŠ  `(512 + 1 (bias)) * num_classes` å¯è®­ç»ƒå‚æ•°ï¼Œå…¶ä¸­ `num_classes` æ˜¯åˆ†ç±»ä»»åŠ¡ä¸­çš„ç±»åˆ«æ•°é‡ï¼ˆä¾‹å¦‚ï¼Œå¯¹äº GTSRB æ•°æ®é›†ä¸º 43ï¼‰ã€‚

å¦ä¸€ä¸ªå¸¸è§åšæ³•æ˜¯åœ¨å…¨è¿æ¥å±‚ä¹‹å‰æ·»åŠ ä¸€ä¸ª dropout å±‚ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚è¿™å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®Œæˆï¼š
```python
self.dropout = nn.Dropout(0.5)
```
è¿™ä¸€å±‚åœ¨è®­ç»ƒæœŸé—´éšæœºå°†ä¸€éƒ¨åˆ†è¾“å…¥å•å…ƒè®¾ç½®ä¸ºé›¶ï¼Œè¿™æœ‰åŠ©äºé€šè¿‡å‡å°‘å¯¹ç‰¹å®šç¥ç»å…ƒçš„ä¾èµ–æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

### CNN ä»£ç ç¤ºä¾‹
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MY_NET(nn.Module):
def __init__(self, num_classes=32):
super(MY_NET, self).__init__()
# Initial conv layer: 3 input channels (RGB), 32 output channels, 3x3 kernel, padding 1
# This layer will learn basic features like edges and textures
self.conv1 = nn.Conv2d(
in_channels=3, out_channels=32, kernel_size=3, padding=1
)
# Output: (Batch Size, 32, 48, 48)

# Conv Layer 2: 32 input channels, 64 output channels, 3x3 kernel, padding 1
# This layer will learn more complex features based on the output of conv1
self.conv2 = nn.Conv2d(
in_channels=32, out_channels=64, kernel_size=3, padding=1
)
# Output: (Batch Size, 64, 48, 48)

# Max Pooling 1: Kernel 2x2, Stride 2. Reduces spatial dimensions by half (1/4th of the previous layer).
self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
# Output: (Batch Size, 64, 24, 24)

# Conv Layer 3: 64 input channels, 128 output channels, 3x3 kernel, padding 1
# This layer will learn even more complex features based on the output of conv2
# Note that the number of output channels can be adjusted based on the complexity of the task
self.conv3 = nn.Conv2d(
in_channels=64, out_channels=128, kernel_size=3, padding=1
)
# Output: (Batch Size, 128, 24, 24)

# Max Pooling 2: Kernel 2x2, Stride 2. Reduces spatial dimensions by half again.
# Reducing the dimensions further helps to control the number of parameters and computational complexity.
self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
# Output: (Batch Size, 128, 12, 12)

# From the second pooling layer, we will flatten the output to feed it into fully connected layers.
# The feature size is calculated as follows:
# Feature size = Number of output channels * Height * Width
self._feature_size = 128 * 12 * 12

# Fully Connected Layer 1 (Hidden): Maps flattened features to hidden units.
# This layer will learn to combine the features extracted by the convolutional layers.
self.fc1 = nn.Linear(self._feature_size, 512)

# Fully Connected Layer 2 (Output): Maps hidden units to class logits.
# Output size MUST match num_classes
self.fc2 = nn.Linear(512, num_classes)

# Dropout layer configuration with a dropout rate of 0.5.
# This layer is used to prevent overfitting by randomly setting a fraction of the input units to zero during training.
self.dropout = nn.Dropout(0.5)

def forward(self, x):
"""
The forward method defines the forward pass of the network.
It takes an input tensor `x` and applies the convolutional layers, pooling layers, and fully connected layers in sequence.
The input tensor `x` is expected to have the shape (Batch Size, Channels, Height, Width), where:
- Batch Size: Number of samples in the batch
- Channels: Number of input channels (e.g., 3 for RGB images)
- Height: Height of the input image (e.g., 48 for 48x48 images)
- Width: Width of the input image (e.g., 48 for 48x48 images)
The output of the forward method is the logits for each class, which can be used for classification tasks.
Args:
x (torch.Tensor): Input tensor of shape (Batch Size, Channels, Height, Width)
Returns:
torch.Tensor: Output tensor of shape (Batch Size, num_classes) containing the class logits.
"""

# Conv1 -> ReLU -> Conv2 -> ReLU -> Pool1 -> Conv3 -> ReLU -> Pool2
x = self.conv1(x)
x = F.relu(x)
x = self.conv2(x)
x = F.relu(x)
x = self.pool1(x)
x = self.conv3(x)
x = F.relu(x)
x = self.pool2(x)
# At this point, x has shape (Batch Size, 128, 12, 12)

# Flatten the output to feed it into fully connected layers
x = torch.flatten(x, 1)

# Apply dropout to prevent overfitting
x = self.dropout(x)

# First FC layer with ReLU activation
x = F.relu(self.fc1(x))

# Apply Dropout again
x = self.dropout(x)
# Final FC layer to get logits
x = self.fc2(x)
# Output shape will be (Batch Size, num_classes)
# Note that the output is not passed through a softmax activation here, as it is typically done in the loss function (e.g., CrossEntropyLoss)
return x
```
### CNN ä»£ç è®­ç»ƒç¤ºä¾‹

ä»¥ä¸‹ä»£ç å°†ç”Ÿæˆä¸€äº›è®­ç»ƒæ•°æ®å¹¶è®­ç»ƒä¸Šé¢å®šä¹‰çš„ `MY_NET` æ¨¡å‹ã€‚ä¸€äº›æœ‰è¶£çš„å€¼éœ€è¦æ³¨æ„ï¼š

- `EPOCHS` æ˜¯æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´æŸ¥çœ‹æ•´ä¸ªæ•°æ®é›†çš„æ¬¡æ•°ã€‚å¦‚æœ EPOCH å¤ªå°ï¼Œæ¨¡å‹å¯èƒ½å­¦å¾—ä¸å¤Ÿï¼›å¦‚æœå¤ªå¤§ï¼Œå¯èƒ½ä¼šè¿‡æ‹Ÿåˆã€‚
- `LEARNING_RATE` æ˜¯ä¼˜åŒ–å™¨çš„æ­¥é•¿ã€‚è¾ƒå°çš„å­¦ä¹ ç‡å¯èƒ½å¯¼è‡´æ”¶æ•›ç¼“æ…¢ï¼Œè€Œè¾ƒå¤§çš„å­¦ä¹ ç‡å¯èƒ½ä¼šè¶…å‡ºæœ€ä½³è§£å¹¶é˜»æ­¢æ”¶æ•›ã€‚
- `WEIGHT_DECAY` æ˜¯ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œé€šè¿‡æƒ©ç½šå¤§æƒé‡æ¥å¸®åŠ©é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

å…³äºè®­ç»ƒå¾ªç¯ï¼Œè¿™é‡Œæœ‰ä¸€äº›æœ‰è¶£çš„ä¿¡æ¯éœ€è¦äº†è§£ï¼š
- `criterion = nn.CrossEntropyLoss()` æ˜¯ç”¨äºå¤šç±»åˆ†ç±»ä»»åŠ¡çš„æŸå¤±å‡½æ•°ã€‚å®ƒå°† softmax æ¿€æ´»å’Œäº¤å‰ç†µæŸå¤±ç»“åˆåœ¨ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œä½¿å…¶é€‚åˆè®­ç»ƒè¾“å‡ºç±» logits çš„æ¨¡å‹ã€‚
- å¦‚æœæ¨¡å‹é¢„æœŸè¾“å‡ºå…¶ä»–ç±»å‹çš„è¾“å‡ºï¼Œå¦‚äºŒå…ƒåˆ†ç±»æˆ–å›å½’ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸åŒçš„æŸå¤±å‡½æ•°ï¼Œå¦‚ `nn.BCEWithLogitsLoss()` ç”¨äºäºŒå…ƒåˆ†ç±»æˆ– `nn.MSELoss()` ç”¨äºå›å½’ã€‚
- `optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)` åˆå§‹åŒ–äº† Adam ä¼˜åŒ–å™¨ï¼Œè¿™æ˜¯è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„çƒ­é—¨é€‰æ‹©ã€‚å®ƒæ ¹æ®æ¢¯åº¦çš„ä¸€é˜¶å’ŒäºŒé˜¶çŸ©è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚
- å…¶ä»–ä¼˜åŒ–å™¨å¦‚ `optim.SGD`ï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰æˆ– `optim.RMSprop` ä¹Ÿå¯ä»¥ä½¿ç”¨ï¼Œå…·ä½“å–å†³äºè®­ç»ƒä»»åŠ¡çš„ç‰¹å®šè¦æ±‚ã€‚
- `model.train()` æ–¹æ³•å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œä½¿å¾—åƒ dropout å’Œæ‰¹é‡å½’ä¸€åŒ–è¿™æ ·çš„å±‚åœ¨è®­ç»ƒæœŸé—´ä¸è¯„ä¼°æœŸé—´çš„è¡Œä¸ºä¸åŒã€‚
- `optimizer.zero_grad()` åœ¨åå‘ä¼ æ’­ä¹‹å‰æ¸…é™¤æ‰€æœ‰ä¼˜åŒ–å¼ é‡çš„æ¢¯åº¦ï¼Œè¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºåœ¨ PyTorch ä¸­ï¼Œæ¢¯åº¦é»˜è®¤æ˜¯ç´¯ç§¯çš„ã€‚å¦‚æœä¸æ¸…é™¤ï¼Œå‰å‡ æ¬¡è¿­ä»£çš„æ¢¯åº¦å°†è¢«æ·»åŠ åˆ°å½“å‰æ¢¯åº¦ä¸­ï¼Œå¯¼è‡´æ›´æ–°ä¸æ­£ç¡®ã€‚
- `loss.backward()` è®¡ç®—æŸå¤±ç›¸å¯¹äºæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼Œç„¶åä¼˜åŒ–å™¨ä½¿ç”¨è¿™äº›æ¢¯åº¦æ¥æ›´æ–°æƒé‡ã€‚
- `optimizer.step()` æ ¹æ®è®¡ç®—å‡ºçš„æ¢¯åº¦å’Œå­¦ä¹ ç‡æ›´æ–°æ¨¡å‹å‚æ•°ã€‚
```python
import torch, torch.nn.functional as F
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# ---------------------------------------------------------------------------
# 1. Globals
# ---------------------------------------------------------------------------
IMG_SIZE      = 48               # model expects 48Ã—48
NUM_CLASSES   = 10               # MNIST has 10 digits
BATCH_SIZE    = 64               # batch size for training and validation
EPOCHS        = 5                # number of training epochs
LEARNING_RATE = 1e-3             # initial learning rate for Adam optimiser
WEIGHT_DECAY  = 1e-4             # L2 regularisation to prevent overfitting

# Channel-wise mean / std for MNIST (grayscale â‡’ repeat for 3-channel input)
MNIST_MEAN = (0.1307, 0.1307, 0.1307)
MNIST_STD  = (0.3081, 0.3081, 0.3081)

# ---------------------------------------------------------------------------
# 2. Transforms
# ---------------------------------------------------------------------------
# 1) Baseline transform: resize + tensor (no colour/aug/no normalise)
transform_base = transforms.Compose([
transforms.Resize((IMG_SIZE, IMG_SIZE)),      # ğŸ”¹ Resize â€“ force all images to 48 Ã— 48 so the CNN sees a fixed geometry
transforms.Grayscale(num_output_channels=3),  # ğŸ”¹ Grayscaleâ†’RGB â€“ MNIST is 1-channel; duplicate into 3 channels for convnet
transforms.ToTensor(),                        # ğŸ”¹ ToTensor â€“ convert PIL image [0â€’255] â†’ float tensor [0.0â€’1.0]
])

# 2) Training transform: augment  + normalise
transform_norm = transforms.Compose([
transforms.Resize((IMG_SIZE, IMG_SIZE)),      # keep 48 Ã— 48 input size
transforms.Grayscale(num_output_channels=3),  # still need 3 channels
transforms.RandomRotation(10),                # ğŸ”¹ RandomRotation(Â±10Â°) â€“ small tilt â‡¢ rotation-invariance, combats overfitting
transforms.ColorJitter(brightness=0.2,
contrast=0.2),         # ğŸ”¹ ColorJitter â€“ pseudo-RGB brightness/contrast noise; extra variety
transforms.ToTensor(),                        # convert to tensor before numeric ops
transforms.Normalize(mean=MNIST_MEAN,
std=MNIST_STD),          # ğŸ”¹ Normalize â€“ zero-centre & scale so every channel â‰ˆ N(0,1)
])

# 3) Test/validation transform: only resize + normalise (no aug)
transform_test = transforms.Compose([
transforms.Resize((IMG_SIZE, IMG_SIZE)),      # same spatial size as train
transforms.Grayscale(num_output_channels=3),  # match channel count
transforms.ToTensor(),                        # tensor conversion
transforms.Normalize(mean=MNIST_MEAN,
std=MNIST_STD),          # ğŸ”¹ keep test data on same scale as training data
])

# ---------------------------------------------------------------------------
# 3. Datasets & loaders
# ---------------------------------------------------------------------------
train_set = datasets.MNIST("data",   train=True,  download=True, transform=transform_norm)
test_set  = datasets.MNIST("data",   train=False, download=True, transform=transform_test)

train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
test_loader  = DataLoader(test_set,  batch_size=256,          shuffle=False)

print(f"Training on {len(train_set)} samples, validating on {len(test_set)} samples.")

# ---------------------------------------------------------------------------
# 4. Model / loss / optimiser
# ---------------------------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model  = MY_NET(num_classes=NUM_CLASSES).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

# ---------------------------------------------------------------------------
# 5. Training loop
# ---------------------------------------------------------------------------
for epoch in range(1, EPOCHS + 1):
model.train()                          # Set model to training mode enabling dropout and batch norm

running_loss = 0.0                     # sums batch losses to compute epoch average
correct      = 0                       # number of correct predictions
total        = 0                       # number of samples seen

# tqdm wraps the loader to show a live progress-bar per epoch
for X_batch, y_batch in tqdm(train_loader, desc=f"Epoch {epoch}", leave=False):
# 3-a) Move data to GPU (if available) ----------------------------------
X_batch, y_batch = X_batch.to(device), y_batch.to(device)

# 3-b) Forward pass -----------------------------------------------------
logits = model(X_batch)            # raw class scores (shape: [B, NUM_CLASSES])
loss   = criterion(logits, y_batch)

# 3-c) Backward pass & parameter update --------------------------------
optimizer.zero_grad()              # clear old gradients
loss.backward()                    # compute new gradients
optimizer.step()                   # gradient â†’ weight update

# 3-d) Statistics -------------------------------------------------------
running_loss += loss.item() * X_batch.size(0)     # sum of (batch loss Ã— batch size)
preds   = logits.argmax(dim=1)                    # predicted class labels
correct += (preds == y_batch).sum().item()        # correct predictions in this batch
total   += y_batch.size(0)                        # samples processed so far

# 3-e) Epoch-level metrics --------------------------------------------------
epoch_loss = running_loss / total
epoch_acc  = 100.0 * correct / total
print(f"[Epoch {epoch}] loss = {epoch_loss:.4f} | accuracy = {epoch_acc:.2f}%")

print("\nâœ… Training finished.\n")

# ---------------------------------------------------------------------------
# 6. Evaluation on test set
# ---------------------------------------------------------------------------
model.eval() # Set model to evaluation mode (disables dropout and batch norm)
with torch.no_grad():
logits_all, labels_all = [], []
for X, y in test_loader:
logits_all.append(model(X.to(device)).cpu())
labels_all.append(y)
logits_all = torch.cat(logits_all)
labels_all = torch.cat(labels_all)
preds_all  = logits_all.argmax(1)

test_loss = criterion(logits_all, labels_all).item()
test_acc  = (preds_all == labels_all).float().mean().item() * 100

print(f"Test loss: {test_loss:.4f}")
print(f"Test accuracy: {test_acc:.2f}%\n")

print("Classification report (precision / recall / F1):")
print(classification_report(labels_all, preds_all, zero_division=0))

print("Confusion matrix (rows = true, cols = pred):")
print(confusion_matrix(labels_all, preds_all))
```
## å¾ªç¯ç¥ç»ç½‘ç»œ (RNNs)

å¾ªç¯ç¥ç»ç½‘ç»œ (RNNs) æ˜¯ä¸€ç§ä¸“ä¸ºå¤„ç†åºåˆ—æ•°æ®ï¼ˆå¦‚æ—¶é—´åºåˆ—æˆ–è‡ªç„¶è¯­è¨€ï¼‰è€Œè®¾è®¡çš„ç¥ç»ç½‘ç»œç±»åˆ«ã€‚ä¸ä¼ ç»Ÿçš„å‰é¦ˆç¥ç»ç½‘ç»œä¸åŒï¼ŒRNNs å…·æœ‰è‡ªæˆ‘å›ç¯çš„è¿æ¥ï¼Œä½¿å…¶èƒ½å¤Ÿä¿æŒä¸€ä¸ªéšè—çŠ¶æ€ï¼Œè¯¥çŠ¶æ€æ•æ‰åºåˆ—ä¸­å…ˆå‰è¾“å…¥çš„ä¿¡æ¯ã€‚

RNNs çš„ä¸»è¦ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š
- **å¾ªç¯å±‚**ï¼šè¿™äº›å±‚ä¸€æ¬¡å¤„ç†ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥åºåˆ—ï¼Œæ ¹æ®å½“å‰è¾“å…¥å’Œå…ˆå‰çš„éšè—çŠ¶æ€æ›´æ–°å…¶éšè—çŠ¶æ€ã€‚è¿™ä½¿å¾— RNNs èƒ½å¤Ÿå­¦ä¹ æ•°æ®ä¸­çš„æ—¶é—´ä¾èµ–æ€§ã€‚
- **éšè—çŠ¶æ€**ï¼šéšè—çŠ¶æ€æ˜¯ä¸€ä¸ªå‘é‡ï¼Œæ±‡æ€»äº†å…ˆå‰æ—¶é—´æ­¥çš„ä¿¡æ¯ã€‚å®ƒåœ¨æ¯ä¸ªæ—¶é—´æ­¥æ›´æ–°ï¼Œå¹¶ç”¨äºå¯¹å½“å‰è¾“å…¥è¿›è¡Œé¢„æµ‹ã€‚
- **è¾“å‡ºå±‚**ï¼šè¾“å‡ºå±‚æ ¹æ®éšè—çŠ¶æ€ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼ŒRNNs ç”¨äºè¯­è¨€å»ºæ¨¡ç­‰ä»»åŠ¡ï¼Œå…¶ä¸­è¾“å‡ºæ˜¯åºåˆ—ä¸­ä¸‹ä¸€ä¸ªå•è¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚

ä¾‹å¦‚ï¼Œåœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼ŒRNN å¤„ç†ä¸€ä¸ªå•è¯åºåˆ—ï¼Œä¾‹å¦‚ "The cat sat on the"ï¼Œå¹¶æ ¹æ®å‰é¢å•è¯æä¾›çš„ä¸Šä¸‹æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ "mat"ã€‚

### é•¿çŸ­æœŸè®°å¿† (LSTM) å’Œé—¨æ§å¾ªç¯å•å…ƒ (GRU)

RNNs åœ¨å¤„ç†æ¶‰åŠåºåˆ—æ•°æ®çš„ä»»åŠ¡ï¼ˆå¦‚è¯­è¨€å»ºæ¨¡ã€æœºå™¨ç¿»è¯‘å’Œè¯­éŸ³è¯†åˆ«ï¼‰æ—¶ç‰¹åˆ«æœ‰æ•ˆã€‚ç„¶è€Œï¼Œç”±äº **æ¢¯åº¦æ¶ˆå¤±ç­‰é—®é¢˜ï¼Œå®ƒä»¬åœ¨å¤„ç†é•¿èŒƒå›´ä¾èµ–æ€§æ—¶å¯èƒ½ä¼šé‡åˆ°å›°éš¾**ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¼€å‘äº†é•¿çŸ­æœŸè®°å¿† (LSTM) å’Œé—¨æ§å¾ªç¯å•å…ƒ (GRU) ç­‰ä¸“é—¨æ¶æ„ã€‚è¿™äº›æ¶æ„å¼•å…¥äº†æ§åˆ¶ä¿¡æ¯æµåŠ¨çš„é—¨æ§æœºåˆ¶ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰é•¿èŒƒå›´ä¾èµ–æ€§ã€‚

- **LSTM**ï¼šLSTM ç½‘ç»œä½¿ç”¨ä¸‰ä¸ªé—¨ï¼ˆè¾“å…¥é—¨ã€é—å¿˜é—¨å’Œè¾“å‡ºé—¨ï¼‰æ¥è°ƒèŠ‚ä¿¡æ¯åœ¨å•å…ƒçŠ¶æ€ä¸­çš„æµåŠ¨ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨é•¿åºåˆ—ä¸­è®°ä½æˆ–é—å¿˜ä¿¡æ¯ã€‚è¾“å…¥é—¨æ ¹æ®è¾“å…¥å’Œå…ˆå‰çš„éšè—çŠ¶æ€æ§åˆ¶æ·»åŠ å¤šå°‘æ–°ä¿¡æ¯ï¼Œé—å¿˜é—¨æ§åˆ¶ä¸¢å¼ƒå¤šå°‘ä¿¡æ¯ã€‚ç»“åˆè¾“å…¥é—¨å’Œé—å¿˜é—¨ï¼Œæˆ‘ä»¬å¾—åˆ°æ–°çš„çŠ¶æ€ã€‚æœ€åï¼Œå°†æ–°çš„å•å…ƒçŠ¶æ€ä¸è¾“å…¥å’Œå…ˆå‰çš„éšè—çŠ¶æ€ç»“åˆï¼Œæˆ‘ä»¬ä¹Ÿå¾—åˆ°æ–°çš„éšè—çŠ¶æ€ã€‚
- **GRU**ï¼šGRU ç½‘ç»œé€šè¿‡å°†è¾“å…¥é—¨å’Œé—å¿˜é—¨åˆå¹¶ä¸ºä¸€ä¸ªæ›´æ–°é—¨æ¥ç®€åŒ– LSTM æ¶æ„ï¼Œä½¿å…¶åœ¨è®¡ç®—ä¸Šæ›´é«˜æ•ˆï¼ŒåŒæ—¶ä»èƒ½æ•æ‰é•¿èŒƒå›´ä¾èµ–æ€§ã€‚

## LLMs (å¤§å‹è¯­è¨€æ¨¡å‹)

å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ˜¯ä¸€ç§ä¸“é—¨ä¸ºè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡è®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚å®ƒä»¬åœ¨å¤§é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆç±»äººæ–‡æœ¬ã€å›ç­”é—®é¢˜ã€ç¿»è¯‘è¯­è¨€ä»¥åŠæ‰§è¡Œå„ç§å…¶ä»–ä¸è¯­è¨€ç›¸å…³çš„ä»»åŠ¡ã€‚
LLMs é€šå¸¸åŸºäºå˜æ¢å™¨æ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰åºåˆ—ä¸­å•è¯ä¹‹é—´çš„å…³ç³»ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆè¿è´¯çš„æ–‡æœ¬ã€‚

### å˜æ¢å™¨æ¶æ„
å˜æ¢å™¨æ¶æ„æ˜¯è®¸å¤š LLMs çš„åŸºç¡€ã€‚å®ƒç”±ç¼–ç å™¨-è§£ç å™¨ç»“æ„ç»„æˆï¼Œå…¶ä¸­ç¼–ç å™¨å¤„ç†è¾“å…¥åºåˆ—ï¼Œè§£ç å™¨ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚å˜æ¢å™¨æ¶æ„çš„å…³é”®ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š
- **è‡ªæ³¨æ„åŠ›æœºåˆ¶**ï¼šè¯¥æœºåˆ¶å…è®¸æ¨¡å‹åœ¨ç”Ÿæˆè¡¨ç¤ºæ—¶æƒè¡¡åºåˆ—ä¸­ä¸åŒå•è¯çš„é‡è¦æ€§ã€‚å®ƒæ ¹æ®å•è¯ä¹‹é—´çš„å…³ç³»è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå…³æ³¨ç›¸å…³ä¸Šä¸‹æ–‡ã€‚
- **å¤šå¤´æ³¨æ„åŠ›**ï¼šè¯¥ç»„ä»¶å…è®¸æ¨¡å‹é€šè¿‡ä½¿ç”¨å¤šä¸ªæ³¨æ„åŠ›å¤´æ¥æ•æ‰å•è¯ä¹‹é—´çš„å¤šç§å…³ç³»ï¼Œæ¯ä¸ªå¤´å…³æ³¨è¾“å…¥çš„ä¸åŒæ–¹é¢ã€‚
- **ä½ç½®ç¼–ç **ï¼šç”±äºå˜æ¢å™¨æ²¡æœ‰å†…ç½®çš„å•è¯é¡ºåºæ¦‚å¿µï¼Œå› æ­¤åœ¨è¾“å…¥åµŒå…¥ä¸­æ·»åŠ ä½ç½®ç¼–ç ï¼Œä»¥æä¾›æœ‰å…³åºåˆ—ä¸­å•è¯ä½ç½®çš„ä¿¡æ¯ã€‚

## æ‰©æ•£æ¨¡å‹
æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç±»ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡æ¨¡æ‹Ÿæ‰©æ•£è¿‡ç¨‹æ¥å­¦ä¹ ç”Ÿæˆæ•°æ®ã€‚å®ƒä»¬åœ¨å›¾åƒç”Ÿæˆç­‰ä»»åŠ¡ä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œå¹¶åœ¨è¿‘å¹´æ¥è·å¾—äº†å¹¿æ³›å…³æ³¨ã€‚
æ‰©æ•£æ¨¡å‹é€šè¿‡é€æ¸å°†ç®€å•çš„å™ªå£°åˆ†å¸ƒè½¬å˜ä¸ºå¤æ‚çš„æ•°æ®åˆ†å¸ƒï¼Œç»è¿‡ä¸€ç³»åˆ—æ‰©æ•£æ­¥éª¤ã€‚æ‰©æ•£æ¨¡å‹çš„å…³é”®ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š
- **å‰å‘æ‰©æ•£è¿‡ç¨‹**ï¼šè¯¥è¿‡ç¨‹é€æ¸å‘æ•°æ®æ·»åŠ å™ªå£°ï¼Œå°†å…¶è½¬å˜ä¸ºç®€å•çš„å™ªå£°åˆ†å¸ƒã€‚å‰å‘æ‰©æ•£è¿‡ç¨‹é€šå¸¸ç”±ä¸€ç³»åˆ—å™ªå£°æ°´å¹³å®šä¹‰ï¼Œæ¯ä¸ªæ°´å¹³å¯¹åº”äºæ·»åŠ åˆ°æ•°æ®ä¸­çš„ç‰¹å®šå™ªå£°é‡ã€‚
- **åå‘æ‰©æ•£è¿‡ç¨‹**ï¼šè¯¥è¿‡ç¨‹å­¦ä¹ åè½¬å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼Œé€æ¸å»å™ªæ•°æ®ä»¥ä»ç›®æ ‡åˆ†å¸ƒç”Ÿæˆæ ·æœ¬ã€‚åå‘æ‰©æ•£è¿‡ç¨‹ä½¿ç”¨æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒï¼Œè¯¥å‡½æ•°é¼“åŠ±æ¨¡å‹ä»å™ªå£°æ ·æœ¬ä¸­é‡å»ºåŸå§‹æ•°æ®ã€‚

æ­¤å¤–ï¼Œä¸ºäº†ä»æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒï¼Œæ‰©æ•£æ¨¡å‹é€šå¸¸éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š
1. **æ–‡æœ¬ç¼–ç **ï¼šä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨ï¼ˆä¾‹å¦‚åŸºäºå˜æ¢å™¨çš„æ¨¡å‹ï¼‰å°†æ–‡æœ¬æç¤ºç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚è¯¥è¡¨ç¤ºæ•æ‰æ–‡æœ¬çš„è¯­ä¹‰å«ä¹‰ã€‚
2. **å™ªå£°é‡‡æ ·**ï¼šä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªéšæœºå™ªå£°å‘é‡ã€‚
3. **æ‰©æ•£æ­¥éª¤**ï¼šæ¨¡å‹åº”ç”¨ä¸€ç³»åˆ—æ‰©æ•£æ­¥éª¤ï¼Œé€æ¸å°†å™ªå£°å‘é‡è½¬å˜ä¸ºä¸æ–‡æœ¬æç¤ºå¯¹åº”çš„å›¾åƒã€‚æ¯ä¸€æ­¥æ¶‰åŠåº”ç”¨å­¦ä¹ åˆ°çš„å˜æ¢ä»¥å»å™ªå›¾åƒã€‚

{{#include ../banners/hacktricks-training.md}}
