# Προετοιμασία & Αξιολόγηση Δεδομένων Μοντέλου

{{#include ../banners/hacktricks-training.md}}

Η προετοιμασία δεδομένων μοντέλου είναι ένα κρίσιμο βήμα στη διαδικασία μηχανικής μάθησης, καθώς περιλαμβάνει τη μετατροπή των ακατέργαστων δεδομένων σε μια μορφή κατάλληλη για την εκπαίδευση μοντέλων μηχανικής μάθησης. Αυτή η διαδικασία περιλαμβάνει αρκετά βασικά βήματα:

1. **Συλλογή Δεδομένων**: Συγκέντρωση δεδομένων από διάφορες πηγές, όπως βάσεις δεδομένων, APIs ή αρχεία. Τα δεδομένα μπορεί να είναι δομημένα (π.χ. πίνακες) ή αδόμητα (π.χ. κείμενα, εικόνες).
2. **Καθαρισμός Δεδομένων**: Αφαίρεση ή διόρθωση εσφαλμένων, ελλιπών ή μη σχετικών σημείων δεδομένων. Αυτό το βήμα μπορεί να περιλαμβάνει την αντιμετώπιση ελλειπόντων τιμών, την αφαίρεση διπλότυπων και την φιλτράρισμα εξαιρετικών τιμών.
3. **Μετασχηματισμός Δεδομένων**: Μετατροπή των δεδομένων σε κατάλληλη μορφή για μοντελοποίηση. Αυτό μπορεί να περιλαμβάνει κανονικοποίηση, κλιμάκωση, κωδικοποίηση κατηγορικών μεταβλητών και δημιουργία νέων χαρακτηριστικών μέσω τεχνικών όπως η μηχανική χαρακτηριστικών.
4. **Διαχωρισμός Δεδομένων**: Διαίρεση του συνόλου δεδομένων σε σύνολα εκπαίδευσης, επικύρωσης και δοκιμής για να διασφαλιστεί ότι το μοντέλο μπορεί να γενικεύσει καλά σε αόρατα δεδομένα.

## Συλλογή Δεδομένων

Η συλλογή δεδομένων περιλαμβάνει τη συγκέντρωση δεδομένων από διάφορες πηγές, οι οποίες μπορεί να περιλαμβάνουν:
- **Βάσεις Δεδομένων**: Εξαγωγή δεδομένων από σχεσιακές βάσεις δεδομένων (π.χ. SQL βάσεις δεδομένων) ή NoSQL βάσεις δεδομένων (π.χ. MongoDB).
- **APIs**: Ανάκτηση δεδομένων από διαδικτυακά APIs, τα οποία μπορούν να παρέχουν δεδομένα σε πραγματικό χρόνο ή ιστορικά δεδομένα.
- **Αρχεία**: Ανάγνωση δεδομένων από αρχεία σε μορφές όπως CSV, JSON ή XML.
- **Web Scraping**: Συλλογή δεδομένων από ιστοσελίδες χρησιμοποιώντας τεχνικές web scraping.

Ανάλογα με τον στόχο του έργου μηχανικής μάθησης, τα δεδομένα θα εξάγονται και θα συλλέγονται από σχετικές πηγές για να διασφαλιστεί ότι είναι αντιπροσωπευτικά του τομέα του προβλήματος.

## Καθαρισμός Δεδομένων

Ο καθαρισμός δεδομένων είναι η διαδικασία αναγνώρισης και διόρθωσης σφαλμάτων ή ασυνεπειών στο σύνολο δεδομένων. Αυτό το βήμα είναι απαραίτητο για να διασφαλιστεί η ποιότητα των δεδομένων που χρησιμοποιούνται για την εκπαίδευση μοντέλων μηχανικής μάθησης. Βασικές εργασίες στον καθαρισμό δεδομένων περιλαμβάνουν:
- **Διαχείριση Ελλειπόντων Τιμών**: Αναγνώριση και αντιμετώπιση ελλειπόντων σημείων δεδομένων. Κοινές στρατηγικές περιλαμβάνουν:
- Αφαίρεση γραμμών ή στηλών με ελλείπουσες τιμές.
- Συμπλήρωση ελλειπόντων τιμών χρησιμοποιώντας τεχνικές όπως η μέση, η διάμεσος ή η πιο συχνή τιμή.
- Χρήση προηγμένων μεθόδων όπως η συμπλήρωση K-πλησιέστερων γειτόνων (KNN) ή η συμπλήρωση μέσω παλινδρόμησης.
- **Αφαίρεση Διπλότυπων**: Αναγνώριση και αφαίρεση διπλότυπων εγγραφών για να διασφαλιστεί ότι κάθε σημείο δεδομένων είναι μοναδικό.
- **Φιλτράρισμα Εξαιρετικών Τιμών**: Ανίχνευση και αφαίρεση εξαιρετικών τιμών που μπορεί να παραμορφώσουν την απόδοση του μοντέλου. Τεχνικές όπως το Z-score, το IQR (Διακυμάνσεις Διαμερισμάτων) ή οπτικοποιήσεις (π.χ. διαγράμματα κουτιών) μπορούν να χρησιμοποιηθούν για την αναγνώριση εξαιρετικών τιμών.

### Παράδειγμα καθαρισμού δεδομένων
```python
import pandas as pd
# Load the dataset
data = pd.read_csv('data.csv')

# Finding invalid values based on a specific function
def is_valid_possitive_int(num):
try:
num = int(num)
return 1 <= num <= 31
except ValueError:
return False

invalid_days = data[~data['days'].astype(str).apply(is_valid_positive_int)]

## Dropping rows with invalid days
data = data.drop(invalid_days.index, errors='ignore')



# Set "NaN" values to a specific value
## For example, setting NaN values in the 'days' column to 0
data['days'] = pd.to_numeric(data['days'], errors='coerce')

## For example, set "NaN" to not ips
def is_valid_ip(ip):
pattern = re.compile(r'^((25[0-5]|2[0-4][0-9]|[01]?\d?\d)\.){3}(25[0-5]|2[0-4]\d|[01]?\d?\d)$')
if pd.isna(ip) or not pattern.match(str(ip)):
return np.nan
return ip
df['ip'] = df['ip'].apply(is_valid_ip)

# Filling missing values based on different strategies
numeric_cols = ["days", "hours", "minutes"]
categorical_cols = ["ip", "status"]

## Filling missing values in numeric columns with the median
num_imputer = SimpleImputer(strategy='median')
df[numeric_cols] = num_imputer.fit_transform(df[numeric_cols])

## Filling missing values in categorical columns with the most frequent value
cat_imputer = SimpleImputer(strategy='most_frequent')
df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])

## Filling missing values in numeric columns using KNN imputation
knn_imputer = KNNImputer(n_neighbors=5)
df[numeric_cols] = knn_imputer.fit_transform(df[numeric_cols])



# Filling missing values
data.fillna(data.mean(), inplace=True)

# Removing duplicates
data.drop_duplicates(inplace=True)
# Filtering outliers using Z-score
from scipy import stats
z_scores = stats.zscore(data.select_dtypes(include=['float64', 'int64']))
data = data[(z_scores < 3).all(axis=1)]
```
## Μετασχηματισμός Δεδομένων

Ο μετασχηματισμός δεδομένων περιλαμβάνει τη μετατροπή των δεδομένων σε μια μορφή κατάλληλη για μοντελοποίηση. Αυτό το βήμα μπορεί να περιλαμβάνει:
- **Κανονικοποίηση & Τυποποίηση**: Κλιμάκωση αριθμητικών χαρακτηριστικών σε μια κοινή κλίμακα, συνήθως [0, 1] ή [-1, 1]. Αυτό βοηθά στη βελτίωση της σύγκλισης των αλγορίθμων βελτιστοποίησης.
- **Κλιμάκωση Min-Max**: Επανακλιμάκωση χαρακτηριστικών σε μια σταθερή κλίμακα, συνήθως [0, 1]. Αυτό γίνεται χρησιμοποιώντας τον τύπο: `X' = (X - X_{min}) / (X_{max} - X_{min})`
- **Κανονικοποίηση Z-Score**: Τυποποίηση χαρακτηριστικών αφαιρώντας τον μέσο όρο και διαιρώντας με την τυπική απόκλιση, με αποτέλεσμα μια κατανομή με μέσο όρο 0 και τυπική απόκλιση 1. Αυτό γίνεται χρησιμοποιώντας τον τύπο: `X' = (X - μ) / σ`, όπου μ είναι ο μέσος όρος και σ είναι η τυπική απόκλιση.
- **Σκοewness και Kurtosis**: Ρύθμιση της κατανομής των χαρακτηριστικών για τη μείωση της ασυμμετρίας (skewness) και της κορυφής (kurtosis). Αυτό μπορεί να γίνει χρησιμοποιώντας μετασχηματισμούς όπως λογαριθμικούς, τετραγωνικούς ή μετασχηματισμούς Box-Cox. Για παράδειγμα, αν ένα χαρακτηριστικό έχει μια skewed κατανομή, η εφαρμογή ενός λογαριθμικού μετασχηματισμού μπορεί να βοηθήσει στην κανονικοποίησή του.
- **Κανονικοποίηση Συμβολοσειρών**: Μετατροπή συμβολοσειρών σε μια συνεπή μορφή, όπως:
- Χαμηλά γράμματα
- Αφαίρεση ειδικών χαρακτήρων (διατηρώντας τους σχετικούς)
- Αφαίρεση stop words (κοινές λέξεις που δεν συμβάλλουν στη σημασία, όπως "το", "είναι", "και")
- Αφαίρεση πολύ συχνών και πολύ σπάνιων λέξεων (π.χ., λέξεις που εμφανίζονται σε περισσότερα από 90% των εγγράφων ή λιγότερο από 5 φορές στο σύνολο)
- Αφαίρεση κενών
- Stemming/Lemmatization: Μείωση λέξεων στη βασική ή ριζική τους μορφή (π.χ., "τρέχοντας" σε "τρέξιμο").

- **Κωδικοποίηση Κατηγορικών Μεταβλητών**: Μετατροπή κατηγορικών μεταβλητών σε αριθμητικές αναπαραστάσεις. Κοινές τεχνικές περιλαμβάνουν:
- **One-Hot Encoding**: Δημιουργία δυαδικών στηλών για κάθε κατηγορία.
- Για παράδειγμα, αν ένα χαρακτηριστικό έχει κατηγορίες "κόκκινο", "πράσινο" και "μπλε", θα μετατραπεί σε τρεις δυαδικές στήλες: `is_red`(100), `is_green`(010), και `is_blue`(001).
- **Label Encoding**: Ανάθεση μιας μοναδικής ακέραιας σε κάθε κατηγορία.
- Για παράδειγμα, "κόκκινο" = 0, "πράσινο" = 1, "μπλε" = 2.
- **Ordinal Encoding**: Ανάθεση ακεραίων με βάση τη σειρά των κατηγοριών.
- Για παράδειγμα, αν οι κατηγορίες είναι "χαμηλό", "μεσαίο" και "υψηλό", μπορούν να κωδικοποιηθούν ως 0, 1 και 2, αντίστοιχα.
- **Hashing Encoding**: Χρήση μιας συνάρτησης κατακερματισμού για τη μετατροπή κατηγοριών σε σταθερού μεγέθους διανύσματα, που μπορεί να είναι χρήσιμη για κατηγορίες υψηλής διακριτικότητας.
- Για παράδειγμα, αν ένα χαρακτηριστικό έχει πολλές μοναδικές κατηγορίες, η κατακερμάτωση μπορεί να μειώσει τη διαστατικότητα διατηρώντας κάποιες πληροφορίες σχετικά με τις κατηγορίες.
- **Bag of Words (BoW)**: Αναπαράσταση δεδομένων κειμένου ως μήτρα μετρήσεων ή συχνοτήτων λέξεων, όπου κάθε γραμμή αντιστοιχεί σε ένα έγγραφο και κάθε στήλη σε μια μοναδική λέξη στο σύνολο.
- Για παράδειγμα, αν το σύνολο περιέχει τις λέξεις "γάτα", "σκύλος" και "ψάρι", ένα έγγραφο που περιέχει "γάτα" και "σκύλο" θα αναπαρίσταται ως [1, 1, 0]. Αυτή η συγκεκριμένη αναπαράσταση ονομάζεται "unigram" και δεν καταγράφει τη σειρά των λέξεων, οπότε χάνει πληροφορίες σημασίας.
- **Bigram/Trigram**: Επέκταση του BoW για την καταγραφή ακολουθιών λέξεων (bigrams ή trigrams) για τη διατήρηση κάποιου πλαισίου. Για παράδειγμα, "γάτα και σκύλος" θα αναπαρίσταται ως bigram [1, 1] για "γάτα και" και [1, 1] για "και σκύλος". Σε αυτές τις περιπτώσεις συγκεντρώνεται περισσότερη πληροφορία σημασίας (αυξάνοντας τη διαστατικότητα της αναπαράστασης) αλλά μόνο για 2 ή 3 λέξεις ταυτόχρονα.
- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Ένα στατιστικό μέτρο που αξιολογεί τη σημασία μιας λέξης σε ένα έγγραφο σε σχέση με μια συλλογή εγγράφων (σύνολο). Συνδυάζει τη συχνότητα όρου (πόσο συχνά εμφανίζεται μια λέξη σε ένα έγγραφο) και τη σπανιότητα του εγγράφου (πόσο σπάνια είναι μια λέξη σε όλα τα έγγραφα).
- Για παράδειγμα, αν η λέξη "γάτα" εμφανίζεται συχνά σε ένα έγγραφο αλλά είναι σπάνια σε ολόκληρο το σύνολο, θα έχει υψηλή βαθμολογία TF-IDF, υποδεικνύοντας τη σημασία της σε αυτό το έγγραφο.

- **Μηχανική Χαρακτηριστικών**: Δημιουργία νέων χαρακτηριστικών από υπάρχοντα για την ενίσχυση της προβλεπτικής ικανότητας του μοντέλου. Αυτό μπορεί να περιλαμβάνει τη συνδυαστική χαρακτηριστικών, την εξαγωγή στοιχείων ημερομηνίας/ώρας ή την εφαρμογή μετασχηματισμών ειδικών για το πεδίο.

## Διαχωρισμός Δεδομένων

Ο διαχωρισμός δεδομένων περιλαμβάνει τη διαίρεση του συνόλου δεδομένων σε ξεχωριστά υποσύνολα για εκπαίδευση, επικύρωση και δοκιμή. Αυτό είναι απαραίτητο για την αξιολόγηση της απόδοσης του μοντέλου σε αόρατα δεδομένα και την αποφυγή υπερβολικής προσαρμογής. Κοινές στρατηγικές περιλαμβάνουν:
- **Διαχωρισμός Εκπαίδευσης-Δοκιμής**: Διαίρεση του συνόλου δεδομένων σε ένα σύνολο εκπαίδευσης (συνήθως 60-80% των δεδομένων), ένα σύνολο επικύρωσης (10-15% των δεδομένων) για τη ρύθμιση υπερπαραμέτρων, και ένα σύνολο δοκιμής (10-15% των δεδομένων). Το μοντέλο εκπαιδεύεται στο σύνολο εκπαίδευσης και αξιολογείται στο σύνολο δοκιμής.
- Για παράδειγμα, αν έχετε ένα σύνολο δεδομένων 1000 δειγμάτων, μπορεί να χρησιμοποιήσετε 700 δείγματα για εκπαίδευση, 150 για επικύρωση και 150 για δοκιμή.
- **Στρατολογημένη Δειγματοληψία**: Διασφάλιση ότι η κατανομή των κατηγοριών στα σύνολα εκπαίδευσης και δοκιμής είναι παρόμοια με το συνολικό σύνολο δεδομένων. Αυτό είναι ιδιαίτερα σημαντικό για ανισόρροπα σύνολα δεδομένων, όπου ορισμένες κατηγορίες μπορεί να έχουν σημαντικά λιγότερα δείγματα από άλλες.
- **Διαχωρισμός Χρονικών Σειρών**: Για δεδομένα χρονικών σειρών, το σύνολο δεδομένων διαχωρίζεται με βάση το χρόνο, διασφαλίζοντας ότι το σύνολο εκπαίδευσης περιέχει δεδομένα από προηγούμενες χρονικές περιόδους και το σύνολο δοκιμής περιέχει δεδομένα από μεταγενέστερες περιόδους. Αυτό βοηθά στην αξιολόγηση της απόδοσης του μοντέλου σε μελλοντικά δεδομένα.
- **K-Fold Cross-Validation**: Διαχωρισμός του συνόλου δεδομένων σε K υποσύνολα (folds) και εκπαίδευση του μοντέλου K φορές, κάθε φορά χρησιμοποιώντας ένα διαφορετικό fold ως σύνολο δοκιμής και τα υπόλοιπα folds ως σύνολο εκπαίδευσης. Αυτό βοηθά να διασφαλιστεί ότι το μοντέλο αξιολογείται σε διαφορετικά υποσύνολα δεδομένων, παρέχοντας μια πιο αξιόπιστη εκτίμηση της απόδοσής του.

## Αξιολόγηση Μοντέλου

Η αξιολόγηση μοντέλου είναι η διαδικασία εκτίμησης της απόδοσης ενός μοντέλου μηχανικής μάθησης σε αόρατα δεδομένα. Περιλαμβάνει τη χρήση διαφόρων μετρικών για να ποσοτικοποιήσει πόσο καλά γενικεύει το μοντέλο σε νέα δεδομένα. Κοινές μετρικές αξιολόγησης περιλαμβάνουν:

### Ακρίβεια

Η ακρίβεια είναι το ποσοστό των σωστά προβλεπόμενων περιπτώσεων σε σχέση με το συνολικό αριθμό περιπτώσεων. Υπολογίζεται ως:
```plaintext
Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)
```
> [!TIP]
> Η ακρίβεια είναι ένα απλό και διαισθητικό μέτρο, αλλά μπορεί να μην είναι κατάλληλη για μη ισορροπημένα σύνολα δεδομένων όπου μια κατηγορία κυριαρχεί στις άλλες, καθώς μπορεί να δώσει μια παραπλανητική εντύπωση της απόδοσης του μοντέλου. Για παράδειγμα, αν το 90% των δεδομένων ανήκει στην κατηγορία A και το μοντέλο προβλέπει όλες τις περιπτώσεις ως κατηγορία A, θα επιτύχει 90% ακρίβεια, αλλά δεν θα είναι χρήσιμο για την πρόβλεψη της κατηγορίας B.

### Precision

Η ακρίβεια είναι το ποσοστό των αληθών θετικών προβλέψεων από όλες τις θετικές προβλέψεις που έκανε το μοντέλο. Υπολογίζεται ως:
```plaintext
Precision = (True Positives) / (True Positives + False Positives)
```
> [!TIP]
> Η ακρίβεια είναι ιδιαίτερα σημαντική σε σενάρια όπου τα ψευδώς θετικά είναι δαπανηρά ή ανεπιθύμητα, όπως στη ιατρική διάγνωση ή την ανίχνευση απάτης. Για παράδειγμα, αν ένα μοντέλο προβλέπει 100 περιπτώσεις ως θετικές, αλλά μόνο οι 80 από αυτές είναι πραγματικά θετικές, η ακρίβεια θα ήταν 0.8 (80%).

### Ανάκληση (Ευαισθησία)

Η ανάκληση, γνωστή επίσης ως ευαισθησία ή ποσοστό πραγματικών θετικών, είναι το ποσοστό των πραγματικών θετικών προβλέψεων από όλες τις πραγματικές θετικές περιπτώσεις. Υπολογίζεται ως:
```plaintext
Recall = (True Positives) / (True Positives + False Negatives)
```
> [!TIP]
> Η ανάκληση είναι κρίσιμη σε σενάρια όπου τα ψευδώς αρνητικά είναι δαπανηρά ή ανεπιθύμητα, όπως στην ανίχνευση ασθενειών ή στη φιλτράρισμα ανεπιθύμητης αλληλογραφίας. Για παράδειγμα, αν ένα μοντέλο αναγνωρίζει 80 από 100 πραγματικές θετικές περιπτώσεις, η ανάκληση θα είναι 0.8 (80%).

### F1 Score

Ο δείκτης F1 είναι ο αρμονικός μέσος όρος της ακρίβειας και της ανάκλησης, παρέχοντας μια ισορροπία μεταξύ των δύο μετρικών. Υπολογίζεται ως:
```plaintext
F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
```
> [!TIP]
> Ο δείκτης F1 είναι ιδιαίτερα χρήσιμος όταν ασχολούμαστε με μη ισορροπημένα σύνολα δεδομένων, καθώς λαμβάνει υπόψη τόσο τα ψευδώς θετικά όσο και τα ψευδώς αρνητικά. Παρέχει έναν ενιαίο δείκτη που αποτυπώνει την ισορροπία μεταξύ ακρίβειας και ανάκλησης. Για παράδειγμα, αν ένα μοντέλο έχει ακρίβεια 0.8 και ανάκληση 0.6, ο δείκτης F1 θα είναι περίπου 0.69.

### ROC-AUC (Receiver Operating Characteristic - Area Under the Curve)

Ο δείκτης ROC-AUC αξιολογεί την ικανότητα του μοντέλου να διακρίνει μεταξύ των κατηγοριών, σχεδιάζοντας τον ρυθμό αληθών θετικών (ευαισθησία) σε σχέση με τον ρυθμό ψευδώς θετικών σε διάφορες ρυθμίσεις κατωφλίου. Η περιοχή κάτω από την καμπύλη ROC (AUC) ποσοτικοποιεί την απόδοση του μοντέλου, με μια τιμή 1 να υποδηλώνει τέλεια κατηγοριοποίηση και μια τιμή 0.5 να υποδηλώνει τυχαία μαντεψιά.

> [!TIP]
> Ο ROC-AUC είναι ιδιαίτερα χρήσιμος για προβλήματα δυαδικής κατηγοριοποίησης και παρέχει μια συνολική εικόνα της απόδοσης του μοντέλου σε διάφορα κατώφλια. Είναι λιγότερο ευαίσθητος στην ανισορροπία κατηγορίας σε σύγκριση με την ακρίβεια. Για παράδειγμα, ένα μοντέλο με AUC 0.9 υποδηλώνει ότι έχει υψηλή ικανότητα να διακρίνει μεταξύ θετικών και αρνητικών περιπτώσεων.

### Specificity

Η ειδικότητα, γνωστή επίσης ως ρυθμός αληθών αρνητικών, είναι το ποσοστό των αληθών αρνητικών προβλέψεων από όλες τις πραγματικές αρνητικές περιπτώσεις. Υπολογίζεται ως:
```plaintext
Specificity = (True Negatives) / (True Negatives + False Positives)
```
> [!TIP]
> Η ειδικότητα είναι σημαντική σε σενάρια όπου τα ψευδώς θετικά είναι δαπανηρά ή ανεπιθύμητα, όπως σε ιατρικές εξετάσεις ή ανίχνευση απάτης. Βοηθά στην εκτίμηση του πόσο καλά το μοντέλο αναγνωρίζει τις αρνητικές περιπτώσεις. Για παράδειγμα, αν ένα μοντέλο αναγνωρίζει σωστά 90 από τις 100 πραγματικές αρνητικές περιπτώσεις, η ειδικότητα θα είναι 0.9 (90%).

### Matthews Correlation Coefficient (MCC)
Ο Συντελεστής Συσχέτισης Matthews (MCC) είναι ένα μέτρο της ποιότητας των δυαδικών ταξινομήσεων. Λαμβάνει υπόψη τα αληθή και ψευδή θετικά και αρνητικά, παρέχοντας μια ισορροπημένη άποψη της απόδοσης του μοντέλου. Ο MCC υπολογίζεται ως:
```plaintext
MCC = (TP * TN - FP * FN) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
```
όπου:
- **TP**: Αληθώς Θετικά
- **TN**: Αληθώς Αρνητικά
- **FP**: Ψευδώς Θετικά
- **FN**: Ψευδώς Αρνητικά

> [!TIP]
> Ο MCC κυμαίνεται από -1 έως 1, όπου το 1 υποδεικνύει τέλεια ταξινόμηση, το 0 υποδεικνύει τυχαία μαντεψιά και το -1 υποδεικνύει πλήρη διαφωνία μεταξύ πρόβλεψης και παρατήρησης. Είναι ιδιαίτερα χρήσιμος για μη ισορροπημένα σύνολα δεδομένων, καθώς λαμβάνει υπόψη όλα τα τέσσερα στοιχεία του πίνακα σύγχυσης.

### Μέσο Απόλυτο Σφάλμα (MAE)
Το Μέσο Απόλυτο Σφάλμα (MAE) είναι ένα μέτρο παλινδρόμησης που μετρά τη μέση απόλυτη διαφορά μεταξύ προβλεπόμενων και πραγματικών τιμών. Υπολογίζεται ως:
```plaintext
MAE = (1/n) * Σ|y_i - ŷ_i|
```
όπου:
- **n**: Αριθμός περιπτώσεων
- **y_i**: Πραγματική τιμή για την περίπτωση i
- **ŷ_i**: Προβλεπόμενη τιμή για την περίπτωση i

> [!TIP]
> Το MAE παρέχει μια απλή ερμηνεία του μέσου σφάλματος στις προβλέψεις, διευκολύνοντας την κατανόηση. Είναι λιγότερο ευαίσθητο σε εξαιρέσεις σε σύγκριση με άλλες μετρικές όπως το Μέσο Τετραγωνικό Σφάλμα (MSE). Για παράδειγμα, αν ένα μοντέλο έχει MAE 5, σημαίνει ότι, κατά μέσο όρο, οι προβλέψεις του μοντέλου αποκλίνουν από τις πραγματικές τιμές κατά 5 μονάδες.

### Πίνακας Σύγχυσης

Ο πίνακας σύγχυσης είναι ένας πίνακας που συνοψίζει την απόδοση ενός μοντέλου ταξινόμησης δείχνοντας τους αριθμούς των αληθών θετικών, αληθών αρνητικών, ψευδών θετικών και ψευδών αρνητικών προβλέψεων. Παρέχει μια λεπτομερή εικόνα του πόσο καλά αποδίδει το μοντέλο σε κάθε κατηγορία.

|               | Προβλεπόμενα Θετικά | Προβλεπόμενα Αρνητικά |
|---------------|---------------------|---------------------|
| Πραγματικά Θετικά| Αληθές Θετικό (TP)  | Ψευδές Αρνητικό (FN)  |
| Πραγματικά Αρνητικά| Ψευδές Θετικό (FP) | Αληθές Αρνητικό (TN)   |

- **Αληθές Θετικό (TP)**: Το μοντέλο προέβλεψε σωστά την θετική κατηγορία.
- **Αληθές Αρνητικό (TN)**: Το μοντέλο προέβλεψε σωστά την αρνητική κατηγορία.
- **Ψευδές Θετικό (FP)**: Το μοντέλο προέβλεψε λανθασμένα την θετική κατηγορία (Σφάλμα Τύπου I).
- **Ψευδές Αρνητικό (FN)**: Το μοντέλο προέβλεψε λανθασμένα την αρνητική κατηγορία (Σφάλμα Τύπου II).

Ο πίνακας σύγχυσης μπορεί να χρησιμοποιηθεί για να υπολογίσει διάφορες μετρικές αξιολόγησης, όπως η ακρίβεια, η ακρίβεια, η ανάκληση και το σκορ F1.

{{#include ../banners/hacktricks-training.md}}
