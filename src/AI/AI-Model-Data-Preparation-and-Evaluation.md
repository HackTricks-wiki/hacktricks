# Підготовка та оцінка даних моделі

{{#include ../banners/hacktricks-training.md}}

Підготовка даних моделі є критично важливим етапом у процесі машинного навчання, оскільки вона передбачає перетворення сирих даних у формат, придатний для навчання моделей машинного навчання. Цей процес включає кілька ключових етапів:

1. **Збір даних**: Збір даних з різних джерел, таких як бази даних, API або файли. Дані можуть бути структурованими (наприклад, таблиці) або неструктурованими (наприклад, текст, зображення).
2. **Очищення даних**: Видалення або виправлення помилкових, неповних або нерелевантних даних. Цей етап може включати обробку відсутніх значень, видалення дублікатів та фільтрацію викидів.
3. **Перетворення даних**: Перетворення даних у придатний формат для моделювання. Це може включати нормалізацію, масштабування, кодування категоріальних змінних та створення нових ознак за допомогою технік, таких як інженерія ознак.
4. **Розподіл даних**: Поділ набору даних на навчальні, валідаційні та тестові набори, щоб забезпечити хорошу узагальненість моделі на невідомих даних.

## Збір даних

Збір даних передбачає збір даних з різних джерел, які можуть включати:
- **Бази даних**: Витягування даних з реляційних баз даних (наприклад, SQL бази даних) або NoSQL баз даних (наприклад, MongoDB).
- **API**: Отримання даних з веб-API, які можуть надавати дані в реальному часі або історичні дані.
- **Файли**: Читання даних з файлів у форматах, таких як CSV, JSON або XML.
- **Веб-скрапінг**: Збір даних з веб-сайтів за допомогою технік веб-скрапінгу.

В залежності від мети проекту машинного навчання, дані будуть витягнуті та зібрані з відповідних джерел, щоб забезпечити їх репрезентативність для предметної області.

## Очищення даних

Очищення даних є процесом виявлення та виправлення помилок або невідповідностей у наборі даних. Цей етап є важливим для забезпечення якості даних, що використовуються для навчання моделей машинного навчання. Ключові завдання в очищенні даних включають:
- **Обробка відсутніх значень**: Виявлення та усунення відсутніх даних. Загальні стратегії включають:
- Видалення рядків або стовпців з відсутніми значеннями.
- Заповнення відсутніх значень за допомогою технік, таких як середнє, медіана або мода.
- Використання розширених методів, таких як імпутація K найближчих сусідів (KNN) або регресійна імпутація.
- **Видалення дублікатів**: Виявлення та видалення дублікатів записів, щоб забезпечити унікальність кожної точки даних.
- **Фільтрація викидів**: Виявлення та видалення викидів, які можуть спотворити продуктивність моделі. Техніки, такі як Z-оцінка, IQR (міжквартильний діапазон) або візуалізації (наприклад, діаграми ящиків), можуть бути використані для виявлення викидів.

### Приклад очищення даних
```python
import pandas as pd
# Load the dataset
data = pd.read_csv('data.csv')

# Finding invalid values based on a specific function
def is_valid_possitive_int(num):
try:
num = int(num)
return 1 <= num <= 31
except ValueError:
return False

invalid_days = data[~data['days'].astype(str).apply(is_valid_positive_int)]

## Dropping rows with invalid days
data = data.drop(invalid_days.index, errors='ignore')



# Set "NaN" values to a specific value
## For example, setting NaN values in the 'days' column to 0
data['days'] = pd.to_numeric(data['days'], errors='coerce')

## For example, set "NaN" to not ips
def is_valid_ip(ip):
pattern = re.compile(r'^((25[0-5]|2[0-4][0-9]|[01]?\d?\d)\.){3}(25[0-5]|2[0-4]\d|[01]?\d?\d)$')
if pd.isna(ip) or not pattern.match(str(ip)):
return np.nan
return ip
df['ip'] = df['ip'].apply(is_valid_ip)

# Filling missing values based on different strategies
numeric_cols = ["days", "hours", "minutes"]
categorical_cols = ["ip", "status"]

## Filling missing values in numeric columns with the median
num_imputer = SimpleImputer(strategy='median')
df[numeric_cols] = num_imputer.fit_transform(df[numeric_cols])

## Filling missing values in categorical columns with the most frequent value
cat_imputer = SimpleImputer(strategy='most_frequent')
df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])

## Filling missing values in numeric columns using KNN imputation
knn_imputer = KNNImputer(n_neighbors=5)
df[numeric_cols] = knn_imputer.fit_transform(df[numeric_cols])



# Filling missing values
data.fillna(data.mean(), inplace=True)

# Removing duplicates
data.drop_duplicates(inplace=True)
# Filtering outliers using Z-score
from scipy import stats
z_scores = stats.zscore(data.select_dtypes(include=['float64', 'int64']))
data = data[(z_scores < 3).all(axis=1)]
```
## Трансформація Даних

Трансформація даних передбачає перетворення даних у формат, придатний для моделювання. Цей етап може включати:
- **Нормалізація та Стандартизація**: Масштабування числових ознак до загального діапазону, зазвичай [0, 1] або [-1, 1]. Це допомагає покращити збіжність алгоритмів оптимізації.
- **Масштабування Min-Max**: Перемасштабування ознак до фіксованого діапазону, зазвичай [0, 1]. Це робиться за допомогою формули: `X' = (X - X_{min}) / (X_{max} - X_{min})`
- **Нормалізація Z-Score**: Стандартизація ознак шляхом віднімання середнього та ділення на стандартне відхилення, що призводить до розподілу зі середнім 0 та стандартним відхиленням 1. Це робиться за допомогою формули: `X' = (X - μ) / σ`, де μ - середнє, а σ - стандартне відхилення.
- **Скевність та Куртозис**: Коригування розподілу ознак для зменшення скевності (асиметрії) та куртозису (піковості). Це можна зробити за допомогою трансформацій, таких як логарифмічна, квадратний корінь або трансформації Бокса-Кокса. Наприклад, якщо ознака має скевний розподіл, застосування логарифмічної трансформації може допомогти нормалізувати його.
- **Нормалізація рядків**: Перетворення рядків у єдиний формат, наприклад:
- Перетворення в нижній регістр
- Видалення спеціальних символів (збереження релевантних)
- Видалення стоп-слів (поширених слів, які не сприяють значенню, таких як "the", "is", "and")
- Видалення занадто частих слів і занадто рідкісних слів (наприклад, слів, які з'являються у більше ніж 90% документів або менше ніж 5 разів у корпусі)
- Обрізка пробілів
- Стемінг/Лематизація: Зменшення слів до їх базової або кореневої форми (наприклад, "running" до "run").

- **Кодування Категоріальних Змінних**: Перетворення категоріальних змінних у числові представлення. Поширені техніки включають:
- **One-Hot Кодування**: Створення бінарних стовпців для кожної категорії.
- Наприклад, якщо ознака має категорії "red", "green" і "blue", вона буде перетворена на три бінарні стовпці: `is_red`(100), `is_green`(010) та `is_blue`(001).
- **Label Кодування**: Присвоєння унікального цілого числа кожній категорії.
- Наприклад, "red" = 0, "green" = 1, "blue" = 2.
- **Ordinal Кодування**: Присвоєння цілих чисел на основі порядку категорій.
- Наприклад, якщо категорії "low", "medium" і "high", їх можна закодувати як 0, 1 і 2 відповідно.
- **Hashing Кодування**: Використання хеш-функції для перетворення категорій у вектори фіксованого розміру, що може бути корисним для категоріальних змінних з високою кардинальністю.
- Наприклад, якщо ознака має багато унікальних категорій, хешування може зменшити розмірність, зберігаючи деяку інформацію про категорії.
- **Bag of Words (BoW)**: Представлення текстових даних у вигляді матриці кількостей або частот слів, де кожен рядок відповідає документу, а кожен стовпець відповідає унікальному слову в корпусі.
- Наприклад, якщо корпус містить слова "cat", "dog" і "fish", документ, що містить "cat" і "dog", буде представлений як [1, 1, 0]. Це специфічне представлення називається "уніграма" і не фіксує порядок слів, тому втрачає семантичну інформацію.
- **Біграм/Триграм**: Розширення BoW для захоплення послідовностей слів (біграм або триграм), щоб зберегти деякий контекст. Наприклад, "cat and dog" буде представлене як біграм [1, 1] для "cat and" і [1, 1] для "and dog". У цих випадках збирається більше семантичної інформації (збільшуючи розмірність представлення), але лише для 2 або 3 слів одночасно.
- **TF-IDF (Частота терміна-Обернена частота документа)**: Статистичний показник, який оцінює важливість слова в документі відносно колекції документів (корпусу). Він поєднує частоту терміна (як часто слово з'являється в документі) та обернену частоту документа (наскільки рідкісне слово в усіх документах).
- Наприклад, якщо слово "cat" часто з'являється в документі, але рідко в усьому корпусі, воно матиме високий бал TF-IDF, що вказує на його важливість у цьому документі.

- **Інженерія Ознак**: Створення нових ознак з існуючих для підвищення прогностичної сили моделі. Це може включати поєднання ознак, витягування компонентів дати/часу або застосування специфічних для домену трансформацій.

## Розподіл Даних

Розподіл даних передбачає поділ набору даних на окремі підмножини для навчання, валідації та тестування. Це необхідно для оцінки продуктивності моделі на невідомих даних і запобігання перенавчанню. Поширені стратегії включають:
- **Розподіл Навчання-Тестування**: Поділ набору даних на навчальний набір (зазвичай 60-80% даних), валідаційний набір (10-15% даних) для налаштування гіперпараметрів і тестовий набір (10-15% даних). Модель навчається на навчальному наборі та оцінюється на тестовому наборі.
- Наприклад, якщо у вас є набір даних з 1000 зразків, ви можете використати 700 зразків для навчання, 150 для валідації та 150 для тестування.
- **Стратифіковане Вибіркове**: Забезпечення того, щоб розподіл класів у навчальних та тестових наборах був схожий на загальний набір даних. Це особливо важливо для незбалансованих наборів даних, де деякі класи можуть мати значно менше зразків, ніж інші.
- **Розподіл Часових Рядів**: Для даних часових рядів набір даних розділяється на основі часу, забезпечуючи, щоб навчальний набір містив дані з ранніх періодів, а тестовий набір містив дані з пізніших періодів. Це допомагає оцінити продуктивність моделі на майбутніх даних.
- **K-Fold Перехресна Валідація**: Поділ набору даних на K підмножин (складок) і навчання моделі K разів, кожного разу використовуючи різну складку як тестовий набір, а решту складок як навчальний набір. Це допомагає забезпечити, щоб модель оцінювалася на різних підмножинах даних, надаючи більш надійну оцінку її продуктивності.

## Оцінка Моделі

Оцінка моделі - це процес оцінки продуктивності моделі машинного навчання на невідомих даних. Це передбачає використання різних метрик для кількісної оцінки того, наскільки добре модель узагальнює на нових даних. Поширені метрики оцінки включають:

### Точність

Точність - це частка правильно передбачених випадків з загальної кількості випадків. Вона обчислюється як:
```plaintext
Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)
```
> [!TIP]
> Точність є простою та інтуїтивною метрикою, але вона може бути непридатною для незбалансованих наборів даних, де один клас домінує над іншими, оскільки може створити оманливе враження про продуктивність моделі. Наприклад, якщо 90% даних належать до класу A, а модель прогнозує всі випадки як клас A, вона досягне 90% точності, але не буде корисною для прогнозування класу B.

### Precision

Precision є часткою істинно позитивних прогнозів серед усіх позитивних прогнозів, зроблених моделлю. Він обчислюється як:
```plaintext
Precision = (True Positives) / (True Positives + False Positives)
```
> [!TIP]
> Точність особливо важлива в сценаріях, де хибнопозитивні результати є дорогими або небажаними, таких як медичні діагнози або виявлення шахрайства. Наприклад, якщо модель прогнозує 100 випадків як позитивні, але лише 80 з них насправді позитивні, точність буде 0.8 (80%).

### Recall (Чутливість)

Recall, також відомий як чутливість або частка справжніх позитивних, є пропорцією справжніх позитивних прогнозів серед усіх фактичних позитивних випадків. Він розраховується як:
```plaintext
Recall = (True Positives) / (True Positives + False Negatives)
```
> [!TIP]
> Відтворення є критично важливим у сценаріях, де хибні негативи є дорогими або небажаними, таких як виявлення захворювань або фільтрація спаму. Наприклад, якщо модель ідентифікує 80 з 100 фактичних позитивних випадків, відтворення буде 0.8 (80%).

### F1 Score

F1 score - це гармонійне середнє значення точності та відтворення, що забезпечує баланс між цими двома метриками. Він розраховується як:
```plaintext
F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
```
> [!TIP]
> F1-оцінка особливо корисна при роботі з незбалансованими наборами даних, оскільки вона враховує як хибнопозитивні, так і хибнонегативні результати. Вона надає єдину метрику, яка відображає компроміс між точністю та відзивом. Наприклад, якщо модель має точність 0.8 і відзив 0.6, F1-оцінка буде приблизно 0.69.

### ROC-AUC (Receiver Operating Characteristic - Area Under the Curve)

Метрика ROC-AUC оцінює здатність моделі розрізняти класи, наносячи на графік справжню позитивну ставку (чутливість) проти хибнопозитивної ставки при різних налаштуваннях порогу. Площа під кривою ROC (AUC) кількісно оцінює продуктивність моделі, значення 1 вказує на ідеальну класифікацію, а значення 0.5 вказує на випадкове вгадування.

> [!TIP]
> ROC-AUC особливо корисна для задач бінарної класифікації та надає всебічний огляд продуктивності моделі при різних порогах. Вона менш чутлива до дисбалансу класів у порівнянні з точністю. Наприклад, модель з AUC 0.9 вказує на високу здатність розрізняти позитивні та негативні випадки.

### Специфічність

Специфічність, також відома як ставка справжніх негативів, є часткою справжніх негативних прогнозів серед усіх фактичних негативних випадків. Вона обчислюється як:
```plaintext
Specificity = (True Negatives) / (True Negatives + False Positives)
```
> [!TIP]
> Специфічність важлива в сценаріях, де хибнопозитивні результати є дорогими або небажаними, таких як медичне тестування або виявлення шахрайства. Це допомагає оцінити, наскільки добре модель ідентифікує негативні випадки. Наприклад, якщо модель правильно ідентифікує 90 з 100 фактичних негативних випадків, специфічність буде 0.9 (90%).

### Matthews Correlation Coefficient (MCC)
Коефіцієнт кореляції Мэттьюса (MCC) є мірою якості бінарних класифікацій. Він враховує істинні та хибнопозитивні і хибнонегативні результати, надаючи збалансований погляд на продуктивність моделі. MCC розраховується як:
```plaintext
MCC = (TP * TN - FP * FN) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
```
де:
- **TP**: Справжні позитиви
- **TN**: Справжні негативи
- **FP**: Хибні позитиви
- **FN**: Хибні негативи

> [!TIP]
> MCC коливається від -1 до 1, де 1 вказує на ідеальну класифікацію, 0 вказує на випадкове вгадування, а -1 вказує на повну незгоду між прогнозом і спостереженням. Це особливо корисно для незбалансованих наборів даних, оскільки враховує всі чотири компоненти матриці плутанини.

### Середня абсолютна помилка (MAE)
Середня абсолютна помилка (MAE) є метрикою регресії, яка вимірює середню абсолютну різницю між прогнозованими та фактичними значеннями. Вона обчислюється як:
```plaintext
MAE = (1/n) * Σ|y_i - ŷ_i|
```
де:
- **n**: Кількість екземплярів
- **y_i**: Фактичне значення для екземпляра i
- **ŷ_i**: Прогнозоване значення для екземпляра i

> [!TIP]
> MAE забезпечує просту інтерпретацію середньої помилки в прогнозах, що робить її легкою для розуміння. Вона менш чутлива до викидів у порівнянні з іншими метриками, такими як середньоквадратична помилка (MSE). Наприклад, якщо модель має MAE 5, це означає, що в середньому прогнози моделі відхиляються від фактичних значень на 5 одиниць.

### Матриця плутанини

Матриця плутанини - це таблиця, яка підсумовує ефективність моделі класифікації, показуючи кількість істинно позитивних, істинно негативних, хибно позитивних і хибно негативних прогнозів. Вона надає детальний огляд того, як добре модель працює для кожного класу.

|               | Прогнозований позитивний | Прогнозований негативний |
|---------------|---------------------------|---------------------------|
| Фактичний позитивний| Істинно позитивний (TP)  | Хибно негативний (FN)     |
| Фактичний негативний| Хибно позитивний (FP)    | Істинно негативний (TN)   |

- **Істинно позитивний (TP)**: Модель правильно передбачила позитивний клас.
- **Істинно негативний (TN)**: Модель правильно передбачила негативний клас.
- **Хибно позитивний (FP)**: Модель неправильно передбачила позитивний клас (помилка типу I).
- **Хибно негативний (FN)**: Модель неправильно передбачила негативний клас (помилка типу II).

Матрицю плутанини можна використовувати для розрахунку різних метрик оцінки, таких як точність, точність, відгук і F1-оцінка.

{{#include ../banners/hacktricks-training.md}}
