# AI в кібербезпеці

{{#include ../banners/hacktricks-training.md}}

## Основні алгоритми машинного навчання

Найкраща відправна точка для вивчення AI - це зрозуміти, як працюють основні алгоритми машинного навчання. Це допоможе вам зрозуміти, як працює AI, як його використовувати і як на нього атакувати:

{{#ref}}
./AI-Supervised-Learning-Algorithms.md
{{#endref}}

{{#ref}}
./AI-Unsupervised-Learning-Algorithms.md
{{#endref}}

{{#ref}}
./AI-Reinforcement-Learning-Algorithms.md
{{#endref}}

{{#ref}}
./AI-Deep-Learning.md
{{#endref}}

### Архітектура LLM

На наступній сторінці ви знайдете основи кожного компонента для побудови базового LLM за допомогою трансформерів:

{{#ref}}
AI-llm-architecture/README.md
{{#endref}}

## Безпека AI

### Рамки ризиків AI

На даний момент основними 2 рамками для оцінки ризиків систем AI є OWASP ML Top 10 та Google SAIF:

{{#ref}}
AI-Risk-Frameworks.md
{{#endref}}

### Безпека запитів AI

LLMs зробили використання AI вибуховим в останні роки, але вони не ідеальні і можуть бути обмануті ворожими запитами. Це дуже важлива тема для розуміння, як безпечно використовувати AI і як на нього атакувати:

{{#ref}}
AI-Prompts.md
{{#endref}}

### RCE моделей AI

Досить поширено, що розробники та компанії запускають моделі, завантажені з Інтернету, однак просто завантаження моделі може бути достатнім для виконання довільного коду на системі. Це дуже важлива тема для розуміння, як безпечно використовувати AI і як на нього атакувати:

{{#ref}}
AI-Models-RCE.md
{{#endref}}

### Протокол контексту моделі AI

MCP (Протокол контексту моделі) - це протокол, який дозволяє клієнтам агентів AI підключатися до зовнішніх інструментів і джерел даних у режимі plug-and-play. Це дозволяє створювати складні робочі процеси та взаємодії між моделями AI та зовнішніми системами:

{{#ref}}
AI-MCP-Servers.md
{{#endref}}

### AI-підтримуване фуззингування та автоматизоване виявлення вразливостей

{{#ref}}
AI-Assisted-Fuzzing-and-Vulnerability-Discovery.md
{{#endref}}

{{#include ../banners/hacktricks-training.md}}
