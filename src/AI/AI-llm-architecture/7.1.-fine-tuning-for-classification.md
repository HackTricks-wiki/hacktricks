# 7.1. Fine-Tuning for Classification

{{#include ../../banners/hacktricks-training.md}}

## What is

फाइन-ट्यूनिंग एक **पूर्व-प्रशिक्षित मॉडल** लेने की प्रक्रिया है जिसने विशाल मात्रा में डेटा से **सामान्य भाषा पैटर्न** सीखे हैं और इसे एक **विशिष्ट कार्य** करने या डोमेन-विशिष्ट भाषा को समझने के लिए **अनुकूलित** करना है। यह एक छोटे, कार्य-विशिष्ट डेटा सेट पर मॉडल के प्रशिक्षण को जारी रखकर प्राप्त किया जाता है, जिससे इसे नए डेटा की बारीकियों के अनुसार अपने पैरामीटर को समायोजित करने की अनुमति मिलती है जबकि यह पहले से अधिग्रहित व्यापक ज्ञान का लाभ उठाता है। फाइन-ट्यूनिंग मॉडल को विशेष अनुप्रयोगों में अधिक सटीक और प्रासंगिक परिणाम देने में सक्षम बनाता है बिना नए मॉडल को शून्य से प्रशिक्षित करने की आवश्यकता के।

> [!TIP]
> चूंकि एक LLM को "समझने" के लिए पूर्व-प्रशिक्षण करना काफी महंगा है, इसलिए आमतौर पर एक विशिष्ट कार्य को करने के लिए ओपन-सोर्स पूर्व-प्रशिक्षित मॉडलों को फाइन-ट्यून करना आसान और सस्ता होता है।

> [!TIP]
> इस अनुभाग का लक्ष्य यह दिखाना है कि पहले से पूर्व-प्रशिक्षित मॉडल को कैसे फाइन-ट्यून किया जाए ताकि LLM नए पाठ उत्पन्न करने के बजाय **प्रत्येक दिए गए श्रेणी में वर्गीकृत होने के लिए दिए गए पाठ की संभावनाएँ** प्रदान करे (जैसे कि यदि कोई पाठ स्पैम है या नहीं)।

## Preparing the data set

### Data set size

बेशक, एक मॉडल को फाइन-ट्यून करने के लिए आपको अपने LLM को विशेष बनाने के लिए कुछ संरचित डेटा की आवश्यकता होती है। [https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb) में प्रस्तावित उदाहरण में, GPT2 को यह पता लगाने के लिए फाइन ट्यून किया गया है कि क्या एक ईमेल स्पैम है या नहीं, [https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip](https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip) से डेटा का उपयोग करके।

इस डेटा सेट में "स्पैम" की तुलना में "स्पैम नहीं" के बहुत अधिक उदाहरण हैं, इसलिए पुस्तक सुझाव देती है कि **"स्पैम नहीं" के उतने ही उदाहरणों का उपयोग करें जितने "स्पैम" के** (इसलिए, प्रशिक्षण डेटा से सभी अतिरिक्त उदाहरणों को हटा दें)। इस मामले में, यह प्रत्येक के 747 उदाहरण थे।

फिर, **70%** डेटा सेट का उपयोग **प्रशिक्षण** के लिए, **10%** **मान्यता** के लिए और **20%** **परीक्षण** के लिए किया जाता है।

- **मान्यता सेट** का उपयोग प्रशिक्षण चरण के दौरान मॉडल के **हाइपरपैरामीटर** को फाइन-ट्यून करने और मॉडल आर्किटेक्चर के बारे में निर्णय लेने के लिए किया जाता है, प्रभावी रूप से अज्ञात डेटा पर मॉडल के प्रदर्शन के बारे में फीडबैक प्रदान करके ओवरफिटिंग को रोकने में मदद करता है। यह अंतिम मूल्यांकन को पूर्वाग्रहित किए बिना क्रमिक सुधार की अनुमति देता है।
- इसका मतलब है कि हालांकि इस डेटा सेट में शामिल डेटा का उपयोग सीधे प्रशिक्षण के लिए नहीं किया जाता है, इसका उपयोग सबसे अच्छे **हाइपरपैरामीटर** को ट्यून करने के लिए किया जाता है, इसलिए इस सेट का उपयोग परीक्षण सेट की तरह मॉडल के प्रदर्शन का मूल्यांकन करने के लिए नहीं किया जा सकता है।
- इसके विपरीत, **परीक्षण सेट** का उपयोग **केवल तब** किया जाता है जब मॉडल को पूरी तरह से प्रशिक्षित किया गया हो और सभी समायोजन पूर्ण हो चुके हों; यह नए, अज्ञात डेटा पर सामान्यीकृत करने की मॉडल की क्षमता का पूर्वाग्रह-मुक्त आकलन प्रदान करता है। परीक्षण सेट पर यह अंतिम मूल्यांकन यह दर्शाता है कि मॉडल वास्तविक दुनिया के अनुप्रयोगों में कैसे प्रदर्शन करने की उम्मीद है।

### Entries length

चूंकि प्रशिक्षण उदाहरण समान लंबाई के प्रविष्टियों (इस मामले में ईमेल पाठ) की अपेक्षा करता है, इसलिए यह तय किया गया कि प्रत्येक प्रविष्टि को सबसे बड़ी प्रविष्टि के आकार का बनाया जाए, जिसमें `<|endoftext|>` के आईडी को पैडिंग के रूप में जोड़ा जाए।

### Initialize the model

ओपन-सोर्स पूर्व-प्रशिक्षित वेट्स का उपयोग करके मॉडल को प्रशिक्षित करने के लिए प्रारंभ करें। हमने पहले ही यह किया है और [https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb) के निर्देशों का पालन करके आप इसे आसानी से कर सकते हैं।

## Classification head

इस विशेष उदाहरण (यह भविष्यवाणी करना कि कोई पाठ स्पैम है या नहीं) में, हम GPT2 के पूर्ण शब्दावली के अनुसार फाइन ट्यून करने में रुचि नहीं रखते हैं, बल्कि हम केवल नए मॉडल से यह कहना चाहते हैं कि ईमेल स्पैम है (1) या नहीं (0)। इसलिए, हम **अंतिम परत को संशोधित करने जा रहे हैं** जो शब्दावली के लिए प्रति टोकन संभावनाएँ देती है, एक ऐसी परत में जो केवल स्पैम होने या न होने की संभावनाएँ देती है (तो जैसे 2 शब्दों की शब्दावली)।
```python
# This code modified the final layer with a Linear one with 2 outs
num_classes = 2
model.out_head = torch.nn.Linear(

in_features=BASE_CONFIG["emb_dim"],

out_features=num_classes
)
```
## Parameters to tune

तेज़ी से फाइन ट्यून करने के लिए सभी पैरामीटर को फाइन ट्यून करना आसान नहीं है, बल्कि केवल कुछ अंतिम पैरामीटर को फाइन ट्यून करना बेहतर है। इसका कारण यह है कि यह ज्ञात है कि निचले स्तर आमतौर पर बुनियादी भाषा संरचनाओं और प्रासंगिक अर्थों को कैप्चर करते हैं। इसलिए, केवल **अंतिम स्तरों को फाइन ट्यून करना आमतौर पर पर्याप्त और तेज़ होता है**।
```python
# This code makes all the parameters of the model unrtainable
for param in model.parameters():
param.requires_grad = False

# Allow to fine tune the last layer in the transformer block
for param in model.trf_blocks[-1].parameters():
param.requires_grad = True

# Allow to fine tune the final layer norm
for param in model.final_norm.parameters():

param.requires_grad = True
```
## Entries to use for training

पिछले अनुभागों में LLM को हर पूर्वानुमानित टोकन के नुकसान को कम करके प्रशिक्षित किया गया था, हालांकि लगभग सभी पूर्वानुमानित टोकन इनपुट वाक्य में थे (केवल अंत में 1 वास्तव में पूर्वानुमानित था) ताकि मॉडल भाषा को बेहतर समझ सके।

इस मामले में, हम केवल इस बात की परवाह करते हैं कि मॉडल यह पूर्वानुमानित कर सके कि मॉडल स्पैम है या नहीं, इसलिए हम केवल अंतिम पूर्वानुमानित टोकन की परवाह करते हैं। इसलिए, हमें अपने पिछले प्रशिक्षण हानि कार्यों को संशोधित करने की आवश्यकता है ताकि केवल उस टोकन को ध्यान में रखा जा सके।

यह [https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb) में इस प्रकार लागू किया गया है:
```python
def calc_accuracy_loader(data_loader, model, device, num_batches=None):
model.eval()
correct_predictions, num_examples = 0, 0

if num_batches is None:
num_batches = len(data_loader)
else:
num_batches = min(num_batches, len(data_loader))
for i, (input_batch, target_batch) in enumerate(data_loader):
if i < num_batches:
input_batch, target_batch = input_batch.to(device), target_batch.to(device)

with torch.no_grad():
logits = model(input_batch)[:, -1, :]  # Logits of last output token
predicted_labels = torch.argmax(logits, dim=-1)

num_examples += predicted_labels.shape[0]
correct_predictions += (predicted_labels == target_batch).sum().item()
else:
break
return correct_predictions / num_examples


def calc_loss_batch(input_batch, target_batch, model, device):
input_batch, target_batch = input_batch.to(device), target_batch.to(device)
logits = model(input_batch)[:, -1, :]  # Logits of last output token
loss = torch.nn.functional.cross_entropy(logits, target_batch)
return loss
```
ध्यान दें कि प्रत्येक बैच के लिए हम केवल **अंतिम टोकन की भविष्यवाणी के लॉजिट्स** में रुचि रखते हैं।

## पूर्ण GPT2 फाइन-ट्यून वर्गीकरण कोड

आप [https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/load-finetuned-model.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/load-finetuned-model.ipynb) में स्पैम वर्गीकरणकर्ता के रूप में GPT2 को फाइन-ट्यून करने के लिए सभी कोड पा सकते हैं।

## संदर्भ

- [https://www.manning.com/books/build-a-large-language-model-from-scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)

{{#include ../../banners/hacktricks-training.md}}
