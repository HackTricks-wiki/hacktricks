# 7.2. 지침을 따르기 위한 미세 조정

{{#include /banners/hacktricks-training.md}}

> [!TIP]
> 이 섹션의 목표는 **텍스트 생성만 하는 것이 아니라 지침을 따르도록 이미 사전 훈련된 모델을 미세 조정하는 방법**을 보여주는 것입니다. 예를 들어, 챗봇으로서 작업에 응답하는 것입니다.

## 데이터셋

LLM을 지침을 따르도록 미세 조정하기 위해서는 지침과 응답이 포함된 데이터셋이 필요합니다. LLM을 지침을 따르도록 훈련하는 데는 다양한 형식이 있습니다. 예를 들어:

- Apply Alpaca 프롬프트 스타일 예제:
```csharp
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
Calculate the area of a circle with a radius of 5 units.

### Response:
The area of a circle is calculated using the formula \( A = \pi r^2 \). Plugging in the radius of 5 units:

\( A = \pi (5)^2 = \pi \times 25 = 25\pi \) square units.
```
- Phi-3 프롬프트 스타일 예시:
```vbnet
<|User|>
Can you explain what gravity is in simple terms?

<|Assistant|>
Absolutely! Gravity is a force that pulls objects toward each other.
```
LLM을 이러한 종류의 데이터 세트로 훈련시키는 것은 단순한 원시 텍스트 대신 LLM이 받는 질문에 대해 구체적인 응답을 제공해야 한다는 것을 이해하는 데 도움이 됩니다.

따라서 요청과 응답이 포함된 데이터 세트로 수행해야 할 첫 번째 작업 중 하나는 원하는 프롬프트 형식으로 해당 데이터를 모델링하는 것입니다. 예:
```python
# Code from https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb
def format_input(entry):
instruction_text = (
f"Below is an instruction that describes a task. "
f"Write a response that appropriately completes the request."
f"\n\n### Instruction:\n{entry['instruction']}"
)

input_text = f"\n\n### Input:\n{entry['input']}" if entry["input"] else ""

return instruction_text + input_text

model_input = format_input(data[50])

desired_response = f"\n\n### Response:\n{data[50]['output']}"

print(model_input + desired_response)
```
그런 다음, 항상 그렇듯이 데이터셋을 훈련, 검증 및 테스트 세트로 분리해야 합니다.

## 배치 및 데이터 로더

그런 다음, 훈련을 위해 모든 입력과 예상 출력을 배치해야 합니다. 이를 위해 필요한 것은:

- 텍스트를 토큰화합니다.
- 모든 샘플을 동일한 길이로 패딩합니다(일반적으로 길이는 LLM을 사전 훈련하는 데 사용된 컨텍스트 길이만큼 큽니다).
- 사용자 정의 콜레이트 함수에서 입력을 1만큼 이동시켜 예상 토큰을 생성합니다.
- 훈련 손실에서 제외하기 위해 일부 패딩 토큰을 -100으로 교체합니다: 첫 번째 `endoftext` 토큰 이후에 모든 다른 `endoftext` 토큰을 -100으로 대체합니다(왜냐하면 `cross_entropy(...,ignore_index=-100)`를 사용하면 -100인 타겟을 무시하기 때문입니다).
- \[선택 사항\] LLM이 답변을 생성하는 방법만 배우도록 질문에 속하는 모든 토큰을 -100으로 마스킹합니다. Alpaca 스타일을 적용하면 `### Response:`까지 모든 것을 마스킹하는 것을 의미합니다.

이렇게 생성한 후, 각 데이터셋(훈련, 검증 및 테스트)을 위한 데이터 로더를 생성할 시간입니다.

## 사전 훈련된 LLM 로드 및 미세 조정 및 손실 확인

미세 조정을 위해 사전 훈련된 LLM을 로드해야 합니다. 이는 다른 페이지에서 이미 논의되었습니다. 그런 다음, 이전에 사용된 훈련 함수를 사용하여 LLM을 미세 조정할 수 있습니다.

훈련 중에는 에포크 동안 훈련 손실과 검증 손실이 어떻게 변하는지 확인하여 손실이 줄어들고 있는지, 과적합이 발생하고 있는지를 확인할 수 있습니다.\
과적합은 훈련 손실이 줄어들고 있지만 검증 손실이 줄어들지 않거나 오히려 증가할 때 발생합니다. 이를 피하기 위해 가장 간단한 방법은 이러한 행동이 시작되는 에포크에서 훈련을 중단하는 것입니다.

## 응답 품질

이것은 손실 변동을 더 신뢰할 수 있는 분류 미세 조정이 아니기 때문에, 테스트 세트에서 응답의 품질을 확인하는 것도 중요합니다. 따라서 모든 테스트 세트에서 생성된 응답을 수집하고 **그 품질을 수동으로 확인**하여 잘못된 답변이 있는지 확인하는 것이 좋습니다(LLM이 응답 문장의 형식과 구문을 올바르게 생성할 수 있지만 완전히 잘못된 응답을 제공할 수 있다는 점에 유의하십시오. 손실 변동은 이러한 행동을 반영하지 않습니다).\
생성된 응답과 예상 응답을 **다른 LLM에 전달하여 응답을 평가하도록 요청**하는 방식으로 이 검토를 수행할 수도 있습니다.

응답 품질을 검증하기 위해 실행할 다른 테스트:

1. **대규모 다중 작업 언어 이해 (**[**MMLU**](https://arxiv.org/abs/2009.03300)**):** MMLU는 인문학, 과학 등 57개 주제에 걸쳐 모델의 지식과 문제 해결 능력을 평가합니다. 다양한 난이도에서 이해도를 평가하기 위해 객관식 질문을 사용합니다.
2. [**LMSYS 챗봇 아레나**](https://arena.lmsys.org): 이 플랫폼은 사용자가 서로 다른 챗봇의 응답을 나란히 비교할 수 있도록 합니다. 사용자가 프롬프트를 입력하면 여러 챗봇이 응답을 생성하여 직접 비교할 수 있습니다.
3. [**AlpacaEval**](https://github.com/tatsu-lab/alpaca_eval)**:** AlpacaEval은 GPT-4와 같은 고급 LLM이 다양한 프롬프트에 대한 다른 모델의 응답을 평가하는 자동화된 평가 프레임워크입니다.
4. **일반 언어 이해 평가 (**[**GLUE**](https://gluebenchmark.com/)**):** GLUE는 감정 분석, 텍스트 함의 및 질문 응답을 포함한 아홉 가지 자연어 이해 작업의 모음입니다.
5. [**SuperGLUE**](https://super.gluebenchmark.com/)**:** GLUE를 기반으로 하여 SuperGLUE는 현재 모델에 대해 어렵게 설계된 더 도전적인 작업을 포함합니다.
6. **모방 게임 벤치마크 초월 (**[**BIG-bench**](https://github.com/google/BIG-bench)**):** BIG-bench는 추론, 번역 및 질문 응답과 같은 영역에서 모델의 능력을 테스트하는 200개 이상의 작업을 포함하는 대규모 벤치마크입니다.
7. **언어 모델의 전체적인 평가 (**[**HELM**](https://crfm.stanford.edu/helm/lite/latest/)**):** HELM은 정확성, 강건성 및 공정성과 같은 다양한 메트릭에 걸쳐 포괄적인 평가를 제공합니다.
8. [**OpenAI Evals**](https://github.com/openai/evals)**:** OpenAI에서 제공하는 오픈 소스 평가 프레임워크로, 사용자 정의 및 표준화된 작업에서 AI 모델을 테스트할 수 있습니다.
9. [**HumanEval**](https://github.com/openai/human-eval)**:** 언어 모델의 코드 생성 능력을 평가하는 데 사용되는 프로그래밍 문제 모음입니다.
10. **스탠포드 질문 응답 데이터셋 (**[**SQuAD**](https://rajpurkar.github.io/SQuAD-explorer/)**):** SQuAD는 모델이 정확하게 답변하기 위해 텍스트를 이해해야 하는 위키피디아 기사에 대한 질문으로 구성됩니다.
11. [**TriviaQA**](https://nlp.cs.washington.edu/triviaqa/)**:** 방대한 양의 퀴즈 질문과 답변, 증거 문서로 구성된 데이터셋입니다.

그리고 많은 많은 더 있습니다.

## 지침 따르기 미세 조정 코드

이 미세 조정을 수행하기 위한 코드 예제를 [https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py)에서 찾을 수 있습니다.

## 참고 문헌

- [https://www.manning.com/books/build-a-large-language-model-from-scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)

{{#include /banners/hacktricks-training.md}}
