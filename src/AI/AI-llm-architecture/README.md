# LLM Training - Data Preparation

**ये मेरे नोट्स हैं बहुत ही अनुशंसित पुस्तक से** [**https://www.manning.com/books/build-a-large-language-model-from-scratch**](https://www.manning.com/books/build-a-large-language-model-from-scratch) **कुछ अतिरिक्त जानकारी के साथ।**

## Basic Information

आपको कुछ बुनियादी अवधारणाओं के बारे में जानने के लिए इस पोस्ट को पढ़ना शुरू करना चाहिए:

{{#ref}}
0.-basic-llm-concepts.md
{{#endref}}

## 1. Tokenization

> [!TIP]
> इस प्रारंभिक चरण का लक्ष्य बहुत सरल है: **इनपुट को कुछ इस तरह से टोकन (ids) में विभाजित करें जो समझ में आए।**

{{#ref}}
1.-tokenizing.md
{{#endref}}

## 2. Data Sampling

> [!TIP]
> इस दूसरे चरण का लक्ष्य बहुत सरल है: **इनपुट डेटा का सैंपल लें और इसे प्रशिक्षण चरण के लिए तैयार करें, आमतौर पर डेटासेट को एक विशिष्ट लंबाई के वाक्यों में विभाजित करके और अपेक्षित प्रतिक्रिया भी उत्पन्न करके।**

{{#ref}}
2.-data-sampling.md
{{#endref}}

## 3. Token Embeddings

> [!TIP]
> इस तीसरे चरण का लक्ष्य बहुत सरल है: **शब्दकोश में पिछले टोकनों में से प्रत्येक को मॉडल को प्रशिक्षित करने के लिए इच्छित आयामों का एक वेक्टर सौंपें।** शब्दकोश में प्रत्येक शब्द X आयामों के एक स्थान में एक बिंदु होगा।\
> ध्यान दें कि प्रारंभ में प्रत्येक शब्द का स्थान "यादृच्छिक" रूप से प्रारंभ किया गया है और ये स्थान प्रशिक्षित करने योग्य पैरामीटर हैं (प्रशिक्षण के दौरान सुधारित होंगे)।
>
> इसके अलावा, टोकन एम्बेडिंग के दौरान **एक और एम्बेडिंग परत बनाई जाती है** जो (इस मामले में) **प्रशिक्षण वाक्य में शब्द की पूर्ण स्थिति का प्रतिनिधित्व करती है।** इस तरह वाक्य में विभिन्न स्थानों पर एक शब्द का अलग प्रतिनिधित्व (अर्थ) होगा।

{{#ref}}
3.-token-embeddings.md
{{#endref}}

## 4. Attention Mechanisms

> [!TIP]
> इस चौथे चरण का लक्ष्य बहुत सरल है: **कुछ ध्यान तंत्र लागू करें।** ये बहुत सारे **दोहराए जाने वाले परतें** होंगी जो **शब्दकोश में एक शब्द के पड़ोसियों के साथ वर्तमान वाक्य में संबंध को पकड़ेंगी जिसका उपयोग LLM को प्रशिक्षित करने के लिए किया जा रहा है।**\
> इसके लिए बहुत सारी परतें उपयोग की जाती हैं, इसलिए बहुत सारे प्रशिक्षित करने योग्य पैरामीटर इस जानकारी को पकड़ने जा रहे हैं।

{{#ref}}
4.-attention-mechanisms.md
{{#endref}}

## 5. LLM Architecture

> [!TIP]
> इस पांचवे चरण का लक्ष्य बहुत सरल है: **पूर्ण LLM की वास्तुकला विकसित करें।** सब कुछ एक साथ रखें, सभी परतें लागू करें और पाठ उत्पन्न करने या पाठ को IDs में और इसके विपरीत परिवर्तित करने के लिए सभी कार्यों को बनाएं।
>
> यह वास्तुकला दोनों के लिए उपयोग की जाएगी, प्रशिक्षण और भविष्यवाणी पाठ के लिए जब इसे प्रशिक्षित किया गया हो।

{{#ref}}
5.-llm-architecture.md
{{#endref}}

## 6. Pre-training & Loading models

> [!TIP]
> इस छठे चरण का लक्ष्य बहुत सरल है: **मॉडल को शून्य से प्रशिक्षित करें।** इसके लिए पिछले LLM वास्तुकला का उपयोग किया जाएगा जिसमें डेटा सेट पर परिभाषित हानि कार्यों और ऑप्टिमाइज़र का उपयोग करते हुए लूप होंगे ताकि मॉडल के सभी पैरामीटर को प्रशिक्षित किया जा सके।

{{#ref}}
6.-pre-training-and-loading-models.md
{{#endref}}

## 7.0. LoRA Improvements in fine-tuning

> [!TIP]
> **LoRA का उपयोग पहले से प्रशिक्षित मॉडलों को ठीक करने के लिए आवश्यक गणना को बहुत कम कर देता है।**

{{#ref}}
7.0.-lora-improvements-in-fine-tuning.md
{{#endref}}

## 7.1. Fine-Tuning for Classification

> [!TIP]
> इस अनुभाग का लक्ष्य यह दिखाना है कि पहले से प्रशिक्षित मॉडल को कैसे ठीक किया जाए ताकि नए पाठ उत्पन्न करने के बजाय LLM **प्रत्येक दिए गए श्रेणी में वर्गीकृत किए जाने की संभावनाएं** प्रदान करे (जैसे कि कोई पाठ स्पैम है या नहीं)।

{{#ref}}
7.1.-fine-tuning-for-classification.md
{{#endref}}

## 7.2. Fine-Tuning to follow instructions

> [!TIP]
> इस अनुभाग का लक्ष्य यह दिखाना है कि **निर्देशों का पालन करने के लिए पहले से प्रशिक्षित मॉडल को कैसे ठीक किया जाए** न कि केवल पाठ उत्पन्न करने के लिए, उदाहरण के लिए, एक चैट बॉट के रूप में कार्यों का उत्तर देना।

{{#ref}}
7.2.-fine-tuning-to-follow-instructions.md
{{#endref}}
