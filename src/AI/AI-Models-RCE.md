# Models RCE

{{#include ../banners/hacktricks-training.md}}

## RCEへのモデルのロード

機械学習モデルは通常、ONNX、TensorFlow、PyTorchなどの異なる形式で共有されます。これらのモデルは、開発者のマシンや本番システムにロードされて使用されます。通常、モデルには悪意のあるコードが含まれていないはずですが、モデルのロードライブラリの脆弱性や意図された機能として、モデルを使用してシステム上で任意のコードを実行できる場合があります。

執筆時点でのこの種の脆弱性のいくつかの例は以下の通りです：

| **フレームワーク / ツール** | **脆弱性 (CVEが利用可能な場合)**                                                                 | **RCEベクター**                                                                                                                        | **参照**                                   |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *不正なデシリアライズ* `torch.load` **(CVE-2025-32434)**                                                              | モデルチェックポイント内の悪意のあるピクルがコード実行を引き起こす（`weights_only`の保護をバイパス）                                        | |
| PyTorch **TorchServe**      | *ShellTorch* – **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + 悪意のあるモデルダウンロードがコード実行を引き起こす; 管理APIにおけるJavaデシリアライズRCE                                        | |
| **TensorFlow/Keras**        | **CVE-2021-37678** (安全でないYAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | YAMLからモデルをロードすると`yaml.unsafe_load`を使用（コード実行） <br> **Lambda**レイヤーを使用したモデルのロードが任意のPythonコードを実行する          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLiteパース)                                                                                          | 作成された`.tflite`モデルが整数オーバーフローを引き起こし→ヒープ破損（潜在的なRCE）                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | `joblib.load`を介してモデルをロードすると、攻撃者の`__reduce__`ペイロードを持つピクルが実行される                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (安全でない`np.load`) *異議あり*                                                                              | `numpy.load`のデフォルトがピクルオブジェクト配列を許可 – 悪意のある`.npy/.npz`がコード実行を引き起こす                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (ディレクトリトラバーサル) <br> **CVE-2024-5187** (tarトラバーサル)                                                    | ONNXモデルの外部ウェイトパスがディレクトリを脱出できる（任意のファイルを読み取る） <br> 悪意のあるONNXモデルtarが任意のファイルを上書きできる（RCEにつながる） | |
| ONNX Runtime (設計リスク)  | *(CVEなし)* ONNXカスタムオペレーター / 制御フロー                                                                                    | カスタムオペレーターを持つモデルは攻撃者のネイティブコードをロードする必要がある; 複雑なモデルグラフが論理を悪用して意図しない計算を実行する   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (パストラバーサル)                                                                                          | `--model-control`が有効なモデルロードAPIを使用すると、相対パストラバーサルが可能になり、ファイルを書き込むことができる（例：RCEのために`.bashrc`を上書き）    | |
| **GGML (GGUF形式)**      | **CVE-2024-25664 … 25668** (複数のヒープオーバーフロー)                                                                         | 形式が不正なGGUFモデルファイルがパーサー内でヒープバッファオーバーフローを引き起こし、被害者システムでの任意のコード実行を可能にする                     | |
| **Keras (古い形式)**   | *(新しいCVEなし)* レガシーKeras H5モデル                                                                                         | 悪意のあるHDF5（`.h5`）モデルがLambdaレイヤーコードを持ち、ロード時に実行される（Kerasのsafe_modeは古い形式をカバーしていない – “ダウングレード攻撃”） | |
| **その他** (一般)        | *設計上の欠陥* – ピクルシリアライズ                                                                                         | 多くのMLツール（例：ピクルベースのモデル形式、Python `pickle.load`）は、緩和策が講じられない限り、モデルファイルに埋め込まれた任意のコードを実行します | |

さらに、[PyTorch](https://github.com/pytorch/pytorch/security)で使用されるようなPythonピクルベースのモデルは、`weights_only=True`でロードされない場合、システム上で任意のコードを実行するために使用される可能性があります。したがって、上記の表にリストされていなくても、すべてのピクルベースのモデルはこの種の攻撃に特に脆弱である可能性があります。

{{#include ../banners/hacktricks-training.md}}
